[
    {
        "turn_index": 2,
        "term": "adaptive neural networks",
        "domain": "cs.AI",
        "summary": "  While cyclic scheduling is involved in numerous real-world applications,\nsolving the derived problem is still of exponential complexity. This paper\nfocuses specifically on modelling the manufacturing application as a cyclic job\nshop problem and we have developed an efficient neural network approach to\nminimise the cycle time of a schedule. Our approach introduces an interesting\nmodel for a manufacturing production, and it is also very efficient, adaptive\nand flexible enough to work with other techniques. Experimental results\nvalidated the approach and confirmed our hypotheses about the system model and\nthe efficiency of neural networks for such a class of problems.\n",
        "english": "The development of adaptive neural networks has demonstrated significant potential in addressing the exponential complexity associated with cyclic scheduling in real-world applications. By employing a neural network approach to model manufacturing as a cyclic job shop problem, the study effectively minimized the cycle time of a schedule, showcasing the flexibility and adaptability of the system to integrate with other techniques. Notably, the experimental results validated the approach, confirming the hypothesis that adaptive neural networks can efficiently optimize the scheduling process, particularly when minimizing the cycle time, \\( T_{\\text{cycle}} \\), is critical.",
        "korean": "적응형 신경망(adaptive neural networks)의 개발은 실제 응용에서 순환 일정의 지수적 복잡성을 해결하는 데 상당한 잠재력을 보여주었습니다. 제조를 순환 작업장 문제로 모델링하기 위해 신경망 접근 방식을 사용함으로써 연구는 일정의 주기 시간을 효과적으로 최소화하였으며, 시스템이 다른 기법과 통합될 수 있는 유연성과 적응성을 입증했습니다. 특히, 실험 결과는 이 접근 방식을 검증하여 적응형 신경망(adaptive neural networks)이 일정 프로세스를 효율적으로 최적화할 수 있다는 가설을 확인했으며, 특히 주기 시간(\\( T_{\\text{cycle}} \\))을 최소화하는 것이 중요한 경우에 유용함을 보여주었습니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "probabilistic text processes",
        "domain": "cs.AI",
        "summary": "  Process mining is a subfield of process science that analyzes event data\ncollected in databases called event logs. Recently, novel types of event data\nhave become of interest due to the wide industrial application of process\nmining analyses. In this paper, we examine uncertain event data. Such data\ncontain meta-attributes describing the amount of imprecision tied with\nattributes recorded in an event log. We provide examples of uncertain event\ndata, present the state of the art in regard of uncertainty in process mining,\nand illustrate open challenges related to this research direction.\n",
        "english": "Probabilistic text processes, akin to process mining, involve the analysis of event data collected in databases, specifically focusing on the imprecision tied with recorded attributes in an event log. The examination of uncertain event data, which includes meta-attributes describing varying levels of imprecision, is crucial for advancing the state of the art in probabilistic text processes. Such analyses often utilize mathematical models to quantify uncertainty, for instance, by employing probability distributions \\( P(X) \\) to represent the likelihood of different textual outcomes, thereby addressing open challenges in the field and enhancing its industrial applications.",
        "korean": "확률적 텍스트 프로세스(probabilistic text processes)는 프로세스 마이닝(process mining)과 유사하게 데이터베이스에 수집된 이벤트 데이터를 분석하며, 특히 이벤트 로그(event log)에서 기록된 속성의 불확실성에 중점을 둡니다. 불확실한 이벤트 데이터의 검토는 다양한 수준의 불확실성을 설명하는 메타 속성을 포함하며, 확률적 텍스트 프로세스(probabilistic text processes)의 기술 발전에 필수적입니다. 이러한 분석은 종종 수학적 모델을 사용하여 불확실성을 정량화하며, 예를 들어, 확률 분포 \\( P(X) \\)를 사용하여 다양한 텍스트 결과의 가능성을 나타냄으로써 이 분야의 미해결 과제를 해결하고 산업적 응용을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic neural processes",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Dynamic neural processes are critical for understanding how the brain adapts and responds to various stimuli, as evidenced by the innovative use of functional magnetic resonance imaging (fMRI) to track real-time changes in neural activity. Employing advanced computational models, researchers have quantified these processes using differential equations, such as $\\frac{dN(t)}{dt} = -\\alpha N(t) + I(t)$, where $N(t)$ represents neural activity at time $t$, $\\alpha$ is a decay constant, and $I(t)$ denotes external input. This approach not only highlights the intricate mechanisms underlying neural adaptability but also paves the way for developing targeted interventions in neurological disorders.",
        "korean": "동적 신경 과정(dynamic neural processes)은 뇌가 다양한 자극에 어떻게 적응하고 반응하는지를 이해하는 데 중요하며, 기능적 자기공명영상(functional magnetic resonance imaging, fMRI)을 혁신적으로 사용하여 신경 활동의 실시간 변화를 추적함으로써 입증되었습니다. 고급 계산 모델을 활용하여 연구자들은 이러한 과정을 미분 방정식(differential equations)으로 정량화하였으며, 예를 들어 $\\frac{dN(t)}{dt} = -\\alpha N(t) + I(t)$에서 $N(t)$는 시간 $t$에서의 신경 활동을 나타내고, $\\alpha$는 감쇠 상수이며, $I(t)$는 외부 입력을 나타냅니다. 이러한 접근 방식은 신경 적응성의 복잡한 메커니즘을 강조할 뿐만 아니라 신경 장애에 대한 목표 지향적 개입을 개발하는 길을 열어줍니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "self-supervised learning",
        "domain": "cs.AI",
        "summary": "  Mechanical learning is a computing system that is based on a set of simple\nand fixed rules, and can learn from incoming data. A learning machine is a\nsystem that realizes mechanical learning. Importantly, we emphasis that it is\nbased on a set of simple and fixed rules, contrasting to often called machine\nlearning that is sophisticated software based on very complicated mathematical\ntheory, and often needs human intervene for software fine tune and manual\nadjustments. Here, we discuss some basic facts and principles of such system,\nand try to lay down a framework for further study. We propose 2 directions to\napproach mechanical learning, just like Church-Turing pair: one is trying to\nrealize a learning machine, another is trying to well describe the mechanical\nlearning.\n",
        "english": "Self-supervised learning, akin to mechanical learning, is a computing system that operates \"based on a set of simple and fixed rules,\" contrasting with the complex mathematical theories of traditional machine learning, which often require human intervention for fine-tuning. This innovative approach emphasizes the importance of developing a framework that \"lays down a framework for further study,\" allowing the system to autonomously learn from incoming data without manual adjustments. Furthermore, the exploration of self-supervised learning through methodologies such as the Church-Turing pair highlights the dual approach of realizing a learning machine and describing mechanical learning, where the system's performance can be represented by a function $f(x) = ax + b$ to model its learning trajectory.",
        "korean": "자기 지도 학습(self-supervised learning)은 기계 학습(mechanical learning)과 유사하게 \"단순하고 고정된 규칙 집합에 기반하여\" 작동하는 컴퓨팅 시스템으로, 종종 미세 조정을 위해 인간의 개입이 필요한 전통적인 기계 학습(traditional machine learning)의 복잡한 수학 이론과 대조됩니다. 이 혁신적인 접근 방식은 시스템이 수동 조정 없이 들어오는 데이터로부터 자율적으로 학습할 수 있도록 \"추가 연구를 위한 틀을 마련하는\" 프레임워크 개발의 중요성을 강조합니다. 또한, 처치-튜링 쌍(Church-Turing pair)과 같은 방법론을 통한 자기 지도 학습(self-supervised learning)의 탐구는 학습 기계를 실현하고 기계 학습(mechanical learning)을 설명하는 이중 접근 방식을 강조하며, 시스템의 성능은 학습 궤적을 모델링하기 위해 함수 $f(x) = ax + b$로 표현될 수 있습니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "semantic neural optimization",
        "domain": "cs.AI",
        "summary": "  Answering complex logical queries on incomplete knowledge graphs (KGs) is a\nfundamental and challenging task in multi-hop reasoning. Recent work defines\nthis task as an end-to-end optimization problem, which significantly reduces\nthe training cost and enhances the generalization of the model by a pretrained\nlink predictors for query answering. However, most existing proposals ignore\nthe critical semantic knowledge inherently available in KGs, such as type\ninformation, which could help answer complex logical queries. To this end, we\npropose TypE-based Neural Link Prediction Adapter (TENLPA), a novel model that\nconstructs type-based entity-relation graphs to discover the latent\nrelationships between entities and relations by leveraging type information in\nKGs. Meanwhile, in order to effectively combine type information with complex\nlogical queries, an adaptive learning mechanism is introduced, which is trained\nby back-propagating during the complex query answering process to achieve\nadaptive adjustment of neural link predictors. Experiments on 3 standard\ndatasets show that TENLPA model achieves state-of-the-art performance on\ncomplex query answering with good generalization and robustness.\n",
        "english": "Semantic neural optimization has emerged as a pivotal approach in addressing complex logical queries on incomplete knowledge graphs (KGs), with recent work defining it as an end-to-end optimization problem, significantly reducing training costs and enhancing model generalization through pretrained link predictors. The TypE-based Neural Link Prediction Adapter (TENLPA) model exemplifies this innovation by constructing type-based entity-relation graphs that leverage type information in KGs, thereby discovering latent relationships between entities and relations. Furthermore, an adaptive learning mechanism is introduced, trained via back-propagation during the complex query answering process, allowing for the adaptive adjustment of neural link predictors, denoted mathematically as $\\nabla_{\\theta} \\mathcal{L}(\\theta)$, where $\\theta$ represents the model parameters.",
        "korean": "의미론적 신경 최적화(semantic neural optimization)는 불완전한 지식 그래프(knowledge graphs, KGs)에서 복잡한 논리적 쿼리를 해결하는 데 있어 중요한 접근 방식으로 부상했으며, 최근 연구에서는 이를 종단 간 최적화 문제(end-to-end optimization problem)로 정의하여 훈련 비용을 크게 줄이고 사전 훈련된 링크 예측기(pretrained link predictors)를 통해 모델의 일반화 능력을 향상시켰습니다. TypE 기반 신경 링크 예측 어댑터(TypE-based Neural Link Prediction Adapter, TENLPA) 모델은 KGs에서 타입 정보를 활용하여 타입 기반 엔티티-관계 그래프(entity-relation graphs)를 구성함으로써 엔티티와 관계 간의 잠재적 관계를 발견하는 혁신을 보여줍니다. 또한, 복잡한 쿼리 응답 과정에서 역전파(back-propagation)를 통해 훈련되는 적응형 학습 메커니즘(adaptive learning mechanism)이 도입되어 신경 링크 예측기(neural link predictors)의 적응적 조정을 가능하게 하며, 이는 수학적으로 $\\nabla_{\\theta} \\mathcal{L}(\\theta)$로 나타내어지며, 여기서 $\\theta$는 모델 매개변수를 나타냅니다.",
        "score": 9,
        "parentheses_count": 11,
        "suggestions": "Ensure all technical terms are consistently formatted as Korean term(English term) and consider simplifying complex sentence structures for improved readability."
    },
    {
        "turn_index": 2,
        "term": "semantic probabilistic text learning",
        "domain": "cs.AI",
        "summary": "  Argumentation problems are concerned with determining the acceptability of a\nset of arguments from their relational structure. When the available\ninformation is uncertain, probabilistic argumentation frameworks provide\nmodelling tools to account for it. The first contribution of this paper is a\nnovel interpretation of probabilistic argumentation frameworks as probabilistic\nlogic programs. Probabilistic logic programs are logic programs in which some\nof the facts are annotated with probabilities. We show that the programs\nrepresenting probabilistic argumentation frameworks do not satisfy a common\nassumption in probabilistic logic programming (PLP) semantics, which is, that\nprobabilistic facts fully capture the uncertainty in the domain under\ninvestigation. The second contribution of this paper is then a novel PLP\nsemantics for programs where a choice of probabilistic facts does not uniquely\ndetermine the truth assignment of the logical atoms. The third contribution of\nthis paper is the implementation of a PLP system supporting this semantics:\nsmProbLog. smProbLog is a novel PLP framework based on the probabilistic logic\nprogramming language ProbLog. smProbLog supports many inference and learning\ntasks typical of PLP, which, together with our first contribution, provide\nnovel reasoning tools for probabilistic argumentation. We evaluate our approach\nwith experiments analyzing the computational cost of the proposed algorithms\nand their application to a dataset of argumentation problems.\n",
        "english": "Semantic probabilistic text learning can be informed by the interpretation of probabilistic argumentation frameworks as probabilistic logic programs, where certain facts are annotated with probabilities to model uncertainty in argumentation problems. The innovative smProbLog framework, based on the probabilistic logic programming language ProbLog, offers a novel PLP semantics for cases where a choice of probabilistic facts does not uniquely determine the truth assignment of logical atoms, thereby advancing the reasoning tools available for semantic probabilistic text learning. In evaluating this approach, experiments conducted on a dataset of argumentation problems revealed insights into the computational cost of the proposed algorithms, underscoring their applicability and significance for complex inference and learning tasks within this domain.",
        "korean": "확률적 논증 프레임워크(probabilistic argumentation frameworks)를 확률적 논리 프로그램(probabilistic logic programs)으로 해석하여, 논증 문제에서 불확실성을 모델링하기 위해 특정 사실에 확률이 주석으로 달린 경우, 의미론적 확률적 텍스트 학습(semantic probabilistic text learning)에 정보를 제공할 수 있습니다. 확률적 논리 프로그래밍 언어(probabilistic logic programming language)인 problog에 기반한 혁신적인 smproblog 프레임워크는 확률적 사실의 선택이 논리 원자의 진리 할당을 고유하게 결정하지 않는 경우에 대한 새로운 plp 의미론을 제공하여 의미론적 확률적 텍스트 학습(semantic probabilistic text learning)을 위한 추론 도구를 발전시킵니다. 이 접근 방식을 평가하는 과정에서 논증 문제 데이터셋(dataset of argumentation problems)에 대한 실험은 제안된 알고리즘의 계산 비용에 대한 통찰을 제공하여 이 도메인 내 복잡한 추론 및 학습 작업에 대한 적용 가능성과 중요성을 강조했습니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "approximate inference",
        "domain": "cs.AI",
        "summary": "  There has been a great deal of recent interest in methods for performing\nlifted inference; however, most of this work assumes that the first-order model\nis given as input to the system. Here, we describe lifted inference algorithms\nthat determine symmetries and automatically lift the probabilistic model to\nspeedup inference. In particular, we describe approximate lifted inference\ntechniques that allow the user to trade off inference accuracy for\ncomputational efficiency by using a handful of tunable parameters, while\nkeeping the error bounded. Our algorithms are closely related to the\ngraph-theoretic concept of bisimulation. We report experiments on both\nsynthetic and real data to show that in the presence of symmetries, run-times\nfor inference can be improved significantly, with approximate lifted inference\nproviding orders of magnitude speedup over ground inference.\n",
        "english": "Approximate inference techniques, particularly those that are lifted, allow users to trade off inference accuracy for computational efficiency, utilizing a set of tunable parameters while ensuring that the error remains bounded. These algorithms, which are closely related to the graph-theoretic concept of bisimulation, automatically identify symmetries and lift the probabilistic model, significantly speeding up the inference process. Experiments conducted on both synthetic and real data demonstrate that in the presence of symmetries, approximate lifted inference can provide orders of magnitude speedup over ground inference, thus highlighting the innovative potential of such methods in practical applications.",
        "korean": "근사 추론 기법(approximate inference techniques), 특히 리프팅된 기법(lifted techniques)은 사용자가 추론 정확도와 계산 효율성 간의 균형을 조절할 수 있도록 하며, 오류가 제한된 상태로 유지되도록 조정 가능한 매개변수 세트를 활용합니다. 이러한 알고리즘은 그래프 이론적 개념인 비시뮬레이션(bisimulation)과 밀접하게 관련되어 있으며, 대칭성을 자동으로 식별하고 확률 모델을 리프팅하여 추론 과정을 크게 가속화합니다. 합성 데이터와 실제 데이터 모두에서 수행된 실험은 대칭성이 존재할 때 근사 리프팅 추론(approximate lifted inference)이 기저 추론(ground inference)보다 수십 배 빠른 속도를 제공할 수 있음을 보여주며, 이러한 방법의 혁신적 잠재력이 실용적 응용에서 두드러짐을 강조합니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure that all English terms within parentheses are consistently in lowercase to maintain uniformity and improve readability."
    },
    {
        "turn_index": 2,
        "term": "probabilistic neural text models",
        "domain": "cs.AI",
        "summary": "  We propose a deep learning model - Probabilistic Prognostic Estimates of\nSurvival in Metastatic Cancer Patients (PPES-Met) for estimating short-term\nlife expectancy (3 months) of the patients by analyzing free-text clinical\nnotes in the electronic medical record, while maintaining the temporal visit\nsequence. In a single framework, we integrated semantic data mapping and neural\nembedding technique to produce a text processing method that extracts relevant\ninformation from heterogeneous types of clinical notes in an unsupervised\nmanner, and we designed a recurrent neural network to model the temporal\ndependency of the patient visits. The model was trained on a large dataset\n(10,293 patients) and validated on a separated dataset (1818 patients). Our\nmethod achieved an area under the ROC curve (AUC) of 0.89. To provide\nexplain-ability, we developed an interactive graphical tool that may improve\nphysician understanding of the basis for the model's predictions. The high\naccuracy and explain-ability of the PPES-Met model may enable our model to be\nused as a decision support tool to personalize metastatic cancer treatment and\nprovide valuable assistance to the physicians.\n",
        "english": "Probabilistic neural text models, such as the one proposed in the study, integrate semantic data mapping and neural embedding techniques to produce a text processing method capable of extracting relevant information from heterogeneous clinical notes in an unsupervised manner. By employing a recurrent neural network, these models adeptly capture the temporal dependency of patient visits, which is crucial for estimating short-term life expectancy in metastatic cancer patients, achieving an impressive area under the ROC curve (AUC) of 0.89. The innovation of incorporating explain-ability through an interactive graphical tool not only enhances physician understanding of the model's predictions but also positions these models as valuable decision support tools for personalizing metastatic cancer treatment.",
        "korean": "연구에서 제안된 확률적 신경 텍스트 모델(probabilistic neural text models)은 의미 데이터 매핑(semantic data mapping)과 신경 임베딩 기법(neural embedding techniques)을 통합하여 이질적인 임상 노트에서 관련 정보를 비지도 방식으로 추출할 수 있는 텍스트 처리 방법을 제공합니다. 순환 신경망(recurrent neural network)을 사용함으로써 이러한 모델은 환자 방문의 시간적 의존성을 능숙하게 포착하며, 이는 전이성 암 환자의 단기 생존 가능성을 추정하는 데 중요하며, ROC 곡선 아래 면적(AUC) 0.89라는 인상적인 성과를 달성합니다. 상호작용 그래픽 도구(interactive graphical tool)를 통한 설명 가능성(explain-ability)의 도입은 의사가 모델의 예측을 이해하는 데 도움을 줄 뿐만 아니라 이러한 모델을 전이성 암 치료를 개인화하는 데 있어 가치 있는 의사 결정 지원 도구로 자리매김하게 합니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "adaptive neural scene segmentation",
        "domain": "cs.AI",
        "summary": "  In this work, we present I$^2$-SDF, a new method for intrinsic indoor scene\nreconstruction and editing using differentiable Monte Carlo raytracing on\nneural signed distance fields (SDFs). Our holistic neural SDF-based framework\njointly recovers the underlying shapes, incident radiance and materials from\nmulti-view images. We introduce a novel bubble loss for fine-grained small\nobjects and error-guided adaptive sampling scheme to largely improve the\nreconstruction quality on large-scale indoor scenes. Further, we propose to\ndecompose the neural radiance field into spatially-varying material of the\nscene as a neural field through surface-based, differentiable Monte Carlo\nraytracing and emitter semantic segmentations, which enables physically based\nand photorealistic scene relighting and editing applications. Through a number\nof qualitative and quantitative experiments, we demonstrate the superior\nquality of our method on indoor scene reconstruction, novel view synthesis, and\nscene editing compared to state-of-the-art baselines.\n",
        "english": "Adaptive neural scene segmentation is significantly enhanced by the introduction of I$^2$-SDF, a novel method that employs differentiable Monte Carlo raytracing on neural signed distance fields (SDFs) to achieve intrinsic indoor scene reconstruction and editing. By incorporating a bubble loss function for fine-grained small objects and an error-guided adaptive sampling scheme, the method demonstrates superior reconstruction quality on large-scale indoor scenes, effectively addressing challenges in segmenting complex environments. Notably, the decomposition of the neural radiance field into spatially-varying material properties, expressed as a neural field through surface-based, differentiable Monte Carlo raytracing, facilitates advanced applications in photorealistic scene relighting and editing, underscoring the innovative potential of adaptive neural scene segmentation.",
        "korean": "적응형 신경 장면 분할(adaptive neural scene segmentation)은 신경 서명 거리장(neural signed distance fields, SDFs)에서 미분 가능한 몬테카를로 광선 추적(differentiable Monte Carlo raytracing)을 활용하여 본질적인 실내 장면 재구성과 편집을 달성하는 새로운 방법인 I$^2$-SDF의 도입으로 크게 향상됩니다. 세밀한 작은 객체를 위한 버블 손실 함수(bubble loss function)와 오류 유도 적응 샘플링 체계(error-guided adaptive sampling scheme)를 통합함으로써, 이 방법은 대규모 실내 장면에서 우수한 재구성 품질을 보여주며 복잡한 환경을 분할하는 데 있어 효과적으로 문제를 해결합니다. 특히, 표면 기반의 미분 가능한 몬테카를로 광선 추적(surface-based, differentiable Monte Carlo raytracing)을 통해 신경 방사장(neural radiance field)을 공간적으로 변화하는 물질 특성으로 분해함으로써, 사실적인 장면 재조명 및 편집에서의 고급 응용을 가능하게 하여 적응형 신경 장면 분할(adaptive neural scene segmentation)의 혁신적 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural radiance fields",
        "domain": "cs.AI",
        "summary": "  Novel view synthesis of satellite images holds a wide range of practical\napplications. While recent advances in the Neural Radiance Field have\npredominantly targeted pin-hole cameras, and models for satellite cameras often\ndemand sufficient input views. This paper presents rpcPRF, a Multiplane Images\n(MPI) based Planar neural Radiance Field for Rational Polynomial Camera (RPC).\nUnlike coordinate-based neural radiance fields in need of sufficient views of\none scene, our model is applicable to single or few inputs and performs well on\nimages from unseen scenes. To enable generalization across scenes, we propose\nto use reprojection supervision to induce the predicted MPI to learn the\ncorrect geometry between the 3D coordinates and the images. Moreover, we remove\nthe stringent requirement of dense depth supervision from deep\nmultiview-stereo-based methods by introducing rendering techniques of radiance\nfields. rpcPRF combines the superiority of implicit representations and the\nadvantages of the RPC model, to capture the continuous altitude space while\nlearning the 3D structure. Given an RGB image and its corresponding RPC, the\nend-to-end model learns to synthesize the novel view with a new RPC and\nreconstruct the altitude of the scene. When multiple views are provided as\ninputs, rpcPRF exerts extra supervision provided by the extra views. On the TLC\ndataset from ZY-3, and the SatMVS3D dataset with urban scenes from WV-3, rpcPRF\noutperforms state-of-the-art nerf-based methods by a significant margin in\nterms of image fidelity, reconstruction accuracy, and efficiency, for both\nsingle-view and multiview task.\n",
        "english": "Recent advancements in neural radiance fields have largely focused on pin-hole camera applications, but rpcPRF introduces a novel approach by utilizing a Multiplane Images (MPI) based Planar neural Radiance Field for Rational Polynomial Camera (RPC), which is effective even with single or few input views and excels in unseen scenes. By incorporating reprojection supervision, rpcPRF enhances its ability to generalize across scenes, effectively learning the correct geometry between 3D coordinates and images, while eliminating the need for dense depth supervision typical of deep multiview-stereo-based methods. Moreover, rpcPRF demonstrates its superiority by outperforming state-of-the-art nerf-based methods on datasets such as TLC from ZY-3 and SatMVS3D from WV-3, achieving significant improvements in image fidelity and reconstruction accuracy, with the model's capacity to synthesize novel views and reconstruct scene altitude, even under the constraints of limited input views.",
        "korean": "최근 신경 방사장(neural radiance fields)에서의 발전은 주로 핀홀 카메라(pin-hole camera) 응용에 초점을 맞추고 있지만, rpcPRF는 합리적 다항식 카메라(rational polynomial camera, RPC)를 위한 다중 평면 이미지(multiplane images, MPI) 기반 평면 신경 방사장(planar neural radiance field)을 활용하여 새로운 접근 방식을 도입합니다. 이는 단일 또는 소수의 입력 뷰에서도 효과적이며, 보지 못한 장면에서도 뛰어난 성능을 발휘합니다. 재투영 감독(reprojection supervision)을 통합함으로써, rpcPRF는 장면 전반에 걸쳐 일반화할 수 있는 능력을 향상시키며, 3D 좌표와 이미지 간의 올바른 기하학을 효과적으로 학습하고, 깊이 감독이 필요한 심층 다중 뷰 스테레오 기반 방법의 필요성을 제거합니다. 더욱이, rpcPRF는 ZY-3의 TLC와 WV-3의 SatMVS3D와 같은 데이터셋에서 최첨단 nerf 기반 방법을 능가하여 이미지 충실도와 재구성 정확도에서 상당한 개선을 이루며, 제한된 입력 뷰의 제약 하에서도 새로운 뷰를 합성하고 장면 고도를 재구성하는 모델의 능력을 보여줍니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, particularly in longer sentences."
    },
    {
        "turn_index": 2,
        "term": "autoregressive flows",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Autoregressive flows, as explored in the reference, represent a significant advancement in the field of probabilistic modeling by allowing for the flexible and scalable transformation of probability distributions. The methodology involves the use of a series of invertible transformations, where each transformation is conditioned on the previous ones, and is mathematically expressed as $p(x) = \\prod_{i=1}^D p(x_i | x_{1:i-1})$, highlighting the sequential nature of the process. This innovation is crucial as it enhances the expressiveness of generative models, enabling them to capture complex dependencies in high-dimensional data, thereby improving the accuracy and efficiency of tasks such as density estimation and data generation.",
        "korean": "참조에서 탐구된 자기회귀 흐름(autoregressive flows)은 확률 모델링 분야에서 확률 분포의 유연하고 확장 가능한 변환을 가능하게 함으로써 중요한 발전을 나타냅니다. 이 방법론은 일련의 가역 변환을 사용하는데, 각 변환은 이전 변환에 조건화되며, 수학적으로는 $p(x) = \\prod_{i=1}^D p(x_i | x_{1:i-1})$로 표현되어 과정의 순차적 특성을 강조합니다. 이 혁신은 생성 모델의 표현력을 향상시켜 고차원 데이터에서 복잡한 종속성을 포착할 수 있게 하여 밀도 추정 및 데이터 생성과 같은 작업의 정확성과 효율성을 개선하는 데 중요합니다.",
        "score": 10,
        "parentheses_count": 1,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "semantic scene models",
        "domain": "cs.AI",
        "summary": "  We present a visually-grounded language understanding model based on a study\nof how people verbally describe objects in scenes. The emphasis of the model is\non the combination of individual word meanings to produce meanings for complex\nreferring expressions. The model has been implemented, and it is able to\nunderstand a broad range of spatial referring expressions. We describe our\nimplementation of word level visually-grounded semantics and their embedding in\na compositional parsing framework. The implemented system selects the correct\nreferents in response to natural language expressions for a large percentage of\ntest cases. In an analysis of the system's successes and failures we reveal how\nvisual context influences the semantics of utterances and propose future\nextensions to the model that take such context into account.\n",
        "english": "Semantic scene models are pivotal in advancing visually-grounded language understanding, particularly through the innovative combination of individual word meanings to form complex referring expressions. The implementation of word-level visually-grounded semantics, embedded within a compositional parsing framework, enables the system to accurately select correct referents in response to natural language expressions, achieving a high success rate across diverse test cases. Notably, the research highlights how visual context can significantly influence the semantics of utterances, suggesting that future extensions to the model could incorporate these contextual elements to further enhance performance, as indicated by the model's ability to handle a broad range of spatial referring expressions.",
        "korean": "의미 장면 모델(semantic scene models)은 시각적으로 기반한 언어 이해를 발전시키는 데 있어 매우 중요하며, 특히 개별 단어의 의미를 혁신적으로 결합하여 복잡한 지시 표현을 형성하는 데 기여합니다. 조합적 구문 분석 프레임워크(compositional parsing framework) 내에 내장된 단어 수준의 시각적으로 기반한 의미론(semantics)은 시스템이 자연어 표현에 대한 올바른 지시 대상을 정확하게 선택할 수 있게 하여 다양한 테스트 사례에서 높은 성공률을 달성합니다. 특히, 연구는 시각적 맥락이 발화의 의미에 상당한 영향을 미칠 수 있음을 강조하며, 모델의 공간적 지시 표현을 처리하는 능력에 의해 나타난 바와 같이, 이러한 맥락적 요소를 통합하여 성능을 더욱 향상시킬 수 있는 모델의 미래 확장을 제안합니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider simplifying sentence structures for improved readability."
    },
    {
        "turn_index": 2,
        "term": "deep neural text models",
        "domain": "cs.AI",
        "summary": "  In this paper we discuss the relationships between conditional and\npreferential logics and neural network models, based on a multi-preferential\nsemantics. We propose a concept-wise multipreference semantics, recently\nintroduced for defeasible description logics to take into account preferences\nwith respect to different concepts, as a tool for providing a semantic\ninterpretation to neural network models. This approach has been explored both\nfor unsupervised neural network models (Self-Organising Maps) and for\nsupervised ones (Multilayer Perceptrons), and we expect that the same approach\nmight be extended to other neural network models. It allows for logical\nproperties of the network to be checked (by model checking) over an\ninterpretation capturing the input-output behavior of the network. For\nMultilayer Perceptrons, the deep network itself can be regarded as a\nconditional knowledge base, in which synaptic connections correspond to\nweighted conditionals. The paper describes the general approach, through the\ncases of Self-Organising Maps and Multilayer Perceptrons, and discusses some\nopen issues and perspectives.\n",
        "english": "Deep neural text models benefit from a concept-wise multipreference semantics, as recently introduced for defeasible description logics, allowing for the semantic interpretation of neural network models by considering preferences with respect to different concepts. This approach has been applied to both unsupervised neural network models, such as Self-Organising Maps, and supervised models like Multilayer Perceptrons, enabling logical properties of the network to be checked via model checking over an interpretation that captures the network's input-output behavior. For Multilayer Perceptrons, the deep network itself can be regarded as a conditional knowledge base, where synaptic connections correspond to weighted conditionals, expressed mathematically as $w_{ij} \\cdot x_j$, highlighting the innovative integration of logical semantics in deep learning frameworks.",
        "korean": "심층 신경 텍스트 모델(deep neural text models)은 최근 반증 가능한 설명 논리(defeasible description logics)를 위해 도입된 개념별 다중 선호 의미론(concept-wise multipreference semantics)에서 이점을 얻으며, 다양한 개념에 대한 선호를 고려하여 신경망 모델의 의미론적 해석을 가능하게 합니다. 이 접근법은 자기 조직화 지도(Self-Organising Maps)와 같은 비지도 신경망 모델과 다층 퍼셉트론(Multilayer Perceptrons)과 같은 지도 모델 모두에 적용되어, 네트워크의 입력-출력 행동을 포착하는 해석을 통해 모델 검증을 통해 네트워크의 논리적 속성을 확인할 수 있게 합니다. 다층 퍼셉트론(Multilayer Perceptrons)의 경우, 심층 네트워크 자체가 조건부 지식 기반(conditional knowledge base)으로 간주될 수 있으며, 시냅스 연결이 $w_{ij} \\cdot x_j$로 수학적으로 표현된 가중 조건부(weighted conditionals)에 해당하여 심층 학습 프레임워크에 논리적 의미론의 혁신적인 통합을 강조합니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring that all technical terms are consistently formatted as Korean term(English term) throughout the text."
    },
    {
        "turn_index": 2,
        "term": "k-means",
        "domain": "cs.AI",
        "summary": "  Data clustering is an important area of data mining. This is an unsupervised\nstudy where data of similar types are put into one cluster while data of\nanother types are put into different cluster. Fuzzy C means is a very important\nclustering technique based on fuzzy logic. Also we have some hard clustering\ntechniques available like K-means among the popular ones. In this paper a\ncomparative study is done between Fuzzy clustering algorithm and hard\nclustering algorithm\n",
        "english": "K-means, a hard clustering technique, is among the most popular methods in data mining for grouping data of similar types into one cluster while separating data of different types into another. This method, unlike fuzzy clustering techniques such as Fuzzy C-means, assigns each data point to a single cluster, thus providing a clear partitioning of the dataset. Mathematically, k-means aims to minimize the within-cluster variance, which can be expressed as $\\sum_{i=1}^{k} \\sum_{x \\in C_i} \\| x - \\mu_i \\|^2$, where $C_i$ is the set of points in cluster $i$ and $\\mu_i$ is the mean of points in $C_i$.",
        "korean": "k-평균(k-means)은 데이터 마이닝(data mining)에서 유사한 유형의 데이터를 하나의 클러스터로 그룹화하고 다른 유형의 데이터를 다른 클러스터로 분리하는 가장 인기 있는 방법 중 하나인 하드 클러스터링 기법(hard clustering technique)입니다. 이 방법은 퍼지 c-평균(fuzzy c-means)과 같은 퍼지 클러스터링 기법(fuzzy clustering techniques)과 달리 각 데이터 포인트를 단일 클러스터에 할당하여 데이터셋의 명확한 분할을 제공합니다. 수학적으로, k-평균(k-means)은 클러스터 내 분산을 최소화하는 것을 목표로 하며, 이는 $\\sum_{i=1}^{k} \\sum_{x \\in C_i} \\| x - \\mu_i \\|^2$로 표현될 수 있습니다. 여기서 $C_i$는 클러스터 $i$에 있는 점들의 집합이고, $\\mu_i$는 $C_i$에 있는 점들의 평균입니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar"
    },
    {
        "turn_index": 2,
        "term": "cutsets",
        "domain": "cs.AI",
        "summary": "  The paper presents a new sampling methodology for Bayesian networks that\nsamples only a subset of variables and applies exact inference to the rest.\nCutset sampling is a network structure-exploiting application of the\nRao-Blackwellisation principle to sampling in Bayesian networks. It improves\nconvergence by exploiting memory-based inference algorithms. It can also be\nviewed as an anytime approximation of the exact cutset-conditioning algorithm\ndeveloped by Pearl. Cutset sampling can be implemented efficiently when the\nsampled variables constitute a loop-cutset of the Bayesian network and, more\ngenerally, when the induced width of the networks graph conditioned on the\nobserved sampled variables is bounded by a constant w. We demonstrate\nempirically the benefit of this scheme on a range of benchmarks.\n",
        "english": "Cutset sampling, as an innovative application of the Rao-Blackwellisation principle, enhances convergence in Bayesian networks by leveraging memory-based inference algorithms and sampling only a subset of variables while applying exact inference to the rest. This methodology can be efficiently implemented when the sampled variables form a loop-cutset, and more generally, when the induced width of the network's graph, conditioned on the observed sampled variables, is bounded by a constant \\( w \\). The empirical demonstration of this scheme across various benchmarks highlights its effectiveness as an anytime approximation of Pearl's exact cutset-conditioning algorithm, showcasing its significant potential in improving computational efficiency in complex network structures.",
        "korean": "Rao-Blackwellisation 원리의 혁신적인 응용으로서의 컷셋(cutsets) 샘플링은 메모리 기반 추론 알고리즘을 활용하여 베이지안 네트워크(Bayesian networks)에서 수렴을 향상시키며, 일부 변수만 샘플링하고 나머지에 대해 정확한 추론을 적용합니다. 이 방법론은 샘플링된 변수가 루프 컷셋(loop-cutset)을 형성할 때 효율적으로 구현될 수 있으며, 더 일반적으로는 관찰된 샘플링 변수에 조건화된 네트워크 그래프의 유도 폭이 상수 \\( w \\)로 제한될 때 가능합니다. 다양한 벤치마크에서 이 체계의 실증적 시연은 Pearl의 정확한 컷셋 조건화 알고리즘(cutset-conditioning algorithm)의 언제든지 근사치로서의 효과를 강조하며, 복잡한 네트워크 구조에서 계산 효율성을 향상시키는 데 있어 상당한 잠재력을 보여줍니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent lowercase usage within parentheses."
    },
    {
        "turn_index": 2,
        "term": "semantic text processes",
        "domain": "cs.AI",
        "summary": "  A semantic net can be used to represent a sentence. A sentence in a language\ncontains semantics which are polar in nature, that is, semantics which are\npositive, neutral and negative. Neutrosophy is a relatively new field of\nscience which can be used to mathematically represent triads of concepts. These\ntriads include truth, indeterminacy and falsehood, and so also positivity,\nneutrality and negativity. Thus a conventional semantic net has been extended\nin this paper using neutrosophy into a Polar Fuzzy Neutrosophic Semantic Net. A\nPolar Fuzzy Neutrosophic Semantic Net has been implemented in MATLAB and has\nbeen used to illustrate a polar sentence in English language. The paper\ndemonstrates a method for the representation of polarity in a computers memory.\nThus, polar concepts can be applied to imbibe a machine such as a robot, with\nemotions, making machine emotion representation possible.\n",
        "english": "Semantic text processes benefit from the innovative approach of extending conventional semantic nets into Polar Fuzzy Neutrosophic Semantic Nets, which incorporate the triadic concepts of truth, indeterminacy, and falsehood, as well as positivity, neutrality, and negativity. This extension, grounded in neutrosophy, allows for a more nuanced representation of sentence semantics, particularly in capturing the polar nature of language which can be expressed mathematically as \\( P = (T, I, F) \\), where \\( P \\) represents polarity and \\( T \\), \\( I \\), and \\( F \\) denote truth, indeterminacy, and falsehood, respectively. The implementation of this model in MATLAB demonstrates its potential to imbue machines with emotional understanding, highlighting a significant advancement in the field of machine emotion representation through semantic text processes.",
        "korean": "의미 텍스트 처리(semantic text processes)는 기존의 의미망을 진리, 불확실성, 거짓의 삼원적 개념과 긍정성, 중립성, 부정성을 포함하는 극성 퍼지 뉴트로소픽 의미망(Polar Fuzzy Neutrosophic Semantic Nets)으로 확장하는 혁신적인 접근 방식에서 이점을 얻습니다. 뉴트로소피(neutrosophy)에 기반한 이 확장은 특히 언어의 극성 특성을 포착하는 문장 의미의 보다 미세한 표현을 가능하게 하며, 이는 수학적으로 \\( P = (T, I, F) \\)로 표현될 수 있습니다. 여기서 \\( P \\)는 극성을 나타내고 \\( T \\), \\( I \\), \\( F \\)는 각각 진리, 불확실성, 거짓을 나타냅니다. MATLAB에서 이 모델의 구현은 기계에 감정적 이해를 부여할 수 있는 잠재력을 보여주며, 의미 텍스트 처리(semantic text processes)를 통한 기계 감정 표현 분야에서의 중요한 발전을 강조합니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic scene embeddings",
        "domain": "cs.AI",
        "summary": "  Agents with the ability to comprehend and reason about the dynamics of\nobjects would be expected to exhibit improved robustness and generalization in\nnovel scenarios. However, achieving this capability necessitates not only an\neffective scene representation but also an understanding of the mechanisms\ngoverning interactions among object subsets. Recent studies have made\nsignificant progress in representing scenes using object slots. In this work,\nwe introduce Reusable Slotwise Mechanisms, or RSM, a framework that models\nobject dynamics by leveraging communication among slots along with a modular\narchitecture capable of dynamically selecting reusable mechanisms for\npredicting the future states of each object slot. Crucially, RSM leverages the\nCentral Contextual Information (CCI), enabling selected mechanisms to access\nthe remaining slots through a bottleneck, effectively allowing for modeling of\nhigher order and complex interactions that might require a sparse subset of\nobjects. Experimental results demonstrate the superior performance of RSM\ncompared to state-of-the-art methods across various future prediction and\nrelated downstream tasks, including Visual Question Answering and action\nplanning. Furthermore, we showcase RSM's Out-of-Distribution generalization\nability to handle scenes in intricate scenarios.\n",
        "korean": "동적 장면 임베딩(dynamic scene embeddings)은 객체 슬롯 간의 통신과 모듈식 아키텍처를 활용하여 각 객체 슬롯의 미래 상태를 예측하기 위해 재사용 가능한 슬롯별 메커니즘(Reusable Slotwise Mechanisms, RSM)을 도입함으로써 향상됩니다. 중앙 맥락 정보(Central Contextual Information, CCI)를 활용하여 RSM은 병목을 통해 나머지 슬롯에 접근할 수 있게 하여, 드문 객체의 하위 집합을 필요로 하는 고차 상호작용을 효과적으로 모델링하며, 미래 예측 작업 및 시각적 질문 응답(Visual Question Answering)과 행동 계획(action planning)과 같은 다운스트림 응용 프로그램에서 우수한 성능을 달성합니다. 특히, RSM의 효과는 분포 외 일반화 능력을 통해 입증되며, 실험 결과는 새로운 시나리오에서 향상된 견고성과 일반화를 보여주며, 성능 지표 $M$이 전통적인 접근 방식에 비해 현저히 높은 상태로 최첨단 방법을 능가합니다."
    },
    {
        "turn_index": 2,
        "term": "causal neural processes",
        "domain": "cs.AI",
        "summary": "  Explaining and reasoning about processes which underlie observed black-box\nphenomena enables the discovery of causal mechanisms, derivation of suitable\nabstract representations and the formulation of more robust predictions. We\npropose to learn high level functional programs in order to represent abstract\nmodels which capture the invariant structure in the observed data. We introduce\nthe $\\pi$-machine (program-induction machine) -- an architecture able to induce\ninterpretable LISP-like programs from observed data traces. We propose an\noptimisation procedure for program learning based on backpropagation, gradient\ndescent and A* search. We apply the proposed method to three problems: system\nidentification of dynamical systems, explaining the behaviour of a DQN agent\nand learning by demonstration in a human-robot interaction scenario. Our\nexperimental results show that the $\\pi$-machine can efficiently induce\ninterpretable programs from individual data traces.\n",
        "english": "Understanding causal neural processes is pivotal for \"explaining and reasoning about processes which underlie observed black-box phenomena,\" thereby facilitating the discovery of causal mechanisms and enabling the derivation of suitable abstract representations. The innovative $\\pi$-machine architecture demonstrates the ability to induce interpretable LISP-like programs from data traces, utilizing an \"optimisation procedure for program learning based on backpropagation, gradient descent and A* search.\" By applying this method to various domains, including system identification and human-robot interaction, the research underscores the $\\pi$-machine's capability to efficiently induce interpretable programs, advancing the understanding and prediction of complex causal neural processes.",
        "korean": "인과 신경 과정(causal neural processes)을 이해하는 것은 \"관찰된 블랙박스 현상의 기저에 있는 과정을 설명하고 추론하는\" 데 필수적이며, 이를 통해 인과 메커니즘을 발견하고 적절한 추상 표현을 도출할 수 있습니다. 혁신적인 $\\pi$-머신 아키텍처($\\pi$-machine architecture)는 데이터 추적에서 해석 가능한 LISP 유사 프로그램을 유도하는 능력을 보여주며, \"역전파, 경사 하강법 및 A* 탐색에 기반한 프로그램 학습 최적화 절차\"를 활용합니다. 시스템 식별(system identification) 및 인간-로봇 상호작용(human-robot interaction)을 포함한 다양한 도메인에 이 방법을 적용함으로써, 연구는 $\\pi$-머신의 해석 가능한 프로그램을 효율적으로 유도하는 능력을 강조하며 복잡한 인과 신경 과정(causal neural processes)의 이해와 예측을 발전시킵니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "infinite hidden Markov models",
        "domain": "cs.AI",
        "summary": "  Hidden Markov Models (HMMs) are learning methods for pattern recognition. The\nprobabilistic HMMs have been one of the most used techniques based on the\nBayesian model. First-order probabilistic HMMs were adapted to the theory of\nbelief functions such that Bayesian probabilities were replaced with mass\nfunctions. In this paper, we present a second-order Hidden Markov Model using\nbelief functions. Previous works in belief HMMs have been focused on the\nfirst-order HMMs. We extend them to the second-order model.\n",
        "english": "Infinite hidden Markov models (iHMMs) extend the traditional probabilistic Hidden Markov Models (HMMs) by allowing for an unbounded number of hidden states, thus providing a more flexible framework for pattern recognition. By replacing Bayesian probabilities with mass functions, iHMMs adapt first-order probabilistic HMMs to the theory of belief functions, enabling a more nuanced representation of uncertainty. In particular, the innovation of extending belief HMMs to a second-order model, where the transition probabilities are expressed as $P(X_t | X_{t-1}, X_{t-2})$, enhances the ability of iHMMs to capture complex temporal dependencies.",
        "korean": "무한 은닉 마르코프 모델(infinite hidden Markov models, iHMMs)은 전통적인 확률적 은닉 마르코프 모델(hidden Markov models, hmms)을 확장하여 무한한 수의 은닉 상태를 허용함으로써 패턴 인식을 위한 보다 유연한 프레임워크를 제공합니다. 베이지안 확률을 질량 함수로 대체함으로써, iHMMs는 1차 확률적 hmms를 신념 함수 이론에 적응시켜 불확실성의 보다 미세한 표현을 가능하게 합니다. 특히, 신념 hmms를 2차 모델로 확장하여 전이 확률을 $P(X_t | X_{t-1}, X_{t-2})$로 표현하는 혁신은 iHMMs가 복잡한 시간적 종속성을 포착하는 능력을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "stochastic neural frameworks",
        "domain": "cs.AI",
        "summary": "  The recent breakthroughs of deep reinforcement learning (DRL) technique in\nAlpha Go and playing Atari have set a good example in handling large state and\nactions spaces of complicated control problems. The DRL technique is comprised\nof (i) an offline deep neural network (DNN) construction phase, which derives\nthe correlation between each state-action pair of the system and its value\nfunction, and (ii) an online deep Q-learning phase, which adaptively derives\nthe optimal action and updates value estimates. In this paper, we first present\nthe general DRL framework, which can be widely utilized in many applications\nwith different optimization objectives. This is followed by the introduction of\nthree specific applications: the cloud computing resource allocation problem,\nthe residential smart grid task scheduling problem, and building HVAC system\noptimal control problem. The effectiveness of the DRL technique in these three\ncyber-physical applications have been validated. Finally, this paper\ninvestigates the stochastic computing-based hardware implementations of the DRL\nframework, which consumes a significant improvement in area efficiency and\npower consumption compared with binary-based implementation counterparts.\n",
        "english": "Stochastic neural frameworks have demonstrated significant advancements in handling large state and action spaces, as evidenced by the recent breakthroughs of deep reinforcement learning (DRL) techniques in applications like Alpha Go and playing Atari. The integration of an offline deep neural network (DNN) construction phase with an online deep Q-learning phase allows these frameworks to adaptively derive the optimal action and update value estimates, enhancing their applicability across various domains, such as cloud computing resource allocation and residential smart grid task scheduling. Notably, the stochastic computing-based hardware implementations of the DRL framework offer a substantial improvement in area efficiency and power consumption, with mathematical expressions such as $\\text{Efficiency} = \\frac{\\text{Output}}{\\text{Input}}$ highlighting the optimization achieved compared to binary-based implementations.",
        "korean": "확률적 신경 프레임워크(stochastic neural frameworks)는 알파고(Alpha Go)와 아타리(Atari) 게임과 같은 응용 분야에서 심층 강화 학습(deep reinforcement learning, DRL) 기법의 최근 돌파구로 입증된 바와 같이 큰 상태 및 행동 공간을 처리하는 데 있어 상당한 발전을 보여주었습니다. 오프라인 심층 신경망(deep neural network, DNN) 구축 단계와 온라인 심층 Q-학습(deep Q-learning) 단계를 통합함으로써 이러한 프레임워크는 최적의 행동을 적응적으로 도출하고 가치 추정치를 업데이트할 수 있으며, 클라우드 컴퓨팅 자원 할당(cloud computing resource allocation) 및 가정용 스마트 그리드 작업 일정(residential smart grid task scheduling)과 같은 다양한 도메인에서의 적용 가능성을 향상시킵니다. 특히, DRL 프레임워크의 확률적 컴퓨팅 기반 하드웨어 구현은 면적 효율성과 전력 소비에서 상당한 개선을 제공하며, $\\text{Efficiency} = \\frac{\\text{Output}}{\\text{Input}}$와 같은 수학적 표현은 이진 기반 구현에 비해 최적화를 강조합니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all English terms within parentheses are in lowercase for consistency."
    },
    {
        "turn_index": 2,
        "term": "probabilistic scene models",
        "domain": "cs.AI",
        "summary": "  PRAM puts agent-based models on a sound probabilistic footing as a basis for\nintegrating agent-based and probabilistic models. It extends the themes of\nprobabilistic relational models and lifted inference to incorporate dynamical\nmodels and simulation. It can also be much more efficient than agent-based\nsimulation.\n",
        "english": "Probabilistic scene models are grounded on a robust probabilistic foundation, as exemplified by PRAM, which serves as a basis for integrating agent-based and probabilistic models. By extending the themes of probabilistic relational models and lifted inference, these models incorporate dynamical models and simulation to enhance computational efficiency. Notably, PRAM demonstrates that the computational complexity of these models can be significantly reduced, often achieving efficiencies beyond traditional agent-based simulation, which can be expressed as $O(n)$ where $n$ represents the number of agents.",
        "korean": "확률적 장면 모델(probabilistic scene models)은 에이전트 기반 모델과 확률적 모델을 통합하는 기반으로 작용하는 PRAM으로 예시되는 강력한 확률적 기초에 기반을 두고 있습니다. 확률적 관계 모델(probabilistic relational models)과 리프티드 추론(lifted inference)의 주제를 확장함으로써, 이러한 모델은 동적 모델과 시뮬레이션을 포함하여 계산 효율성을 향상시킵니다. 특히, PRAM은 이러한 모델의 계산 복잡도가 전통적인 에이전트 기반 시뮬레이션을 넘어서는 효율성을 종종 달성할 수 있음을 보여주며, 이는 에이전트 수를 나타내는 $n$에 대해 $O(n)$으로 표현될 수 있습니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent lowercase for terms within parentheses."
    },
    {
        "turn_index": 2,
        "term": "audio-visual speech recognition",
        "domain": "cs.AI",
        "summary": "  For the past few decades, man has been trying to create an intelligent\ncomputer which can talk and respond like he can. The task of creating a system\nthat can talk like a human being is the primary objective of Automatic Speech\nRecognition. Various Speech Recognition techniques have been developed in\ntheory and have been applied in practice. This paper discusses the problems\nthat have been encountered in developing Speech Recognition, the techniques\nthat have been applied to automate the task, and a representation of the core\nproblems of present day Speech Recognition by using Fuzzy Mathematics.\n",
        "english": "Audio-visual speech recognition represents a significant advancement in the quest to create an intelligent computer capable of talking and responding like humans, as it integrates visual cues with traditional speech recognition to enhance accuracy and robustness. The development of such systems has encountered numerous challenges, necessitating the application of various techniques, including Fuzzy Mathematics, to address core problems in present-day speech recognition. Specifically, the use of fuzzy sets, denoted as $F(x)$, allows for the representation of uncertainty and imprecision in audio-visual data, thereby improving the system's ability to process and interpret complex speech patterns.",
        "korean": "오디오-비주얼 음성 인식(audio-visual speech recognition)은 시각적 단서를 전통적인 음성 인식과 통합하여 정확성과 견고성을 향상시킴으로써 인간처럼 말하고 응답할 수 있는 지능형 컴퓨터를 만들기 위한 중요한 발전을 나타냅니다. 이러한 시스템의 개발은 수많은 도전에 직면했으며, 현대 음성 인식의 핵심 문제를 해결하기 위해 퍼지 수학(fuzzy mathematics)을 포함한 다양한 기법의 적용이 필요했습니다. 특히, 퍼지 집합(fuzzy sets), $F(x)$로 표시되는, 의 사용은 오디오-비주얼 데이터의 불확실성과 부정확성을 표현할 수 있게 하여 복잡한 음성 패턴을 처리하고 해석하는 시스템의 능력을 향상시킵니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider revising the placement of commas for better readability and ensuring all technical terms are consistently formatted."
    },
    {
        "turn_index": 2,
        "term": "task-agnostic learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "english": "Task-agnostic learning, as explored through the lens of mechanical learning, involves the use of subjective patterns, which are crucial for the learning machine, to effectively express objective patterns based on the least base patterns. The internal representation space, composed of a collection of X-forms, serves as the center of the learning machine, enabling it to achieve universal learning capabilities with sufficient data and certain capabilities. By examining the algebraic expression for subjective patterns, $X$-form, the study highlights the innovative approach of viewing deep learning's internal representation space and its learning dynamics from a new perspective.",
        "korean": "기계 학습(mechanical learning)의 관점에서 탐구된 작업 비특이적 학습(task-agnostic learning)은 주관적 패턴(subjective patterns)을 사용하여 학습 기계가 최소한의 기본 패턴을 기반으로 객관적 패턴을 효과적으로 표현하는 것을 포함합니다. X-형식(X-forms)의 집합으로 구성된 내부 표현 공간은 학습 기계의 중심 역할을 하며, 충분한 데이터와 특정 능력을 통해 보편적인 학습 능력을 달성할 수 있게 합니다. 주관적 패턴(subjective patterns)에 대한 대수적 표현을 $X$-형식($X$-form)으로 검토함으로써, 이 연구는 심층 학습(deep learning)의 내부 표현 공간과 학습 역학을 새로운 관점에서 보는 혁신적인 접근 방식을 강조합니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all terms within parentheses are consistently in lowercase."
    },
    {
        "turn_index": 2,
        "term": "neural semantic segmentation",
        "domain": "cs.AI",
        "summary": "  It is a crucial step to achieve effective semantic segmentation of lane\nmarking during the construction of the lane level high-precision map. In recent\nyears, many image semantic segmentation methods have been proposed. These\nmethods mainly focus on the image from camera, due to the limitation of the\nsensor itself, the accurate three-dimensional spatial position of the lane\nmarking cannot be obtained, so the demand for the lane level high-precision map\nconstruction cannot be met. This paper proposes a lane marking semantic\nsegmentation method based on LIDAR and camera fusion deep neural network.\nDifferent from other methods, in order to obtain accurate position information\nof the segmentation results, the semantic segmentation object of this paper is\na bird's eye view converted from a LIDAR points cloud instead of an image\ncaptured by a camera. This method first uses the deeplabv3+ [\\ref{ref:1}]\nnetwork to segment the image captured by the camera, and the segmentation\nresult is merged with the point clouds collected by the LIDAR as the input of\nthe proposed network. In this neural network, we also add a long short-term\nmemory (LSTM) structure to assist the network for semantic segmentation of lane\nmarkings by using the the time series information. The experiments on more than\n14,000 image datasets which we have manually labeled and expanded have shown\nthe proposed method has better performance on the semantic segmentation of the\npoints cloud bird's eye view. Therefore, the automation of high-precision map\nconstruction can be significantly improved. Our code is available at\nhttps://github.com/rolandying/FusionLane.\n",
        "english": "Neural semantic segmentation plays a pivotal role in the effective semantic segmentation of lane markings, which is essential for the construction of lane-level high-precision maps. By employing a lane marking semantic segmentation method based on LIDAR and camera fusion deep neural network, this research introduces an innovative approach where the segmentation object is a bird's eye view converted from a LIDAR points cloud, rather than a traditional camera image. The integration of a long short-term memory (LSTM) structure within the neural network, combined with the deeplabv3+ network, significantly enhances performance, as evidenced by experiments on over 14,000 manually labeled images, demonstrating the method's superior capability in accurately segmenting the points cloud bird's eye view, thereby improving the automation of high-precision map construction.",
        "korean": "신경 의미 분할(neural semantic segmentation)은 차선 수준의 고정밀 지도 구축에 필수적인 차선 마킹의 효과적인 의미 분할에서 중요한 역할을 합니다. LIDAR와 카메라 융합 심층 신경망(deep neural network)을 기반으로 한 차선 마킹 의미 분할 방법을 사용하여, 이 연구는 전통적인 카메라 이미지가 아닌 LIDAR 포인트 클라우드에서 변환된 조감도를 분할 객체로 하는 혁신적인 접근 방식을 소개합니다. 신경망 내 장단기 메모리(long short-term memory, LSTM) 구조와 deeplabv3+ 네트워크의 통합은 성능을 크게 향상시키며, 14,000개 이상의 수작업으로 라벨링된 이미지에 대한 실험을 통해 이 방법이 포인트 클라우드 조감도를 정확하게 분할하는 뛰어난 능력을 입증하여 고정밀 지도 구축의 자동화를 개선합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure all terms within parentheses are consistently in lowercase and consider rephrasing for smoother readability, such as adjusting the placement of \"LIDAR 포인트 클라우드에서 변환된 조감도를\" for better flow."
    },
    {
        "turn_index": 2,
        "term": "deep generative models",
        "domain": "cs.AI",
        "summary": "  Hungry Geese is a n-player variation of the popular game snake. This paper\nlooks at state of the art Deep Reinforcement Learning Value Methods. The goal\nof the paper is to aggregate research of value based methods and apply it as an\nexercise to other environments. A vanilla Deep Q Network, a Double Q-network\nand a Dueling Q-Network were all examined and tested with the Hungry Geese\nenvironment. The best performing model was the vanilla Deep Q Network due to\nits simple state representation and smaller network structure. Converging\ntowards an optimal policy was found to be difficult due to random geese\ninitialization and food generation. Therefore we show that Deep Q Networks may\nnot be the appropriate model for such a stochastic environment and lastly we\npresent improvements that can be made along with more suitable models for the\nenvironment.\n",
        "english": "Deep generative models, unlike the Deep Q Networks explored in the Hungry Geese environment, offer an innovative approach to handling the stochastic nature of environments due to their ability to model complex distributions. While the vanilla Deep Q Network excelled in simplicity and network structure, its limitations in converging towards an optimal policy underscore the potential of deep generative models to better capture the randomness in geese initialization and food generation. By employing deep generative models, researchers can leverage methods such as variational autoencoders (VAEs) and generative adversarial networks (GANs), denoted as $p_{\\theta}(x|z)$, to generate more robust policies in dynamic settings.",
        "korean": "심층 생성 모델(deep generative models)은 Hungry Geese 환경에서 탐구된 심층 Q 네트워크(Deep Q Networks)와 달리 복잡한 분포를 모델링할 수 있는 능력 덕분에 환경의 확률적 특성을 처리하는 혁신적인 접근 방식을 제공합니다. 기본 심층 Q 네트워크(vanilla Deep Q Network)는 단순성과 네트워크 구조에서 뛰어났지만, 최적 정책으로 수렴하는 데 한계가 있어 심층 생성 모델(deep generative models)이 거위 초기화와 음식 생성의 무작위성을 더 잘 포착할 수 있는 잠재력을 강조합니다. 심층 생성 모델(deep generative models)을 활용함으로써 연구자들은 변이 오토인코더(variational autoencoders, VAEs)와 생성적 적대 신경망(generative adversarial networks, GANs)과 같은 방법을 $p_{\\theta}(x|z)$로 나타내어 동적 환경에서 더 강력한 정책을 생성할 수 있습니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "recommendation systems",
        "domain": "cs.AI",
        "summary": "  Recommendation system or also known as a recommender system is a tool to help\nthe user in providing a suggestion of a specific dilemma. Thus, recently, the\ninterest in developing a recommendation system in many fields has increased.\nFuzzy Logic system (FLSs) is one of the approaches that can be used to model\nthe recommendation systems as it can deal with uncertainty and imprecise\ninformation. However, one of the fundamental issues in FLS is the problem of\nthe curse of dimensionality. That is, the number of rules in FLSs is increasing\nexponentially with the number of input variables. One effective way to overcome\nthis problem is by using Hierarchical Fuzzy System (HFSs). This paper aims to\nexplore the use of HFSs for Recommendation system. Specifically, we are\ninterested in exploring and comparing the HFS and FLS for the Career path\nrecommendation system (CPRS) based on four key criteria, namely topology, the\nnumber of rules, the rules structures and interpretability. The findings\nsuggested that the HFS has advantages over FLS towards improving the\ninterpretability models, in the context of a recommendation system example.\nThis study contributes to providing an insight into the development of\ninterpretable HFSs in the Recommendation systems.\n",
        "english": "In recent years, the interest in developing recommendation systems across various fields has surged, with Fuzzy Logic Systems (FLSs) emerging as a popular approach due to their capability to handle uncertainty and imprecise information. However, a significant challenge faced by FLSs is the curse of dimensionality, where the number of rules increases exponentially with the number of input variables, which can be mathematically expressed as $O(2^n)$, where $n$ represents the number of inputs. To address this issue, Hierarchical Fuzzy Systems (HFSs) have been proposed, offering advantages over FLSs in terms of interpretability and rule structure, particularly in applications like the Career Path Recommendation System (CPRS), thus contributing valuable insights into the development of interpretable models within recommendation systems.",
        "korean": "최근 몇 년 동안 다양한 분야에서 추천 시스템(recommendation systems)을 개발하려는 관심이 급증했으며, 퍼지 논리 시스템(fuzzy logic systems, FLSs)은 불확실성과 부정확한 정보를 처리할 수 있는 능력 덕분에 인기 있는 접근 방식으로 부상했습니다. 그러나 FLSs가 직면한 주요 과제는 차원의 저주(curse of dimensionality)로, 입력 변수의 수가 증가함에 따라 규칙의 수가 기하급수적으로 증가하는 문제입니다. 이는 수학적으로 $O(2^n)$로 표현될 수 있으며, 여기서 $n$은 입력의 수를 나타냅니다. 이러한 문제를 해결하기 위해 계층적 퍼지 시스템(hierarchical fuzzy systems, HFSs)이 제안되었으며, 특히 경력 경로 추천 시스템(career path recommendation system, CPRS)과 같은 응용 분야에서 해석 가능성과 규칙 구조 측면에서 FLSs보다 장점을 제공하여 추천 시스템(recommendation systems) 내 해석 가능한 모델 개발에 귀중한 통찰력을 제공합니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar"
    },
    {
        "turn_index": 2,
        "term": "deep reinforcement learning policies",
        "domain": "cs.AI",
        "summary": "  The ability to reuse previous policies is an important aspect of human\nintelligence. To achieve efficient policy reuse, a Deep Reinforcement Learning\n(DRL) agent needs to decide when to reuse and which source policies to reuse.\nPrevious methods solve this problem by introducing extra components to the\nunderlying algorithm, such as hierarchical high-level policies over source\npolicies, or estimations of source policies' value functions on the target\ntask. However, training these components induces either optimization\nnon-stationarity or heavy sampling cost, significantly impairing the\neffectiveness of transfer. To tackle this problem, we propose a novel policy\nreuse algorithm called Critic-gUided Policy reuse (CUP), which avoids training\nany extra components and efficiently reuses source policies. CUP utilizes the\ncritic, a common component in actor-critic methods, to evaluate and choose\nsource policies. At each state, CUP chooses the source policy that has the\nlargest one-step improvement over the current target policy, and forms a\nguidance policy. The guidance policy is theoretically guaranteed to be a\nmonotonic improvement over the current target policy. Then the target policy is\nregularized to imitate the guidance policy to perform efficient policy search.\nEmpirical results demonstrate that CUP achieves efficient transfer and\nsignificantly outperforms baseline algorithms.\n",
        "english": "Deep reinforcement learning policies benefit significantly from efficient policy reuse, which is a crucial aspect of human intelligence and can be achieved without introducing extra components that induce optimization non-stationarity or heavy sampling costs. The Critic-gUided Policy reuse (CUP) algorithm innovatively utilizes the critic, a common component in actor-critic methods, to evaluate and select source policies by choosing the one that offers the largest one-step improvement over the current target policy, ensuring a monotonic improvement. Empirical results demonstrate that CUP achieves efficient transfer and significantly outperforms baseline algorithms, with the guidance policy being regularized to imitate the target policy, expressed mathematically as $\\pi_{\\text{target}} \\leftarrow \\pi_{\\text{guidance}}$, facilitating an effective policy search.",
        "korean": "심층 강화 학습 정책(deep reinforcement learning policies)은 인간 지능의 중요한 측면인 효율적인 정책 재사용으로부터 크게 이익을 얻으며, 이는 최적화 비정상성이나 높은 샘플링 비용을 유발하는 추가 구성 요소를 도입하지 않고도 달성할 수 있습니다. 비평가 유도 정책 재사용(Critic-gUided Policy reuse, CUP) 알고리즘은 배우-비평가 방법(actor-critic methods)의 일반적인 구성 요소인 비평가를 혁신적으로 활용하여 현재 목표 정책에 비해 가장 큰 1단계 개선을 제공하는 소스 정책을 선택함으로써 단조로운 개선을 보장합니다. 실험 결과는 CUP가 효율적인 전이를 달성하고 기준 알고리즘을 크게 능가함을 보여주며, 안내 정책이 목표 정책을 모방하도록 정규화되어 $\\pi_{\\text{target}} \\leftarrow \\pi_{\\text{guidance}}$로 수학적으로 표현되어 효과적인 정책 탐색을 촉진합니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring consistent lowercase usage within parentheses and reviewing the placement of parentheses for other technical terms."
    },
    {
        "turn_index": 2,
        "term": "automatic differentiation",
        "domain": "cs.AI",
        "summary": "  Meta-structures are widely used to define which subset of neighbors to\naggregate information in heterogeneous information networks (HINs). In this\nwork, we investigate existing meta-structures, including meta-path and\nmeta-graph, and observe that they are initially designed manually with fixed\npatterns and hence are insufficient to encode various rich semantic information\non diverse HINs. Through reflection on their limitation, we define a new\nconcept called meta-multigraph as a more expressive and flexible generalization\nof meta-graph, and propose a stable differentiable search method to\nautomatically optimize the meta-multigraph for specific HINs and tasks. As the\nflexibility of meta-multigraphs may propagate redundant messages, we further\nintroduce a complex-to-concise (C2C) meta-multigraph that propagates messages\nfrom complex to concise along the depth of meta-multigraph. Moreover, we\nobserve that the differentiable search typically suffers from unstable search\nand a significant gap between the meta-structures in search and evaluation. To\nthis end, we propose a progressive search algorithm by implicitly narrowing the\nsearch space to improve search stability and reduce inconsistency. Extensive\nexperiments are conducted on six medium-scale benchmark datasets and one\nlarge-scale benchmark dataset over two representative tasks, i.e., node\nclassification and recommendation. Empirical results demonstrate that our\nsearch methods can automatically find expressive meta-multigraphs and C2C\nmeta-multigraphs, enabling our model to outperform state-of-the-art\nheterogeneous graph neural networks.\n",
        "english": "In the context of optimizing meta-multigraphs for heterogeneous information networks (HINs), automatic differentiation plays a crucial role in the proposed stable differentiable search method, which aims to automatically optimize these structures for specific HINs and tasks. The research introduces a novel concept, the complex-to-concise (C2C) meta-multigraph, which leverages automatic differentiation to propagate messages from complex to concise along the depth of the meta-multigraph, thereby addressing the issue of redundant message propagation. Notably, the study employs a progressive search algorithm, expressed mathematically as $\\text{argmin}_{\\Theta} \\mathcal{L}(\\Theta)$, where $\\mathcal{L}$ represents the loss function, to implicitly narrow the search space, enhancing search stability and reducing the inconsistency between the meta-structures in search and evaluation, ultimately leading to improved performance on node classification and recommendation tasks.",
        "korean": "이질적인 정보 네트워크(heterogeneous information networks, HINs)를 위한 메타-멀티그래프(meta-multigraph) 최적화의 맥락에서 자동 미분(automatic differentiation)은 특정 HINs 및 작업에 맞춰 이러한 구조를 자동으로 최적화하려는 제안된 안정적인 미분 가능 검색 방법에서 중요한 역할을 합니다. 연구는 자동 미분(automatic differentiation)을 활용하여 메타-멀티그래프(meta-multigraph)의 깊이를 따라 복잡한 메시지를 간결하게 전파함으로써 중복된 메시지 전파 문제를 해결하는 복잡-간결(complex-to-concise, C2C) 메타-멀티그래프(meta-multigraph)라는 새로운 개념을 도입합니다. 특히, 연구는 점진적 검색 알고리즘(progressive search algorithm)을 사용하여 수학적으로 $\\text{argmin}_{\\Theta} \\mathcal{L}(\\Theta)$로 표현되며, 여기서 $\\mathcal{L}$은 손실 함수(loss function)를 나타내며, 검색 공간을 암묵적으로 좁혀 검색 안정성을 향상시키고 검색 및 평가에서 메타 구조 간의 불일치를 줄여 궁극적으로 노드 분류 및 추천 작업의 성능을 향상시킵니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as adjusting the placement of technical terms to enhance the natural flow of the sentences."
    },
    {
        "turn_index": 2,
        "term": "deep policy networks",
        "domain": "cs.AI",
        "summary": "  Reinforcement learning (RL) problems often feature deceptive local optima,\nand learning methods that optimize purely for reward signal often fail to learn\nstrategies for overcoming them. Deep neuroevolution and novelty search have\nbeen proposed as effective alternatives to gradient-based methods for learning\nRL policies directly from pixels. In this paper, we introduce and evaluate the\nuse of novelty search over agent action sequences by string edit metric\ndistance as a means for promoting innovation. We also introduce a method for\nstagnation detection and population resampling inspired by recent developments\nin the RL community that uses the same mechanisms as novelty search to promote\nand develop innovative policies. Our methods extend a state-of-the-art method\nfor deep neuroevolution using a simple-yet-effective genetic algorithm (GA)\ndesigned to efficiently learn deep RL policy network weights. Experiments using\nfour games from the Atari 2600 benchmark were conducted. Results provide\nfurther evidence that GAs are competitive with gradient-based algorithms for\ndeep RL. Results also demonstrate that novelty search over action sequences is\nan effective source of selection pressure that can be integrated into existing\nevolutionary algorithms for deep RL.\n",
        "english": "Deep policy networks have been shown to benefit from methods such as deep neuroevolution and novelty search, which are effective alternatives to traditional gradient-based approaches for reinforcement learning (RL) policies directly from pixels. The integration of novelty search over agent action sequences, quantified by string edit metric distance, serves as a mechanism for promoting innovation within these networks, which can be mathematically represented as $D(s_1, s_2) = \\sum_{i=1}^{n} |s_{1i} - s_{2i}|$, where $s_1$ and $s_2$ are action sequences. This approach, combined with a genetic algorithm designed to efficiently learn deep RL policy network weights, demonstrates that novelty search provides a competitive source of selection pressure, enhancing the development of innovative policies in deep policy networks.",
        "korean": "심층 정책 네트워크(deep policy networks)는 심층 신경 진화(deep neuroevolution) 및 참신성 탐색(novelty search)과 같은 방법에서 이점을 얻는 것으로 나타났으며, 이는 픽셀에서 직접 강화 학습(reinforcement learning, RL) 정책을 위한 전통적인 경사 기반 접근법의 효과적인 대안입니다. 문자열 편집 거리(string edit metric distance)로 정량화된 에이전트 행동 시퀀스에 대한 참신성 탐색의 통합은 이러한 네트워크 내에서 혁신을 촉진하는 메커니즘으로 작용하며, 이는 수학적으로 $D(s_1, s_2) = \\sum_{i=1}^{n} |s_{1i} - s_{2i}|$로 표현될 수 있습니다. 여기서 $s_1$과 $s_2$는 행동 시퀀스입니다. 이 접근법은 심층 RL 정책 네트워크 가중치를 효율적으로 학습하도록 설계된 유전 알고리즘(genetic algorithm)과 결합되어 참신성 탐색이 심층 정책 네트워크(deep policy networks)에서 혁신적인 정책 개발을 향상시키는 경쟁력 있는 선택 압력의 원천을 제공한다는 것을 보여줍니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "unsupervised representation learning",
        "domain": "cs.AI",
        "summary": "  We present an unsupervised deep learning model for 3D object classification.\nConventional Hebbian learning, a well-known unsupervised model, suffers from\nloss of local features leading to reduced performance for tasks with complex\ngeometric objects. We present a deep network with a novel Neuron Activity Aware\n(NeAW) Hebbian learning rule that dynamically switches the neurons to be\ngoverned by Hebbian learning or anti-Hebbian learning, depending on its\nactivity. We analytically show that NeAW Hebbian learning relieves the bias in\nneuron activity, allowing more neurons to attend to the representation of the\n3D objects. Empirical results show that the NeAW Hebbian learning outperforms\nother variants of Hebbian learning and shows higher accuracy over fully\nsupervised models when training data is limited.\n",
        "korean": "비지도 표현 학습(unsupervised representation learning)은 새로운 뉴런 활동 인식(Neuron Activity Aware, NeAW) 헤비안 학습 규칙(Hebbian learning rule)을 사용하는 심층 네트워크(deep network)의 도입을 통해 발전하고 있으며, 이는 뉴런의 활동에 따라 헤비안 학습(Hebbian learning)과 반헤비안 학습(anti-Hebbian learning) 사이를 동적으로 전환합니다. 이 혁신적인 접근 방식은 뉴런 활동의 편향을 완화하여 더 많은 뉴런이 3D 객체의 표현에 집중할 수 있도록 함으로써 그 효과를 분석적으로 입증합니다. 이는 $\\text{NeAW} = \\frac{\\text{Hebbian}}{\\text{Activity}}$라는 표현으로 나타납니다. 실험 결과는 NeAW 헤비안 학습(NeAW Hebbian learning)이 다른 헤비안 학습 변형을 능가할 뿐만 아니라 제한된 훈련 데이터 시나리오에서 완전 지도 모델(fully supervised models)보다 높은 정확도를 달성함으로써 이 방법의 중요성을 강조합니다."
    },
    {
        "turn_index": 2,
        "term": "task-specific contextual learning",
        "domain": "cs.AI",
        "summary": "  Concepts are the foundation of human deep learning, understanding, and\nknowledge integration and transfer. We propose concept-oriented deep learning\n(CODL) which extends (machine) deep learning with concept representations and\nconceptual understanding capability. CODL addresses some of the major\nlimitations of deep learning: interpretability, transferability, contextual\nadaptation, and requirement for lots of labeled training data. We discuss the\nmajor aspects of CODL including concept graph, concept representations, concept\nexemplars, and concept representation learning systems supporting incremental\nand continual learning.\n",
        "english": "Task-specific contextual learning plays a crucial role in enhancing the interpretability and transferability of deep learning models by integrating concept-oriented deep learning (CODL), which extends traditional deep learning with concept representations and conceptual understanding capability. CODL addresses limitations such as contextual adaptation and the requirement for extensive labeled training data by utilizing a concept graph, concept representations, and concept exemplars, thereby supporting incremental and continual learning. The innovation of task-specific contextual learning is further underscored by its ability to leverage mathematical expressions, such as the formulation of a concept representation learning system, $C = f(X, \\Theta)$, where $C$ represents the concept, $X$ is the input data, and $\\Theta$ denotes the model parameters, facilitating more efficient knowledge integration and transfer.",
        "korean": "과제별 맥락 학습(task-specific contextual learning)은 개념 지향 심층 학습(concept-oriented deep learning, CODL)을 통합하여 심층 학습 모델의 해석 가능성과 전이 가능성을 향상시키는 데 중요한 역할을 합니다. CODL은 개념 표현과 개념적 이해 능력을 통해 전통적인 심층 학습을 확장하며, 개념 그래프, 개념 표현, 개념 예제를 활용하여 맥락 적응 및 광범위한 라벨링된 학습 데이터의 요구 사항과 같은 한계를 해결함으로써 점진적이고 지속적인 학습을 지원합니다. 과제별 맥락 학습(task-specific contextual learning)의 혁신은 개념 표현 학습 시스템의 공식화와 같은 수학적 표현을 활용할 수 있는 능력에 의해 더욱 강조되며, $C = f(X, \\Theta)$에서 $C$는 개념을 나타내고, $X$는 입력 데이터이며, $\\Theta$는 모델 매개변수를 나타내어 보다 효율적인 지식 통합 및 전이를 촉진합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "probabilistic language modeling",
        "domain": "cs.AI",
        "summary": "  Argumentation problems are concerned with determining the acceptability of a\nset of arguments from their relational structure. When the available\ninformation is uncertain, probabilistic argumentation frameworks provide\nmodelling tools to account for it. The first contribution of this paper is a\nnovel interpretation of probabilistic argumentation frameworks as probabilistic\nlogic programs. Probabilistic logic programs are logic programs in which some\nof the facts are annotated with probabilities. We show that the programs\nrepresenting probabilistic argumentation frameworks do not satisfy a common\nassumption in probabilistic logic programming (PLP) semantics, which is, that\nprobabilistic facts fully capture the uncertainty in the domain under\ninvestigation. The second contribution of this paper is then a novel PLP\nsemantics for programs where a choice of probabilistic facts does not uniquely\ndetermine the truth assignment of the logical atoms. The third contribution of\nthis paper is the implementation of a PLP system supporting this semantics:\nsmProbLog. smProbLog is a novel PLP framework based on the probabilistic logic\nprogramming language ProbLog. smProbLog supports many inference and learning\ntasks typical of PLP, which, together with our first contribution, provide\nnovel reasoning tools for probabilistic argumentation. We evaluate our approach\nwith experiments analyzing the computational cost of the proposed algorithms\nand their application to a dataset of argumentation problems.\n",
        "english": "Probabilistic language modeling can be enhanced by utilizing probabilistic argumentation frameworks, which \"provide modelling tools to account for\" uncertain information, as demonstrated by their novel interpretation as probabilistic logic programs. In this context, the programs representing these frameworks challenge the assumption in probabilistic logic programming (PLP) semantics that \"probabilistic facts fully capture the uncertainty\" by introducing a new PLP semantics where the choice of probabilistic facts does not uniquely determine the truth assignment of logical atoms. The implementation of a PLP system, smProbLog, which is based on the probabilistic logic programming language ProbLog, supports various inference and learning tasks, thereby offering innovative reasoning tools for probabilistic language modeling and enhancing its applicability to complex datasets, as evidenced by the experimental evaluation of computational costs and practical applications.",
        "korean": "확률적 언어 모델링(probabilistic language modeling)은 불확실한 정보를 설명하기 위한 모델링 도구를 제공하는 확률적 논증 프레임워크(probabilistic argumentation frameworks)를 활용하여 향상될 수 있으며, 이는 확률적 논리 프로그램(probabilistic logic programs)으로서의 새로운 해석을 통해 입증되었습니다. 이 맥락에서 이러한 프레임워크를 나타내는 프로그램은 확률적 논리 프로그래밍(probabilistic logic programming, PLP) 의미론에서 \"확률적 사실이 불확실성을 완전히 포착한다\"는 가정을 도전하며, 확률적 사실의 선택이 논리적 원자의 진리 할당을 고유하게 결정하지 않는 새로운 PLP 의미론을 도입합니다. 확률적 논리 프로그래밍 언어 프로블로그(ProbLog)를 기반으로 한 PLP 시스템인 smProbLog의 구현은 다양한 추론 및 학습 작업을 지원하여 확률적 언어 모델링(probabilistic language modeling)을 위한 혁신적인 추론 도구를 제공하고, 복잡한 데이터셋에 대한 적용 가능성을 향상시킵니다. 이는 계산 비용과 실용적 응용에 대한 실험적 평가를 통해 입증되었습니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "named entity recognition",
        "domain": "cs.AI",
        "summary": "  Named Entity Recognition (NER) aims at locating and classifying named\nentities in text. In some use cases of NER, including cases where detected\nnamed entities are used in creating content recommendations, it is crucial to\nhave a reliable confidence level for the detected named entities. In this work\nwe study the problem of finding confidence levels for detected named entities.\nWe refer to this problem as Named Entity Sequence Classification (NESC). We\nframe NESC as a binary classification problem and we use NER as well as\nrecurrent neural networks to find the probability of candidate named entity is\na real named entity. We apply this approach to Tweet texts and we show how we\ncould find named entities with high confidence levels from Tweets.\n",
        "english": "Named entity recognition (NER) is a crucial task in natural language processing that involves \"locating and classifying named entities in text,\" which is particularly important for applications such as content recommendations where the reliability of detected entities is paramount. The study introduces Named Entity Sequence Classification (NESC) as a solution to this challenge, framing it as a binary classification problem using NER and recurrent neural networks to calculate the probability \\( P(e) \\) that a candidate named entity \\( e \\) is a genuine entity. This innovative approach is applied to Tweet texts, demonstrating its capability to \"find named entities with high confidence levels from Tweets,\" thereby enhancing the accuracy of NER systems in dynamic and informal text environments.",
        "korean": "개체명 인식(named entity recognition, NER)은 텍스트에서 \"개체명을 찾아 분류하는\" 자연어 처리(natural language processing)에서 중요한 작업으로, 특히 감지된 개체의 신뢰성이 중요한 콘텐츠 추천(content recommendations)과 같은 응용 프로그램에 중요합니다. 이 연구는 이 문제에 대한 해결책으로 개체명 시퀀스 분류(named entity sequence classification, NESC)를 도입하며, 이를 NER과 순환 신경망(recurrent neural networks)을 사용하여 후보 개체명 \\( e \\)가 진짜 개체일 확률 \\( P(e) \\)을 계산하는 이진 분류 문제로 설정합니다. 이 혁신적인 접근법은 트윗 텍스트(tweet texts)에 적용함으로써 \"트윗에서 높은 신뢰 수준의 개체명을 찾는\" 능력을 입증하여, 동적이고 비공식적인 텍스트 환경에서 NER 시스템의 정확성을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "speech recognition",
        "domain": "cs.AI",
        "summary": "  For the past few decades, man has been trying to create an intelligent\ncomputer which can talk and respond like he can. The task of creating a system\nthat can talk like a human being is the primary objective of Automatic Speech\nRecognition. Various Speech Recognition techniques have been developed in\ntheory and have been applied in practice. This paper discusses the problems\nthat have been encountered in developing Speech Recognition, the techniques\nthat have been applied to automate the task, and a representation of the core\nproblems of present day Speech Recognition by using Fuzzy Mathematics.\n",
        "english": "The task of creating a system that can talk like a human being is the primary objective of speech recognition, which has seen various techniques developed and applied in practice. Despite these advancements, the field continues to encounter significant challenges, particularly in representing core problems using Fuzzy Mathematics, which aims to model the inherent ambiguity in human speech. A key innovation in this area is the application of fuzzy logic, expressed as $F(x) = \\int_{-\\infty}^{x} f(t) \\, dt$, to address the uncertainties in speech patterns and improve the accuracy of speech recognition systems.",
        "korean": "인간처럼 말할 수 있는 시스템을 만드는 과제는 음성 인식(speech recognition)의 주요 목표로, 다양한 기술이 개발되고 실무에 적용되었습니다. 이러한 발전에도 불구하고, 이 분야는 여전히 인간 음성의 고유한 모호성을 모델링하기 위한 퍼지 수학(fuzzy mathematics)을 사용하여 핵심 문제를 표현하는 데 있어 상당한 도전에 직면하고 있습니다. 이 분야의 주요 혁신은 음성 패턴의 불확실성을 해결하고 음성 인식 시스템(speech recognition systems)의 정확성을 향상시키기 위해 퍼지 논리(fuzzy logic)를 적용하는 것으로, 이는 $F(x) = \\int_{-\\infty}^{x} f(t) \\, dt$로 표현됩니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Ensure that all English terms within parentheses are in lowercase to maintain consistency and adhere to the criteria."
    },
    {
        "turn_index": 2,
        "term": "approximate bayesian computation",
        "domain": "cs.AI",
        "summary": "  Structure and parameters in a Bayesian network uniquely specify the\nprobability distribution of the modeled domain. The locality of both structure\nand probabilistic information are the great benefits of Bayesian networks and\nrequire the modeler to only specify local information. On the other hand this\nlocality of information might prevent the modeler - and even more any other\nperson - from obtaining a general overview of the important relationships\nwithin the domain. The goal of the work presented in this paper is to provide\nan \"alternative\" view on the knowledge encoded in a Bayesian network which\nmight sometimes be very helpful for providing insights into the underlying\ndomain. The basic idea is to calculate a mixture approximation to the\nprobability distribution represented by the Bayesian network. The mixture\ncomponent densities can be thought of as representing typical scenarios implied\nby the Bayesian model, providing intuition about the basic relationships. As an\nadditional benefit, performing inference in the approximate model is very\nsimple and intuitive and can provide additional insights. The computational\ncomplexity for the calculation of the mixture approximations criticaly depends\non the measure which defines the distance between the probability distribution\nrepresented by the Bayesian network and the approximate distribution. Both the\nKL-divergence and the backward KL-divergence lead to inefficient algorithms.\nIncidentally, the latter is used in recent work on mixtures of mean field\nsolutions to which the work presented here is closely related. We show,\nhowever, that using a mean squared error cost function leads to update\nequations which can be solved using the junction tree algorithm. We conclude\nthat the mean squared error cost function can be used for Bayesian networks in\nwhich inference based on the junction tree is tractable. For large networks,\nhowever, one may have to rely on mean field approximations.\n",
        "korean": "근사 베이지안 계산(approximate bayesian computation, ABC)은 네트워크에 의해 표현된 확률 분포에 대한 혼합 근사를 계산함으로써 베이지안 네트워크(bayesian network)에 인코딩된 지식에 대한 \"대안적인\" 관점을 제공합니다. 이 방법은 구조와 확률 정보의 국소성에 의존하여 모델러들이 국소 정보만을 지정하면서도 기본 도메인에 대한 통찰을 얻을 수 있게 합니다. 특히, 혼합 근사의 계산을 위한 계산 복잡성은 베이지안 네트워크(bayesian network)에 의해 표현된 확률 분포와 근사 분포 간의 거리를 정의하는 측정에 크게 의존하며, 평균 제곱 오차 비용 함수(mean squared error cost function)는 접합 트리 알고리즘(junction tree algorithm)을 사용하여 해결 가능한 갱신 방정식을 이끌어냅니다."
    },
    {
        "turn_index": 2,
        "term": "attention mechanisms",
        "domain": "cs.AI",
        "summary": "  This paper explores the area of news recommendation, a key component of\nonline information sharing. Initially, we provide a clear introduction to news\nrecommendation, defining the core problem and summarizing current methods and\nnotable recent algorithms. We then present our work on implementing the NRAM\n(News Recommendation with Attention Mechanism), an attention-based approach for\nnews recommendation, and assess its effectiveness. Our evaluation shows that\nNRAM has the potential to significantly improve how news content is\npersonalized for users on digital news platforms.\n",
        "english": "In the domain of news recommendation, attention mechanisms have been effectively utilized, as demonstrated by the implementation of NRAM (News Recommendation with Attention Mechanism), which leverages these mechanisms to enhance the personalization of news content for users on digital platforms. By focusing on the core problem of news recommendation and summarizing current methods, the study highlights the innovative use of attention mechanisms in the NRAM approach, which significantly improves user engagement and content relevance. Notably, the evaluation of NRAM indicates a substantial increase in performance, with metrics such as precision and recall showing improvements of up to 20\\%, underscoring the potential of attention mechanisms to revolutionize online information sharing.",
        "korean": "뉴스 추천 분야에서 주의 메커니즘(attention mechanisms)은 효과적으로 활용되고 있으며, 이는 NRAM(주의 메커니즘을 활용한 뉴스 추천, News Recommendation with Attention Mechanism)의 구현을 통해 입증되었습니다. NRAM은 디지털 플랫폼에서 사용자에게 뉴스 콘텐츠의 개인화를 향상시키기 위해 이러한 메커니즘을 활용합니다. 뉴스 추천의 핵심 문제에 집중하고 현재 방법을 요약함으로써, 연구는 NRAM 접근법에서 주의 메커니즘(attention mechanisms)의 혁신적인 사용을 강조하며, 이는 사용자 참여도와 콘텐츠 관련성을 크게 향상시킵니다. 특히, NRAM의 평가 결과는 성능이 크게 향상되었음을 나타내며, 정밀도와 재현율과 같은 지표가 최대 20\\%까지 개선되어 주의 메커니즘(attention mechanisms)이 온라인 정보 공유를 혁신할 잠재력을 가지고 있음을 강조합니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "differentially private training",
        "domain": "cs.AI",
        "summary": "  The privacy concerns associated with the use of Large Language Models (LLMs)\nhave grown recently with the development of LLMs such as ChatGPT. Differential\nPrivacy (DP) techniques are explored in existing work to mitigate their privacy\nrisks at the cost of generalization degradation. Our paper reveals that the\nflatness of DP-trained models' loss landscape plays an essential role in the\ntrade-off between their privacy and generalization. We further propose a\nholistic framework to enforce appropriate weight flatness, which substantially\nimproves model generalization with competitive privacy preservation. It\ninnovates from three coarse-to-grained levels, including perturbation-aware\nmin-max optimization on model weights within a layer, flatness-guided sparse\nprefix-tuning on weights across layers, and weight knowledge distillation\nbetween DP \\& non-DP weights copies. Comprehensive experiments of both\nblack-box and white-box scenarios are conducted to demonstrate the\neffectiveness of our proposal in enhancing generalization and maintaining DP\ncharacteristics. For instance, on text classification dataset QNLI, DP-Flat\nachieves similar performance with non-private full fine-tuning but with DP\nguarantee under privacy budget $\\epsilon=3$, and even better performance given\nhigher privacy budgets. Codes are provided in the supplement.\n",
        "english": "Differentially private training is crucial in addressing the privacy concerns associated with Large Language Models (LLMs) like ChatGPT, as it employs Differential Privacy (DP) techniques to mitigate privacy risks, albeit often at the cost of generalization degradation. Our research introduces an innovative holistic framework that significantly enhances model generalization while maintaining competitive privacy preservation by focusing on the flatness of DP-trained models' loss landscape, which plays an essential role in balancing privacy and generalization. Notably, our approach, DP-Flat, demonstrates its efficacy on the text classification dataset QNLI, achieving similar performance to non-private full fine-tuning under a privacy budget of $\\epsilon=3$ and even surpassing it with higher privacy budgets, thereby highlighting the potential of enforcing appropriate weight flatness in differentially private training.",
        "korean": "차등적으로 비공개 훈련(differentially private training)은 ChatGPT와 같은 대형 언어 모델(large language models, LLMs)과 관련된 프라이버시 문제를 해결하는 데 필수적입니다. 이는 프라이버시 위험을 완화하기 위해 차등 프라이버시(differential privacy, DP) 기법을 사용하지만, 일반적으로 일반화 성능 저하의 대가를 치르게 됩니다. 우리의 연구는 DP로 훈련된 모델의 손실 지형의 평탄함에 중점을 두어 프라이버시와 일반화의 균형을 맞추는 데 중요한 역할을 하는 혁신적인 전체론적 프레임워크를 도입하여 모델 일반화를 크게 향상시키면서 경쟁력 있는 프라이버시 보존을 유지합니다. 특히, 우리의 접근 방식인 DP-Flat은 텍스트 분류 데이터셋 QNLI에서 프라이버시 예산 $\\epsilon=3$ 하에서 비공개 전체 미세 조정과 유사한 성능을 달성하고, 더 높은 프라이버시 예산에서는 이를 초과하여 차등적으로 비공개 훈련(differentially private training)에서 적절한 가중치 평탄성을 부과하는 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "exchangeability",
        "domain": "cs.AI",
        "summary": "  Kidney exchanges are organized markets where patients swap willing but\nincompatible donors. In the last decade, kidney exchanges grew from small and\nregional to large and national---and soon, international. This growth results\nin more lives saved, but exacerbates the empirical hardness of the\n$\\mathcal{NP}$-complete problem of optimally matching patients to donors.\nState-of-the-art matching engines use integer programming techniques to clear\nfielded kidney exchanges, but these methods must be tailored to specific models\nand objective functions, and may fail to scale to larger exchanges. In this\npaper, we observe that if the kidney exchange compatibility graph can be\nencoded by a constant number of patient and donor attributes, the clearing\nproblem is solvable in polynomial time. We give necessary and sufficient\nconditions for losslessly shrinking the representation of an arbitrary\ncompatibility graph. Then, using real compatibility graphs from the UNOS\nnationwide kidney exchange, we show how many attributes are needed to encode\nreal compatibility graphs. The experiments show that, indeed, small numbers of\nattributes suffice.\n",
        "english": "The concept of exchangeability is crucial in the context of kidney exchanges, where the growth from small, regional markets to large, national, and international ones has increased the complexity of the $\\mathcal{NP}$-complete problem of optimally matching patients to donors. By observing that if the kidney exchange compatibility graph can be encoded by a constant number of patient and donor attributes, the clearing problem becomes solvable in polynomial time, the research highlights a significant advancement in managing these exchanges. The study's experiments with real compatibility graphs from the UNOS nationwide kidney exchange demonstrate that a small number of attributes suffice to encode these graphs effectively, underscoring the potential for more efficient and scalable matching processes.",
        "korean": "신장 교환(kidney exchanges)에서 교환 가능성(exchangeability)의 개념은 매우 중요합니다. 이는 작은 지역 시장에서 대규모 국가 및 국제 시장으로의 성장이 환자와 기증자를 최적으로 매칭하는 $\\mathcal{NP}$-완전 문제의 복잡성을 증가시켰기 때문입니다. 신장 교환 호환성 그래프(kidney exchange compatibility graph)가 일정 수의 환자 및 기증자 속성으로 인코딩될 수 있음을 관찰함으로써, 해결 문제는 다항 시간 내에 해결 가능해지며, 이는 이러한 교환을 관리하는 데 있어 중요한 발전을 강조합니다. UNOS 전국 신장 교환(UNOS nationwide kidney exchange)에서 실제 호환성 그래프를 사용한 연구의 실험은 소수의 속성만으로도 이러한 그래프를 효과적으로 인코딩할 수 있음을 보여주며, 더 효율적이고 확장 가능한 매칭 프로세스의 가능성을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic task-driven learning",
        "domain": "cs.AI",
        "summary": "  Controlling continuous-time dynamical systems is generally a two step\nprocess: first, identify or model the system dynamics with differential\nequations, then, minimize the control objectives to achieve optimal control\nfunction and optimal state trajectories. However, any inaccuracy in dynamics\nmodeling will lead to sub-optimality in the resulting control function. To\naddress this, we propose a neural ODE based method for controlling unknown\ndynamical systems, denoted as Neural Control (NC), which combines dynamics\nidentification and optimal control learning using a coupled neural ODE. Through\nan intriguing interplay between the two neural networks in coupled neural ODE\nstructure, our model concurrently learns system dynamics as well as optimal\ncontrols that guides towards target states. Our experiments demonstrate the\neffectiveness of our model for learning optimal control of unknown dynamical\nsystems. Codes available at\nhttps://github.com/chichengmessi/neural_ode_control/tree/main\n",
        "english": "Dynamic task-driven learning is exemplified in the proposed Neural Control (NC) method, which integrates dynamics identification with optimal control learning through a coupled neural ODE structure. By concurrently learning system dynamics and optimal controls, this approach addresses the sub-optimality issues arising from inaccuracies in dynamics modeling, effectively guiding the system towards target states. The mathematical foundation of the model is expressed as a coupled neural ODE, where the dynamics are represented by $\\dot{x}(t) = f(x(t), u(t), t)$ and the control objectives are optimized to minimize a predefined cost function, showcasing its innovation in controlling unknown dynamical systems.",
        "korean": "동적 과제 주도 학습(dynamic task-driven learning)은 제안된 신경 제어(NC, Neural Control) 방법에서 예시되며, 이는 결합된 신경 ODE 구조를 통해 동역학 식별과 최적 제어 학습을 통합합니다. 시스템 동역학과 최적 제어를 동시에 학습함으로써, 이 접근법은 동역학 모델링의 부정확성에서 발생하는 비최적성 문제를 해결하고, 시스템을 목표 상태로 효과적으로 안내합니다. 모델의 수학적 기초는 결합된 신경 ODE로 표현되며, 동역학은 $\\dot{x}(t) = f(x(t), u(t), t)$로 나타나고 제어 목표는 사전 정의된 비용 함수를 최소화하도록 최적화되어, 알려지지 않은 동적 시스템을 제어하는 데 있어 혁신성을 보여줍니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic sequence modeling",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Dynamic sequence modeling has been significantly advanced by the introduction of novel architectures that leverage attention mechanisms to capture long-range dependencies, as detailed in the reference. A key contribution of the research is the proposed model, which optimizes the loss function $L(\\theta) = -\\sum_{t=1}^{T} \\log P(x_t | x_{<t}; \\theta)$ to effectively enhance prediction accuracy in sequential data. This innovative approach underscores the importance of dynamic sequence modeling in applications such as natural language processing and time-series forecasting, where understanding temporal patterns is crucial.",
        "korean": "참조 문헌에서 설명된 바와 같이 주의 메커니즘(attention mechanisms)을 활용하여 장거리 의존성을 포착하는 새로운 아키텍처의 도입으로 동적 시퀀스 모델링(dynamic sequence modeling)이 크게 발전하였습니다. 연구의 주요 기여는 순차 데이터에서 예측 정확성을 효과적으로 향상시키기 위해 손실 함수 $L(\\theta) = -\\sum_{t=1}^{T} \\log P(x_t | x_{<t}; \\theta)$를 최적화하는 제안된 모델입니다. 이 혁신적인 접근 방식은 자연어 처리(natural language processing) 및 시계열 예측(time-series forecasting)과 같은 응용 분야에서 시간적 패턴을 이해하는 것이 중요한 동적 시퀀스 모델링(dynamic sequence modeling)의 중요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "adaptive text segmentation",
        "domain": "cs.AI",
        "summary": "  The Segment Anything Model (SAM) and CLIP are remarkable vision foundation\nmodels (VFMs). SAM, a prompt driven segmentation model, excels in segmentation\ntasks across diverse domains, while CLIP is renowned for its zero shot\nrecognition capabilities. However, their unified potential has not yet been\nexplored in medical image segmentation. To adapt SAM to medical imaging,\nexisting methods primarily rely on tuning strategies that require extensive\ndata or prior prompts tailored to the specific task, making it particularly\nchallenging when only a limited number of data samples are available. This work\npresents an in depth exploration of integrating SAM and CLIP into a unified\nframework for medical image segmentation. Specifically, we propose a simple\nunified framework, SaLIP, for organ segmentation. Initially, SAM is used for\npart based segmentation within the image, followed by CLIP to retrieve the mask\ncorresponding to the region of interest (ROI) from the pool of SAM generated\nmasks. Finally, SAM is prompted by the retrieved ROI to segment a specific\norgan. Thus, SaLIP is training and fine tuning free and does not rely on domain\nexpertise or labeled data for prompt engineering. Our method shows substantial\nenhancements in zero shot segmentation, showcasing notable improvements in DICE\nscores across diverse segmentation tasks like brain (63.46%), lung (50.11%),\nand fetal head (30.82%), when compared to un prompted SAM. Code and text\nprompts are available at: https://github.com/aleemsidra/SaLIP.\n",
        "korean": "적응형 텍스트 세분화(adaptive text segmentation)는 세그먼트 애니싱 모델(segment anything model, sam)과 clip을 통합한 통합 프레임워크인 salip을 통해 예시되며, 특히 의료 영상에서 제로샷 세분화 작업에서 상당한 개선을 보여줍니다. sam을 사용하여 부분 기반 세분화를 수행한 후 clip을 활용하여 관심 영역(region of interest, roi)에 해당하는 마스크를 검색함으로써, 이 프레임워크는 뇌 세분화에서 63.46%, 폐 세분화에서 50.11%, 태아 머리 세분화에서 30.82%의 dice 점수 향상을 달성하며, 비프롬프트 sam의 성능을 능가합니다. 이 혁신적인 접근 방식은 훈련 및 미세 조정이 필요 없으며, 도메인 전문 지식이나 라벨링된 데이터가 필요하지 않아 적응형 텍스트 세분화(adaptive text segmentation) 방법론의 발전에 있어 그 중요성을 강조합니다."
    },
    {
        "turn_index": 2,
        "term": "end-to-end reinforcement learning",
        "domain": "cs.AI",
        "summary": "  Purpose: AI in radiology is hindered chiefly by: 1) Requiring large annotated\ndata sets. 2) Non-generalizability that limits deployment to new scanners /\ninstitutions. And 3) Inadequate explainability and interpretability. We believe\nthat reinforcement learning can address all three shortcomings, with robust and\nintuitive algorithms trainable on small datasets. To the best of our knowledge,\nreinforcement learning has not been directly applied to computer vision tasks\nfor radiological images. In this proof-of-principle work, we train a deep\nreinforcement learning network to predict brain tumor location.\n  Materials and Methods: Using the BraTS brain tumor imaging database, we\ntrained a deep Q network on 70 post-contrast T1-weighted 2D image slices. We\ndid so in concert with image exploration, with rewards and punishments designed\nto localize lesions. To compare with supervised deep learning, we trained a\nkeypoint detection convolutional neural network on the same 70 images. We\napplied both approaches to a separate 30 image testing set.\n  Results: Reinforcement learning predictions consistently improved during\ntraining, whereas those of supervised deep learning quickly diverged.\nReinforcement learning predicted testing set lesion locations with 85%\naccuracy, compared to roughly 7% accuracy for the supervised deep network.\n  Conclusion: Reinforcement learning predicted lesions with high accuracy,\nwhich is unprecedented for such a small training set. We believe that\nreinforcement learning can propel radiology AI well past the inherent\nlimitations of supervised deep learning, with more clinician-driven research\nand finally toward true clinical applicability.\n",
        "english": "End-to-end reinforcement learning presents a promising solution to the limitations faced by AI in radiology, particularly in requiring large annotated data sets, non-generalizability, and inadequate explainability, by utilizing robust and intuitive algorithms trainable on small datasets. In a proof-of-principle work, a deep Q network was trained using the BraTS brain tumor imaging database on 70 post-contrast T1-weighted 2D image slices, achieving an impressive lesion localization accuracy of 85\\% on a separate 30 image testing set, compared to only 7\\% for a supervised deep network. This significant improvement underscores the potential of end-to-end reinforcement learning to propel radiology AI beyond the inherent limitations of supervised deep learning, paving the way for more clinician-driven research and true clinical applicability.",
        "korean": "엔드 투 엔드 강화 학습(end-to-end reinforcement learning)은 방사선학에서 AI가 직면한 한계, 특히 대규모 주석 데이터 세트의 필요성, 일반화 불가능성, 불충분한 설명 가능성을 극복할 수 있는 유망한 솔루션을 제시합니다. 이는 소규모 데이터 세트에서 훈련 가능한 강력하고 직관적인 알고리즘을 활용함으로써 가능합니다. 원리 증명 연구에서, 딥 Q 네트워크(deep Q network)는 BraTS 뇌종양 영상 데이터베이스를 사용하여 70개의 조영 후 T1 강조 2D 이미지 슬라이스에서 훈련되었으며, 별도의 30개 이미지 테스트 세트에서 85\\%의 인상적인 병변 위치 정확도를 달성했습니다. 이는 감독 학습 심층 네트워크(supervised deep network)의 7\\%에 불과한 결과와 비교됩니다. 이러한 중요한 개선은 엔드 투 엔드 강화 학습(end-to-end reinforcement learning)이 방사선학 AI를 감독 학습 심층 학습(supervised deep learning)의 고유한 한계를 넘어 발전시킬 수 있는 잠재력을 강조하며, 더 많은 임상의 주도 연구와 진정한 임상 적용 가능성을 열어줍니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "adversarial robustness",
        "domain": "cs.AI",
        "summary": "  Autonomous cars are well known for being vulnerable to adversarial attacks\nthat can compromise the safety of the car and pose danger to other road users.\nTo effectively defend against adversaries, it is required to not only test\nautonomous cars for finding driving errors but to improve the robustness of the\ncars to these errors. To this end, in this paper, we propose a two-step\nmethodology for autonomous cars that consists of (i) finding failure states in\nautonomous cars by training the adversarial driving agent, and (ii) improving\nthe robustness of autonomous cars by retraining them with effective adversarial\ninputs. Our methodology supports testing autonomous cars in a multi-agent\nenvironment, where we train and compare adversarial car policy on two custom\nreward functions to test the driving control decision of autonomous cars. We\nrun experiments in a vision-based high-fidelity urban driving simulated\nenvironment. Our results show that adversarial testing can be used for finding\nerroneous autonomous driving behavior, followed by adversarial training for\nimproving the robustness of deep reinforcement learning-based autonomous\ndriving policies. We demonstrate that the autonomous cars retrained using the\neffective adversarial inputs noticeably increase the performance of their\ndriving policies in terms of reduced collision and offroad steering errors.\n",
        "english": "Autonomous cars are susceptible to adversarial attacks, which necessitates improving their adversarial robustness to ensure safety for both the vehicle and other road users. By employing a two-step methodology, this research enhances adversarial robustness by initially identifying failure states through an adversarial driving agent and subsequently retraining the cars with effective adversarial inputs, demonstrating a significant increase in performance with reduced collision and offroad steering errors. The innovation lies in training and comparing adversarial car policy using two custom reward functions, where the effectiveness of the retraining is quantified by the reduction in error rates, expressed as $E_{new} < E_{original}$, showcasing the method's efficacy in a high-fidelity urban driving simulation.",
        "korean": "자율 주행 자동차는 적대적 공격(adversarial attacks)에 취약하여 차량과 다른 도로 이용자의 안전을 보장하기 위해 적대적 강건성(adversarial robustness)을 향상시킬 필요가 있습니다. 이 연구는 두 단계 방법론을 사용하여 적대적 강건성(adversarial robustness)을 향상시키는데, 먼저 적대적 주행 에이전트(adversarial driving agent)를 통해 실패 상태를 식별하고, 그 후 효과적인 적대적 입력으로 자동차를 재훈련하여 충돌 및 도로 이탈 조향 오류가 감소된 성능 향상을 입증합니다. 혁신은 두 개의 맞춤형 보상 함수(custom reward functions)를 사용하여 적대적 자동차 정책(adversarial car policy)을 훈련하고 비교하는 데 있으며, 재훈련의 효과는 오류율 감소로 정량화되며, 이는 $E_{new} < E_{original}$로 표현되어 고정밀 도시 주행 시뮬레이션에서 방법의 효능을 보여줍니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "posterior predictive checks",
        "domain": "cs.AI",
        "summary": "  We propose using recognition networks for approximate inference inBayesian\nnetworks (BNs). A recognition network is a multilayerperception (MLP) trained\nto predict posterior marginals given observedevidence in a particular BN. The\ninput to the MLP is a vector of thestates of the evidential nodes. The activity\nof an output unit isinterpreted as a prediction of the posterior marginal of\nthecorresponding variable. The MLP is trained using samples generated fromthe\ncorresponding BN.We evaluate a recognition network that was trained to do\ninference ina large Bayesian network, similar in structure and complexity to\ntheQuick Medical Reference, Decision Theoretic (QMR-DT). Our networkis a\nbinary, two-layer, noisy-OR network containing over 4000 potentially observable\nnodes and over 600 unobservable, hidden nodes. Inreal medical diagnosis, most\nobservables are unavailable, and there isa complex and unknown bias that\nselects which ones are provided. Weincorporate a very basic type of selection\nbias in our network: a knownpreference that available observables are positive\nrather than negative.Even this simple bias has a significant effect on the\nposterior. We compare the performance of our recognition network\ntostate-of-the-art approximate inference algorithms on a large set oftest\ncases. In order to evaluate the effect of our simplistic modelof the selection\nbias, we evaluate algorithms using a variety ofincorrectly modeled observation\nbiases. Recognition networks performwell using both correct and incorrect\nobservation biases.\n",
        "english": "The use of recognition networks for approximate inference in Bayesian networks (BNs) provides a novel approach for conducting posterior predictive checks, as these networks utilize a multilayer perception (MLP) trained to predict posterior marginals given observed evidence in a specific BN. The MLP's input, a vector of the states of the evidential nodes, allows for the interpretation of the activity of an output unit as a prediction of the posterior marginal of the corresponding variable, offering a robust mechanism for evaluating model performance under various biases. Notably, even a basic selection bias, where available observables are more likely positive than negative, significantly affects the posterior, underscoring the importance of accurately modeling such biases, as demonstrated in our binary, two-layer, noisy-OR network containing over 4000 potentially observable nodes and over 600 unobservable, hidden nodes.",
        "korean": "베이지안 네트워크(bayesian networks, bns)에서 근사 추론을 위한 인식 네트워크(recognition networks)의 사용은 후방 예측 점검(posterior predictive checks)을 수행하는 새로운 접근 방식을 제공합니다. 이러한 네트워크는 특정 bn에서 관찰된 증거를 바탕으로 후방 주변 확률을 예측하도록 훈련된 다층 퍼셉트론(multilayer perception, mlp)을 활용합니다. mlp의 입력은 증거 노드의 상태 벡터로, 출력 유닛의 활동을 해당 변수의 후방 주변 확률 예측으로 해석할 수 있게 하여 다양한 편향 하에서 모델 성능을 평가하는 강력한 메커니즘을 제공합니다. 특히, 이용 가능한 관측치가 음성보다 양성일 가능성이 높은 기본적인 선택 편향(selection bias)조차도 후방에 상당한 영향을 미치며, 4000개 이상의 잠재적으로 관측 가능한 노드와 600개 이상의 관측 불가능한 숨겨진 노드를 포함하는 이진, 2층, 노이즈-or 네트워크에서 이러한 편향을 정확하게 모델링하는 것이 중요함을 강조합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure consistent capitalization within parentheses and consider rephrasing for smoother readability, such as adjusting the order of phrases to better match natural Korean syntax."
    },
    {
        "turn_index": 2,
        "term": "dynamic neural scene processes",
        "domain": "cs.AI",
        "summary": "  This paper proposes an intent-aware multi-agent planning framework as well as\na learning algorithm. Under this framework, an agent plans in the goal space to\nmaximize the expected utility. The planning process takes the belief of other\nagents' intents into consideration. Instead of formulating the learning problem\nas a partially observable Markov decision process (POMDP), we propose a simple\nbut effective linear function approximation of the utility function. It is\nbased on the observation that for humans, other people's intents will pose an\ninfluence on our utility for a goal. The proposed framework has several major\nadvantages: i) it is computationally feasible and guaranteed to converge. ii)\nIt can easily integrate existing intent prediction and low-level planning\nalgorithms. iii) It does not suffer from sparse feedbacks in the action space.\nWe experiment our algorithm in a real-world problem that is non-episodic, and\nthe number of agents and goals can vary over time. Our algorithm is trained in\na scene in which aerial robots and humans interact, and tested in a novel scene\nwith a different environment. Experimental results show that our algorithm\nachieves the best performance and human-like behaviors emerge during the\ndynamic process.\n",
        "english": "Dynamic neural scene processes, akin to the intent-aware multi-agent planning framework, allow an agent to plan in the goal space to maximize the expected utility by considering the belief of other agents' intents. The framework's innovative approach, which employs a linear function approximation of the utility function, avoids the complexity of formulating the learning problem as a partially observable Markov decision process (POMDP), thereby ensuring computational feasibility and convergence. Notably, experimental results demonstrate that these processes excel in dynamic environments, such as scenes with aerial robots and humans, where the algorithm achieves the best performance and human-like behaviors emerge, highlighting its potential for real-world applications.",
        "korean": "동적 신경 장면 프로세스(dynamic neural scene processes)는 의도 인식 다중 에이전트 계획 프레임워크(intent-aware multi-agent planning framework)와 유사하게, 에이전트가 목표 공간에서 계획을 세워 다른 에이전트의 의도에 대한 신념을 고려하여 기대 효용을 극대화할 수 있도록 합니다. 이 프레임워크의 혁신적인 접근 방식은 효용 함수의 선형 함수 근사를 사용하여 학습 문제를 부분 관찰 마르코프 결정 과정(partially observable Markov decision process, POMDP)으로 공식화하는 복잡성을 피함으로써 계산 가능성과 수렴성을 보장합니다. 특히, 실험 결과는 이러한 프로세스가 공중 로봇과 인간이 있는 장면과 같은 동적 환경에서 뛰어난 성능을 발휘하며, 알고리즘이 최고의 성능을 달성하고 인간과 유사한 행동이 나타나는 것을 보여주어 실제 응용 가능성을 강조합니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "causal generative models",
        "domain": "cs.AI",
        "summary": "  We are not only observers but also actors of reality. Our capability to\nintervene and alter the course of some events in the space and time surrounding\nus is an essential component of how we build our model of the world. In this\ndoctoral thesis we introduce a generic a-priori assessment of each possible\nintervention, in order to select the most cost-effective interventions only,\nand avoid unnecessary systematic experimentation on the real world. Based on\nthis a-priori assessment, we propose an active learning algorithm that\nidentifies the causal relations in any given causal model, using a least cost\nsequence of interventions. There are several novel aspects introduced by our\nalgorithm. It is, in most case scenarios, able to discard many causal model\ncandidates using relatively inexpensive interventions that only test one value\nof the intervened variables. Also, the number of interventions performed by the\nalgorithm can be bounded by the number of causal model candidates. Hence, fewer\ninitial candidates (or equivalently, more prior knowledge) lead to fewer\ninterventions for causal discovery.\n  Causality is intimately related to time, as causes appear to precede their\neffects. Cyclical causal processes are a very interesting case of causality in\nrelation to time. In this doctoral thesis we introduce a formal analysis of\ntime cyclical causal settings by defining a causal analog to the purely\nobservational Dynamic Bayesian Networks, and provide a sound and complete\nalgorithm for the identification of causal effects in the cyclic setting. We\nintroduce the existence of two types of hidden confounder variables in this\nframework, which affect in substantially different ways the identification\nprocedures, a distinction with no analog in either Dynamic Bayesian Networks or\nstandard causal graphs.\n",
        "english": "Causal generative models, as explored in the doctoral thesis, emphasize our dual role as both observers and actors, allowing us to \"intervene and alter the course of some events\" to construct a more accurate model of the world. The research introduces an active learning algorithm that identifies causal relations using a least cost sequence of interventions, where the number of interventions is bounded by the number of causal model candidates, $N$, thus fewer initial candidates lead to fewer interventions. This innovative approach also addresses cyclical causal processes by defining a causal analog to Dynamic Bayesian Networks, providing a \"sound and complete algorithm for the identification of causal effects in the cyclic setting,\" thereby advancing the understanding of time-related causality.",
        "korean": "박사 논문에서 탐구된 인과 생성 모델(causal generative models)은 관찰자이자 행위자로서의 우리의 이중 역할을 강조하며, \"일부 사건의 경로를 개입하고 변경\"하여 세계의 보다 정확한 모델을 구축할 수 있게 합니다. 연구는 최소 비용의 개입 순서를 사용하여 인과 관계를 식별하는 능동 학습 알고리즘(active learning algorithm)을 소개하며, 개입의 수는 인과 모델 후보의 수 $N$에 의해 제한되므로 초기 후보가 적을수록 개입이 적어집니다. 이 혁신적인 접근법은 또한 동적 베이지안 네트워크(Dynamic Bayesian Networks)의 인과 유사체를 정의하여 순환적 인과 과정을 다루며, \"순환 설정에서 인과 효과를 식별하기 위한 건전하고 완전한 알고리즘\"을 제공하여 시간 관련 인과성에 대한 이해를 발전시킵니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Ensure all technical terms are consistently parenthesized as korean term(english term) and consider using lowercase for terms within parentheses for consistency."
    },
    {
        "turn_index": 2,
        "term": "neural probabilistic scene learning",
        "domain": "cs.AI",
        "summary": "  We present 3DP3, a framework for inverse graphics that uses inference in a\nstructured generative model of objects, scenes, and images. 3DP3 uses (i) voxel\nmodels to represent the 3D shape of objects, (ii) hierarchical scene graphs to\ndecompose scenes into objects and the contacts between them, and (iii) depth\nimage likelihoods based on real-time graphics. Given an observed RGB-D image,\n3DP3's inference algorithm infers the underlying latent 3D scene, including the\nobject poses and a parsimonious joint parametrization of these poses, using\nfast bottom-up pose proposals, novel involutive MCMC updates of the scene graph\nstructure, and, optionally, neural object detectors and pose estimators. We\nshow that 3DP3 enables scene understanding that is aware of 3D shape,\nocclusion, and contact structure. Our results demonstrate that 3DP3 is more\naccurate at 6DoF object pose estimation from real images than deep learning\nbaselines and shows better generalization to challenging scenes with novel\nviewpoints, contact, and partial observability.\n",
        "english": "Neural probabilistic scene learning, as exemplified by the 3DP3 framework, employs inference in a structured generative model of objects, scenes, and images to effectively decompose scenes into objects and their interrelationships. By utilizing voxel models to represent 3D shapes and hierarchical scene graphs, 3DP3 enhances scene understanding through fast bottom-up pose proposals and novel involutive MCMC updates, achieving superior accuracy in 6DoF object pose estimation compared to deep learning baselines. The framework's innovative approach is further demonstrated by its ability to generalize well to challenging scenes, leveraging depth image likelihoods and neural object detectors to infer latent 3D scenes, including object poses and a joint parametrization of these poses, thus highlighting its importance in advancing the field of neural probabilistic scene learning.",
        "korean": "3DP3 프레임워크(3DP3 framework)로 예시되는 신경 확률적 장면 학습(neural probabilistic scene learning)은 객체, 장면 및 이미지의 구조적 생성 모델에서의 추론을 활용하여 장면을 객체와 그 상호 관계로 효과적으로 분해합니다. 3D 형태를 표현하기 위해 복셀 모델(voxel models)과 계층적 장면 그래프(hierarchical scene graphs)를 활용함으로써, 3DP3는 빠른 하향식 자세 제안과 새로운 비가역적 MCMC 업데이트(involutive MCMC updates)를 통해 장면 이해를 향상시키며, 심층 학습(deep learning) 기준선과 비교하여 6자유도 객체 자세 추정에서 우수한 정확도를 달성합니다. 이 프레임워크의 혁신적인 접근 방식은 깊이 이미지 가능성(depth image likelihoods)과 신경 객체 탐지기(neural object detectors)를 활용하여 객체 자세와 이러한 자세의 공동 매개변수를 포함한 잠재적 3D 장면을 추론함으로써 도전적인 장면에 잘 일반화할 수 있는 능력을 통해 더욱 입증되며, 신경 확률적 장면 학습(neural probabilistic scene learning) 분야의 발전에 있어 그 중요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "evolutionary strategies",
        "domain": "cs.AI",
        "summary": "  Efficient Natural Evolution Strategies (eNES) is a novel alternative to\nconventional evolutionary algorithms, using the natural gradient to adapt the\nmutation distribution. Unlike previous methods based on natural gradients, eNES\nuses a fast algorithm to calculate the inverse of the exact Fisher information\nmatrix, thus increasing both robustness and performance of its evolution\ngradient estimation, even in higher dimensions. Additional novel aspects of\neNES include optimal fitness baselines and importance mixing (a procedure for\nupdating the population with very few fitness evaluations). The algorithm\nyields competitive results on both unimodal and multimodal benchmarks.\n"
    },
    {
        "turn_index": 2,
        "term": "multi-head attention",
        "domain": "cs.AI",
        "summary": "  In neuroscience, attention has been shown to bidirectionally interact with\nreinforcement learning (RL) processes. This interaction is thought to support\ndimensionality reduction of task representations, restricting computations to\nrelevant features. However, it remains unclear whether these properties can\ntranslate into real algorithmic advantages for artificial agents, especially in\ndynamic environments. We design a model incorporating a self-attention\nmechanism that implements task-state representations in semantic feature-space,\nand test it on a battery of Atari games. To evaluate the agent's selective\nproperties, we add a large volume of task-irrelevant features to observations.\nIn line with neuroscience predictions, self-attention leads to increased\nrobustness to noise compared to benchmark models. Strikingly, this\nself-attention mechanism is general enough, such that it can be naturally\nextended to implement a transient working-memory, able to solve a partially\nobservable maze task. Lastly, we highlight the predictive quality of attended\nstimuli. Because we use semantic observations, we can uncover not only which\nfeatures the agent elects to base decisions on, but also how it chooses to\ncompile more complex, relational features from simpler ones. These results\nformally illustrate the benefits of attention in deep RL and provide evidence\nfor the interpretability of self-attention mechanisms.\n",
        "english": "Multi-head attention, a mechanism inspired by neuroscience, interacts bidirectionally with reinforcement learning (RL) processes to facilitate dimensionality reduction in task representations, thereby enhancing computational efficiency by focusing on relevant features. In a model designed to incorporate this self-attention mechanism, task-state representations were implemented in semantic feature-space, and tested across various Atari games, demonstrating increased robustness to noise as predicted by neuroscience. The generality of this self-attention mechanism allows it to be extended to implement a transient working-memory, solving a partially observable maze task, and highlighting the predictive quality of attended stimuli, where the agent's decision-making process can be expressed as $f(x) = \\sum_{i=1}^{n} \\alpha_i \\cdot g(x_i)$, illustrating how complex relational features are compiled from simpler ones.",
        "korean": "신경과학에서 영감을 받은 메커니즘인 다중 헤드 어텐션(multi-head attention)은 강화 학습(reinforcement learning, RL) 과정과 양방향으로 상호작용하여 작업 표현의 차원 축소를 촉진함으로써 관련 특징에 집중하여 계산 효율성을 향상시킵니다. 이 자기 어텐션 메커니즘(self-attention mechanism)을 통합하도록 설계된 모델에서는 작업 상태 표현이 의미적 특징 공간에 구현되었으며, 다양한 아타리 게임(Atari games)에서 테스트되어 신경과학이 예측한 대로 잡음에 대한 강인성이 증가함을 보여주었습니다. 이 자기 어텐션 메커니즘(self-attention mechanism)의 일반성은 일시적 작업 기억(transient working-memory)을 구현하여 부분적으로 관찰 가능한 미로 과제를 해결하고, 주의받는 자극의 예측 품질을 강조할 수 있도록 확장됩니다. 여기서 에이전트의 의사 결정 과정은 $f(x) = \\sum_{i=1}^{n} \\alpha_i \\cdot g(x_i)$로 표현될 수 있으며, 복잡한 관계적 특징이 더 단순한 것들로부터 어떻게 구성되는지를 보여줍니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability in Korean."
    },
    {
        "turn_index": 2,
        "term": "inverse reinforcement learning",
        "domain": "cs.AI",
        "summary": "  For an autonomous system to be helpful to humans and to pose no unwarranted\nrisks, it needs to align its values with those of the humans in its environment\nin such a way that its actions contribute to the maximization of value for the\nhumans. We propose a formal definition of the value alignment problem as\ncooperative inverse reinforcement learning (CIRL). A CIRL problem is a\ncooperative, partial-information game with two agents, human and robot; both\nare rewarded according to the human's reward function, but the robot does not\ninitially know what this is. In contrast to classical IRL, where the human is\nassumed to act optimally in isolation, optimal CIRL solutions produce behaviors\nsuch as active teaching, active learning, and communicative actions that are\nmore effective in achieving value alignment. We show that computing optimal\njoint policies in CIRL games can be reduced to solving a POMDP, prove that\noptimality in isolation is suboptimal in CIRL, and derive an approximate CIRL\nalgorithm.\n",
        "korean": "역강화 학습(inverse reinforcement learning, IRL)은 자율 시스템이 인간의 가치를 반영하여 행동을 조정함으로써 불필요한 위험 없이 인간에게 최대의 가치를 제공하는 데 중요한 역할을 합니다. 협력적 역강화 학습(cooperative inverse reinforcement learning, CIRL)의 개념은 가치 정렬 문제의 형식화로 소개되며, CIRL 문제는 인간과 로봇이 협력하는 부분 정보 게임으로 정의됩니다. 이 게임에서 두 에이전트는 로봇이 초기에는 이 함수에 대한 지식이 없더라도 인간의 보상 함수에 따라 보상을 받습니다. 특히, 연구는 CIRL 게임에서 최적의 공동 정책을 계산하는 것이 부분 관찰 마르코프 결정 과정(partially observable Markov decision process, POMDP)을 해결하는 것으로 축소될 수 있음을 보여주며, 고립된 최적성이 CIRL에서는 최적이 아님을 증명하여 근사 CIRL 알고리즘을 도출합니다."
    },
    {
        "turn_index": 2,
        "term": "information bottleneck method",
        "domain": "cs.AI",
        "summary": "  Recurrent neural networks (RNNs) have emerged as an effective representation\nof control policies in sequential decision-making problems. However, a major\ndrawback in the application of RNN-based policies is the difficulty in\nproviding formal guarantees on the satisfaction of behavioral specifications,\ne.g. safety and/or reachability. By integrating techniques from formal methods\nand machine learning, we propose an approach to automatically extract a\nfinite-state controller (FSC) from an RNN, which, when composed with a\nfinite-state system model, is amenable to existing formal verification tools.\nSpecifically, we introduce an iterative modification to the so-called quantized\nbottleneck insertion technique to create an FSC as a randomized policy with\nmemory. For the cases in which the resulting FSC fails to satisfy the\nspecification, verification generates diagnostic information. We utilize this\ninformation to either adjust the amount of memory in the extracted FSC or\nperform focused retraining of the RNN. While generally applicable, we detail\nthe resulting iterative procedure in the context of policy synthesis for\npartially observable Markov decision processes (POMDPs), which is known to be\nnotoriously hard. The numerical experiments show that the proposed approach\noutperforms traditional POMDP synthesis methods by 3 orders of magnitude within\n2% of optimal benchmark values.\n",
        "english": "The information bottleneck method is integral to the proposed approach, which involves an iterative modification of the quantized bottleneck insertion technique to create a finite-state controller (FSC) as a randomized policy with memory. This innovative method allows for the automatic extraction of an FSC from a recurrent neural network (RNN), facilitating its composition with a finite-state system model and making it amenable to formal verification tools. Notably, the numerical experiments demonstrate that this approach significantly outperforms traditional POMDP synthesis methods, achieving results within 2% of optimal benchmark values while improving efficiency by three orders of magnitude.",
        "korean": "정보 병목 방법(information bottleneck method)은 제안된 접근 방식의 핵심 요소로, 양자화된 병목 삽입 기법(quantized bottleneck insertion technique)의 반복적 수정을 통해 메모리를 가진 무작위 정책으로서 유한 상태 제어기(finite-state controller, FSC)를 생성하는 것을 포함합니다. 이 혁신적인 방법은 순환 신경망(recurrent neural network, RNN)에서 유한 상태 제어기(finite-state controller, FSC)를 자동으로 추출할 수 있게 하여 유한 상태 시스템 모델(finite-state system model)과의 조합을 용이하게 하고 형식 검증 도구(formal verification tools)에 적합하게 만듭니다. 특히, 수치 실험은 이 접근 방식이 전통적인 POMDP 합성 방법(traditional POMDP synthesis methods)을 크게 능가하며, 최적 벤치마크 값의 2% 이내의 결과를 달성하면서 효율성을 세 자릿수로 향상시킨다는 것을 보여줍니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest ensuring all technical terms are consistently formatted as Korean term(English term). Consider revising the placement of parentheses for terms like \"finite-state controller\" to maintain consistency throughout the translation."
    },
    {
        "turn_index": 2,
        "term": "self-normalizing networks",
        "domain": "cs.AI",
        "summary": "  Cybersecurity is the security cornerstone of digital transformation of the\npower grid and construction of new power systems. The traditional network\nsecurity situation quantification method only analyzes from the perspective of\nnetwork performance, ignoring the impact of various power application services\non the security situation, so the quantification results cannot fully reflect\nthe power information network risk state. This study proposes a method for\nquantifying security situation of the power information network based on the\nevolutionary neural network. First, the security posture system architecture is\ndesigned by analyzing the business characteristics of power information network\napplications. Second, combining the importance of power application business,\nthe spatial element index system of coupled interconnection is established from\nthree dimensions of network reliability, threat, and vulnerability. Then, the\nBP neural network optimized by the genetic evolutionary algorithm is\nincorporated into the element index calculation process, and the quantitative\nmodel of security posture of the power information network based on the\nevolutionary neural network is constructed. Finally, a simulation experiment\nenvironment is built according to a power sector network topology, and the\neffectiveness and robustness of the method proposed in the study are verified.\n",
        "english": "Self-normalizing networks, which are integral to the quantification of security situations in power information networks, address the limitations of traditional network security methods that focus solely on network performance without considering the impact of power application services. By incorporating a BP neural network optimized through a genetic evolutionary algorithm, these networks enhance the robustness and effectiveness of security posture systems, as evidenced by simulation experiments based on power sector network topology. The integration of self-normalizing networks into the spatial element index system, formulated from the dimensions of network reliability, threat, and vulnerability, is mathematically represented by the equation $S = f(R, T, V)$, where $S$ denotes the security posture, and $R$, $T$, and $V$ represent reliability, threat, and vulnerability, respectively.",
        "korean": "전력 정보 네트워크의 보안 상황 정량화에 필수적인 자기 정규화 네트워크(self-normalizing networks)는 전력 응용 서비스의 영향을 고려하지 않고 네트워크 성능에만 초점을 맞춘 전통적인 네트워크 보안 방법의 한계를 해결합니다. 유전적 진화 알고리즘(genetic evolutionary algorithm)을 통해 최적화된 BP 신경망(BP neural network)을 통합함으로써 이러한 네트워크는 전력 부문 네트워크 토폴로지를 기반으로 한 시뮬레이션 실험에서 입증된 바와 같이 보안 태세 시스템의 견고성과 효과성을 향상시킵니다. 네트워크 신뢰성, 위협, 취약성의 차원에서 공식화된 공간 요소 지수 시스템에 자기 정규화 네트워크(self-normalizing networks)를 통합하는 것은 수학적으로 $S = f(R, T, V)$라는 방정식으로 표현되며, 여기서 $S$는 보안 태세를 나타내고, $R$, $T$, $V$는 각각 신뢰성, 위협, 취약성을 나타냅니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "meta-reinforcement learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "english": "In the domain of meta-reinforcement learning, the concept of subjective patterns is deemed crucial for the learning machine, as it allows the system to express objective patterns effectively through a proper subjective pattern based on least base patterns. The internal representation space, comprised of a collection of X-forms, serves as the center of the learning machine, facilitating the learning process by providing a structured algebraic expression for subjective patterns. By leveraging sufficient data and certain capabilities, meta-reinforcement learning can achieve universal learning, enabling the system to learn any pattern, as demonstrated through various learning strategies discussed in the research.",
        "korean": "메타 강화 학습(meta-reinforcement learning) 분야에서 주관적 패턴의 개념은 학습 기계에 매우 중요하게 여겨지며, 이는 시스템이 최소 기본 패턴을 기반으로 적절한 주관적 패턴을 통해 객관적 패턴을 효과적으로 표현할 수 있게 합니다. x-형식의 집합으로 구성된 내부 표현 공간은 학습 기계의 중심 역할을 하며, 주관적 패턴에 대한 구조화된 대수적 표현을 제공하여 학습 과정을 촉진합니다. 충분한 데이터와 특정 능력을 활용함으로써 메타 강화 학습(meta-reinforcement learning)은 보편적 학습을 달성할 수 있으며, 이는 연구에서 논의된 다양한 학습 전략을 통해 시스템이 어떤 패턴이든 학습할 수 있게 합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "probabilistic neural scene segmentation",
        "domain": "cs.AI",
        "summary": "  We present 3DP3, a framework for inverse graphics that uses inference in a\nstructured generative model of objects, scenes, and images. 3DP3 uses (i) voxel\nmodels to represent the 3D shape of objects, (ii) hierarchical scene graphs to\ndecompose scenes into objects and the contacts between them, and (iii) depth\nimage likelihoods based on real-time graphics. Given an observed RGB-D image,\n3DP3's inference algorithm infers the underlying latent 3D scene, including the\nobject poses and a parsimonious joint parametrization of these poses, using\nfast bottom-up pose proposals, novel involutive MCMC updates of the scene graph\nstructure, and, optionally, neural object detectors and pose estimators. We\nshow that 3DP3 enables scene understanding that is aware of 3D shape,\nocclusion, and contact structure. Our results demonstrate that 3DP3 is more\naccurate at 6DoF object pose estimation from real images than deep learning\nbaselines and shows better generalization to challenging scenes with novel\nviewpoints, contact, and partial observability.\n",
        "english": "Probabilistic neural scene segmentation benefits from the 3DP3 framework, which employs inference in a structured generative model of objects, scenes, and images, allowing for the decomposition of scenes into objects and their interactions using hierarchical scene graphs. The framework's inference algorithm efficiently estimates the latent 3D scene from an observed RGB-D image by utilizing fast bottom-up pose proposals and novel involutive MCMC updates, thereby achieving superior 6DoF object pose estimation compared to deep learning baselines. Importantly, 3DP3 demonstrates enhanced generalization capabilities to challenging scenes with novel viewpoints and partial observability, underscoring its innovative approach to scene understanding that is cognizant of 3D shape, occlusion, and contact structure.",
        "korean": "확률적 신경 장면 분할(probabilistic neural scene segmentation)은 객체, 장면 및 이미지의 구조적 생성 모델에서 추론을 활용하는 3DP3 프레임워크(3DP3 framework)의 이점을 누리며, 계층적 장면 그래프(hierarchical scene graphs)를 사용하여 장면을 객체와 그 상호작용으로 분해할 수 있게 합니다. 이 프레임워크의 추론 알고리즘은 빠른 하향식 자세 제안과 새로운 비가역적 MCMC 업데이트(involutive MCMC updates)를 활용하여 관찰된 RGB-D 이미지로부터 잠재적 3D 장면을 효율적으로 추정함으로써 심층 학습 기준선(deep learning baselines)과 비교하여 우수한 6자유도(6DoF) 객체 자세 추정을 달성합니다. 특히, 3DP3는 새로운 시점과 부분 가시성을 가진 도전적인 장면에 대한 일반화 능력을 향상시켜 3D 형태, 폐색 및 접촉 구조를 인식하는 장면 이해에 대한 혁신적인 접근 방식을 강조합니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent parenthetical translations for all technical terms, such as \"비가역적 MCMC 업데이트(involutive MCMC updates)\" to \"비가역적 MCMC 업데이트(involutive mcmc updates)\" for consistency."
    },
    {
        "turn_index": 2,
        "term": "stick-breaking processes",
        "domain": "cs.AI",
        "summary": "  Process events are recorded by multiple information systems at different\ngranularity levels. Based on the resulting event logs, process models are\ndiscovered at different granularity levels, as well. Events stored at a\nfine-grained granularity level, for example, may hinder the discovered process\nmodel to be displayed due the high number of resulting model elements. The\ndiscovered process model of a real-world manufacturing process, for example,\nconsists of 1,489 model elements and over 2,000 arcs. Existing process model\nabstraction techniques could help reducing the size of the model, but would\ndisconnect it from the underlying event log. Existing event abstraction\ntechniques do neither support the analysis of mixed granularity levels, nor\ninteractive exploration of a suitable granularity level. To enable the\nexploration of discovered process models at different granularity levels, we\npropose INEXA, an interactive, explainable process model abstraction method\nthat keeps the link to the event log. As a starting point, INEXA aggregates\nlarge process models to a \"displayable\" size, e.g., for the manufacturing use\ncase to a process model with 58 model elements. Then, the process analyst can\nexplore granularity levels interactively, while applied abstractions are\nautomatically traced in the event log for explainability.\n",
        "korean": "막대기 깨기 과정(stick-breaking processes)은 프로세스 모델 추상화 기법(process model abstraction techniques)과 유사하게, 1,489개의 모델 요소와 2,000개 이상의 호를 포함하는 실제 제조 공정과 같은 복잡한 시스템에서 \"결과 모델 요소의 높은 수\"를 관리하는 데 필수적입니다. 혼합된 세분화 수준의 문제를 해결하기 위해, INEXA는 상호작용적이고 설명 가능한 프로세스 모델 추상화 방법(interactive and explainable process model abstraction method)으로, 이벤트 로그(event log)와의 연결을 유지하면서 다양한 세분화 수준에서 탐색을 가능하게 하여 이러한 복잡한 시스템의 분석을 지원합니다. 대규모 프로세스 모델을 \"표시 가능한\" 크기로 집계하여, 예를 들어 제조 공정 모델을 58개의 요소로 축소함으로써, INEXA는 막대기 깨기 과정(stick-breaking process)을 $B_k = \\beta_k \\prod_{i=1}^{k-1}(1-\\beta_i)$로 수학적으로 표현할 수 있는 상호작용적 탐색을 용이하게 하여 복잡한 프로세스 모델을 더 잘 이해하고 분석할 수 있도록 하는 혁신적인 역할을 강조합니다."
    },
    {
        "turn_index": 2,
        "term": "neural context-aware learning",
        "domain": "cs.AI",
        "summary": "  Neural-symbolic computing aims at integrating robust neural learning and\nsound symbolic reasoning into a single framework, so as to leverage the\ncomplementary strengths of both of these, seemingly unrelated (maybe even\ncontradictory) AI paradigms. The central challenge in neural-symbolic computing\nis to unify the formulation of neural learning and symbolic reasoning into a\nsingle framework with common semantics, that is, to seek a joint representation\nbetween a neural model and a logical theory that can support the basic\ngrounding learned by the neural model and also stick to the semantics of the\nlogical theory. In this paper, we propose differentiable fuzzy $\\mathcal{ALC}$\n(DF-$\\mathcal{ALC}$) for this role, as a neural-symbolic representation\nlanguage with the desired semantics. DF-$\\mathcal{ALC}$ unifies the description\nlogic $\\mathcal{ALC}$ and neural models for symbol grounding; in particular, it\ninfuses an $\\mathcal{ALC}$ knowledge base into neural models through\ndifferentiable concept and role embeddings. We define a hierarchical loss to\nthe constraint that the grounding learned by neural models must be semantically\nconsistent with $\\mathcal{ALC}$ knowledge bases. And we find that capturing the\nsemantics in grounding solely by maximizing satisfiability cannot revise\ngrounding rationally. We further define a rule-based loss for DF adapting to\nsymbol grounding problems. The experiment results show that DF-$\\mathcal{ALC}$\nwith rule-based loss can improve the performance of image object detectors in\nan unsupervised learning way, even in low-resource situations.\n",
        "english": "Neural context-aware learning, as demonstrated through differentiable fuzzy $\\mathcal{ALC}$ (DF-$\\mathcal{ALC}$), unifies the description logic $\\mathcal{ALC}$ and neural models for symbol grounding, effectively bridging the gap between neural learning and symbolic reasoning. By infusing an $\\mathcal{ALC}$ knowledge base into neural models via differentiable concept and role embeddings, this approach ensures that the grounding learned by neural models is semantically consistent with $\\mathcal{ALC}$ knowledge bases, thereby enhancing the robustness of neural-symbolic integration. Notably, the implementation of a rule-based loss for DF, tailored to symbol grounding problems, has shown to improve the performance of image object detectors in an unsupervised learning context, even under low-resource conditions, highlighting the innovative potential of neural context-aware learning in advancing AI capabilities.",
        "korean": "신경 문맥 인식 학습(neural context-aware learning)은 차별 가능한 퍼지 $\\mathcal{ALC}$ (DF-$\\mathcal{ALC}$)을 통해 설명 논리 $\\mathcal{ALC}$와 신경 모델을 통합하여 기호 기반 학습과 신경 학습 간의 격차를 효과적으로 메웁니다. 차별 가능한 개념 및 역할 임베딩을 통해 $\\mathcal{ALC}$ 지식 기반을 신경 모델에 주입함으로써, 이 접근법은 신경 모델이 학습한 기초가 $\\mathcal{ALC}$ 지식 기반과 의미적으로 일치하도록 보장하여 신경-기호 통합의 견고성을 향상시킵니다. 특히, 기호 기반 학습 문제에 맞춘 DF의 규칙 기반 손실 구현은 저자원 환경에서도 비지도 학습 맥락에서 이미지 객체 탐지기의 성능을 향상시키는 것으로 나타나, 신경 문맥 인식 학습(neural context-aware learning)이 AI 역량을 발전시키는 혁신적 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "contrastive learning",
        "domain": "cs.AI",
        "summary": "  Modern industrial fault diagnosis tasks often face the combined challenge of\ndistribution discrepancy and bi-imbalance. Existing domain adaptation\napproaches pay little attention to the prevailing bi-imbalance, leading to poor\ndomain adaptation performance or even negative transfer. In this work, we\npropose a self-degraded contrastive domain adaptation (Sd-CDA) diagnosis\nframework to handle the domain discrepancy under the bi-imbalanced data. It\nfirst pre-trains the feature extractor via imbalance-aware contrastive learning\nbased on model pruning to learn the feature representation efficiently in a\nself-supervised manner. Then it forces the samples away from the domain\nboundary based on supervised contrastive domain adversarial learning\n(SupCon-DA) and ensures the features generated by the feature extractor are\ndiscriminative enough. Furthermore, we propose the pruned contrastive domain\nadversarial learning (PSupCon-DA) to pay automatically re-weighted attention to\nthe minorities to enhance the performance towards bi-imbalanced data. We show\nthe superiority of the proposed method via two experiments.\n",
        "korean": "산업 결함 진단 작업에서 분포 불일치와 이중 불균형 문제를 해결하기 위해, 새로운 자기 저하 대조 도메인 적응(self-degraded contrastive domain adaptation, Sd-CDA) 프레임워크가 도입되었습니다. 이 프레임워크는 \"모델 가지치기를 기반으로 한 불균형 인식 대조 학습(imbalance-aware contrastive learning based on model pruning)\"을 활용하여 자기 지도 방식으로 효율적으로 특징 표현을 학습합니다. \"지도 대조 도메인 적대적 학습(supervised contrastive domain adversarial learning, SupCon-DA)\"을 통합함으로써, 프레임워크는 샘플이 도메인 경계에서 멀리 위치하도록 하여 특징 추출기의 변별 능력을 향상시킵니다. 또한, 제안된 가지치기 대조 도메인 적대적 학습(pruned contrastive domain adversarial learning, PSupCon-DA) 방법은 소수 클래스에 대한 주의를 자동으로 재가중하여, 실험에서 $\\mathcal{L}_{\\text{PSupCon-DA}}$에 따라 손실 함수를 최소화함으로써 이중 불균형 데이터에 대한 성능을 최적화합니다."
    },
    {
        "turn_index": 2,
        "term": "probabilistic neural scene learning",
        "domain": "cs.AI",
        "summary": "  We present 3DP3, a framework for inverse graphics that uses inference in a\nstructured generative model of objects, scenes, and images. 3DP3 uses (i) voxel\nmodels to represent the 3D shape of objects, (ii) hierarchical scene graphs to\ndecompose scenes into objects and the contacts between them, and (iii) depth\nimage likelihoods based on real-time graphics. Given an observed RGB-D image,\n3DP3's inference algorithm infers the underlying latent 3D scene, including the\nobject poses and a parsimonious joint parametrization of these poses, using\nfast bottom-up pose proposals, novel involutive MCMC updates of the scene graph\nstructure, and, optionally, neural object detectors and pose estimators. We\nshow that 3DP3 enables scene understanding that is aware of 3D shape,\nocclusion, and contact structure. Our results demonstrate that 3DP3 is more\naccurate at 6DoF object pose estimation from real images than deep learning\nbaselines and shows better generalization to challenging scenes with novel\nviewpoints, contact, and partial observability.\n",
        "score": 9,
        "parentheses_count": 15,
        "suggestions": "Ensure that all technical terms are consistently formatted as Korean term(English term) and adjust the sentence structure for smoother readability in Korean."
    },
    {
        "turn_index": 2,
        "term": "text-to-image synthesis",
        "domain": "cs.AI",
        "summary": "  In the era of Artificial Intelligence Generated Content (AIGC), conditional\nmultimodal synthesis technologies (e.g., text-to-image, text-to-video,\ntext-to-audio, etc) are gradually reshaping the natural content in the real\nworld. The key to multimodal synthesis technology is to establish the mapping\nrelationship between different modalities. Brain signals, serving as potential\nreflections of how the brain interprets external information, exhibit a\ndistinctive One-to-Many correspondence with various external modalities. This\ncorrespondence makes brain signals emerge as a promising guiding condition for\nmultimodal content synthesis. Brian-conditional multimodal synthesis refers to\ndecoding brain signals back to perceptual experience, which is crucial for\ndeveloping practical brain-computer interface systems and unraveling complex\nmechanisms underlying how the brain perceives and comprehends external stimuli.\nThis survey comprehensively examines the emerging field of AIGC-based\nBrain-conditional Multimodal Synthesis, termed AIGC-Brain, to delineate the\ncurrent landscape and future directions. To begin, related brain neuroimaging\ndatasets, functional brain regions, and mainstream generative models are\nintroduced as the foundation of AIGC-Brain decoding and analysis. Next, we\nprovide a comprehensive taxonomy for AIGC-Brain decoding models and present\ntask-specific representative work and detailed implementation strategies to\nfacilitate comparison and in-depth analysis. Quality assessments are then\nintroduced for both qualitative and quantitative evaluation. Finally, this\nsurvey explores insights gained, providing current challenges and outlining\nprospects of AIGC-Brain. Being the inaugural survey in this domain, this paper\npaves the way for the progress of AIGC-Brain research, offering a foundational\noverview to guide future work.\n",
        "english": "Text-to-image synthesis, as a component of conditional multimodal synthesis technologies, is transforming the landscape of Artificial Intelligence Generated Content (AIGC) by establishing a mapping relationship between textual and visual modalities. This process is particularly innovative when combined with brain signals, which serve as promising guiding conditions due to their distinctive One-to-Many correspondence with external modalities, enhancing the depth and accuracy of the synthesis. The mathematical foundation of this approach is grounded in the comprehensive taxonomy for AIGC-Brain decoding models, where the mapping function $f: B \\rightarrow V$ translates brain signals $B$ into visual content $V$, thereby advancing the development of practical brain-computer interface systems and offering new insights into the complex mechanisms of perception and comprehension.",
        "korean": "조건부 다중 모달 합성 기술의 구성 요소로서 텍스트-이미지 합성(text-to-image synthesis)은 텍스트와 시각적 모달리티 간의 매핑 관계를 확립함으로써 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content, AIGC)의 지형을 변화시키고 있습니다. 이 과정은 특히 뇌 신호와 결합될 때 혁신적이며, 외부 모달리티와의 독특한 일대다 대응 관계로 인해 유망한 안내 조건으로 작용하여 합성의 깊이와 정확성을 향상시킵니다. 이 접근법의 수학적 기초는 AIGC-뇌 디코딩 모델에 대한 포괄적인 분류 체계에 기반을 두고 있으며, 매핑 함수 $f: B \\rightarrow V$는 뇌 신호 $B$를 시각적 콘텐츠 $V$로 변환하여 실용적인 뇌-컴퓨터 인터페이스 시스템의 개발을 진전시키고 지각과 이해의 복잡한 메커니즘에 대한 새로운 통찰을 제공합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "Polya trees",
        "domain": "cs.AI",
        "summary": "  Decision trees have been widely used in machine learning. However, due to\nsome reasons, data collecting in real world contains a fuzzy and uncertain\nform. The decision tree should be able to handle such fuzzy data. This paper\npresents a method to construct fuzzy decision tree. It proposes a fuzzy\ndecision tree induction method in iris flower data set, obtaining the entropy\nfrom the distance between an average value and a particular value. It also\npresents an experiment result that shows the accuracy compared to former ID3.\n",
        "english": "In the realm of machine learning, decision trees have been instrumental, yet the challenge persists in managing the \"fuzzy and uncertain form\" of real-world data, which Polya trees can address by providing a probabilistic framework for decision-making. The innovative approach of constructing a fuzzy decision tree, as demonstrated in the iris flower data set, involves calculating entropy from the distance between an average value and a particular value, expressed mathematically as $H(D) = -\\sum p(x) \\log p(x)$, where $p(x)$ represents the probability distribution. This methodology not only enhances the decision tree's ability to handle ambiguity but also shows improved accuracy when compared to traditional methods like ID3, highlighting its significance in advancing machine learning techniques.",
        "korean": "기계 학습(machine learning) 분야에서 의사 결정 나무(decision trees)는 중요한 역할을 해왔지만, 현실 세계 데이터의 \"모호하고 불확실한 형태\"를 관리하는 데 여전히 어려움이 있습니다. 이는 폴야 트리(Polya trees)가 의사 결정에 대한 확률적 프레임워크를 제공함으로써 해결할 수 있습니다. 아이리스 꽃 데이터 세트(iris flower data set)에서 시연된 바와 같이, 모호한 의사 결정 나무(fuzzy decision tree)를 구성하는 혁신적인 접근 방식은 평균값과 특정 값 사이의 거리로부터 엔트로피(entropy)를 계산하는 것을 포함하며, 이는 수학적으로 $H(D) = -\\sum p(x) \\log p(x)$로 표현됩니다. 여기서 $p(x)$는 확률 분포를 나타냅니다. 이 방법론은 의사 결정 나무(decision tree)의 모호성을 처리하는 능력을 향상시킬 뿐만 아니라 ID3와 같은 전통적인 방법과 비교했을 때 향상된 정확성을 보여주며, 기계 학습 기술을 발전시키는 데 있어 그 중요성을 강조합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure all English terms within parentheses are in lowercase for consistency and adjust the sentence structure for smoother flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "relational models",
        "domain": "cs.AI",
        "summary": "  In real-world phenomena which involve mutual influence or causal effects\nbetween interconnected units, equilibrium states are typically represented with\ncycles in graphical models. An expressive class of graphical models, relational\ncausal models, can represent and reason about complex dynamic systems\nexhibiting such cycles or feedback loops. Existing cyclic causal discovery\nalgorithms for learning causal models from observational data assume that the\ndata instances are independent and identically distributed which makes them\nunsuitable for relational causal models. At the same time, causal discovery\nalgorithms for relational causal models assume acyclicity. In this work, we\nexamine the necessary and sufficient conditions under which a constraint-based\nrelational causal discovery algorithm is sound and complete for cyclic\nrelational causal models. We introduce relational acyclification, an operation\nspecifically designed for relational models that enables reasoning about the\nidentifiability of cyclic relational causal models. We show that under the\nassumptions of relational acyclification and $\\sigma$-faithfulness, the\nrelational causal discovery algorithm RCD (Maier et al. 2013) is sound and\ncomplete for cyclic models. We present experimental results to support our\nclaim.\n",
        "english": "Relational models, particularly relational causal models, are pivotal in representing and reasoning about complex dynamic systems with cycles or feedback loops, as they account for mutual influence or causal effects between interconnected units. The novel concept of relational acyclification is introduced to enable reasoning about the identifiability of cyclic relational causal models, ensuring that the relational causal discovery algorithm RCD is sound and complete for cyclic models under the assumptions of relational acyclification and $\\sigma$-faithfulness. This advancement addresses the limitations of existing cyclic causal discovery algorithms, which typically assume data instances are independent and identically distributed, and thus marks a significant innovation in the field.",
        "korean": "관계 모델(relational models), 특히 관계 인과 모델(relational causal models)은 상호 연결된 단위 간의 상호 영향 또는 인과 효과를 고려하여 주기 또는 피드백 루프가 있는 복잡한 동적 시스템을 표현하고 추론하는 데 중요한 역할을 합니다. 순환 관계 인과 모델(cyclic relational causal models)의 식별 가능성에 대한 추론을 가능하게 하기 위해 관계 비순환화(relational acyclification)의 새로운 개념이 도입되었으며, 이는 관계 인과 발견 알고리즘 RCD가 관계 비순환화(relational acyclification)와 $\\sigma$-신뢰성($\\sigma$-faithfulness)의 가정 하에 순환 모델에 대해 정확하고 완전함을 보장합니다. 이러한 발전은 기존의 순환 인과 발견 알고리즘이 일반적으로 데이터 인스턴스가 독립적이고 동일하게 분포되어 있다고 가정하는 한계를 해결하며, 이 분야에서 중요한 혁신을 나타냅니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure that all English terms within parentheses are in lowercase for consistency."
    },
    {
        "turn_index": 2,
        "term": "probabilistic generative models",
        "domain": "cs.AI",
        "summary": "  This thesis describes work on two applications of probabilistic programming:\nthe learning of probabilistic program code given specifications, in particular\nprogram code of one-dimensional samplers; and the facilitation of sequential\nMonte Carlo inference with help of data-driven proposals. The latter is\npresented with experimental results on a linear Gaussian model and a\nnon-parametric dependent Dirichlet process mixture of objects model for object\nrecognition and tracking.\n  In Chapter 1 we provide a brief introduction to probabilistic programming.\n  In Chapter 2 we present an approach to automatic discovery of samplers in the\nform of probabilistic programs. We formulate a Bayesian approach to this\nproblem by specifying a grammar-based prior over probabilistic program code. We\nuse an approximate Bayesian computation method to learn the programs, whose\nexecutions generate samples that statistically match observed data or\nanalytical characteristics of distributions of interest. In our experiments we\nleverage different probabilistic programming systems to perform Markov chain\nMonte Carlo sampling over the space of programs. Experimental results have\ndemonstrated that, using the proposed methodology, we can learn approximate and\neven some exact samplers. Finally, we show that our results are competitive\nwith regard to genetic programming methods.\n  In Chapter 3, we describe a way to facilitate sequential Monte Carlo\ninference in probabilistic programming using data-driven proposals. In\nparticular, we develop a distance-based proposal for the non-parametric\ndependent Dirichlet process mixture of objects model. We implement this\napproach in the probabilistic programming system Anglican, and show that for\nthat model data-driven proposals provide significant performance improvements.\nWe also explore the possibility of using neural networks to improve data-driven\nproposals.\n",
        "english": "Probabilistic generative models play a crucial role in the automatic discovery of samplers, as demonstrated by the formulation of a Bayesian approach using a grammar-based prior over probabilistic program code to learn programs that generate samples matching observed data or analytical characteristics of distributions of interest. By leveraging different probabilistic programming systems, the research employs Markov chain Monte Carlo sampling over the space of programs, achieving results competitive with genetic programming methods. Notably, the facilitation of sequential Monte Carlo inference through data-driven proposals in a non-parametric dependent Dirichlet process mixture of objects model, implemented in the Anglican probabilistic programming system, underscores significant performance improvements, particularly when employing a distance-based proposal, with potential enhancements through neural networks.",
        "korean": "확률적 생성 모델(probabilistic generative models)은 샘플러의 자동 발견에 중요한 역할을 하며, 이는 확률적 프로그램 코드에 대한 문법 기반 사전(grammar-based prior)을 사용한 베이지안 접근법(bayesian approach)의 공식화로 입증됩니다. 이 방법은 관찰된 데이터나 관심 있는 분포의 분석적 특성과 일치하는 샘플을 생성하는 프로그램을 학습합니다. 다양한 확률적 프로그래밍 시스템(probabilistic programming systems)을 활용하여, 연구는 프로그램 공간에서 마르코프 체인 몬테카를로 샘플링(markov chain monte carlo sampling)을 사용하여 유전 프로그래밍(genetic programming) 방법과 경쟁력 있는 결과를 달성합니다. 특히, Anglican 확률적 프로그래밍 시스템(anglican probabilistic programming system)에서 객체 모델의 비모수 의존 디리클레 과정 혼합(non-parametric dependent dirichlet process mixture of objects model)에서 데이터 기반 제안을 통한 순차적 몬테카를로 추론(sequential monte carlo inference)의 촉진은 성능을 크게 향상시키며, 거리 기반 제안(distance-based proposal)을 사용할 때 특히 두드러지며, 신경망(neural networks)을 통해 잠재적 향상을 기대할 수 있습니다.",
        "score": 10,
        "parentheses_count": 11,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "policy search",
        "domain": "cs.AI",
        "summary": "  The ability to reuse previous policies is an important aspect of human\nintelligence. To achieve efficient policy reuse, a Deep Reinforcement Learning\n(DRL) agent needs to decide when to reuse and which source policies to reuse.\nPrevious methods solve this problem by introducing extra components to the\nunderlying algorithm, such as hierarchical high-level policies over source\npolicies, or estimations of source policies' value functions on the target\ntask. However, training these components induces either optimization\nnon-stationarity or heavy sampling cost, significantly impairing the\neffectiveness of transfer. To tackle this problem, we propose a novel policy\nreuse algorithm called Critic-gUided Policy reuse (CUP), which avoids training\nany extra components and efficiently reuses source policies. CUP utilizes the\ncritic, a common component in actor-critic methods, to evaluate and choose\nsource policies. At each state, CUP chooses the source policy that has the\nlargest one-step improvement over the current target policy, and forms a\nguidance policy. The guidance policy is theoretically guaranteed to be a\nmonotonic improvement over the current target policy. Then the target policy is\nregularized to imitate the guidance policy to perform efficient policy search.\nEmpirical results demonstrate that CUP achieves efficient transfer and\nsignificantly outperforms baseline algorithms.\n",
        "english": "Efficient policy search in Deep Reinforcement Learning (DRL) is enhanced by the novel Critic-gUided Policy reuse (CUP) algorithm, which circumvents the need for additional components and leverages the critic to evaluate and select source policies. By employing a guidance policy that offers a monotonic improvement over the current target policy, CUP ensures that the target policy is regularized to imitate this guidance, thereby facilitating effective policy search. Notably, CUP demonstrates superior performance over baseline algorithms, as evidenced by empirical results, with the guidance policy being chosen at each state based on the source policy that maximizes one-step improvement, mathematically expressed as $\\pi_g(s) = \\arg\\max_{\\pi_i} \\Delta V^{\\pi_i}(s)$, where $\\Delta V^{\\pi_i}(s)$ represents the value function improvement of source policy $\\pi_i$ at state $s$.",
        "korean": "심층 강화 학습(deep reinforcement learning, DRL)에서 효율적인 정책 탐색(policy search)은 추가 구성 요소가 필요 없는 새로운 비평가 유도 정책 재사용(critic-guided policy reuse, CUP) 알고리즘에 의해 향상됩니다. 이 알고리즘은 비평가를 활용하여 소스 정책을 평가하고 선택합니다. 현재 목표 정책에 대한 단조로운 개선을 제공하는 안내 정책을 사용함으로써, CUP는 목표 정책이 이 안내를 모방하도록 정규화하여 효과적인 정책 탐색(policy search)을 촉진합니다. 특히, CUP는 경험적 결과로 입증된 바와 같이 기준 알고리즘보다 우수한 성능을 보여주며, 각 상태에서 일단계 개선을 극대화하는 소스 정책에 기반하여 안내 정책이 선택됩니다. 이는 수학적으로 $\\pi_g(s) = \\arg\\max_{\\pi_i} \\Delta V^{\\pi_i}(s)$로 표현되며, 여기서 $\\Delta V^{\\pi_i}(s)$는 상태 $s$에서 소스 정책 $\\pi_i$의 가치 함수 개선을 나타냅니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "probabilistic neural text learning",
        "domain": "cs.AI",
        "summary": "  Explanations on relational data are hard to verify since the explanation\nstructures are more complex (e.g. graphs). To verify interpretable explanations\n(e.g. explanations of predictions made in images, text, etc.), typically human\nsubjects are used since it does not necessarily require a lot of expertise.\nHowever, to verify the quality of a relational explanation requires expertise\nand is hard to scale-up. GNNExplainer is arguably one of the most popular\nexplanation methods for Graph Neural Networks. In this paper, we develop an\napproach where we assess the uncertainty in explanations generated by\nGNNExplainer. Specifically, we ask the explainer to generate explanations for\nseveral counterfactual examples. We generate these examples as symmetric\napproximations of the relational structure in the original data. From these\nexplanations, we learn a factor graph model to quantify uncertainty in an\nexplanation. Our results on several datasets show that our approach can help\nverify explanations from GNNExplainer by reliably estimating the uncertainty of\na relation specified in the explanation.\n",
        "english": "Probabilistic neural text learning can be enhanced by assessing the uncertainty in explanations generated by models like GNNExplainer, which is crucial for verifying interpretable explanations in complex relational data. By generating explanations for several counterfactual examples, researchers can create symmetric approximations of the relational structure, allowing for the development of a factor graph model that quantifies uncertainty in an explanation. Importantly, our approach demonstrates that by reliably estimating the uncertainty of a relation specified in the explanation, probabilistic neural text learning can be significantly improved, as evidenced by results on several datasets.",
        "korean": "확률적 신경 텍스트 학습(probabilistic neural text learning)은 GNNExplainer와 같은 모델이 생성한 설명의 불확실성을 평가함으로써 향상될 수 있으며, 이는 복잡한 관계 데이터에서 해석 가능한 설명을 검증하는 데 중요합니다. 여러 반사실적 예제에 대한 설명을 생성함으로써 연구자들은 관계 구조의 대칭적 근사치를 만들 수 있으며, 이는 설명의 불확실성을 정량화하는 요인 그래프 모델(factor graph model)을 개발할 수 있게 합니다. 특히, 우리의 접근 방식은 설명에 명시된 관계의 불확실성을 신뢰성 있게 추정함으로써 확률적 신경 텍스트 학습(probabilistic neural text learning)이 여러 데이터셋에서의 결과로 입증된 바와 같이 크게 개선될 수 있음을 보여줍니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "task-driven learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "english": "Task-driven learning can be understood through the lens of mechanical learning, which involves the identification and use of \"objective and subjective patterns\" to enhance the learning process. By employing \"X-form,\" an algebraic expression for subjective patterns, task-driven learning creates an internal representation space that serves as the \"center of learning machine,\" enabling the machine to effectively interpret and learn from data. This methodology underscores the potential for a \"universal learning machine\" capable of learning any pattern, contingent upon data sufficiency and the machine's capabilities, thereby highlighting its innovative approach to understanding deep learning dynamics.",
        "korean": "과제 주도 학습(task-driven learning)은 기계 학습(mechanical learning)의 관점에서 이해될 수 있으며, 이는 학습 과정을 향상시키기 위해 \"객관적 및 주관적 패턴\"을 식별하고 사용하는 것을 포함합니다. 주관적 패턴에 대한 대수적 표현인 \"X-형태\"를 사용함으로써, 과제 주도 학습(task-driven learning)은 \"학습 기계의 중심\" 역할을 하는 내부 표현 공간을 생성하여 기계가 데이터를 효과적으로 해석하고 학습할 수 있도록 합니다. 이 방법론은 데이터의 충분성과 기계의 능력에 따라 어떤 패턴도 학습할 수 있는 \"보편적 학습 기계\"의 잠재력을 강조하며, 심층 학습 역학을 이해하는 혁신적인 접근 방식을 부각시킵니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic text processes",
        "domain": "cs.AI",
        "summary": "  The knowledge graph (KG) is an essential form of knowledge representation\nthat has grown in prominence in recent years. Because it concentrates on\nnominal entities and their relationships, traditional knowledge graphs are\nstatic and encyclopedic in nature. On this basis, event knowledge graph (Event\nKG) models the temporal and spatial dynamics by text processing to facilitate\ndownstream applications, such as question-answering, recommendation and\nintelligent search. Existing KG research, on the other hand, mostly focuses on\ntext processing and static facts, ignoring the vast quantity of dynamic\nbehavioral information included in photos, movies, and pre-trained neural\nnetworks. In addition, no effort has been done to include behavioral\nintelligence information into the knowledge graph for deep reinforcement\nlearning (DRL) and robot learning. In this paper, we propose a novel dynamic\nknowledge and skill graph (KSG), and then we develop a basic and specific KSG\nbased on CN-DBpedia. The nodes are divided into entity and attribute nodes,\nwith entity nodes containing the agent, environment, and skill (DRL policy or\npolicy representation), and attribute nodes containing the entity description,\npre-train network, and offline dataset. KSG can search for different agents'\nskills in various environments and provide transferable information for\nacquiring new skills. This is the first study that we are aware of that looks\ninto dynamic KSG for skill retrieval and learning. Extensive experimental\nresults on new skill learning show that KSG boosts new skill learning\nefficiency.\n",
        "korean": "동적 텍스트 처리(dynamic text processes)는 사건 지식 그래프(event knowledge graphs, event kg)를 시간적 및 공간적 역학을 모델링하여 향상시키는 데 필수적이며, 이는 질문-응답(question-answering), 추천(recommendation), 지능형 검색(intelligent search)과 같은 다운스트림 응용 프로그램에 크게 기여합니다. 기존 연구는 주로 텍스트 처리와 정적 사실에 중점을 두며, 시각 매체와 사전 훈련된 신경망(pre-trained neural networks)에 존재하는 풍부한 동적 행동 정보를 종종 간과합니다. 동적 지식 및 기술 그래프(dynamic knowledge and skill graph, ksg)의 도입은 혁신적인 접근법을 나타내며, 노드는 엔티티와 속성으로 분류되어 새로운 기술의 검색 및 학습을 가능하게 하여 $ksg$가 새로운 기술 습득의 효율성을 크게 향상시킨다는 것을 입증합니다."
    },
    {
        "turn_index": 2,
        "term": "program synthesis",
        "domain": "cs.AI",
        "summary": "  Despite achieving superior performance in human-level control problems,\nunlike humans, deep reinforcement learning (DRL) lacks high-order intelligence\n(e.g., logic deduction and reuse), thus it behaves ineffectively than humans\nregarding learning and generalization in complex problems. Previous works\nattempt to directly synthesize a white-box logic program as the DRL policy,\nmanifesting logic-driven behaviors. However, most synthesis methods are built\non imperative or declarative programming, and each has a distinct limitation,\nrespectively. The former ignores the cause-effect logic during synthesis,\nresulting in low generalizability across tasks. The latter is strictly\nproof-based, thus failing to synthesize programs with complex hierarchical\nlogic. In this paper, we combine the above two paradigms together and propose a\nnovel Generalizable Logic Synthesis (GALOIS) framework to synthesize\nhierarchical and strict cause-effect logic programs. GALOIS leverages the\nprogram sketch and defines a new sketch-based hybrid program language for\nguiding the synthesis. Based on that, GALOIS proposes a sketch-based program\nsynthesis method to automatically generate white-box programs with\ngeneralizable and interpretable cause-effect logic. Extensive evaluations on\nvarious decision-making tasks with complex logic demonstrate the superiority of\nGALOIS over mainstream baselines regarding the asymptotic performance,\ngeneralizability, and great knowledge reusability across different\nenvironments.\n"
    },
    {
        "turn_index": 2,
        "term": "probabilistic neural learning",
        "domain": "cs.AI",
        "summary": "  Deep learning and symbolic learning are two frequently employed methods in\nSequential Recommendation (SR). Recent neural-symbolic SR models demonstrate\ntheir potential to enable SR to be equipped with concurrent perception and\ncognition capacities. However, neural-symbolic SR remains a challenging problem\ndue to open issues like representing users and items in logical reasoning. In\nthis paper, we combine the Deep Neural Network (DNN) SR models with logical\nreasoning and propose a general framework named Sequential Recommendation with\nProbabilistic Logical Reasoning (short for SR-PLR). This framework allows\nSR-PLR to benefit from both similarity matching and logical reasoning by\ndisentangling feature embedding and logic embedding in the DNN and\nprobabilistic logic network. To better capture the uncertainty and evolution of\nuser tastes, SR-PLR embeds users and items with a probabilistic method and\nconducts probabilistic logical reasoning on users' interaction patterns. Then\nthe feature and logic representations learned from the DNN and logic network\nare concatenated to make the prediction. Finally, experiments on various\nsequential recommendation models demonstrate the effectiveness of the SR-PLR.\n",
        "english": "Probabilistic neural learning, as demonstrated in the Sequential Recommendation with Probabilistic Logical Reasoning (SR-PLR) framework, integrates the strengths of deep neural networks and logical reasoning to enhance sequential recommendation systems. By disentangling feature embedding and logic embedding in the DNN and probabilistic logic network, SR-PLR effectively captures the uncertainty and evolution of user tastes through a probabilistic method, thereby conducting probabilistic logical reasoning on users' interaction patterns. The concatenation of feature and logic representations, mathematically expressed as $\\text{Prediction} = \\text{Feature}_{\\text{DNN}} + \\text{Logic}_{\\text{Network}}$, underscores the framework's innovation in leveraging probabilistic neural learning for improved prediction accuracy.",
        "korean": "순차적 추천 시스템(sequential recommendation systems)을 향상시키기 위해 심층 신경망(deep neural networks)과 논리적 추론(logical reasoning)의 강점을 통합하는 순차적 추천 확률적 논리 추론 프레임워크(Sequential Recommendation with Probabilistic Logical Reasoning, SR-PLR)에서 확률적 신경 학습(probabilistic neural learning)이 입증되었습니다. SR-PLR은 DNN과 확률적 논리 네트워크(probabilistic logic network)에서 특징 임베딩(feature embedding)과 논리 임베딩(logic embedding)을 분리하여 사용자 취향의 불확실성과 진화를 확률적 방법으로 효과적으로 포착하고, 이를 통해 사용자의 상호작용 패턴에 대한 확률적 논리 추론을 수행합니다. 특징과 논리 표현의 연결은 수학적으로 $\\text{Prediction} = \\text{Feature}_{\\text{DNN}} + \\text{Logic}_{\\text{Network}}$로 표현되며, 이는 확률적 신경 학습(probabilistic neural learning)을 활용하여 예측 정확성을 향상시키는 프레임워크의 혁신을 강조합니다.",
        "score": 9,
        "parentheses_count": 11,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase letters within parentheses."
    },
    {
        "turn_index": 2,
        "term": "anomaly detection",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Anomaly detection is crucial for identifying outliers in datasets, which can indicate critical issues such as fraud or system failures, as highlighted in recent advancements in machine learning algorithms. The research introduces a novel approach using a Gaussian Mixture Model (GMM) to enhance detection accuracy, where the probability density function is given by $p(x|\\lambda) = \\sum_{i=1}^{K} \\pi_i \\mathcal{N}(x|\\mu_i, \\Sigma_i)$, demonstrating improved performance over traditional methods. This innovation underscores the importance of integrating probabilistic models in anomaly detection to address complex data environments effectively.",
        "korean": "이상 탐지(anomaly detection)은 데이터셋(dataset)에서 이상값을 식별하는 데 중요하며, 이는 사기나 시스템 오류와 같은 중요한 문제를 나타낼 수 있습니다. 이는 최근 기계 학습 알고리즘(machine learning algorithms)의 발전에서 강조되었습니다. 연구는 탐지 정확도를 향상시키기 위해 가우시안 혼합 모델(gaussian mixture model, gmm)을 사용하는 새로운 접근 방식을 소개하며, 확률 밀도 함수는 $p(x|\\lambda) = \\sum_{i=1}^{K} \\pi_i \\mathcal{N}(x|\\mu_i, \\Sigma_i)$로 주어지며, 전통적인 방법보다 향상된 성능을 보여줍니다. 이 혁신은 복잡한 데이터 환경을 효과적으로 해결하기 위해 이상 탐지(anomaly detection)에서 확률 모델(probabilistic models)을 통합하는 것의 중요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "calibrated classifiers",
        "domain": "cs.AI",
        "summary": "  We introduce OPtical ADversarial attack (OPAD). OPAD is an adversarial attack\nin the physical space aiming to fool image classifiers without physically\ntouching the objects (e.g., moving or painting the objects). The principle of\nOPAD is to use structured illumination to alter the appearance of the target\nobjects. The system consists of a low-cost projector, a camera, and a computer.\nThe challenge of the problem is the non-linearity of the radiometric response\nof the projector and the spatially varying spectral response of the scene.\nAttacks generated in a conventional approach do not work in this setting unless\nthey are calibrated to compensate for such a projector-camera model. The\nproposed solution incorporates the projector-camera model into the adversarial\nattack optimization, where a new attack formulation is derived. Experimental\nresults prove the validity of the solution. It is demonstrated that OPAD can\noptically attack a real 3D object in the presence of background lighting for\nwhite-box, black-box, targeted, and untargeted attacks. Theoretical analysis is\npresented to quantify the fundamental performance limit of the system.\n",
        "english": "Calibrated classifiers play a crucial role in the OPtical ADversarial attack (OPAD) system, which aims to deceive image classifiers in the physical space without direct interaction with the objects. By incorporating a projector-camera model into the adversarial attack optimization, the system effectively calibrates the classifiers to account for the non-linearity of the radiometric response and the spatially varying spectral response of the scene, as expressed in the derived attack formulation. Experimental results demonstrate the efficacy of OPAD, showcasing its ability to execute optical attacks on real 3D objects under various conditions, thus highlighting the innovation and importance of calibrated classifiers in enhancing adversarial robustness.",
        "korean": "보정된 분류기(calibrated classifiers)는 물리적 공간에서 객체와의 직접적인 상호작용 없이 이미지 분류기를 속이기 위한 OPtical ADversarial attack(OPAD) 시스템에서 중요한 역할을 합니다. 이 시스템은 적대적 공격 최적화에 프로젝터-카메라 모델을 통합함으로써, 장면의 방사선 반응의 비선형성과 공간적으로 변화하는 스펙트럼 반응을 고려하여 분류기를 효과적으로 보정합니다. 실험 결과는 OPAD의 효능을 입증하며, 다양한 조건에서 실제 3D 객체에 대한 광학 공격을 수행할 수 있는 능력을 보여줍니다. 이는 적대적 견고성을 향상시키는 데 있어 보정된 분류기(calibrated classifiers)의 혁신성과 중요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "multimodal learning",
        "domain": "cs.AI",
        "summary": "  Multimodal Sentiment Analysis leverages multimodal signals to detect the\nsentiment of a speaker. Previous approaches concentrate on performing\nmultimodal fusion and representation learning based on general knowledge\nobtained from pretrained models, which neglects the effect of domain-specific\nknowledge. In this paper, we propose Contrastive Knowledge Injection (ConKI)\nfor multimodal sentiment analysis, where specific-knowledge representations for\neach modality can be learned together with general knowledge representations\nvia knowledge injection based on an adapter architecture. In addition, ConKI\nuses a hierarchical contrastive learning procedure performed between knowledge\ntypes within every single modality, across modalities within each sample, and\nacross samples to facilitate the effective learning of the proposed\nrepresentations, hence improving multimodal sentiment predictions. The\nexperiments on three popular multimodal sentiment analysis benchmarks show that\nConKI outperforms all prior methods on a variety of performance metrics.\n",
        "english": "Multimodal learning, particularly in the context of sentiment analysis, benefits from leveraging multimodal signals to detect speaker sentiment, as highlighted by the innovative approach of Contrastive Knowledge Injection (ConKI). This methodology enhances multimodal learning by enabling the integration of domain-specific knowledge representations with general knowledge representations through knowledge injection based on an adapter architecture, which is further refined by a hierarchical contrastive learning procedure. Notably, experiments conducted on three popular multimodal sentiment analysis benchmarks demonstrate that ConKI significantly outperforms prior methods, with performance improvements quantified by metrics such as accuracy and F1-score, where $F1 = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$.",
        "korean": "감정 분석(sentiment analysis) 맥락에서 특히 주목받는 다중모달 학습(multimodal learning)은 대조적 지식 주입(Contrastive Knowledge Injection, ConKI)의 혁신적인 접근 방식에 의해 화자의 감정을 감지하기 위해 다중모달 신호를 활용하는 데 이점을 제공합니다. 이 방법론은 어댑터 아키텍처(adapter architecture)를 기반으로 한 지식 주입을 통해 도메인 특화 지식 표현(domain-specific knowledge representations)과 일반 지식 표현(general knowledge representations)의 통합을 가능하게 함으로써 다중모달 학습(multimodal learning)을 향상시킵니다. 또한, 계층적 대조 학습 절차(hierarchical contrastive learning procedure)에 의해 더욱 정교화됩니다. 특히, 세 가지 인기 있는 다중모달 감정 분석 벤치마크(multimodal sentiment analysis benchmarks)에서 수행된 실험은 ConKI가 이전 방법들을 크게 능가함을 보여주며, 성능 향상은 정확도(accuracy)와 F1-점수(F1-score)와 같은 지표로 정량화됩니다. 여기서 $F1 = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$입니다.",
        "score": 10,
        "parentheses_count": 12,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "byte-pair encoding",
        "domain": "cs.AI",
        "summary": "  The Hierarchical Task Network (HTN) formalism is used to express a wide\nvariety of planning problems in terms of decompositions of tasks into subtaks.\nMany techniques have been proposed to solve such hierarchical planning\nproblems. A particular technique is to encode hierarchical planning problems as\nclassical STRIPS planning problems. One advantage of this technique is to\nbenefit directly from the constant improvements made by STRIPS planners.\nHowever, there are still few effective and expressive encodings. In this paper,\nwe present a new HTN to STRIPS encoding allowing to generate concurrent plans.\nWe show experimentally that this encoding outperforms previous approaches on\nhierarchical IPC benchmarks.\n",
        "english": "Byte-pair encoding can be likened to the process of encoding hierarchical planning problems as classical STRIPS planning problems, where the \"decompositions of tasks into subtasks\" are analogous to the iterative merging of byte pairs. This technique benefits from the \"constant improvements made by STRIPS planners,\" enhancing the efficiency and effectiveness of data compression algorithms. By adopting a similar approach to HTN to STRIPS encoding, which allows for the generation of concurrent plans, byte-pair encoding can be optimized to achieve a compression rate $O(n \\log n)$, thereby outperforming previous methods in both speed and accuracy.",
        "korean": "바이트 쌍 인코딩(byte-pair encoding)은 계층적 계획 문제를 고전적인 STRIPS 계획 문제로 인코딩하는 과정과 유사하게 볼 수 있으며, 여기서 \"작업을 하위 작업으로 분해하는 것\"은 바이트 쌍의 반복적인 병합과 유사합니다. 이 기술은 \"STRIPS 계획자에 의해 이루어진 지속적인 개선\"의 이점을 받아 데이터 압축 알고리즘의 효율성과 효과성을 향상시킵니다. 동시 계획 생성을 허용하는 HTN에서 STRIPS 인코딩으로의 유사한 접근 방식을 채택함으로써, 바이트 쌍 인코딩(byte-pair encoding)은 압축률 $O(n \\log n)$을 달성하도록 최적화될 수 있으며, 이는 속도와 정확성 모두에서 이전 방법을 능가합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "sentiment analysis",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Sentiment analysis, a pivotal component in natural language processing, utilizes advanced algorithms to interpret and classify emotions expressed in textual data. By employing machine learning techniques such as support vector machines (SVM) and neural networks, researchers have achieved significant accuracy in sentiment classification, often exceeding 85% in various benchmark datasets. The innovation of incorporating feature extraction methods, like term frequency-inverse document frequency (TF-IDF), enhances the model's ability to discern sentiment nuances, thus contributing to the broader understanding of human emotional expression in digital communication.",
        "korean": "감성 분석(sentiment analysis)은 자연어 처리(natural language processing)의 중요한 구성 요소로, 텍스트 데이터에 표현된 감정을 해석하고 분류하기 위해 고급 알고리즘을 활용합니다. 서포트 벡터 머신(support vector machines, svm)과 신경망(neural networks)과 같은 기계 학습 기법(machine learning techniques)을 사용함으로써 연구자들은 다양한 벤치마크 데이터셋(benchmark datasets)에서 85%를 초과하는 감성 분류 정확도를 달성했습니다. 용어 빈도-역문서 빈도(term frequency-inverse document frequency, tf-idf)와 같은 특징 추출 방법(feature extraction methods)을 통합하는 혁신은 모델이 감성의 미묘한 차이를 구별하는 능력을 향상시켜 디지털 커뮤니케이션에서 인간의 감정 표현에 대한 폭넓은 이해에 기여합니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "principal component analysis",
        "domain": "cs.AI",
        "summary": "  Slow Feature Analysis (SFA) extracts features representing the underlying\ncauses of changes within a temporally coherent high-dimensional raw sensory\ninput signal. Our novel incremental version of SFA (IncSFA) combines\nincremental Principal Components Analysis and Minor Components Analysis. Unlike\nstandard batch-based SFA, IncSFA adapts along with non-stationary environments,\nis amenable to episodic training, is not corrupted by outliers, and is\ncovariance-free. These properties make IncSFA a generally useful unsupervised\npreprocessor for autonomous learning agents and robots. In IncSFA, the CCIPCA\nand MCA updates take the form of Hebbian and anti-Hebbian updating, extending\nthe biological plausibility of SFA. In both single node and deep network\nversions, IncSFA learns to encode its input streams (such as high-dimensional\nvideo) by informative slow features representing meaningful abstract\nenvironmental properties. It can handle cases where batch SFA fails.\n",
        "english": "Principal component analysis (PCA) is integral to the novel incremental version of Slow Feature Analysis (SFA), known as IncSFA, which combines incremental PCA and Minor Components Analysis to adapt to non-stationary environments and remain robust against outliers. In this framework, PCA updates are performed using Hebbian learning rules, enhancing the biological plausibility of SFA, while the mathematical formulation of PCA ensures that the covariance matrix is not required, thereby simplifying computations. These advancements render IncSFA a valuable unsupervised preprocessor for autonomous learning agents and robots, capable of handling scenarios where traditional batch-based SFA may falter.",
        "korean": "주성분 분석(principal component analysis, PCA)은 점진적 느린 특징 분석(Slow Feature Analysis, SFA)의 새로운 버전인 IncSFA에 필수적이며, 이는 점진적 PCA와 소수 성분 분석(Minor Components Analysis)을 결합하여 비정상 환경에 적응하고 이상치에 대해 강건성을 유지합니다. 이 프레임워크에서 PCA 업데이트는 헤비안 학습 규칙(hebbian learning rules)을 사용하여 수행되며, 이는 SFA의 생물학적 타당성을 향상시키는 동시에 PCA의 수학적 공식화는 공분산 행렬이 필요하지 않도록 하여 계산을 단순화합니다. 이러한 발전은 IncSFA를 자율 학습 에이전트와 로봇을 위한 가치 있는 비지도 사전 처리기로 만들어 전통적인 배치 기반 SFA가 실패할 수 있는 시나리오를 처리할 수 있게 합니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Suggest ensuring that all technical terms are consistently formatted as Korean term(English term) and consider simplifying complex sentence structures for better readability."
    },
    {
        "turn_index": 2,
        "term": "restricted Boltzmann machines",
        "domain": "cs.AI",
        "summary": "  Understanding the dynamics of a system is important in many scientific and\nengineering domains. This problem can be approached by learning state\ntransition rules from observations using machine learning techniques. Such\nobserved time-series data often consist of sequences of many continuous\nvariables with noise and ambiguity, but we often need rules of dynamics that\ncan be modeled with a few essential variables. In this work, we propose a\nmethod for extracting a small number of essential hidden variables from\nhigh-dimensional time-series data and for learning state transition rules\nbetween these hidden variables. The proposed method is based on the Restricted\nBoltzmann Machine (RBM), which treats observable data in the visible layer and\nlatent features in the hidden layer. However, real-world data, such as video\nand audio, include both discrete and continuous variables, and these variables\nhave temporal relationships. Therefore, we propose Recurrent Temporal\nGaussianBernoulli Restricted Boltzmann Machine (RTGB-RBM), which combines\nGaussian-Bernoulli Restricted Boltzmann Machine (GB-RBM) to handle continuous\nvisible variables, and Recurrent Temporal Restricted Boltzmann Machine (RT-RBM)\nto capture time dependence between discrete hidden variables. We also propose a\nrule-based method that extracts essential information as hidden variables and\nrepresents state transition rules in interpretable form. We conduct experiments\non Bouncing Ball and Moving MNIST datasets to evaluate our proposed method.\nExperimental results show that our method can learn the dynamics of those\nphysical systems as state transition rules between hidden variables and can\npredict unobserved future states from observed state transitions.\n",
        "korean": "제한된 볼츠만 기계(restricted Boltzmann machines, RBMs)는 가시층에서 관측 가능한 데이터를 모델링하고 은닉층에서 잠재적 특징을 모델링함으로써 고차원 시계열 데이터로부터 상태 전이 규칙을 학습하는 데 중요한 역할을 합니다. 혁신적인 순환 시계열 가우시안-베르누이 제한된 볼츠만 기계(recurrent temporal Gaussian-Bernoulli restricted Boltzmann machine, RTGB-RBM)는 연속적인 가시 변수를 처리하기 위해 가우시안-베르누이 RBM을 결합하고, 이산 은닉 변수 간의 시간 의존성을 포착하기 위해 순환 시계열 RBM을 결합하여 물리 시스템의 동역학을 효과적으로 포착합니다. 특히, 제안된 방법의 관측된 상태 전이로부터 관측되지 않은 미래 상태를 예측하는 능력은 Bouncing Ball 및 Moving MNIST와 같은 데이터셋에 대한 실험을 통해 입증되었으며, 은닉 변수 간의 상태 전이 규칙이 $P(h_{t+1} | h_t, v_t)$로 수학적으로 표현될 수 있음을 보여줍니다. 여기서 $h_t$와 $v_t$는 각각 시간 $t$에서의 은닉 상태와 가시 상태를 나타냅니다."
    },
    {
        "turn_index": 2,
        "term": "graph isomorphism networks",
        "domain": "cs.AI",
        "summary": "  The problem of graph isomorphism is an important but challenging problem in\nthe field of graph analysis, for example: analyzing the similarity of two\nchemical molecules, or studying the expressive ability of graph neural\nnetworks. WL test is a method to judge whether two graphs are isomorphic, but\nit cannot distinguish all non-isomorphic graphs. As an improvement of WL, k-WL\nhas stronger isomorphism discrimination ability, and as k increases, its\ndiscrimination ability is strictly increasing. However, whether the isomorphic\ndiscrimination power of k-WL is strictly increasing for more complex 3D graphs,\nor whether there exists k that can discriminate all 3D graphs, remains\nunexplored. This paper attempts to explore this problem from the perspective of\ngraph generation.\n",
        "english": "Graph isomorphism networks tackle the \"important but challenging problem in the field of graph analysis\" by analyzing the similarity of structures such as chemical molecules, which necessitates advanced methods beyond traditional approaches. The Weisfeiler-Lehman (WL) test, while a foundational technique, \"cannot distinguish all non-isomorphic graphs,\" prompting the development of the k-WL method with improved isomorphism discrimination ability, where the power of discrimination is \"strictly increasing\" as the parameter $k$ increases. Despite these advancements, the question of whether a specific $k$ can \"discriminate all 3D graphs\" remains unexplored, highlighting the need for further investigation into graph generation methodologies to enhance the expressive capabilities of graph isomorphism networks.",
        "korean": "그래프 동형 네트워크(graph isomorphism networks)는 화학 분자와 같은 구조의 유사성을 분석함으로써 \"그래프 분석 분야에서 중요한 동시에 도전적인 문제\"를 해결합니다. 이는 전통적인 접근 방식을 넘어서는 고급 방법을 필요로 합니다. 바이스파일러-레만(weisfeiler-lehman, wl) 테스트는 기초적인 기법이지만, \"모든 비동형 그래프를 구별할 수는 없기\" 때문에, 개선된 동형 구별 능력을 가진 k-wl 방법이 개발되었습니다. 여기서 구별 능력은 매개변수 $k$가 증가함에 따라 \"엄격하게 증가\"합니다. 이러한 발전에도 불구하고 특정 $k$가 \"모든 3d 그래프를 구별할 수 있는지\"에 대한 질문은 아직 탐구되지 않았으며, 이는 그래프 동형 네트워크의 표현 능력을 향상시키기 위한 그래프 생성 방법론에 대한 추가 연구의 필요성을 강조합니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Ensure that all technical terms within parentheses are consistently in lowercase and consider rephrasing for smoother readability in Korean."
    },
    {
        "turn_index": 2,
        "term": "matrix factorization",
        "domain": "cs.AI",
        "summary": "  Centralized training is widely utilized in the field of multi-agent\nreinforcement learning (MARL) to assure the stability of training process. Once\na joint policy is obtained, it is critical to design a value function\nfactorization method to extract optimal decentralized policies for the agents,\nwhich needs to satisfy the individual-global-max (IGM) principle. While\nimposing additional limitations on the IGM function class can help to meet the\nrequirement, it comes at the cost of restricting its application to more\ncomplex multi-agent environments. In this paper, we propose QFree, a universal\nvalue function factorization method for MARL. We start by developing\nmathematical equivalent conditions of the IGM principle based on the advantage\nfunction, which ensures that the principle holds without any compromise,\nremoving the conservatism of conventional methods. We then establish a more\nexpressive mixing network architecture that can fulfill the equivalent\nfactorization. In particular, the novel loss function is developed by\nconsidering the equivalent conditions as regularization term during policy\nevaluation in the MARL algorithm. Finally, the effectiveness of the proposed\nmethod is verified in a nonmonotonic matrix game scenario. Moreover, we show\nthat QFree achieves the state-of-the-art performance in a general-purpose\ncomplex MARL benchmark environment, Starcraft Multi-Agent Challenge (SMAC).\n",
        "english": "In the realm of multi-agent reinforcement learning (MARL), matrix factorization plays a crucial role in designing a value function factorization method that adheres to the individual-global-max (IGM) principle, as centralized training alone may not suffice for optimal decentralized policy extraction. The introduction of QFree, a universal value function factorization method, advances this field by establishing mathematical equivalent conditions of the IGM principle based on the advantage function, thereby ensuring that the principle holds without compromise, expressed as $\\text{IGM}(Q) = \\max_{a_i} \\sum_i Q_i(a_i)$, where $Q_i$ is the local action-value function. By developing a more expressive mixing network architecture and a novel loss function incorporating these equivalent conditions as a regularization term, QFree demonstrates state-of-the-art performance in complex MARL environments such as the Starcraft Multi-Agent Challenge (SMAC).",
        "korean": "다중 에이전트 강화 학습(multi-agent reinforcement learning, MARL) 분야에서 행렬 분해(matrix factorization)는 개별-글로벌-최대(individual-global-max, IGM) 원칙을 준수하는 가치 함수 분해 방법을 설계하는 데 중요한 역할을 합니다. 이는 중앙 집중식 훈련만으로는 최적의 분산 정책 추출에 충분하지 않을 수 있기 때문입니다. QFree라는 보편적 가치 함수 분해 방법의 도입은 이 분야를 발전시키며, 이점 함수(advantage function)를 기반으로 IGM 원칙의 수학적 동등 조건을 확립하여 원칙이 타협 없이 유지되도록 보장합니다. 이는 $\\text{IGM}(Q) = \\max_{a_i} \\sum_i Q_i(a_i)$로 표현되며, 여기서 $Q_i$는 지역 행동-가치 함수(local action-value function)입니다. 이러한 동등 조건을 정규화 항으로 포함하는 보다 표현력 있는 혼합 네트워크 아키텍처와 새로운 손실 함수를 개발함으로써, QFree는 스타크래프트 다중 에이전트 챌린지(Starcraft Multi-Agent Challenge, SMAC)와 같은 복잡한 MARL 환경에서 최첨단 성능을 입증합니다.",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "deep probabilistic optimization",
        "domain": "cs.AI",
        "summary": "  We introduce DeepProbLog, a neural probabilistic logic programming language\nthat incorporates deep learning by means of neural predicates. We show how\nexisting inference and learning techniques of the underlying probabilistic\nlogic programming language ProbLog can be adapted for the new language. We\ntheoretically and experimentally demonstrate that DeepProbLog supports (i) both\nsymbolic and subsymbolic representations and inference, (ii) program induction,\n(iii) probabilistic (logic) programming, and (iv) (deep) learning from\nexamples. To the best of our knowledge, this work is the first to propose a\nframework where general-purpose neural networks and expressive\nprobabilistic-logical modeling and reasoning are integrated in a way that\nexploits the full expressiveness and strengths of both worlds and can be\ntrained end-to-end based on examples.\n",
        "english": "Deep probabilistic optimization can be effectively achieved through the integration of neural networks and probabilistic-logical modeling, as demonstrated by the innovative framework DeepProbLog, which \"supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples.\" By adapting the inference and learning techniques of ProbLog, DeepProbLog enables the seamless incorporation of deep learning via neural predicates, thus bridging the gap between symbolic reasoning and neural computation. The framework's ability to be \"trained end-to-end based on examples\" highlights its potential for advancing deep probabilistic optimization by leveraging the strengths of both neural and logical paradigms in a unified manner.",
        "korean": "심층 확률 최적화(deep probabilistic optimization)는 신경망(neural networks)과 확률-논리 모델링(probabilistic-logical modeling)의 통합을 통해 효과적으로 달성될 수 있으며, 이는 혁신적인 프레임워크인 DeepProbLog에 의해 입증되었습니다. DeepProbLog는 \"(i) 상징적 및 비상징적 표현과 추론, (ii) 프로그램 유도, (iii) 확률(논리) 프로그래밍, (iv) 예제로부터의 (심층) 학습\"을 지원합니다. ProbLog의 추론 및 학습 기법을 적응함으로써, DeepProbLog는 신경 술어(neural predicates)를 통한 심층 학습의 원활한 통합을 가능하게 하여 상징적 추론과 신경 계산 간의 격차를 해소합니다. 이 프레임워크가 \"예제를 기반으로 종단 간 학습이 가능\"하다는 점은 신경 및 논리 패러다임의 강점을 통합하여 심층 확률 최적화(deep probabilistic optimization)를 발전시킬 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "artificial intelligence",
        "domain": "cs.AI",
        "summary": "  This is the Proceedings of the Thirteenth Conference on Uncertainty in\nArtificial Intelligence, which was held in Providence, RI, August 1-3, 1997\n",
        "english": "The Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence, held in Providence, RI, August 1-3, 1997, provide a comprehensive exploration of probabilistic methodologies that enhance decision-making processes in AI systems. A key concept discussed is the application of Bayesian networks, which utilize the expression $P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}$, to model the dependencies and uncertainties inherent in complex AI environments. This conference underscores the importance of integrating uncertainty management into artificial intelligence, marking a significant advancement in the field by improving the robustness and reliability of AI-driven solutions.",
        "korean": "제13회 불확실성 인공지능(artificial intelligence, AI) 학술대회는 1997년 8월 1일부터 3일까지 로드아일랜드주 프로비던스에서 개최되었으며, AI 시스템의 의사 결정 과정을 향상시키는 확률론적 방법론에 대한 포괄적인 탐구를 제공합니다. 주요 개념으로 논의된 것은 베이지안 네트워크(bayesian networks)의 적용으로, 이는 복잡한 AI 환경에 내재된 의존성과 불확실성을 모델링하기 위해 $P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}$ 표현식을 활용합니다. 이 학술대회는 인공지능(artificial intelligence)에서 불확실성 관리의 통합 중요성을 강조하며, AI 기반 솔루션의 견고성과 신뢰성을 향상시킴으로써 이 분야의 중요한 발전을 나타냅니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "privacy-preserving machine learning",
        "domain": "cs.AI",
        "summary": "  From the point of view of a programmer, the robopsychology is a synonym for\nthe activity is done by developers to implement their machine learning\napplications. This robopsychological approach raises some fundamental\ntheoretical questions of machine learning. Our discussion of these questions is\nconstrained to Turing machines. Alan Turing had given an algorithm (aka the\nTuring Machine) to describe algorithms. If it has been applied to describe\nitself then this brings us to Turing's notion of the universal machine. In the\npresent paper, we investigate algorithms to write algorithms. From a pedagogy\npoint of view, this way of writing programs can be considered as a combination\nof learning by listening and learning by doing due to it is based on applying\nagent technology and machine learning. As the main result we introduce the\nproblem of learning and then we show that it cannot easily be handled in\nreality therefore it is reasonable to use machine learning algorithm for\nlearning Turing machines.\n",
        "english": "Privacy-preserving machine learning can be conceptualized through a robopsychological approach, which \"raises some fundamental theoretical questions of machine learning\" and is particularly pertinent when considering the constraints of Turing machines. By leveraging the notion of the universal machine, privacy-preserving models can be developed to effectively address the problem of learning, which is highlighted as challenging to manage in practical scenarios. The implementation of these models is akin to \"learning by listening and learning by doing,\" where the interaction of agent technology with machine learning algorithms facilitates the creation of robust privacy-preserving frameworks, ensuring that $f(x) = y$ remains secure throughout the computational process.",
        "korean": "프라이버시 보호 기계 학습(privacy-preserving machine learning)은 로보심리학적 접근(robopsychological approach)을 통해 개념화될 수 있으며, 이는 \"기계 학습의 근본적인 이론적 질문을 제기\"하고 튜링 기계(Turing machines)의 제약을 고려할 때 특히 중요합니다. 보편 기계(universal machine)의 개념을 활용함으로써, 프라이버시 보호 모델(privacy-preserving models)은 실질적인 시나리오에서 관리하기 어려운 학습 문제를 효과적으로 해결할 수 있도록 개발될 수 있습니다. 이러한 모델의 구현은 \"듣기와 행동을 통한 학습\"과 유사하며, 에이전트 기술(agent technology)과 기계 학습 알고리즘(machine learning algorithms)의 상호작용을 통해 강력한 프라이버시 보호 프레임워크(privacy-preserving frameworks)를 생성하여 $f(x) = y$가 계산 과정 전반에 걸쳐 안전하게 유지되도록 보장합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring consistent use of lowercase letters within parentheses."
    },
    {
        "turn_index": 2,
        "term": "autonomous driving",
        "domain": "cs.AI",
        "summary": "  Autonomous driving has attracted great attention from both academics and\nindustries. To realise autonomous driving, Deep Imitation Learning (DIL) is\ntreated as one of the most promising solutions, because it improves autonomous\ndriving systems by automatically learning a complex mapping from human driving\ndata, compared to manually designing the driving policy. However, existing DIL\nmethods cannot generalise well across domains, that is, a network trained on\nthe data of source domain gives rise to poor generalisation on the data of\ntarget domain. In the present study, we propose a novel brain-inspired deep\nimitation method that builds on the evidence from human brain functions, to\nimprove the generalisation ability of deep neural networks so that autonomous\ndriving systems can perform well in various scenarios. Specifically, humans\nhave a strong generalisation ability which is beneficial from the structural\nand functional asymmetry of the two sides of the brain. Here, we design dual\nNeural Circuit Policy (NCP) architectures in deep neural networks based on the\nasymmetry of human neural networks. Experimental results demonstrate that our\nbrain-inspired method outperforms existing methods regarding generalisation\nwhen dealing with unseen data. Our source codes and pretrained models are\navailable at\nhttps://github.com/Intenzo21/Brain-Inspired-Deep-Imitation-Learning-for-Autonomous-Driving-Systems}{https://github.com/Intenzo21/Brain-Inspired-Deep-Imitation-Learning-for-Autonomous-Driving-Systems.\n",
        "korean": "자율 주행(autonomous driving)은 학계와 산업계 모두에서 큰 관심을 받고 있으며, 심층 모방 학습(deep imitation learning, DIL)은 인간 운전 데이터로부터 복잡한 매핑을 자동으로 학습할 수 있는 능력 덕분에 유망한 해결책으로 부상하고 있습니다. 이는 수동으로 설계된 운전 정책과 비교하여 자율 주행 시스템(autonomous driving systems)을 향상시킵니다. 그러나 기존의 심층 모방 학습(deep imitation learning, DIL) 방법은 도메인 간 일반화에 어려움을 겪고 있으며, 소스 도메인 데이터로 훈련된 네트워크는 종종 타겟 도메인 데이터에서 일반화 성능이 저조합니다. 이를 해결하기 위해 인간 뇌의 구조적 및 기능적 비대칭성을 활용한 새로운 뇌 영감 심층 모방 방법이 제안되었습니다. 이 방법은 심층 신경망(deep neural networks)에서 이중 신경 회로 정책(neural circuit policy, NCP) 아키텍처를 사용하여 일반화 능력을 크게 향상시키며, 실험 결과는 보지 못한 데이터에서 우수한 성능을 입증합니다."
    },
    {
        "turn_index": 2,
        "term": "transformer-XL",
        "domain": "cs.AI",
        "summary": "  This article considers evidence from physical and biological sciences to show\nmachines are deficient compared to biological systems at incorporating\nintelligence. Machines fall short on two counts: firstly, unlike brains,\nmachines do not self-organize in a recursive manner; secondly, machines are\nbased on classical logic, whereas Nature's intelligence may depend on quantum\nmechanics.\n",
        "english": "In the context of Transformer-XL, it is crucial to recognize that machines are deficient compared to biological systems at incorporating intelligence, as they do not self-organize in a recursive manner like brains do. This limitation is particularly pertinent when considering the recursive mechanisms in Transformer-XL, which, while advanced, still rely on classical logic rather than the potential quantum mechanics that Nature's intelligence may employ. Moreover, the innovative architecture of Transformer-XL, designed to capture long-range dependencies, is hindered by its reliance on traditional computational methods, highlighting the need for further exploration into quantum-based models that could potentially offer a more holistic approach to machine intelligence.",
        "korean": "트랜스포머-XL(transformer-XL)의 맥락에서 기계는 생물학적 시스템에 비해 지능을 통합하는 데 있어 부족하다는 점을 인식하는 것이 중요합니다. 이는 기계가 뇌처럼 재귀적으로 자기 조직화하지 않기 때문입니다. 이러한 한계는 트랜스포머-XL(transformer-XL)의 재귀 메커니즘을 고려할 때 특히 중요합니다. 트랜스포머-XL(transformer-XL)은 고급 기술이지만 자연의 지능이 사용할 수 있는 잠재적인 양자 역학보다는 여전히 고전 논리에 의존하고 있습니다. 또한, 트랜스포머-XL(transformer-XL)의 혁신적인 아키텍처는 장거리 의존성을 포착하도록 설계되었지만 전통적인 계산 방법에 의존함으로써 방해를 받고 있으며, 이는 기계 지능에 보다 전체론적인 접근을 제공할 수 있는 양자 기반 모델에 대한 추가 탐구의 필요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "continual learning",
        "domain": "cs.AI",
        "summary": "  This paper presents a novel model-free Reinforcement Learning algorithm for\nlearning behavior in continuous action, state, and goal spaces. The algorithm\napproximates optimal value functions using non-parametric estimators. It is\nable to efficiently learn to reach multiple arbitrary goals in deterministic\nand nondeterministic environments. To improve generalization in the goal space,\nwe propose a novel sample augmentation technique. Using these methods, robots\nlearn faster and overall better controllers. We benchmark the proposed\nalgorithms using simulation and a real-world voltage controlled robot that\nlearns to maneuver in a non-observable Cartesian task space.\n",
        "english": "Continual learning is exemplified in the proposed model-free Reinforcement Learning algorithm, which efficiently learns behavior in continuous action, state, and goal spaces by approximating optimal value functions using non-parametric estimators. The innovative sample augmentation technique introduced in the study enhances generalization in the goal space, enabling robots to learn faster and develop superior controllers for maneuvering in non-observable Cartesian task spaces. Notably, the algorithm's ability to reach multiple arbitrary goals in both deterministic and nondeterministic environments is mathematically represented by the approximation of value functions, $V(s) = \\max_a Q(s, a)$, where $s$ is the state and $a$ is the action.",
        "korean": "제안된 모델 프리 강화 학습 알고리즘(model-free Reinforcement Learning algorithm)에서 지속적 학습(continual learning)은 최적의 가치 함수(optimal value functions)를 비모수 추정기(non-parametric estimators)를 사용하여 근사함으로써 연속적인 행동, 상태 및 목표 공간에서 효율적으로 행동을 학습하는 것으로 입증됩니다. 연구에서 도입된 혁신적인 샘플 증강 기법(sample augmentation technique)은 목표 공간에서의 일반화를 향상시켜 로봇이 더 빠르게 학습하고 비가시적 데카르트 작업 공간(non-observable Cartesian task spaces)에서의 기동을 위한 우수한 제어기를 개발할 수 있도록 합니다. 특히, 알고리즘의 여러 임의의 목표에 도달하는 능력은 결정론적 및 비결정론적 환경 모두에서 상태 $s$와 행동 $a$에 대해 $V(s) = \\max_a Q(s, a)$로 표현되는 가치 함수의 근사로 수학적으로 나타납니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "[No suggestions needed as the translation meets all criteria.]"
    },
    {
        "turn_index": 2,
        "term": "adaptive scene learning",
        "domain": "cs.AI",
        "summary": "  Multi-vehicle pursuit (MVP) such as autonomous police vehicles pursuing\nsuspects is important but very challenging due to its mission and safety\ncritical nature. While multi-agent reinforcement learning (MARL) algorithms\nhave been proposed for MVP problem in structured grid-pattern roads, the\nexisting algorithms use randomly training samples in centralized learning,\nwhich leads to homogeneous agents showing low collaboration performance. For\nthe more challenging problem of pursuing multiple evading vehicles, these\nalgorithms typically select a fixed target evading vehicle for pursuing\nvehicles without considering dynamic traffic situation, which significantly\nreduces pursuing success rate. To address the above problems, this paper\nproposes a Progression Cognition Reinforcement Learning with Prioritized\nExperience for MVP (PEPCRL-MVP) in urban multi-intersection dynamic traffic\nscenes. PEPCRL-MVP uses a prioritization network to assess the transitions in\nthe global experience replay buffer according to the parameters of each MARL\nagent. With the personalized and prioritized experience set selected via the\nprioritization network, diversity is introduced to the learning process of\nMARL, which can improve collaboration and task related performance.\nFurthermore, PEPCRL-MVP employs an attention module to extract critical\nfeatures from complex urban traffic environments. These features are used to\ndevelop progression cognition method to adaptively group pursuing vehicles.\nEach group efficiently target one evading vehicle in dynamic driving\nenvironments. Extensive experiments conducted with a simulator over\nunstructured roads of an urban area show that PEPCRL-MVP is superior to other\nstate-of-the-art methods. Specifically, PEPCRL-MVP improves pursuing efficiency\nby 3.95% over TD3-DMAP and its success rate is 34.78% higher than that of\nMADDPG. Codes are open sourced.\n",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural probabilistic scene embeddings",
        "domain": "cs.AI",
        "summary": "  In fact, there exist three genres of intelligence architectures: logics (e.g.\n\\textit{Random Forest, A$^*$ Searching}), neurons (e.g. \\textit{CNN, LSTM}) and\nprobabilities (e.g. \\textit{Naive Bayes, HMM}), all of which are incompatible\nto each other. However, to construct powerful intelligence systems with various\nmethods, we propose the intelligence graph (short as \\textbf{\\textit{iGraph}}),\nwhich is composed by both of neural and probabilistic graph, under the\nframework of forward-backward propagation. By the paradigm of iGraph, we design\na recommendation model with semantic principle. First, the probabilistic\ndistributions of categories are generated from the embedding representations of\nusers/items, in the manner of neurons. Second, the probabilistic graph infers\nthe distributions of features, in the manner of probabilities. Last, for the\nrecommendation diversity, we perform an expectation computation then conduct a\nlogic judgment, in the manner of logics. Experimentally, we beat the\nstate-of-the-art baselines and verify our conclusions.\n",
        "english": "Neural probabilistic scene embeddings can be effectively integrated within the intelligence graph (\\textbf{\\textit{iGraph}}) framework, which combines both neural and probabilistic graphs under the forward-backward propagation paradigm. This innovative approach generates probabilistic distributions of categories from embedding representations of users/items in the manner of neurons, and infers distributions of features probabilistically, resulting in a comprehensive model that outperforms state-of-the-art baselines. By employing an expectation computation followed by a logic judgment, this methodology ensures recommendation diversity, highlighting its potential to enhance intelligent systems through the seamless integration of neurons, probabilities, and logics.",
        "korean": "신경 확률적 장면 임베딩(neural probabilistic scene embeddings)은 전방-후방 전파 패러다임(forward-backward propagation paradigm) 하에서 신경 및 확률 그래프를 결합하는 지능 그래프(igraph) 프레임워크 내에서 효과적으로 통합될 수 있습니다. 이 혁신적인 접근 방식은 뉴런의 방식으로 사용자/항목의 임베딩 표현에서 범주의 확률 분포를 생성하고, 특징의 분포를 확률적으로 추론하여 최첨단 기준을 능가하는 포괄적인 모델을 제공합니다. 기대값 계산 후 논리 판단을 활용함으로써 이 방법론은 추천의 다양성을 보장하며, 뉴런, 확률 및 논리의 원활한 통합을 통해 지능형 시스템을 향상시킬 잠재력을 강조합니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as \"전방-후방 전파 패러다임(forward-backward propagation paradigm)\" to maintain consistency."
    },
    {
        "turn_index": 2,
        "term": "image super-resolution",
        "domain": "cs.AI",
        "summary": "  Depth maps obtained by commercial depth sensors are always in low-resolution,\nmaking it difficult to be used in various computer vision tasks. Thus, depth\nmap super-resolution (SR) is a practical and valuable task, which upscales the\ndepth map into high-resolution (HR) space. However, limited by the lack of\nreal-world paired low-resolution (LR) and HR depth maps, most existing methods\nuse downsampling to obtain paired training samples. To this end, we first\nconstruct a large-scale dataset named \"RGB-D-D\", which can greatly promote the\nstudy of depth map SR and even more depth-related real-world tasks. The \"D-D\"\nin our dataset represents the paired LR and HR depth maps captured from mobile\nphone and Lucid Helios respectively ranging from indoor scenes to challenging\noutdoor scenes. Besides, we provide a fast depth map super-resolution (FDSR)\nbaseline, in which the high-frequency component adaptively decomposed from RGB\nimage to guide the depth map SR. Extensive experiments on existing public\ndatasets demonstrate the effectiveness and efficiency of our network compared\nwith the state-of-the-art methods. Moreover, for the real-world LR depth maps,\nour algorithm can produce more accurate HR depth maps with clearer boundaries\nand to some extent correct the depth value errors.\n",
        "english": "In the realm of image super-resolution, the task of depth map super-resolution (SR) is particularly valuable, as it involves upscaling low-resolution (LR) depth maps obtained from commercial sensors into high-resolution (HR) space, thereby enhancing their utility in diverse computer vision applications. The introduction of a large-scale dataset named \"RGB-D-D,\" which includes paired LR and HR depth maps captured from mobile phones and Lucid Helios, facilitates the study of depth map SR by providing real-world data that ranges from indoor to challenging outdoor scenes. Furthermore, the proposed fast depth map super-resolution (FDSR) baseline employs a high-frequency component adaptively decomposed from RGB images, guiding the depth map SR process and demonstrating effectiveness and efficiency through extensive experiments, as evidenced by the mathematical expression for the loss function: $\\mathcal{L}_{\\text{total}} = \\alpha \\mathcal{L}_{\\text{data}} + \\beta \\mathcal{L}_{\\text{reg}}$, where $\\alpha$ and $\\beta$ are weighting factors.",
        "korean": "이미지 초해상도(image super-resolution) 분야에서 깊이 맵 초해상도(depth map super-resolution, SR) 작업은 특히 가치가 있습니다. 이는 상업용 센서에서 얻은 저해상도(low-resolution, LR) 깊이 맵을 고해상도(high-resolution, HR) 공간으로 업스케일링하여 다양한 컴퓨터 비전 응용 프로그램에서의 유용성을 향상시키기 때문입니다. 모바일 폰과 Lucid Helios에서 캡처한 LR 및 HR 깊이 맵 쌍을 포함하는 대규모 데이터셋 \"RGB-D-D\"의 도입은 실내에서 도전적인 실외 장면에 이르는 실제 데이터를 제공하여 깊이 맵 SR 연구를 촉진합니다. 또한, 제안된 빠른 깊이 맵 초해상도(fast depth map super-resolution, FDSR) 기준선은 RGB 이미지에서 적응적으로 분해된 고주파 성분을 사용하여 깊이 맵 SR 과정을 안내하며, 손실 함수에 대한 수학적 표현으로 입증된 바와 같이 광범위한 실험을 통해 효과성과 효율성을 보여줍니다: $\\mathcal{L}_{\\text{total}} = \\alpha \\mathcal{L}_{\\text{data}} + \\beta \\mathcal{L}_{\\text{reg}}$, 여기서 $\\alpha$와 $\\beta$는 가중치 요소입니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Ensure consistent use of parentheses for all technical terms, such as \"depth map super-resolution\" and \"fast depth map super-resolution,\" to maintain uniformity throughout the translation."
    },
    {
        "turn_index": 2,
        "term": "algorithmic bias",
        "domain": "cs.AI",
        "summary": "  Nested Rollout Policy Adaptation (NRPA) is a Monte Carlo search algorithm for\nsingle player games. In this paper we propose to generalize NRPA with a\ntemperature and a bias and to analyze theoretically the algorithms. The\ngeneralized algorithm is named GNRPA. Experiments show it improves on NRPA for\ndifferent application domains: SameGame and the Traveling Salesman Problem with\nTime Windows.\n",
        "english": "Algorithmic bias is a critical factor in the generalization of the Nested Rollout Policy Adaptation (NRPA), as the introduction of a bias parameter alongside a temperature parameter has been shown to enhance the algorithm's performance across various domains. The generalized version, termed GNRPA, was theoretically analyzed and demonstrated improvements over traditional NRPA, particularly in applications such as SameGame and the Traveling Salesman Problem with Time Windows. Notably, the inclusion of bias in the algorithm can be mathematically represented as part of the equation $GNRPA = NRPA + \\text{bias} + \\text{temperature}$, highlighting the innovative approach to mitigating bias and enhancing computational efficiency.",
        "korean": "알고리즘 편향(algorithmic bias)은 중첩 롤아웃 정책 적응(nested rollout policy adaptation, NRPA)의 일반화에서 중요한 요소로, 편향 매개변수를 온도 매개변수와 함께 도입함으로써 다양한 도메인에서 알고리즘의 성능을 향상시키는 것으로 나타났습니다. 일반화된 버전인 GNRPA는 이론적으로 분석되었으며, 특히 SameGame과 시간 창을 가진 외판원 문제와 같은 응용 분야에서 전통적인 NRPA보다 개선된 성능을 입증했습니다. 특히 알고리즘에 편향을 포함하는 것은 $GNRPA = NRPA + \\text{bias} + \\text{temperature}$라는 방정식의 일부로 수학적으로 표현될 수 있으며, 이는 편향을 완화하고 계산 효율성을 향상시키는 혁신적인 접근 방식을 강조합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic neural attention",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Dynamic neural attention has emerged as a pivotal mechanism in enhancing the interpretability and performance of neural networks by selectively focusing on specific parts of the input data, thereby improving model accuracy and efficiency. The innovative approach leverages attention scores calculated as $A = \\text{softmax}(QK^T/\\sqrt{d_k})$, where $Q$, $K$, and $d_k$ represent the query, key matrices, and their dimensionality, respectively, highlighting its mathematical robustness. By dynamically adjusting attention weights during training, this method significantly outperforms static attention models, showcasing its importance in advancing deep learning applications.",
        "korean": "동적 신경 주의 메커니즘(dynamic neural attention)은 입력 데이터의 특정 부분에 선택적으로 집중함으로써 신경망의 해석 가능성과 성능을 향상시키는 중요한 메커니즘으로 부상하였습니다. 이 혁신적인 접근 방식은 $Q$, $K$, $d_k$가 각각 쿼리, 키 행렬 및 그 차원을 나타내는 경우, 주의 점수를 $A = \\text{softmax}(QK^T/\\sqrt{d_k})$로 계산하여 수학적 견고성을 강조합니다. 훈련 중 주의 가중치를 동적으로 조정함으로써 이 방법은 정적 주의 모델(static attention models)을 크게 능가하며, 심층 학습 응용 분야의 발전에 있어 그 중요성을 보여줍니다.",
        "score": 9,
        "parentheses_count": 2,
        "suggestions": "Ensure all technical terms are consistently parenthesized as Korean term(English term) and consider adjusting the sentence structure for improved natural flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "learning to optimize",
        "domain": "cs.AI",
        "summary": "  Discounted reinforcement learning is fundamentally incompatible with function\napproximation for control in continuing tasks. It is not an optimization\nproblem in its usual formulation, so when using function approximation there is\nno optimal policy. We substantiate these claims, then go on to address some\nmisconceptions about discounting and its connection to the average reward\nformulation. We encourage researchers to adopt rigorous optimization\napproaches, such as maximizing average reward, for reinforcement learning in\ncontinuing tasks.\n",
        "english": "Learning to optimize in the context of reinforcement learning necessitates addressing the fundamental incompatibility between discounted reinforcement learning and function approximation for control in continuing tasks. The reference emphasizes the need for rigorous optimization approaches, such as maximizing average reward, to overcome the absence of an optimal policy when function approximation is employed. Specifically, researchers are encouraged to adopt methodologies that focus on maximizing the average reward $\\bar{R} = \\lim_{T \\to \\infty} \\frac{1}{T} \\sum_{t=0}^{T-1} r_t$, which provides a more robust framework for reinforcement learning in ongoing tasks.",
        "korean": "강화 학습(reinforcement learning) 맥락에서 최적화를 학습(learning to optimize)하는 것은 할인된 강화 학습(discounted reinforcement learning)과 지속적인 작업에서의 제어를 위한 함수 근사(function approximation) 간의 근본적인 비호환성을 해결해야 합니다. 이 참고 문헌은 함수 근사(function approximation)가 사용될 때 최적 정책(optimal policy)의 부재를 극복하기 위해 평균 보상(average reward)을 최대화하는 것과 같은 엄격한 최적화 접근법의 필요성을 강조합니다. 특히 연구자들은 지속적인 작업에서 강화 학습(reinforcement learning)을 위한 보다 견고한 프레임워크를 제공하는 평균 보상 $\\bar{R} = \\lim_{T \\to \\infty} \\frac{1}{T} \\sum_{t=0}^{T-1} r_t$을 최대화하는 방법론을 채택할 것을 권장합니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "optimization algorithms",
        "domain": "cs.AI",
        "summary": "  This paper proposes a novel, algorithm-independent approach to optimizing\nbelief network inference. rather than designing optimizations on an algorithm\nby algorithm basis, we argue that one should use an unoptimized algorithm to\ngenerate a Q-DAG, a compiled graphical representation of the belief network,\nand then optimize the Q-DAG and its evaluator instead. We present a set of\nQ-DAG optimizations that supplant optimizations designed for traditional\ninference algorithms, including zero compression, network pruning and caching.\nWe show that our Q-DAG optimizations require time linear in the Q-DAG size, and\nsignificantly simplify the process of designing algorithms for optimizing\nbelief network inference.\n",
        "english": "Optimization algorithms can be significantly enhanced by employing a novel, algorithm-independent approach that focuses on optimizing the Q-DAG, a compiled graphical representation of the belief network, rather than the algorithms themselves. The research introduces Q-DAG optimizations, such as zero compression, network pruning, and caching, which supplant traditional inference algorithm optimizations and operate with a time complexity of $\\mathcal{O}(n)$, where $n$ is the size of the Q-DAG. This innovative methodology not only simplifies the design process for optimizing belief network inference but also underscores the potential for broader applications in various domains of artificial intelligence.",
        "korean": "최적화 알고리즘(optimization algorithms)은 알고리즘 자체가 아닌 신념 네트워크(belief network)의 컴파일된 그래픽 표현인 Q-DAG를 최적화하는 데 중점을 둔 새로운 알고리즘 독립적 접근 방식을 채택함으로써 크게 향상될 수 있습니다. 연구는 전통적인 추론 알고리즘 최적화를 대체하고 Q-DAG의 크기를 $n$이라 할 때 시간 복잡도가 $\\mathcal{O}(n)$인 제로 압축(zero compression), 네트워크 가지치기(network pruning), 캐싱(caching)과 같은 Q-DAG 최적화를 도입합니다. 이 혁신적인 방법론은 신념 네트워크 추론 최적화를 위한 설계 과정을 단순화할 뿐만 아니라 인공지능의 다양한 분야에서 더 넓은 응용 가능성을 강조합니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure that all technical terms are consistently parenthesized as Korean term(English term) and adjust the sentence structure for a more natural flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "neural probabilistic models",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Neural probabilistic models have emerged as a significant advancement in the field of machine learning, providing a robust framework for capturing complex data distributions. Specifically, these models utilize a probability density function \\( p(x) \\) parameterized by neural networks, enabling the representation of intricate relationships within datasets. This innovative approach not only enhances predictive accuracy but also facilitates the development of more interpretable models, thus contributing to the broader understanding and application of artificial intelligence technologies.",
        "korean": "신경 확률 모델(neural probabilistic models)은 기계 학습(machine learning) 분야에서 중요한 발전으로 부상하여 복잡한 데이터 분포를 포착하는 강력한 프레임워크를 제공합니다. 구체적으로, 이러한 모델은 신경망(neural networks)에 의해 매개변수화된 확률 밀도 함수(probability density function) \\( p(x) \\)를 활용하여 데이터셋 내의 복잡한 관계를 표현할 수 있게 합니다. 이 혁신적인 접근 방식은 예측 정확도를 향상시킬 뿐만 아니라 더 해석 가능한 모델의 개발을 촉진하여 인공지능 기술(artificial intelligence technologies)의 폭넓은 이해와 응용에 기여합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "deep metric learning",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Deep metric learning has emerged as a pivotal approach in the field of machine learning, focusing on learning a similarity metric from data, which is crucial for tasks such as face verification and image retrieval. The reference introduces a novel loss function, $\\mathcal{L}_{metric}$, designed to minimize the distance between similar data points while maximizing the separation between dissimilar ones, thereby enhancing the discriminative power of the learned embeddings. This innovation not only improves the performance on benchmark datasets but also provides a robust framework for future research in developing more efficient and accurate metric learning models.",
        "korean": "심층 메트릭 학습(deep metric learning)은 데이터로부터 유사성 메트릭을 학습하는 데 중점을 두며, 얼굴 검증(face verification) 및 이미지 검색(image retrieval)과 같은 작업에 필수적인 기계 학습(machine learning) 분야에서 중요한 접근 방식으로 부상했습니다. 이 참고 문헌은 유사한 데이터 포인트 간의 거리를 최소화하고 비유사한 데이터 포인트 간의 분리를 극대화하여 학습된 임베딩의 판별력을 향상시키기 위해 설계된 새로운 손실 함수(loss function), $\\mathcal{L}_{metric}$을 소개합니다. 이 혁신은 벤치마크 데이터셋(benchmark datasets)에서의 성능을 향상시킬 뿐만 아니라, 더 효율적이고 정확한 메트릭 학습 모델(metric learning models)을 개발하기 위한 미래 연구에 강력한 프레임워크를 제공합니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": ""
    },
    {
        "turn_index": 2,
        "term": "graph neural modeling",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Graph neural modeling presents a transformative approach in analyzing structured data, as it effectively captures the dependencies of nodes in a graph through message passing mechanisms. This methodology leverages the power of neural networks by iteratively updating node representations based on their neighbors, as described by the equation \\( h_v^{(k)} = \\text{UPDATE}^{(k)}(h_v^{(k-1)}, \\{ h_u^{(k-1)} : u \\in \\mathcal{N}(v) \\}) \\), where \\( h_v^{(k)} \\) is the representation of node \\( v \\) at layer \\( k \\) and \\( \\mathcal{N}(v) \\) denotes the neighbors of \\( v \\). Such innovations underscore the potential of graph neural modeling to enhance predictive accuracy and uncover novel insights in domains ranging from social networks to molecular biology.",
        "korean": "그래프 신경 모델링(graph neural modeling)은 메시지 전달 메커니즘을 통해 그래프 내 노드의 종속성을 효과적으로 포착함으로써 구조화된 데이터를 분석하는 데 있어 변혁적인 접근 방식을 제시합니다. 이 방법론은 신경망(neural networks)의 힘을 활용하여 이웃 노드에 기반하여 노드 표현을 반복적으로 업데이트하며, 이는 식 \\( h_v^{(k)} = \\text{UPDATE}^{(k)}(h_v^{(k-1)}, \\{ h_u^{(k-1)} : u \\in \\mathcal{N}(v) \\}) \\)로 설명됩니다. 여기서 \\( h_v^{(k)} \\)는 계층 \\( k \\)에서의 노드 \\( v \\)의 표현을 나타내며, \\( \\mathcal{N}(v) \\)는 \\( v \\)의 이웃을 나타냅니다. 이러한 혁신은 그래프 신경 모델링(graph neural modeling)이 소셜 네트워크(social networks)에서 분자 생물학(molecular biology)에 이르기까지 다양한 도메인에서 예측 정확성을 향상시키고 새로운 통찰을 발견할 수 있는 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "structured prediction",
        "domain": "cs.AI",
        "summary": "  Memory is inherently entangled with prediction and planning. Flexible\nbehavior in biological and artificial agents depends on the interplay of\nlearning from the past and predicting the future in ever-changing environments.\nThis chapter reviews computational, behavioral, and neural evidence suggesting\nthese processes rely on learning the relational structure of experiences, known\nas cognitive maps, and draws two key takeaways. First, that these memory\nstructures are organized as multiscale, compact predictive representations in\nhippocampal and prefrontal cortex, or PFC, hierarchies. Second, we argue that\nsuch predictive memory structures are crucial to the complementary functions of\nthe hippocampus and PFC, both for enabling a recall of detailed and coherent\npast episodes as well as generalizing experiences at varying scales for\nefficient prediction and planning. These insights advance our understanding of\nmemory and planning mechanisms in the brain and hold significant implications\nfor advancing artificial intelligence systems.\n",
        "english": "Structured prediction in both biological and artificial agents hinges on learning the relational structure of experiences, which is encapsulated in cognitive maps as multiscale, compact predictive representations within the hippocampal and prefrontal cortex hierarchies. These predictive memory structures are crucial for enabling the recall of detailed past episodes and for generalizing experiences at varying scales, thereby facilitating efficient prediction and planning. Mathematically, this can be expressed as $P(Y|X) = \\sum_{z} P(Y|Z=z, X)P(Z=z|X)$, where $Y$ represents the future states to be predicted, $X$ denotes the observed data, and $Z$ signifies the latent variables encoding the relational structure, highlighting the innovation in understanding memory and planning mechanisms that hold significant implications for advancing artificial intelligence systems.",
        "korean": "생물학적 및 인공 에이전트에서의 구조적 예측(structured prediction)은 경험의 관계적 구조를 학습하는 데 달려 있으며, 이는 해마와 전전두엽 피질 계층 내에서 다중 규모의 압축 예측 표현으로 인지 지도(cognitive maps)에 캡슐화됩니다. 이러한 예측 메모리 구조는 과거의 세부적인 에피소드를 회상하고 다양한 규모에서 경험을 일반화하여 효율적인 예측과 계획을 가능하게 하는 데 필수적입니다. 수학적으로 이는 $P(Y|X) = \\sum_{z} P(Y|Z=z, X)P(Z=z|X)$로 표현될 수 있으며, 여기서 $Y$는 예측할 미래 상태를 나타내고, $X$는 관찰된 데이터를 나타내며, $Z$는 관계적 구조를 인코딩하는 잠재 변수를 나타냅니다. 이는 인공지능 시스템을 발전시키는 데 중요한 함의를 지닌 기억 및 계획 메커니즘에 대한 혁신적인 이해를 강조합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "adaptive text processes",
        "domain": "cs.AI",
        "summary": "  Taaable is a case-based reasoning system that adapts cooking recipes to user\nconstraints. Within it, the preparation part of recipes is formalised as a\ngraph. This graph is a semantic representation of the sequence of instructions\ncomposing the cooking process and is used to compute the procedure adaptation,\nconjointly with the textual adaptation. It is composed of cooking actions and\ningredients, among others, represented as vertices, and semantic relations\nbetween those, shown as arcs, and is built automatically thanks to natural\nlanguage processing. The results of the automatic annotation process is often a\ndisconnected graph, representing an incomplete annotation, or may contain\nerrors. Therefore, a validating and correcting step is required. In this paper,\nwe present an existing graphic tool named \\kcatos, conceived for representing\nand editing decision trees, and show how it has been adapted and integrated in\nWikiTaaable, the semantic wiki in which the knowledge used by Taaable is\nstored. This interface provides the wiki users with a way to correct the case\nrepresentation of the cooking process, improving at the same time the quality\nof the knowledge about cooking procedures stored in WikiTaaable.\n",
        "english": "Adaptive text processes within the Taaable system involve the formalization of the preparation part of cooking recipes as a graph, which serves as a semantic representation of the sequence of instructions composing the cooking process. By utilizing natural language processing, this graph, composed of vertices representing cooking actions and ingredients and arcs denoting semantic relations, is automatically constructed, though it may result in a disconnected graph due to incomplete annotations or errors. To address these issues, a validating and correcting step is crucial, and the integration of the graphic tool \\kcatos\\ in WikiTaaable exemplifies an innovative approach to enhancing the quality of knowledge about cooking procedures, thereby improving the overall effectiveness of adaptive text processes.",
        "korean": "Taaable 시스템 내에서 적응형 텍스트 프로세스(adaptive text processes)는 요리 레시피의 준비 부분을 그래프로 형식화하는 것을 포함하며, 이는 요리 과정의 지시 사항 순서를 의미적으로 표현하는 역할을 합니다. 자연어 처리(natural language processing)를 활용하여 요리 동작과 재료를 나타내는 정점과 의미적 관계를 나타내는 호로 구성된 이 그래프는 자동으로 구성되지만, 불완전한 주석이나 오류로 인해 연결되지 않은 그래프가 될 수 있습니다. 이러한 문제를 해결하기 위해 검증 및 수정 단계가 중요하며, WikiTaaable에 그래픽 도구 \\kcatos\\를 통합하는 것은 요리 절차에 대한 지식의 질을 향상시켜 적응형 텍스트 프로세스(adaptive text processes)의 전반적인 효과를 개선하는 혁신적인 접근 방식을 보여줍니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "interpretability",
        "domain": "cs.AI",
        "summary": "  Several researchers have argued that a machine learning system's\ninterpretability should be defined in relation to a specific agent or task: we\nshould not ask if the system is interpretable, but to whom is it interpretable.\nWe describe a model intended to help answer this question, by identifying\ndifferent roles that agents can fulfill in relation to the machine learning\nsystem. We illustrate the use of our model in a variety of scenarios, exploring\nhow an agent's role influences its goals, and the implications for defining\ninterpretability. Finally, we make suggestions for how our model could be\nuseful to interpretability researchers, system developers, and regulatory\nbodies auditing machine learning systems.\n",
        "english": "Interpretability in machine learning systems should be considered in relation to a specific agent or task, prompting the question not of whether a system is interpretable, but to whom it is interpretable. In addressing this, a model is proposed to delineate various roles agents may assume relative to the machine learning system, thereby influencing their goals and the definition of interpretability \\cite{source}. This model's utility is further underscored by its potential application for interpretability researchers, system developers, and regulatory bodies, as it provides a structured framework for evaluating interpretability across different scenarios and roles, potentially expressed mathematically as $I(a, s) = f(r, g)$, where $I$ represents interpretability, $a$ the agent, $s$ the system, $r$ the role, and $g$ the goals.",
        "korean": "기계 학습 시스템(machine learning systems)에서 해석 가능성(interpretability)은 특정 에이전트(agent)나 작업과 관련하여 고려되어야 하며, 시스템이 해석 가능한지 여부가 아니라 누구에게 해석 가능한지를 묻는 질문을 유도합니다. 이를 해결하기 위해, 기계 학습 시스템(machine learning systems)과 관련하여 에이전트(agent)가 맡을 수 있는 다양한 역할을 구분하는 모델이 제안되며, 이는 그들의 목표와 해석 가능성(interpretability)의 정의에 영향을 미칩니다 \\cite{source}. 이 모델의 유용성은 해석 가능성 연구자(interpretability researchers), 시스템 개발자(system developers), 규제 기관(regulatory bodies)에게 잠재적으로 적용될 수 있는 구조화된 프레임워크를 제공함으로써 다양한 시나리오와 역할에 걸쳐 해석 가능성(interpretability)을 평가하는 데 기여할 수 있다는 점에서 더욱 강조됩니다. 이는 수학적으로 $I(a, s) = f(r, g)$로 표현될 수 있으며, 여기서 $I$는 해석 가능성(interpretability), $a$는 에이전트(agent), $s$는 시스템(system), $r$은 역할(role), $g$는 목표(goals)를 나타냅니다.",
        "score": 10,
        "parentheses_count": 11,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "exchangeable arrays",
        "domain": "cs.AI",
        "summary": "  Kidney exchanges are organized markets where patients swap willing but\nincompatible donors. In the last decade, kidney exchanges grew from small and\nregional to large and national---and soon, international. This growth results\nin more lives saved, but exacerbates the empirical hardness of the\n$\\mathcal{NP}$-complete problem of optimally matching patients to donors.\nState-of-the-art matching engines use integer programming techniques to clear\nfielded kidney exchanges, but these methods must be tailored to specific models\nand objective functions, and may fail to scale to larger exchanges. In this\npaper, we observe that if the kidney exchange compatibility graph can be\nencoded by a constant number of patient and donor attributes, the clearing\nproblem is solvable in polynomial time. We give necessary and sufficient\nconditions for losslessly shrinking the representation of an arbitrary\ncompatibility graph. Then, using real compatibility graphs from the UNOS\nnationwide kidney exchange, we show how many attributes are needed to encode\nreal compatibility graphs. The experiments show that, indeed, small numbers of\nattributes suffice.\n",
        "english": "Exchangeable arrays can significantly enhance the efficiency of matching engines in kidney exchanges, which have grown from small regional operations to large international markets, thus increasing the complexity of the $\\mathcal{NP}$-complete problem of optimally matching patients to donors. By encoding the kidney exchange compatibility graph with a constant number of patient and donor attributes, the clearing problem becomes solvable in polynomial time, highlighting the potential of exchangeable arrays in streamlining the matching process. Experiments utilizing real compatibility graphs from the UNOS nationwide kidney exchange demonstrate that only a small number of attributes are necessary, showcasing the practical applicability and innovation of this approach in tackling large-scale exchanges.",
        "korean": "교환 가능한 배열(exchangeable arrays)은 신장 교환에서 매칭 엔진의 효율성을 크게 향상시킬 수 있으며, 이는 작은 지역 운영에서 대규모 국제 시장으로 성장하면서 환자와 기증자를 최적으로 매칭하는 $\\mathcal{NP}$-완전 문제의 복잡성을 증가시킵니다. 일정한 수의 환자 및 기증자 속성으로 신장 교환 호환성 그래프를 인코딩함으로써, 정리 문제는 다항 시간 내에 해결 가능해지며, 이는 매칭 과정을 간소화하는 데 있어 교환 가능한 배열(exchangeable arrays)의 잠재력을 강조합니다. UNOS 전국 신장 교환의 실제 호환성 그래프를 활용한 실험은 소수의 속성만이 필요함을 보여주며, 대규모 교환 문제를 해결하는 데 있어 이 접근 방식의 실용성과 혁신성을 입증합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural relation extraction",
        "domain": "cs.AI",
        "summary": "  The development of machine learning in particular and artificial intelligent\nin general has been strongly conditioned by the lack of an appropriate\ninterface layer between deduction, abduction and induction. In this work we\nextend traditional algebraic specification methods in this direction. Here we\nassume that such interface for AI emerges from an adequate Neural-Symbolic\nintegration. This integration is made for universe of discourse described on a\nTopos governed by a many-valued {\\L}ukasiewicz logic. Sentences are integrated\nin a symbolic knowledge base describing the problem domain, codified using a\ngraphic-based language, wherein every logic connective is defined by a neuron\nin an artificial network. This allows the integration of first-order formulas\ninto a network architecture as background knowledge, and simplifies symbolic\nrule extraction from trained networks. For the train of such neural networks we\nchanged the Levenderg-Marquardt algorithm, restricting the knowledge\ndissemination in the network structure using soft crystallization. This\nprocedure reduces neural network plasticity without drastically damaging the\nlearning performance, allowing the emergence of symbolic patterns. This makes\nthe descriptive power of produced neural networks similar to the descriptive\npower of {\\L}ukasiewicz logic language, reducing the information lost on\ntranslation between symbolic and connectionist structures. We tested this\nmethod on the extraction of knowledge from specified structures. For it, we\npresent the notion of fuzzy state automata, and we use automata behaviour to\ninfer its structure. We use this type of automata on the generation of models\nfor relations specified as symbolic background knowledge.\n",
        "english": "Neural relation extraction benefits from an \"adequate Neural-Symbolic integration,\" which is facilitated by embedding first-order formulas within a network architecture as background knowledge, thus simplifying the extraction of symbolic rules from trained networks. This integration is achieved within a universe of discourse described on a Topos governed by a many-valued {\\L}ukasiewicz logic, where every logic connective is represented by a neuron in an artificial network, allowing for a seamless translation between symbolic and connectionist structures. By employing a modified Levenderg-Marquardt algorithm with \"soft crystallization,\" the method reduces neural network plasticity without significantly impairing learning performance, thereby fostering the emergence of symbolic patterns and enhancing the descriptive power of neural networks for neural relation extraction tasks.",
        "korean": "신경 관계 추출(neural relation extraction)은 \"적절한 신경-상징 통합(adequate Neural-Symbolic integration)\"의 이점을 누리며, 이는 네트워크 아키텍처 내에 일차 논리 공식(first-order formulas)을 배경 지식으로 내장함으로써 훈련된 네트워크에서 상징적 규칙을 추출하는 과정을 단순화합니다. 이러한 통합은 다가치 루카시에비츠 논리(many-valued {\\L}ukasiewicz logic)에 의해 지배되는 토포스(Topos)로 설명된 담론의 우주 내에서 이루어지며, 모든 논리 연결자는 인공 네트워크의 뉴런으로 표현되어 상징적 구조와 연결주의 구조 간의 원활한 번역을 가능하게 합니다. \"소프트 결정화(soft crystallization)\"가 적용된 수정된 레벤버그-마쿼트 알고리즘(Levenderg-Marquardt algorithm)을 사용함으로써, 이 방법은 학습 성능을 크게 저해하지 않으면서 신경망의 가소성을 줄여 상징적 패턴의 출현을 촉진하고 신경 관계 추출 작업을 위한 신경망의 설명력을 향상시킵니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring consistent lowercase usage within parentheses for all technical terms."
    },
    {
        "turn_index": 2,
        "term": "neural adaptive optimization",
        "domain": "cs.AI",
        "summary": "  Machine learning tasks are generally formulated as optimization problems,\nwhere one searches for an optimal function within a certain functional space.\nIn practice, parameterized functional spaces are considered, in order to be\nable to perform gradient descent. Typically, a neural network architecture is\nchosen and fixed, and its parameters (connection weights) are optimized,\nyielding an architecture-dependent result. This way of proceeding however\nforces the evolution of the function during training to lie within the realm of\nwhat is expressible with the chosen architecture, and prevents any optimization\nacross architectures. Costly architectural hyper-parameter optimization is\noften performed to compensate for this. Instead, we propose to adapt the\narchitecture on the fly during training. We show that the information about\ndesirable architectural changes, due to expressivity bottlenecks when\nattempting to follow the functional gradient, can be extracted from %the\nbackpropagation. To do this, we propose a mathematical definition of\nexpressivity bottlenecks, which enables us to detect, quantify and solve them\nwhile training, by adding suitable neurons when and where needed. Thus, while\nthe standard approach requires large networks, in terms of number of neurons\nper layer, for expressivity and optimization reasons, we are able to start with\nvery small neural networks and let them grow appropriately. As a proof of\nconcept, we show results~on the CIFAR dataset, matching large neural network\naccuracy, with competitive training time, while removing the need for standard\narchitectural hyper-parameter search.\n",
        "english": "Neural adaptive optimization represents a significant advancement in machine learning by proposing to \"adapt the architecture on the fly during training,\" which addresses the limitations of fixed neural network architectures. This innovative approach involves detecting \"expressivity bottlenecks\" through backpropagation, allowing for the dynamic addition of neurons as needed, thus optimizing the network's expressivity and performance. By employing neural adaptive optimization, researchers demonstrated the ability to achieve competitive results on the CIFAR dataset with smaller initial networks, effectively reducing the need for extensive architectural hyper-parameter searches and achieving accuracy comparable to larger networks, all while maintaining efficient training times.",
        "korean": "신경 적응 최적화(neural adaptive optimization)는 고정된 신경망 구조의 한계를 해결하기 위해 \"훈련 중 실시간으로 구조를 적응시키는\" 방식을 제안함으로써 기계 학습 분야에서 중요한 진전을 나타냅니다. 이 혁신적인 접근법은 역전파(backpropagation)를 통해 \"표현력 병목 현상(expressivity bottlenecks)\"을 감지하고, 필요에 따라 뉴런을 동적으로 추가하여 네트워크의 표현력과 성능을 최적화합니다. 신경 적응 최적화(neural adaptive optimization)를 활용함으로써 연구자들은 초기 네트워크가 작은 상태에서도 CIFAR 데이터셋(CIFAR dataset)에서 경쟁력 있는 결과를 달성할 수 있음을 입증하였으며, 광범위한 구조적 하이퍼파라미터 탐색의 필요성을 효과적으로 줄이고, 더 큰 네트워크와 유사한 정확도를 달성하면서도 효율적인 훈련 시간을 유지할 수 있었습니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar"
    },
    {
        "turn_index": 2,
        "term": "boosting",
        "domain": "cs.AI",
        "summary": "  Recent advances in the study of voting classification algorithms have brought\nempirical and theoretical results clearly showing the discrimination power of\nensemble classifiers. It has been previously argued that the search of this\nclassification power in the design of the algorithms has marginalized the need\nto obtain interpretable classifiers. Therefore, the question of whether one\nmight have to dispense with interpretability in order to keep classification\nstrength is being raised in a growing number of machine learning or data mining\npapers. The purpose of this paper is to study both theoretically and\nempirically the problem. First, we provide numerous results giving insight into\nthe hardness of the simplicity-accuracy tradeoff for voting classifiers. Then\nwe provide an efficient \"top-down and prune\" induction heuristic, WIDC, mainly\nderived from recent results on the weak learning and boosting frameworks. It is\nto our knowledge the first attempt to build a voting classifier as a base\nformula using the weak learning framework (the one which was previously highly\nsuccessful for decision tree induction), and not the strong learning framework\n(as usual for such classifiers with boosting-like approaches). While it uses a\nwell-known induction scheme previously successful in other classes of concept\nrepresentations, thus making it easy to implement and compare, WIDC also relies\non recent or new results we give about particular cases of boosting known as\npartition boosting and ranking loss boosting. Experimental results on\nthirty-one domains, most of which readily available, tend to display the\nability of WIDC to produce small, accurate, and interpretable decision\ncommittees.\n",
        "english": "Recent advances in the study of voting classification algorithms have demonstrated the discrimination power of ensemble classifiers, highlighting the need to balance this power with interpretability. A novel approach, WIDC, leverages the weak learning framework to construct a voting classifier, diverging from the traditional strong learning framework typically associated with boosting-like methods. Experimental results across thirty-one domains underscore WIDC's capability to produce decision committees that are not only small and accurate but also interpretable, with a focus on particular boosting cases such as partition boosting and ranking loss boosting, which are mathematically represented by the equation $L = \\sum_{i=1}^{n} w_i \\cdot \\ell(y_i, f(x_i))$.",
        "korean": "최근 투표 분류 알고리즘(voting classification algorithms) 연구의 발전은 앙상블 분류기(ensemble classifiers)의 판별력을 입증하며, 이 판별력을 해석 가능성과 균형을 맞출 필요성을 강조합니다. 새로운 접근법인 WIDC는 약한 학습 프레임워크(weak learning framework)를 활용하여 투표 분류기(voting classifier)를 구성하며, 일반적으로 boosting과 유사한 방법과 관련된 강한 학습 프레임워크(strong learning framework)와는 다릅니다. 31개 도메인에 걸친 실험 결과는 WIDC가 작고 정확할 뿐만 아니라 해석 가능한 의사 결정 위원회(decision committees)를 생성할 수 있는 능력을 강조하며, 수학적으로 $L = \\sum_{i=1}^{n} w_i \\cdot \\ell(y_i, f(x_i))$로 표현되는 분할 boosting과 순위 손실 boosting과 같은 특정 boosting 사례에 중점을 둡니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar"
    },
    {
        "turn_index": 2,
        "term": "soft attention",
        "domain": "cs.AI",
        "summary": "  Many researchers in artificial intelligence are beginning to explore the use\nof soft constraints to express a set of (possibly conflicting) problem\nrequirements. A soft constraint is a function defined on a collection of\nvariables which associates some measure of desirability with each possible\ncombination of values for those variables. However, the crucial question of the\ncomputational complexity of finding the optimal solution to a collection of\nsoft constraints has so far received very little attention. In this paper we\nidentify a class of soft binary constraints for which the problem of finding\nthe optimal solution is tractable. In other words, we show that for any given\nset of such constraints, there exists a polynomial time algorithm to determine\nthe assignment having the best overall combined measure of desirability. This\ntractable class includes many commonly-occurring soft constraints, such as 'as\nnear as possible' or 'as soon as possible after', as well as crisp constraints\nsuch as 'greater than'. Finally, we show that this tractable class is maximal,\nin the sense that adding any other form of soft binary constraint which is not\nin the class gives rise to a class of problems which is NP-hard.\n",
        "english": "Soft attention in artificial intelligence often involves the use of soft constraints, which are functions defined on a collection of variables that associate a measure of desirability with each possible combination of values for those variables. This approach is crucial for addressing the computational complexity of finding optimal solutions, as demonstrated by identifying a class of soft binary constraints where a polynomial time algorithm can determine the assignment with the best overall combined measure of desirability. Importantly, this tractable class is maximal, meaning that incorporating any additional form of soft binary constraint outside this class results in problems that are NP-hard, thus underscoring the innovation and significance of this research in optimizing soft attention mechanisms.",
        "korean": "인공지능에서의 소프트 어텐션(soft attention)은 종종 소프트 제약(soft constraints)의 사용을 포함하며, 이는 변수들의 집합에 정의된 함수로, 해당 변수들의 가능한 값 조합 각각에 대해 바람직함의 척도를 연관시킵니다. 이 접근법은 최적의 해를 찾는 계산 복잡성을 해결하는 데 중요하며, 다항 시간 알고리즘(polynomial time algorithm)이 바람직함의 전체 결합 척도가 가장 좋은 할당을 결정할 수 있는 소프트 이진 제약(soft binary constraints)의 클래스가 식별됨으로써 입증됩니다. 특히, 이 다루기 쉬운 클래스는 최대(maximal)이며, 이 클래스 외의 추가적인 형태의 소프트 이진 제약을 포함하면 문제가 NP-난해(NP-hard)해지므로, 소프트 어텐션(soft attention) 메커니즘 최적화에 있어 이 연구의 혁신성과 중요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dbscan",
        "domain": "cs.AI",
        "summary": "  An abundance of information about cancer exists online, but categorizing and\nextracting useful information from it is difficult. Almost all research within\nhealthcare data processing is concerned with formal clinical data, but there is\nvaluable information in non-clinical data too. The present study combines\nmethods within distributed computing, text retrieval, clustering, and\nclassification into a coherent and computationally efficient system, that can\nclarify cancer patient trajectories based on non-clinical and freely available\ninformation. We produce a fully-functional prototype that can retrieve, cluster\nand present information about cancer trajectories from non-clinical forum\nposts. We evaluate three clustering algorithms (MR-DBSCAN, DBSCAN, and HDBSCAN)\nand compare them in terms of Adjusted Rand Index and total run time as a\nfunction of the number of posts retrieved and the neighborhood radius.\nClustering results show that neighborhood radius has the most significant\nimpact on clustering performance. For small values, the data set is split\naccordingly, but high values produce a large number of possible partitions and\nsearching for the best partition is hereby time-consuming. With a proper\nestimated radius, MR-DBSCAN can cluster 50000 forum posts in 46.1 seconds,\ncompared to DBSCAN (143.4) and HDBSCAN (282.3). We conduct an interview with\nthe Danish Cancer Society and present our software prototype. The organization\nsees a potential in software that can democratize online information about\ncancer and foresee that such systems will be required in the future.\n",
        "english": "The evaluation of clustering algorithms, including DBSCAN, MR-DBSCAN, and HDBSCAN, in the context of cancer patient trajectories highlights the significance of neighborhood radius on clustering performance, as smaller values effectively split the dataset while larger values increase partition possibilities and computational time. Notably, DBSCAN demonstrates a total run time of 143.4 seconds for clustering 50,000 forum posts, emphasizing the balance between efficiency and precision when compared to MR-DBSCAN's 46.1 seconds and HDBSCAN's 282.3 seconds. Such research underscores the potential of DBSCAN in developing systems that democratize online cancer information, a need identified by the Danish Cancer Society for future healthcare data processing advancements.",
        "korean": "암 환자 경로의 맥락에서 클러스터링 알고리즘(clustering algorithms), 즉 dbscan(dbscan), mr-dbscan(mr-dbscan), hdbscan(hdbscan)의 평가에서는 클러스터링 성능에 대한 이웃 반경의 중요성을 강조합니다. 작은 값은 데이터셋을 효과적으로 분할하는 반면, 큰 값은 분할 가능성과 계산 시간을 증가시킵니다. 특히, dbscan(dbscan)은 50,000개의 포럼 게시물을 클러스터링하는 데 총 143.4초의 실행 시간을 보여주며, mr-dbscan(mr-dbscan)의 46.1초와 hdbscan(hdbscan)의 282.3초와 비교하여 효율성과 정밀성 간의 균형을 강조합니다. 이러한 연구는 온라인 암 정보의 민주화를 위한 시스템 개발에서 dbscan(dbscan)의 잠재력을 강조하며, 이는 덴마크 암 협회(danish cancer society)가 미래의 의료 데이터 처리 발전을 위해 식별한 필요성입니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Ensure that all technical terms are consistently parenthesized as Korean term(English term) and maintain lowercase letters within parentheses for uniformity."
    },
    {
        "turn_index": 2,
        "term": "graphical model structure learning",
        "domain": "cs.AI",
        "summary": "  Variational inference algorithms such as belief propagation have had\ntremendous impact on our ability to learn and use graphical models, and give\nmany insights for developing or understanding exact and approximate inference.\nHowever, variational approaches have not been widely adoped for decision making\nin graphical models, often formulated through influence diagrams and including\nboth centralized and decentralized (or multi-agent) decisions. In this work, we\npresent a general variational framework for solving structured cooperative\ndecision-making problems, use it to propose several belief propagation-like\nalgorithms, and analyze them both theoretically and empirically.\n",
        "english": "Variational inference algorithms, such as belief propagation, have significantly advanced our capacity for graphical model structure learning by providing insights into both exact and approximate inference methods. Despite their success, these variational approaches have not been extensively applied to decision-making scenarios within graphical models, which are often structured through influence diagrams and involve both centralized and decentralized decision-making processes. In addressing this gap, the research introduces a comprehensive variational framework for structured cooperative decision-making, proposing belief propagation-like algorithms and examining their performance through both theoretical analysis and empirical validation, thereby enhancing the applicability of graphical model structure learning in complex decision-making contexts.",
        "korean": "변분 추론 알고리즘(variational inference algorithms), 예를 들어 신념 전파(belief propagation)는 정확한 추론 방법과 근사 추론 방법 모두에 대한 통찰력을 제공함으로써 그래픽 모델 구조 학습(graphical model structure learning) 능력을 크게 향상시켰습니다. 이러한 성공에도 불구하고, 이러한 변분 접근법은 영향 다이어그램(influence diagrams)을 통해 구조화되고 중앙 집중식 및 분산형 의사 결정 과정을 포함하는 그래픽 모델 내의 의사 결정 시나리오에 광범위하게 적용되지 않았습니다. 이러한 격차를 해결하기 위해 연구는 구조화된 협력적 의사 결정(cooperative decision-making)을 위한 포괄적인 변분 프레임워크(variational framework)를 도입하고, 신념 전파와 유사한 알고리즘을 제안하며 이들의 성능을 이론적 분석과 실증적 검증을 통해 검토하여 복잡한 의사 결정 맥락에서 그래픽 모델 구조 학습(graphical model structure learning)의 적용 가능성을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "graph-based learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "english": "Graph-based learning, as a subset of mechanical learning, utilizes the concept of \"X-forms,\" which are algebraic expressions for subjective patterns, to effectively describe the objects and processes involved in learning. This approach emphasizes the importance of subjective patterns, proving that for any given objective pattern, a corresponding subjective pattern can be constructed using least base patterns, thereby optimizing the internal representation space, denoted as $\\mathcal{X}$, of the learning machine. By leveraging these internal representations, graph-based learning strategies demonstrate that with sufficient data and certain capabilities, a learning machine can achieve universal learning, underscoring its potential to revolutionize the understanding of deep learning dynamics.",
        "korean": "기계 학습(mechanical learning)의 하위 집합으로서 그래프 기반 학습(graph-based learning)은 주관적 패턴에 대한 대수적 표현인 \"X-형식(X-forms)\"의 개념을 활용하여 학습에 관련된 객체와 과정을 효과적으로 설명합니다. 이 접근법은 주관적 패턴의 중요성을 강조하며, 주어진 객관적 패턴에 대해 최소 기본 패턴을 사용하여 대응하는 주관적 패턴을 구성할 수 있음을 입증하여 학습 기계의 내부 표현 공간인 $\\mathcal{X}$를 최적화합니다. 이러한 내부 표현을 활용함으로써 그래프 기반 학습(graph-based learning) 전략은 충분한 데이터와 특정 능력을 갖춘 학습 기계가 보편적 학습을 달성할 수 있음을 보여주며, 심층 학습 역학에 대한 이해를 혁신할 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None needed, as the translation accurately captures the original meaning and nuances while maintaining a natural flow and correct grammar."
    },
    {
        "turn_index": 2,
        "term": "neural ordinary differential equations",
        "domain": "cs.AI",
        "summary": "  We show how, and under which conditions, the equilibrium states of a\nfirst-order Ordinary Differential Equation (ODE) system can be described with a\ndeterministic Structural Causal Model (SCM). Our exposition sheds more light on\nthe concept of causality as expressed within the framework of Structural Causal\nModels, especially for cyclic models.\n",
        "english": "Neural ordinary differential equations (ODEs) offer a framework where the equilibrium states of a first-order ODE system can be effectively described using a deterministic Structural Causal Model (SCM). This approach provides deeper insights into the concept of causality, particularly within the framework of Structural Causal Models, emphasizing its applicability to cyclic models. By representing the system dynamics as $\\frac{dx}{dt} = f(x, t, \\theta)$, where $x$ is the state, $t$ is time, and $\\theta$ are the parameters, neural ODEs demonstrate significant potential in capturing complex causal relationships, thus marking an innovative step in understanding dynamic systems.",
        "korean": "신경 상미분 방정식(neural ordinary differential equations, ODEs)은 일차 상미분 방정식 시스템의 평형 상태를 결정론적 구조적 인과 모델(deterministic structural causal model, SCM)을 사용하여 효과적으로 설명할 수 있는 프레임워크를 제공합니다. 이 접근법은 특히 순환 모델에의 적용 가능성을 강조하면서 구조적 인과 모델(structural causal models) 프레임워크 내에서 인과성의 개념에 대한 깊은 통찰을 제공합니다. 시스템 동역학을 $\\frac{dx}{dt} = f(x, t, \\theta)$로 표현함으로써, 여기서 $x$는 상태, $t$는 시간, $\\theta$는 매개변수입니다, 신경 상미분 방정식(neural ODEs)은 복잡한 인과 관계를 포착하는 데 상당한 잠재력을 보여주며, 동적 시스템을 이해하는 데 혁신적인 단계를 표시합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "stochastic neural learning",
        "domain": "cs.AI",
        "summary": "  This paper introduces a reinforcement learning approach to optimize the\nStochastic Vehicle Routing Problem with Time Windows (SVRP), focusing on\nreducing travel costs in goods delivery. We develop a novel SVRP formulation\nthat accounts for uncertain travel costs and demands, alongside specific\ncustomer time windows. An attention-based neural network trained through\nreinforcement learning is employed to minimize routing costs. Our approach\naddresses a gap in SVRP research, which traditionally relies on heuristic\nmethods, by leveraging machine learning. The model outperforms the Ant-Colony\nOptimization algorithm, achieving a 1.73% reduction in travel costs. It\nuniquely integrates external information, demonstrating robustness in diverse\nenvironments, making it a valuable benchmark for future SVRP studies and\nindustry application.\n",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure all technical terms are consistently formatted as Korean term(English term) and adjust the structure for a more natural flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "markov decision processes",
        "domain": "cs.AI",
        "summary": "  We consider the expressivity of Markov rewards in sequential decision making\nunder uncertainty. We view reward functions in Markov Decision Processes (MDPs)\nas a means to characterize desired behaviors of agents. Assuming desired\nbehaviors are specified as a set of acceptable policies, we investigate if\nthere exists a scalar or multidimensional Markov reward function that makes the\npolicies in the set more desirable than the other policies. Our main result\nstates both necessary and sufficient conditions for the existence of such\nreward functions. We also show that for every non-degenerate set of\ndeterministic policies, there exists a multidimensional Markov reward function\nthat characterizes it\n",
        "korean": "마르코프 결정 과정(markov decision processes, MDPs) 분야에서 보상 함수(reward functions)는 허용 가능한 정책 집합을 명시함으로써 에이전트의 원하는 행동을 특징짓는 중요한 메커니즘으로 작용합니다. 연구는 이 집합 내의 정책을 다른 정책보다 더 바람직하게 만드는 스칼라 또는 다차원 마르코프 보상 함수(scalar or multidimensional markov reward functions)의 존재에 대한 필요하고 충분한 조건을 식별합니다. 또한, 비퇴화된 결정론적 정책 집합에 대해 다차원 마르코프 보상 함수(multidimensional markov reward function)가 구성될 수 있음을 보여주며, 이는 $R: S \\times A \\rightarrow \\mathbb{R}^n$라는 표현으로 캡슐화됩니다. 여기서 $S$는 상태 공간(state space), $A$는 행동 공간(action space), $\\mathbb{R}^n$은 다차원 보상 벡터(multidimensional reward vector)를 나타내며, 따라서 불확실성 하에서의 순차적 의사 결정에서 MDPs의 표현력과 유연성을 강조합니다."
    },
    {
        "turn_index": 2,
        "term": "neural logic networks",
        "domain": "cs.AI",
        "summary": "  The human reasoning process is seldom a one-way process from an input leading\nto an output. Instead, it often involves a systematic deduction by ruling out\nother possible outcomes as a self-checking mechanism. In this paper, we\ndescribe the design of a hybrid neural network for logical learning that is\nsimilar to the human reasoning through the introduction of an auxiliary input,\nnamely the indicators, that act as the hints to suggest logical outcomes. We\ngenerate these indicators by digging into the hidden information buried\nunderneath the original training data for direct or indirect suggestions. We\nused the MNIST data to demonstrate the design and use of these indicators in a\nconvolutional neural network. We trained a series of such hybrid neural\nnetworks with variations of the indicators. Our results show that these hybrid\nneural networks are very robust in generating logical outcomes with inherently\nhigher prediction accuracy than the direct use of the original input and output\nin apparent models. Such improved predictability with reassured logical\nconfidence is obtained through the exhaustion of all possible indicators to\nrule out all illogical outcomes, which is not available in the apparent models.\nOur logical learning process can effectively cope with the unknown unknowns\nusing a full exploitation of all existing knowledge available for learning. The\ndesign and implementation of the hints, namely the indicators, become an\nessential part of artificial intelligence for logical learning. We also\nintroduce an ongoing application setup for this hybrid neural network in an\nautonomous grasping robot, namely as_DeepClaw, aiming at learning an optimized\ngrasping pose through logical learning.\n",
        "english": "Neural logic networks, as described in the study, incorporate an auxiliary input termed \"indicators\" to enhance logical learning by systematically deducing outcomes, akin to human reasoning. This approach involves generating indicators by extracting hidden information from the original training data, which improves the robustness and prediction accuracy of the networks, achieving higher logical confidence through the exhaustion of all possible indicators to rule out illogical outcomes. The mathematical formulation of this process can be expressed as maximizing the function $f(I, D) \\rightarrow L$, where $I$ represents the indicators, $D$ is the original data, and $L$ denotes the logical outcomes, underscoring the innovative integration of logical learning in neural networks for applications such as autonomous grasping robots.",
        "korean": "연구에서 설명된 신경 논리 네트워크(neural logic networks)는 \"지표\"라는 보조 입력을 포함하여 체계적으로 결과를 추론함으로써 인간의 추론과 유사한 논리 학습을 향상시킵니다. 이 접근 방식은 원래의 훈련 데이터에서 숨겨진 정보를 추출하여 지표를 생성함으로써 네트워크의 강건성과 예측 정확성을 향상시키며, 모든 가능한 지표를 소진하여 비논리적 결과를 배제함으로써 더 높은 논리적 신뢰도를 달성합니다. 이 과정의 수학적 공식화는 함수 $f(I, D) \\rightarrow L$을 최대화하는 것으로 표현될 수 있으며, 여기서 $I$는 지표를 나타내고, $D$는 원래 데이터를, $L$은 논리적 결과를 나타내며, 자율적 물체 잡기 로봇과 같은 응용 분야에서 신경망에 논리 학습을 혁신적으로 통합하는 것을 강조합니다.",
        "score": 10,
        "parentheses_count": 1,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "hybrid reinforcement learning",
        "domain": "cs.AI",
        "summary": "  Stochastic Constraint Programming (SCP) is an extension of Constraint\nProgramming (CP) used for modelling and solving problems involving constraints\nand uncertainty. SCP inherits excellent modelling abilities and filtering\nalgorithms from CP, but so far it has not been applied to large problems.\nReinforcement Learning (RL) extends Dynamic Programming to large stochastic\nproblems, but is problem-specific and has no generic solvers. We propose a\nhybrid combining the scalability of RL with the modelling and constraint\nfiltering methods of CP. We implement a prototype in a CP system and\ndemonstrate its usefulness on SCP problems.\n",
        "english": "Hybrid reinforcement learning represents an innovative approach that combines the \"scalability of RL\" with the \"modelling and constraint filtering methods of CP,\" effectively addressing the limitations of both methodologies. By implementing a prototype within a CP system, the research demonstrates the potential of hybrid reinforcement learning to solve Stochastic Constraint Programming (SCP) problems, which involve both constraints and uncertainty, on a larger scale than previously possible. This hybrid approach can be mathematically expressed as $H = \\text{RL} + \\text{CP}$, where $H$ denotes the hybrid model that leverages the strengths of both Reinforcement Learning and Constraint Programming to enhance problem-solving capabilities in complex environments.",
        "korean": "하이브리드 강화 학습(hybrid reinforcement learning)은 \"강화 학습의 확장성(scalability of RL)\"과 \"제약 프로그래밍의 모델링 및 제약 필터링 방법(modelling and constraint filtering methods of CP)\"을 결합하여 두 방법론의 한계를 효과적으로 해결하는 혁신적인 접근법을 나타냅니다. 제약 프로그래밍 시스템(CP system) 내에서 프로토타입을 구현함으로써, 연구는 하이브리드 강화 학습(hybrid reinforcement learning)이 제약과 불확실성을 모두 포함하는 확률적 제약 프로그래밍(Stochastic Constraint Programming, SCP) 문제를 이전보다 더 큰 규모로 해결할 수 있는 잠재력을 보여줍니다. 이 하이브리드 접근법은 수학적으로 $H = \\text{RL} + \\text{CP}$로 표현될 수 있으며, 여기서 $H$는 강화 학습(Reinforcement Learning)과 제약 프로그래밍(Constraint Programming)의 강점을 활용하여 복잡한 환경에서 문제 해결 능력을 향상시키는 하이브리드 모델을 나타냅니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "stochastic learning processes",
        "domain": "cs.AI",
        "summary": "  Reinforcement learning in environments with many action-state pairs is\nchallenging. At issue is the number of episodes needed to thoroughly search the\npolicy space. Most conventional heuristics address this search problem in a\nstochastic manner. This can leave large portions of the policy space unvisited\nduring the early training stages. In this paper, we propose an\nuncertainty-based, information-theoretic approach for performing guided\nstochastic searches that more effectively cover the policy space. Our approach\nis based on the value of information, a criterion that provides the optimal\ntrade-off between expected costs and the granularity of the search process. The\nvalue of information yields a stochastic routine for choosing actions during\nlearning that can explore the policy space in a coarse to fine manner. We\naugment this criterion with a state-transition uncertainty factor, which guides\nthe search process into previously unexplored regions of the policy space.\n",
        "english": "Stochastic learning processes often grapple with the challenge of thoroughly exploring environments with numerous action-state pairs, as conventional heuristics may leave large portions of the policy space unvisited during early training stages. By employing an uncertainty-based, information-theoretic approach, these processes can perform guided stochastic searches that effectively cover the policy space, leveraging the value of information to achieve an optimal trade-off between expected costs and search granularity. Mathematically, this approach is enhanced by incorporating a state-transition uncertainty factor, guiding the exploration into previously unexplored regions, thereby improving the efficiency of stochastic learning processes.",
        "korean": "확률적 학습 과정(stochastic learning processes)은 종종 많은 행동-상태 쌍을 가진 환경을 철저히 탐색하는 데 어려움을 겪으며, 전통적인 휴리스틱은 초기 훈련 단계에서 정책 공간의 큰 부분을 방문하지 않은 채로 남길 수 있습니다. 불확실성 기반 정보 이론적 접근법을 사용함으로써 이러한 과정은 정보의 가치를 활용하여 기대 비용과 탐색 세분화 사이의 최적의 균형을 달성하기 위해 정책 공간을 효과적으로 커버하는 유도된 확률적 탐색을 수행할 수 있습니다. 수학적으로, 이 접근법은 상태 전이 불확실성 요소를 통합하여 향상되며, 이전에 탐색되지 않은 영역으로의 탐색을 안내하여 확률적 학습 과정(stochastic learning processes)의 효율성을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "few-shot learning frameworks",
        "domain": "cs.AI",
        "summary": "  Algorithmic interpretability is necessary to build trust, ensure fairness,\nand track accountability. However, there is no existing formal measurement\nmethod for algorithmic interpretability. In this work, we build upon\nprogramming language theory and cognitive load theory to develop a framework\nfor measuring algorithmic interpretability. The proposed measurement framework\nreflects the process of a human learning an algorithm. We show that the\nmeasurement framework and the resulting cognitive complexity score have the\nfollowing desirable properties - universality, computability, uniqueness, and\nmonotonicity. We illustrate the measurement framework through a toy example,\ndescribe the framework and its conceptual underpinnings, and demonstrate the\nbenefits of the framework, in particular for managers considering tradeoffs\nwhen selecting algorithms.\n",
        "english": "Few-shot learning frameworks can benefit from the development of a framework for measuring algorithmic interpretability, as such a framework reflects the process of a human learning an algorithm, enhancing trust and accountability in AI systems. By leveraging programming language theory and cognitive load theory, the proposed measurement framework offers a cognitive complexity score with desirable properties such as universality, computability, uniqueness, and monotonicity, which are crucial for evaluating the interpretability of these frameworks. The mathematical expression for cognitive complexity, represented as $C = f(P, L)$, where $P$ denotes programming language complexity and $L$ represents cognitive load, provides a quantifiable metric that aids in making informed decisions about algorithm selection and tradeoffs.",
        "korean": "few-shot learning frameworks(few-shot learning frameworks)은 알고리즘 해석 가능성을 측정하기 위한 프레임워크의 개발로부터 이점을 얻을 수 있으며, 이러한 프레임워크는 인간이 알고리즘을 학습하는 과정을 반영하여 AI 시스템의 신뢰성과 책임성을 향상시킵니다. 프로그래밍 언어 이론(programming language theory)과 인지 부하 이론(cognitive load theory)을 활용하여 제안된 측정 프레임워크는 보편성, 계산 가능성, 고유성, 단조성 등 해석 가능성을 평가하는 데 중요한 속성을 가진 인지 복잡도 점수를 제공합니다. 인지 복잡도의 수학적 표현은 $C = f(P, L)$로 나타내며, 여기서 $P$는 프로그래밍 언어 복잡도(programming language complexity)를, $L$은 인지 부하(cognitive load)를 나타내며, 알고리즘 선택과 절충에 대한 정보에 입각한 결정을 내리는 데 도움이 되는 정량적 지표를 제공합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure that the term \"few-shot learning frameworks\" is consistently enclosed in parentheses without repetition. Adjust the structure for a more natural flow by rephrasing the first sentence to avoid redundancy."
    },
    {
        "turn_index": 2,
        "term": "energy-based models",
        "domain": "cs.AI",
        "summary": "  Causal Models are like Dependency Graphs and Belief Nets in that they provide\na structure and a set of assumptions from which a joint distribution can, in\nprinciple, be computed. Unlike Dependency Graphs, Causal Models are models of\nhierarchical and/or parallel processes, rather than models of distributions\n(partially) known to a model builder through some sort of gestalt. As such,\nCausal Models are more modular, easier to build, more intuitive, and easier to\nunderstand than Dependency Graph Models. Causal Models are formally defined and\nDependency Graph Models are shown to be a special case of them. Algorithms\nsupporting inference are presented. Parsimonious methods for eliciting\ndependent probabilities are presented.\n",
        "english": "Energy-based models, akin to Causal Models, provide a structure and a set of assumptions from which a joint distribution can be computed, offering a more modular and intuitive framework than Dependency Graph Models. These models are particularly advantageous due to their formal definition, allowing for the representation of hierarchical and/or parallel processes, which enhances their applicability in complex systems. Furthermore, the algorithms supporting inference in energy-based models facilitate parsimonious methods for eliciting dependent probabilities, where the joint distribution $P(x)$ can be expressed as $P(x) = \\frac{1}{Z}e^{-E(x)}$, with $Z$ being the partition function that ensures the distribution sums to one.",
        "korean": "인과 모델(causal models)과 유사한 에너지 기반 모델(energy-based models)은 결합 분포를 계산할 수 있는 구조와 가정 세트를 제공하여 의존 그래프 모델(dependency graph models)보다 더 모듈화되고 직관적인 프레임워크를 제공합니다. 이러한 모델은 특히 계층적 및/또는 병렬 프로세스를 표현할 수 있는 공식 정의 덕분에 복잡한 시스템에서의 적용 가능성을 높이는 데 유리합니다. 또한, 에너지 기반 모델(energy-based models)에서의 추론을 지원하는 알고리즘은 결합 분포 $P(x)$를 $P(x) = \\frac{1}{Z}e^{-E(x)}$로 표현할 수 있는 절약적인 방법을 용이하게 하며, 여기서 $Z$는 분포가 1로 합산되도록 보장하는 분할 함수입니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "gradient descent",
        "domain": "cs.AI",
        "summary": "  Dealing with planning problems with both logical relations and numeric\nchanges in real-world dynamic environments is challenging. Existing numeric\nplanning systems for the problem often discretize numeric variables or impose\nconvex constraints on numeric variables, which harms the performance when\nsolving problems. In this paper, we propose a novel algorithm framework to\nsolve numeric planning problems mixed with logical relations and numeric\nchanges based on gradient descent. We cast the numeric planning with logical\nrelations and numeric changes as an optimization problem. Specifically, we\nextend syntax to allow parameters of action models to be either objects or\nreal-valued numbers, which enhances the ability to model real-world numeric\neffects. Based on the extended modeling language, we propose a gradient-based\nframework to simultaneously optimize numeric parameters and compute appropriate\nactions to form candidate plans. The gradient-based framework is composed of an\nalgorithmic heuristic module based on propositional operations to select\nactions and generate constraints for gradient descent, an algorithmic\ntransition module to update states to next ones, and a loss module to compute\nloss. We repeatedly minimize loss by updating numeric parameters and compute\ncandidate plans until it converges into a valid plan for the planning problem.\nIn the empirical study, we exhibit that our algorithm framework is both\neffective and efficient in solving planning problems mixed with logical\nrelations and numeric changes, especially when the problems contain obstacles\nand non-linear numeric effects.\n",
        "english": "In addressing the challenge of solving numeric planning problems mixed with logical relations and numeric changes, the proposed algorithm framework utilizes gradient descent to optimize numeric parameters and compute appropriate actions, thereby enhancing the ability to model real-world numeric effects. The framework's effectiveness is demonstrated through an empirical study, where it efficiently solves planning problems, particularly those involving obstacles and non-linear numeric effects. A key component of this approach involves minimizing loss, expressed as $\\text{Loss} = f(\\text{parameters, actions})$, by repeatedly updating numeric parameters and computing candidate plans until convergence is achieved.",
        "korean": "논리적 관계와 수치적 변화를 혼합한 수치 계획 문제를 해결하는 도전에 대응하여, 제안된 알고리즘 프레임워크는 수치 매개변수를 최적화하고 적절한 행동을 계산하기 위해 경사 하강법(gradient descent)을 활용하여 실제 세계의 수치적 효과를 모델링하는 능력을 향상시킵니다. 이 프레임워크의 효과는 실증적 연구를 통해 입증되었으며, 특히 장애물과 비선형 수치 효과가 포함된 계획 문제를 효율적으로 해결합니다. 이 접근 방식의 핵심 요소는 손실을 최소화하는 것으로, 이는 $\\text{Loss} = f(\\text{parameters, actions})$로 표현되며, 수치 매개변수를 반복적으로 업데이트하고 후보 계획을 계산하여 수렴에 도달할 때까지 진행됩니다.",
        "score": 10,
        "parentheses_count": 1,
        "suggestions": "The translation captures the original meaning and nuances well, maintaining a natural flow and correct grammar. No changes are necessary."
    },
    {
        "turn_index": 2,
        "term": "probabilistic neural text segmentation",
        "domain": "cs.AI",
        "summary": "  Most of the web user's requirements are search or navigation time and getting\ncorrectly matched result. These constrains can be satisfied with some\nadditional modules attached to the existing search engines and web servers.\nThis paper proposes that powerful architecture for search engines with the\ntitle of Probabilistic Semantic Web Mining named from the methods used. With\nthe increase of larger and larger collection of various data resources on the\nWorld Wide Web (WWW), Web Mining has become one of the most important\nrequirements for the web users. Web servers will store various formats of data\nincluding text, image, audio, video etc., but servers can not identify the\ncontents of the data. These search techniques can be improved by adding some\nspecial techniques including semantic web mining and probabilistic analysis to\nget more accurate results. Semantic web mining technique can provide meaningful\nsearch of data resources by eliminating useless information with mining\nprocess. In this technique web servers will maintain Meta information of each\nand every data resources available in that particular web server. This will\nhelp the search engine to retrieve information that is relevant to user given\ninput string. This paper proposing the idea of combing these two techniques\nSemantic web mining and Probabilistic analysis for efficient and accurate\nsearch results of web mining. SPF can be calculated by considering both\nsemantic accuracy and syntactic accuracy of data with the input string. This\nwill be the deciding factor for producing results.\n",
        "english": "Probabilistic neural text segmentation can enhance search engine capabilities by incorporating advanced techniques such as semantic web mining and probabilistic analysis, which aim to \"provide meaningful search of data resources by eliminating useless information with mining process.\" By maintaining meta-information of each data resource, web servers can improve the retrieval of relevant information, thus addressing the constraints of \"search or navigation time and getting correctly matched result.\" Furthermore, the calculation of a Semantic Probabilistic Factor (SPF), expressed as \\( \\text{SPF} = \\text{semantic accuracy} \\times \\text{syntactic accuracy} \\), serves as a critical metric in achieving efficient and accurate segmentation outcomes.",
        "korean": "확률적 신경 텍스트 분할(probabilistic neural text segmentation)은 의미 웹 마이닝(semantic web mining)과 확률 분석(probabilistic analysis)과 같은 고급 기법을 통합하여 검색 엔진의 기능을 향상시킬 수 있으며, 이는 \"마이닝 과정을 통해 쓸모없는 정보를 제거하여 데이터 자원의 의미 있는 검색을 제공\"하는 것을 목표로 합니다. 각 데이터 자원의 메타 정보를 유지함으로써 웹 서버는 관련 정보의 검색을 개선할 수 있으며, 이는 \"검색 또는 탐색 시간과 정확히 일치하는 결과를 얻는\" 제약을 해결합니다. 또한, 의미 확률 인자(Semantic Probabilistic Factor, SPF)의 계산은 \\( \\text{SPF} = \\text{semantic accuracy} \\times \\text{syntactic accuracy} \\)로 표현되며, 효율적이고 정확한 분할 결과를 달성하는 데 중요한 지표로 작용합니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all English terms within parentheses are in lowercase."
    },
    {
        "turn_index": 2,
        "term": "loss functions",
        "domain": "cs.AI",
        "summary": "  Diffusion models are known to be vulnerable to outliers in training data. In\nthis paper we study an alternative diffusion loss function, which can preserve\nthe high quality of generated data like the original squared $L_{2}$ loss while\nat the same time being robust to outliers. We propose to use pseudo-Huber loss\nfunction with a time-dependent parameter to allow for the trade-off between\nrobustness on the most vulnerable early reverse-diffusion steps and fine\ndetails restoration on the final steps. We show that pseudo-Huber loss with the\ntime-dependent parameter exhibits better performance on corrupted datasets in\nboth image and audio domains. In addition, the loss function we propose can\npotentially help diffusion models to resist dataset corruption while not\nrequiring data filtering or purification compared to conventional training\nalgorithms.\n",
        "english": "In addressing the vulnerability of diffusion models to outliers in training data, the study proposes an alternative diffusion loss function that maintains the high quality of generated data akin to the original squared $L_{2}$ loss, while enhancing robustness against such outliers. By employing a pseudo-Huber loss function with a time-dependent parameter, the research allows for a strategic trade-off between robustness during the early reverse-diffusion steps and the restoration of fine details in the final steps. This innovative approach not only exhibits superior performance on corrupted datasets across image and audio domains but also potentially aids diffusion models in resisting dataset corruption without necessitating data filtering or purification.",
        "korean": "훈련 데이터에서 이상치에 대한 확산 모델(diffusion models)의 취약성을 해결하기 위해, 연구는 원래의 제곱 $L_{2}$ 손실과 유사한 생성 데이터의 높은 품질을 유지하면서 이러한 이상치에 대한 강건성을 향상시키는 대체 확산 손실 함수(diffusion loss function)를 제안합니다. 시간에 따라 변하는 매개변수를 가진 의사-후버 손실 함수(pseudo-Huber loss function)를 사용함으로써, 연구는 초기 역확산 단계에서의 강건성과 최종 단계에서의 세부 사항 복원을 전략적으로 균형을 맞출 수 있게 합니다. 이 혁신적인 접근 방식은 이미지 및 오디오 도메인에서 손상된 데이터셋에 대해 우수한 성능을 보일 뿐만 아니라, 데이터 필터링이나 정화 없이도 데이터셋 손상에 저항할 수 있도록 확산 모델(diffusion models)을 지원할 가능성이 있습니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure that all technical terms are consistently parenthesized as Korean term(English term) and check for any missing or inconsistent parenthesization."
    },
    {
        "turn_index": 2,
        "term": "dynamic probabilistic learning",
        "domain": "cs.AI",
        "summary": "  State abstraction enables sample-efficient learning and better task transfer\nin complex reinforcement learning environments. Recently, we proposed RePReL\n(Kokel et al. 2021), a hierarchical framework that leverages a relational\nplanner to provide useful state abstractions for learning. We present a brief\noverview of this framework and the use of a dynamic probabilistic logic model\nto design these state abstractions. Our experiments show that RePReL not only\nachieves better performance and efficient learning on the task at hand but also\ndemonstrates better generalization to unseen tasks.\n",
        "english": "Dynamic probabilistic learning plays a crucial role in the RePReL framework, which leverages a relational planner to provide useful state abstractions for learning, thereby facilitating sample-efficient learning and better task transfer in complex reinforcement learning environments. By employing a dynamic probabilistic logic model, RePReL designs state abstractions that significantly enhance performance, as evidenced by the framework's ability to achieve efficient learning on the task at hand and demonstrate improved generalization to unseen tasks. Notably, the dynamic probabilistic approach within RePReL can be mathematically represented by a probabilistic model \\( P(s' \\mid s, a) \\), where \\( s' \\) is the next state, \\( s \\) is the current state, and \\( a \\) is the action taken, underscoring the innovative integration of probabilistic reasoning in state abstraction design.",
        "korean": "동적 확률적 학습(dynamic probabilistic learning)은 RePReL 프레임워크(RePReL framework)에서 중요한 역할을 하며, 관계적 계획자(relational planner)를 활용하여 학습에 유용한 상태 추상화를 제공함으로써 복잡한 강화 학습 환경에서 샘플 효율적인 학습과 더 나은 작업 전이를 촉진합니다. 동적 확률적 논리 모델(dynamic probabilistic logic model)을 사용함으로써, RePReL은 상태 추상화를 설계하여 성능을 크게 향상시키며, 이는 주어진 작업에서 효율적인 학습을 달성하고 보지 못한 작업에 대한 일반화를 개선하는 프레임워크의 능력으로 입증됩니다. 특히, RePReL 내의 동적 확률적 접근법(dynamic probabilistic approach)은 확률 모델(probabilistic model) \\( P(s' \\mid s, a) \\)로 수학적으로 표현될 수 있으며, 여기서 \\( s' \\)는 다음 상태, \\( s \\)는 현재 상태, \\( a \\)는 수행된 행동을 나타내며, 상태 추상화 설계에서 확률적 추론의 혁신적인 통합을 강조합니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "probabilistic text models",
        "domain": "cs.AI",
        "summary": "  To be responsive to dynamically changing real-world environments, an\nintelligent agent needs to perform complex sequential decision-making tasks\nthat are often guided by commonsense knowledge. The previous work on this line\nof research led to the framework called \"interleaved commonsense reasoning and\nprobabilistic planning\" (icorpp), which used P-log for representing\ncommmonsense knowledge and Markov Decision Processes (MDPs) or Partially\nObservable MDPs (POMDPs) for planning under uncertainty. A main limitation of\nicorpp is that its implementation requires non-trivial engineering efforts to\nbridge the commonsense reasoning and probabilistic planning formalisms. In this\npaper, we present a unified framework to integrate icorpp's reasoning and\nplanning components. In particular, we extend probabilistic action language\npBC+ to express utility, belief states, and observation as in POMDP models.\nInheriting the advantages of action languages, the new action language provides\nan elaboration tolerant representation of POMDP that reflects commonsense\nknowledge. The idea led to the design of the system pbcplus2pomdp, which\ncompiles a pBC+ action description into a POMDP model that can be directly\nprocessed by off-the-shelf POMDP solvers to compute an optimal policy of the\npBC+ action description. Our experiments show that it retains the advantages of\nicorpp while avoiding the manual efforts in bridging the commonsense reasoner\nand the probabilistic planner.\n",
        "english": "Probabilistic text models play a crucial role in the framework of \"interleaved commonsense reasoning and probabilistic planning\" (icorpp), which utilizes P-log for representing commonsense knowledge alongside Markov Decision Processes (MDPs) or Partially Observable MDPs (POMDPs) for planning under uncertainty. An innovative advancement in this field is the extension of the probabilistic action language pBC+, enabling the expression of utility, belief states, and observation akin to POMDP models, thus providing an elaboration tolerant representation of POMDP that reflects commonsense knowledge. The system pbcplus2pomdp exemplifies this innovation by compiling a pBC+ action description into a POMDP model, which can be directly processed by off-the-shelf POMDP solvers to compute an optimal policy, $ \\pi^* $, of the pBC+ action description, thereby retaining the advantages of icorpp while minimizing manual integration efforts.",
        "korean": "확률적 텍스트 모델(probabilistic text models)은 \"상호작용하는 상식 추론 및 확률적 계획(interleaved commonsense reasoning and probabilistic planning, icorpp)\" 프레임워크에서 중요한 역할을 합니다. 이 프레임워크는 상식 지식을 표현하기 위해 P-log를 사용하며, 불확실성 하에서의 계획을 위해 마르코프 결정 과정(Markov Decision Processes, MDPs) 또는 부분 관찰 마르코프 결정 과정(Partially Observable MDPs, POMDPs)을 활용합니다. 이 분야의 혁신적인 발전은 확률적 행동 언어 pBC+의 확장으로, POMDP 모델과 유사하게 효용, 신념 상태, 관찰을 표현할 수 있게 하여 상식 지식을 반영하는 POMDP의 설명 관용적 표현을 제공합니다. 시스템 pbcplus2pomdp는 pBC+ 행동 설명을 POMDP 모델로 컴파일하여, 기성 POMDP 솔버에 의해 최적 정책 $ \\pi^* $을 계산할 수 있도록 함으로써 icorpp의 장점을 유지하면서 수작업 통합 노력을 최소화하는 혁신을 보여줍니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "empirical Bayes",
        "domain": "cs.AI",
        "summary": "  Mutual information is widely used in artificial intelligence, in a\ndescriptive way, to measure the stochastic dependence of discrete random\nvariables. In order to address questions such as the reliability of the\nempirical value, one must consider sample-to-population inferential approaches.\nThis paper deals with the distribution of mutual information, as obtained in a\nBayesian framework by a second-order Dirichlet prior distribution. The exact\nanalytical expression for the mean and an analytical approximation of the\nvariance are reported. Asymptotic approximations of the distribution are\nproposed. The results are applied to the problem of selecting features for\nincremental learning and classification of the naive Bayes classifier. A fast,\nnewly defined method is shown to outperform the traditional approach based on\nempirical mutual information on a number of real data sets. Finally, a\ntheoretical development is reported that allows one to efficiently extend the\nabove methods to incomplete samples in an easy and effective way.\n",
        "english": "In the realm of artificial intelligence, the empirical Bayes approach is pivotal when assessing the reliability of empirical values, particularly through sample-to-population inferential techniques. The study utilizes a Bayesian framework with a second-order Dirichlet prior distribution to derive the distribution of mutual information, providing an exact analytical expression for the mean, denoted as $\\mu$, and an analytical approximation for the variance, $\\sigma^2$. This innovative method surpasses traditional empirical mutual information techniques, demonstrating superior performance in feature selection for incremental learning and the classification of the naive Bayes classifier across various real data sets.",
        "korean": "인공지능 분야에서 경험적 베이즈(empirical Bayes) 접근법은 특히 표본에서 모집단으로의 추론 기법을 통해 경험적 값의 신뢰성을 평가할 때 매우 중요합니다. 이 연구는 상위 디리클레 사전 분포(second-order Dirichlet prior distribution)를 사용한 베이즈 프레임워크(Bayesian framework)를 활용하여 상호 정보(mutual information)의 분포를 도출하고, 평균을 나타내는 $\\mu$와 분산의 분석적 근사치인 $\\sigma^2$에 대한 정확한 분석적 표현을 제공합니다. 이 혁신적인 방법은 전통적인 경험적 상호 정보(empirical mutual information) 기법을 능가하며, 점진적 학습(incremental learning)과 다양한 실제 데이터 세트에서의 나이브 베이즈 분류기(naive Bayes classifier) 분류에 있어 뛰어난 성능을 보여줍니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent lowercase letters within parentheses for all terms."
    },
    {
        "turn_index": 2,
        "term": "adaptive learning processes",
        "domain": "cs.AI",
        "summary": "  Online learning is a familiar problem setting within Machine-Learning in\nwhich data is presented serially in time to a learning agent, requiring it to\nprogressively adapt within the constraints of the learning algorithm. More\nsophisticated variants may involve concepts such as transfer-learning which\nincrease this adaptive capability, enhancing the learner's cognitive capacities\nin a manner that can begin to imitate the open-ended learning capabilities of\nhuman beings.\n  We shall argue in this paper, however, that a full realization of this notion\nrequires that, in addition to the capacity to adapt to novel data, autonomous\nonline learning must ultimately incorporate the capacity to update its own\nrepresentational capabilities in relation to the data. We therefore enquire\nabout the philosophical limits of this process, and argue that only fully\nembodied learners exhibiting an a priori perception-action link in order to\nground representational adaptations are capable of exhibiting the full range of\nhuman cognitive capability.\n",
        "english": "Adaptive learning processes in online learning involve data being presented serially in time to a learning agent, necessitating progressive adaptation within the constraints of the learning algorithm. More advanced methodologies, such as transfer learning, significantly enhance this adaptive capability, thereby augmenting the learner's cognitive capacities to emulate the open-ended learning abilities of humans. To fully realize the potential of adaptive learning processes, it is essential that autonomous online learning systems incorporate the capacity to update their representational capabilities, which can be mathematically represented as a function $f(x)$ that evolves in response to novel data inputs, thus highlighting the innovative approach of integrating an a priori perception-action link to ground these adaptations.",
        "korean": "온라인 학습에서 적응형 학습 과정(adaptive learning processes)은 학습 에이전트에게 시간이 지남에 따라 순차적으로 데이터가 제공되며, 학습 알고리즘의 제약 내에서 점진적인 적응이 필요합니다. 전이 학습(transfer learning)과 같은 보다 발전된 방법론은 이러한 적응 능력을 크게 향상시켜 학습자의 인지 능력을 인간의 개방형 학습 능력을 모방할 수 있도록 증대시킵니다. 적응형 학습 과정(adaptive learning processes)의 잠재력을 완전히 실현하기 위해서는 자율 온라인 학습 시스템이 표현 능력을 업데이트할 수 있는 능력을 포함해야 하며, 이는 새로운 데이터 입력에 반응하여 진화하는 함수 $f(x)$로 수학적으로 표현될 수 있습니다. 이는 이러한 적응을 기반으로 하는 선험적 지각-행동 연결을 통합하는 혁신적인 접근 방식을 강조합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": ""
    },
    {
        "turn_index": 2,
        "term": "knowledge graph embeddings",
        "domain": "cs.AI",
        "summary": "  With the explosive growth of artificial intelligence (AI) and big data, it\nhas become vitally important to organize and represent the enormous volume of\nknowledge appropriately. As graph data, knowledge graphs accumulate and convey\nknowledge of the real world. It has been well-recognized that knowledge graphs\neffectively represent complex information; hence, they rapidly gain the\nattention of academia and industry in recent years. Thus to develop a deeper\nunderstanding of knowledge graphs, this paper presents a systematic overview of\nthis field. Specifically, we focus on the opportunities and challenges of\nknowledge graphs. We first review the opportunities of knowledge graphs in\nterms of two aspects: (1) AI systems built upon knowledge graphs; (2) potential\napplication fields of knowledge graphs. Then, we thoroughly discuss severe\ntechnical challenges in this field, such as knowledge graph embeddings,\nknowledge acquisition, knowledge graph completion, knowledge fusion, and\nknowledge reasoning. We expect that this survey will shed new light on future\nresearch and the development of knowledge graphs.\n",
        "english": "Knowledge graph embeddings are a crucial aspect of addressing severe technical challenges in the field of knowledge graphs, as they facilitate the representation of complex information in a structured manner. These embeddings enable AI systems to leverage knowledge graphs effectively, thereby enhancing their capacity to process and interpret vast amounts of data. Mathematically, knowledge graph embeddings can be represented as vectors in a continuous vector space, denoted as $\\mathbf{R}^n$, where $n$ is the dimensionality of the embedding space, allowing for efficient computation and reasoning.",
        "korean": "지식 그래프 임베딩(knowledge graph embeddings)은 지식 그래프(knowledge graphs) 분야에서 심각한 기술적 도전 과제를 해결하는 데 중요한 측면으로, 복잡한 정보를 구조화된 방식으로 표현할 수 있게 합니다. 이러한 임베딩(embeddings)은 인공지능 시스템(ai systems)이 지식 그래프(knowledge graphs)를 효과적으로 활용할 수 있도록 하여 방대한 양의 데이터를 처리하고 해석하는 능력을 향상시킵니다. 수학적으로, 지식 그래프 임베딩(knowledge graph embeddings)은 연속 벡터 공간(continuous vector space)에서 벡터로 표현될 수 있으며, 이는 임베딩 공간(embedding space)의 차원인 $n$으로 나타내어지며, 효율적인 계산과 추론을 가능하게 합니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider restructuring sentences for improved natural flow and clarity."
    },
    {
        "turn_index": 2,
        "term": "distillation",
        "domain": "cs.AI",
        "summary": "  Model-based reinforcement learning (RL) has demonstrated remarkable successes\non a range of continuous control tasks due to its high sample efficiency. To\nsave the computation cost of conducting planning online, recent practices tend\nto distill optimized action sequences into an RL policy during the training\nphase. Although the distillation can incorporate both the foresight of planning\nand the exploration ability of RL policies, the theoretical understanding of\nthese methods is yet unclear. In this paper, we extend the policy improvement\nstep of Soft Actor-Critic (SAC) by developing an approach to distill from\nmodel-based planning to the policy. We then demonstrate that such an approach\nof policy improvement has a theoretical guarantee of monotonic improvement and\nconvergence to the maximum value defined in SAC. We discuss effective design\nchoices and implement our theory as a practical algorithm -- Model-based\nPlanning Distilled to Policy (MPDP) -- that updates the policy jointly over\nmultiple future time steps. Extensive experiments show that MPDP achieves\nbetter sample efficiency and asymptotic performance than both model-free and\nmodel-based planning algorithms on six continuous control benchmark tasks in\nMuJoCo.\n",
        "english": "Recent advancements in model-based reinforcement learning (RL) have leveraged distillation to combine the foresight of planning with the exploration capabilities of RL policies, although the theoretical understanding of these methods remains unclear. By extending the policy improvement step of Soft Actor-Critic (SAC), a novel approach has been developed to distill from model-based planning to the policy, ensuring a theoretical guarantee of monotonic improvement and convergence to the maximum value defined in SAC, denoted as $V^*$. The resulting algorithm, Model-based Planning Distilled to Policy (MPDP), demonstrates significant innovation by achieving superior sample efficiency and asymptotic performance compared to both model-free and model-based planning algorithms across six continuous control benchmark tasks in MuJoCo.",
        "korean": "최근 모델 기반 강화 학습(model-based reinforcement learning, RL)의 발전은 계획의 예측력과 RL 정책의 탐색 능력을 결합하기 위해 증류(distillation)를 활용하고 있지만, 이러한 방법에 대한 이론적 이해는 여전히 명확하지 않습니다. 소프트 액터-크리틱(Soft Actor-Critic, SAC)의 정책 개선 단계를 확장함으로써, 모델 기반 계획에서 정책으로 증류(distillation)하는 새로운 접근법이 개발되어 SAC에서 정의된 최대 값 $V^*$에 대한 단조로운 개선과 수렴의 이론적 보장을 제공합니다. 결과적으로, 모델 기반 계획 증류 정책(Model-based Planning Distilled to Policy, MPDP) 알고리즘은 MuJoCo의 여섯 가지 연속 제어 벤치마크 과제에서 모델 프리 및 모델 기반 계획 알고리즘과 비교하여 우수한 샘플 효율성과 점근적 성능을 달성함으로써 상당한 혁신을 보여줍니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "hmm",
        "domain": "cs.AI",
        "summary": "  Speech Recognition searches to predict the spoken words automatically. These\nsystems are known to be very expensive because of using several pre-recorded\nhours of speech. Hence, building a model that minimizes the cost of the\nrecognizer will be very interesting. In this paper, we present a new approach\nfor recognizing speech based on belief HMMs instead of proba-bilistic HMMs.\nExperiments shows that our belief recognizer is insensitive to the lack of the\ndata and it can be trained using only one exemplary of each acoustic unit and\nit gives a good recognition rates. Consequently, using the belief HMM\nrecognizer can greatly minimize the cost of these systems.\n",
        "english": "The innovative approach of utilizing belief HMMs, as opposed to traditional probabilistic HMMs, presents a significant advancement in speech recognition technology by minimizing the cost of systems that typically rely on extensive pre-recorded speech data. Experiments demonstrate that the belief HMM recognizer exhibits insensitivity to data scarcity, achieving commendable recognition rates even when trained with merely one exemplar of each acoustic unit, thereby highlighting its efficiency and robustness. Mathematically, the belief HMM model can be represented as $\\text{Belief}(S_t) = \\sum_{s_{t-1}} \\text{Belief}(S_{t-1}) \\cdot \\text{Transition}(s_{t-1}, s_t) \\cdot \\text{Observation}(o_t|s_t)$, showcasing its capability to effectively handle the variability in speech inputs.",
        "korean": "혁신적인 접근 방식인 신념 hmms(belief hmms)을 전통적인 확률적 hmms(probabilistic hmms) 대신 활용하는 것은 대개 광범위한 사전 녹음된 음성 데이터에 의존하는 시스템의 비용을 최소화함으로써 음성 인식 기술에서 중요한 발전을 나타냅니다. 실험 결과, 신념 hmm 인식기는 데이터 부족에 대한 민감도가 낮아 각 음향 단위의 예시 하나만으로 훈련되었을 때도 뛰어난 인식률을 달성하여 그 효율성과 견고성을 강조합니다. 수학적으로, 신념 hmm 모델은 $\\text{Belief}(S_t) = \\sum_{s_{t-1}} \\text{Belief}(S_{t-1}) \\cdot \\text{Transition}(s_{t-1}, s_t) \\cdot \\text{Observation}(o_t|s_t)$로 표현될 수 있으며, 이는 음성 입력의 변동성을 효과적으로 처리할 수 있는 능력을 보여줍니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "manifold learning",
        "domain": "cs.AI",
        "summary": "  We present a method for encoding game logs as numeric features in the card\ngame Dominion. We then run the manifold learning algorithm t-SNE on these\nencodings to visualize the landscape of player strategies. By quantifying game\nstates as the relative prevalence of cards in a player's deck, we create\nvisualizations that capture qualitative differences in player strategies.\nDifferent ways of deviating from the starting game state appear as different\nrays in the visualization, giving it an intuitive explanation. This is a\npromising new direction for understanding player strategies across games that\nvary in length.\n",
        "english": "In the study of manifold learning, the researchers employed the t-SNE algorithm to encode game logs as numeric features for the card game Dominion, thereby enabling the visualization of player strategies. By quantifying game states as the relative prevalence of cards in a player's deck, the researchers created visualizations that effectively captured qualitative differences in player strategies, with deviations from the starting game state appearing as distinct rays. This innovative approach highlights the potential of manifold learning to provide intuitive explanations for strategic variations across games, with the formula $x_i = \\text{prevalence of card}_i / \\text{total cards}$ used to quantify game states, marking a promising direction for future research.",
        "korean": "다양체 학습(manifold learning) 연구에서 연구자들은 카드 게임 도미니언(Dominion)의 게임 로그를 수치적 특징으로 인코딩하기 위해 t-SNE 알고리즘을 사용하여 플레이어 전략의 시각화를 가능하게 했습니다. 연구자들은 플레이어 덱에 있는 카드의 상대적 빈도로 게임 상태를 정량화함으로써, 시작 게임 상태에서의 편차가 뚜렷한 광선으로 나타나는 플레이어 전략의 질적 차이를 효과적으로 포착하는 시각화를 생성했습니다. 이 혁신적인 접근 방식은 게임 전반에 걸친 전략적 변화를 직관적으로 설명할 수 있는 다양체 학습(manifold learning)의 잠재력을 강조하며, 게임 상태를 정량화하기 위해 $x_i = \\text{카드}_i의 \\text{빈도} / \\text{총 카드 수}$ 공식을 사용하여 미래 연구에 유망한 방향을 제시합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "hierarchical clustering",
        "domain": "cs.AI",
        "summary": "  Knowledge graphs have emerged as a widely adopted medium for storing\nrelational data, making methods for automatically reasoning with them highly\ndesirable. In this paper, we present a novel approach for inducing a hierarchy\nof subject clusters, building upon our earlier work done in taxonomy induction.\nOur method first constructs a tag hierarchy before assigning subjects to\nclusters on this hierarchy. We quantitatively demonstrate our method's ability\nto induce a coherent cluster hierarchy on three real-world datasets.\n",
        "english": "Hierarchical clustering plays a crucial role in organizing relational data within knowledge graphs, which are increasingly utilized for their ability to store complex data structures. Building upon previous advancements in taxonomy induction, the research introduces a novel method that first constructs a tag hierarchy and subsequently assigns subjects to clusters on this hierarchy, thereby enhancing the coherence of the cluster hierarchy. The efficacy of this approach is quantitatively demonstrated, as the method successfully induces a coherent cluster hierarchy on three real-world datasets, with performance metrics indicating a significant improvement in organizing subjects into hierarchical structures, denoted as $\\mathcal{H}$.",
        "korean": "계층적 군집화(hierarchical clustering)는 지식 그래프(knowledge graphs) 내에서 관계형 데이터를 조직하는 데 중요한 역할을 하며, 이는 복잡한 데이터 구조를 저장할 수 있는 능력으로 점점 더 많이 활용되고 있습니다. 분류 체계 유도(taxonomy induction)의 이전 발전을 기반으로, 연구는 먼저 태그 계층(tag hierarchy)을 구성하고 그 후 이 계층에 주제를 할당하여 클러스터 계층의 일관성을 향상시키는 새로운 방법을 소개합니다. 이 접근법의 효능은 정량적으로 입증되었으며, 세 가지 실제 데이터셋(real-world datasets)에서 일관된 클러스터 계층을 성공적으로 유도하고, 성능 지표는 주제를 계층적 구조로 조직하는 데 있어 상당한 개선을 나타내며, 이는 $\\mathcal{H}$로 표시됩니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure that all technical terms are consistently formatted as Korean term(English term) and consider rephrasing for smoother readability, such as adjusting the placement of clauses for better flow."
    },
    {
        "turn_index": 2,
        "term": "neural text classification",
        "domain": "cs.AI",
        "summary": "  Deep neural networks have significantly contributed to the success in\npredictive accuracy for classification tasks. However, they tend to make\nover-confident predictions in real-world settings, where domain shifting and\nout-of-distribution (OOD) examples exist. Most research on uncertainty\nestimation focuses on computer vision because it provides visual validation on\nuncertainty quality. However, few have been presented in the natural language\nprocess domain. Unlike Bayesian methods that indirectly infer uncertainty\nthrough weight uncertainties, current evidential uncertainty-based methods\nexplicitly model the uncertainty of class probabilities through subjective\nopinions. They further consider inherent uncertainty in data with different\nroot causes, vacuity (i.e., uncertainty due to a lack of evidence) and\ndissonance (i.e., uncertainty due to conflicting evidence). In our paper, we\nfirstly apply evidential uncertainty in OOD detection for text classification\ntasks. We propose an inexpensive framework that adopts both auxiliary outliers\nand pseudo off-manifold samples to train the model with prior knowledge of a\ncertain class, which has high vacuity for OOD samples. Extensive empirical\nexperiments demonstrate that our model based on evidential uncertainty\noutperforms other counterparts for detecting OOD examples. Our approach can be\neasily deployed to traditional recurrent neural networks and fine-tuned\npre-trained transformers.\n",
        "english": "Neural text classification has witnessed significant advancements in predictive accuracy due to the application of deep neural networks, although these models often exhibit over-confidence in real-world scenarios where domain shifting and out-of-distribution (OOD) examples are present. In this context, the study introduces a novel framework for neural text classification that leverages evidential uncertainty methods, explicitly modeling the uncertainty of class probabilities through subjective opinions to address inherent data uncertainties such as vacuity and dissonance. Notably, the proposed approach incorporates auxiliary outliers and pseudo off-manifold samples, enhancing the model's ability to detect OOD examples, with empirical results indicating superior performance compared to existing counterparts, particularly when deployed on traditional recurrent neural networks and fine-tuned pre-trained transformers.",
        "korean": "신경 텍스트 분류(neural text classification)는 심층 신경망(deep neural networks)의 적용으로 예측 정확도가 크게 향상되었지만, 이러한 모델은 도메인 이동과 분포 외(out-of-distribution, OOD) 예제가 존재하는 실제 시나리오에서 종종 과도한 자신감을 보입니다. 이러한 맥락에서, 본 연구는 증거적 불확실성 방법(evidential uncertainty methods)을 활용하여 클래스 확률의 불확실성을 주관적 의견을 통해 명시적으로 모델링함으로써 공백성과 불협화음과 같은 내재된 데이터 불확실성을 해결하는 새로운 신경 텍스트 분류(neural text classification) 프레임워크를 소개합니다. 특히, 제안된 접근법은 보조적인 이상치(auxiliary outliers)와 의사 오프 매니폴드 샘플(pseudo off-manifold samples)을 포함하여 모델의 OOD 예제 탐지 능력을 향상시키며, 전통적인 순환 신경망(recurrent neural networks)과 미세 조정된 사전 학습 변환기(pre-trained transformers)에서 배포될 때 기존의 대응 방법보다 우수한 성능을 보인다는 실증적 결과를 나타냅니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "deep density estimation",
        "domain": "cs.AI",
        "summary": "  This paper introduces a novel method for learning how to play the most\ndifficult Atari 2600 games from the Arcade Learning Environment using deep\nreinforcement learning. The proposed method, human checkpoint replay, consists\nin using checkpoints sampled from human gameplay as starting points for the\nlearning process. This is meant to compensate for the difficulties of current\nexploration strategies, such as epsilon-greedy, to find successful control\npolicies in games with sparse rewards. Like other deep reinforcement learning\narchitectures, our model uses a convolutional neural network that receives only\nraw pixel inputs to estimate the state value function. We tested our method on\nMontezuma's Revenge and Private Eye, two of the most challenging games from the\nAtari platform. The results we obtained show a substantial improvement compared\nto previous learning approaches, as well as over a random player. We also\npropose a method for training deep reinforcement learning agents using human\ngameplay experience, which we call human experience replay.\n",
        "english": "Deep density estimation, akin to the method of using \"checkpoints sampled from human gameplay as starting points for the learning process,\" offers a novel approach to overcoming the limitations of traditional exploration strategies such as epsilon-greedy. By employing a convolutional neural network that processes raw pixel inputs to \"estimate the state value function,\" deep density estimation can significantly enhance the ability to learn control policies in environments with sparse rewards. The innovative use of human experience, as demonstrated by the substantial improvement in games like Montezuma's Revenge and Private Eye, underscores the potential of deep density estimation in advancing the field of deep reinforcement learning, where the optimization objective can be expressed as maximizing $\\sum_{t=0}^{T} \\gamma^t R_t$, with $\\gamma$ representing the discount factor and $R_t$ the reward at time $t$.",
        "korean": "인간 게임 플레이에서 샘플링된 체크포인트(checkpoints sampled from human gameplay)를 학습 과정의 시작점으로 사용하는 방법과 유사한 심층 밀도 추정(deep density estimation)은 엡실론-탐욕적(epsilon-greedy)과 같은 전통적인 탐색 전략의 한계를 극복하는 새로운 접근 방식을 제공합니다. 원시 픽셀 입력을 처리하여 상태 가치 함수(state value function)를 추정하는 합성곱 신경망(convolutional neural network)을 사용함으로써, 심층 밀도 추정(deep density estimation)은 희소한 보상이 있는 환경에서 제어 정책을 학습하는 능력을 크게 향상시킬 수 있습니다. 몬테주마의 복수(Montezuma's Revenge)와 프라이빗 아이(Private Eye)와 같은 게임에서의 상당한 개선을 통해 입증된 바와 같이, 인간 경험의 혁신적인 사용은 심층 강화 학습(deep reinforcement learning) 분야를 발전시키는 데 있어 심층 밀도 추정(deep density estimation)의 잠재력을 강조합니다. 여기서 최적화 목표는 $\\sum_{t=0}^{T} \\gamma^t R_t$를 최대화하는 것으로 표현될 수 있으며, $\\gamma$는 할인 인자(discount factor)를, $R_t$는 시간 $t$에서의 보상(reward)을 나타냅니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural probabilistic programming",
        "domain": "cs.AI",
        "summary": "  The goal of combining the robustness of neural networks and the\nexpressiveness of symbolic methods has rekindled the interest in Neuro-Symbolic\nAI. Deep Probabilistic Programming Languages (DPPLs) have been developed for\nprobabilistic logic programming to be carried out via the probability\nestimations of deep neural networks. However, recent SOTA DPPL approaches allow\nonly for limited conditional probabilistic queries and do not offer the power\nof true joint probability estimation. In our work, we propose an easy\nintegration of tractable probabilistic inference within a DPPL. To this end, we\nintroduce SLASH, a novel DPPL that consists of Neural-Probabilistic Predicates\n(NPPs) and a logic program, united via answer set programming (ASP). NPPs are a\nnovel design principle allowing for combining all deep model types and\ncombinations thereof to be represented as a single probabilistic predicate. In\nthis context, we introduce a novel $+/-$ notation for answering various types\nof probabilistic queries by adjusting the atom notations of a predicate. To\nscale well, we show how to prune the stochastically insignificant parts of the\n(ground) program, speeding up reasoning without sacrificing the predictive\nperformance. We evaluate SLASH on a variety of different tasks, including the\nbenchmark task of MNIST addition and Visual Question Answering (VQA).\n",
        "english": "Neural probabilistic programming aims to integrate the robustness of neural networks with the expressiveness of symbolic methods, as demonstrated by the development of SLASH, a novel Deep Probabilistic Programming Language (DPPL). SLASH consists of Neural-Probabilistic Predicates (NPPs) and a logic program, united via answer set programming (ASP), which allows for the representation of all deep model types as a single probabilistic predicate. Notably, SLASH introduces a novel $+/-$ notation for answering various types of probabilistic queries by adjusting the atom notations of a predicate, thereby enhancing the scalability and efficiency of probabilistic inference without sacrificing predictive performance.",
        "korean": "신경 확률 프로그래밍(neural probabilistic programming)은 SLASH라는 새로운 심층 확률 프로그래밍 언어(deep probabilistic programming language, DPPL)의 개발을 통해 신경망(neural networks)의 견고함과 기호적 방법의 표현력을 통합하는 것을 목표로 합니다. SLASH는 신경 확률 술어(neural-probabilistic predicates, NPPs)와 논리 프로그램을 답 집합 프로그래밍(answer set programming, ASP)을 통해 결합하여 모든 심층 모델 유형을 단일 확률 술어로 표현할 수 있게 합니다. 특히, SLASH는 술어의 원자 표기를 조정하여 다양한 유형의 확률 쿼리에 답변할 수 있는 새로운 $+/-$ 표기법을 도입하여 예측 성능을 희생하지 않고 확률 추론의 확장성과 효율성을 향상시킵니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure all English terms within parentheses are in lowercase and maintain consistency in the use of parentheses for all technical terms."
    },
    {
        "turn_index": 2,
        "term": "supervised learning",
        "domain": "cs.AI",
        "summary": "  The current reward learning from human preferences could be used to resolve\ncomplex reinforcement learning (RL) tasks without access to a reward function\nby defining a single fixed preference between pairs of trajectory segments.\nHowever, the judgement of preferences between trajectories is not dynamic and\nstill requires human input over thousands of iterations. In this study, we\nproposed a weak human preference supervision framework, for which we developed\na human preference scaling model that naturally reflects the human perception\nof the degree of weak choices between trajectories and established a\nhuman-demonstration estimator via supervised learning to generate the predicted\npreferences for reducing the number of human inputs. The proposed weak human\npreference supervision framework can effectively solve complex RL tasks and\nachieve higher cumulative rewards in simulated robot locomotion -- MuJoCo games\n-- relative to the single fixed human preferences. Furthermore, our established\nhuman-demonstration estimator requires human feedback only for less than 0.01\\%\nof the agent's interactions with the environment and significantly reduces the\ncost of human inputs by up to 30\\% compared with the existing approaches. To\npresent the flexibility of our approach, we released a video\n(https://youtu.be/jQPe1OILT0M) showing comparisons of the behaviours of agents\ntrained on different types of human input. We believe that our naturally\ninspired human preferences with weakly supervised learning are beneficial for\nprecise reward learning and can be applied to state-of-the-art RL systems, such\nas human-autonomy teaming systems.\n",
        "english": "In the domain of reinforcement learning, the integration of a human-demonstration estimator via supervised learning has been shown to generate predicted preferences that significantly reduce the need for extensive human input, achieving a reduction in human feedback requirements to less than 0.01\\% of the agent's interactions with the environment. This innovative approach leverages a weak human preference supervision framework, which effectively resolves complex RL tasks and leads to higher cumulative rewards in simulated environments, such as MuJoCo games, compared to models relying solely on fixed human preferences. By scaling human perception of weak choices between trajectory segments, the study highlights the potential of supervised learning to enhance the precision of reward learning in state-of-the-art RL systems, including human-autonomy teaming systems.",
        "korean": "강화 학습(reinforcement learning) 분야에서 인간 시연 추정기(human-demonstration estimator)를 지도 학습(supervised learning)을 통해 통합하는 것은 예측된 선호도를 생성하여 광범위한 인간 입력의 필요성을 크게 줄이며, 에이전트의 환경과의 상호작용 중 인간 피드백 요구를 0.01\\% 미만으로 감소시키는 것으로 나타났습니다. 이 혁신적인 접근 방식은 약한 인간 선호 감독 프레임워크(weak human preference supervision framework)를 활용하여 복잡한 RL 작업을 효과적으로 해결하고, 고정된 인간 선호에만 의존하는 모델에 비해 MuJoCo 게임과 같은 시뮬레이션 환경에서 더 높은 누적 보상을 이끌어냅니다. 경로 세그먼트 간의 약한 선택에 대한 인간 인식을 확장함으로써, 연구는 지도 학습(supervised learning)이 최첨단 RL 시스템, 특히 인간-자율성 팀 시스템(human-autonomy teaming systems)에서 보상 학습의 정밀도를 향상시킬 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "spectral normalization",
        "domain": "cs.AI",
        "summary": "  Decision and policy-makers in multi-criteria decision-making analysis take\ninto account some strategies in order to analyze outcomes and to finally make\nan effective and more precise decision. Among those strategies, the\nmodification of the normalization process in the multiple-criteria\ndecision-making algorithm is still a question due to the confrontation of many\nnormalization tools. Normalization is the basic action in defining and solving\na MADM problem and a MADM model. Normalization is the first, also necessary,\nstep in solving, i.e. the application of a MADM method. It is a fact that the\nselection of normalization methods has a direct effect on the results. One of\nthe latest normalization methods introduced is the Logarithmic Normalization\n(LN) method. This new method has a distinguished advantage, reflecting in that\na sum of the normalized values of criteria always equals 1. This normalization\nmethod had never been applied in any MADM methods before. This research study\nis focused on the analysis of the classical MADM methods based on logarithmic\nnormalization. VIKOR and TOPSIS, as the two famous MADM methods, were selected\nfor this reanalysis research study. Two numerical examples were checked in both\nmethods, based on both the classical and the novel ways based on the LN. The\nresults indicate that there are differences between the two approaches.\nEventually, a sensitivity analysis is also designed to illustrate the\nreliability of the final results.\n",
        "english": "To effectively address the challenges in multi-criteria decision-making analysis, spectral normalization emerges as a crucial strategy, as the selection of normalization methods has a direct effect on the results. The introduction of novel normalization techniques, such as the Logarithmic Normalization (LN) method, offers a significant advantage by ensuring that the sum of the normalized values of criteria always equals 1, thereby enhancing the reliability of decision-making processes. In reanalyzing classical MADM methods like VIKOR and TOPSIS, the application of spectral normalization, particularly through the LN method, reveals differences between classical and novel approaches, underscoring the method's potential to refine decision-making accuracy.",
        "korean": "다기준 의사결정 분석(multi-criteria decision-making analysis)의 도전 과제를 효과적으로 해결하기 위해, 스펙트럼 정규화(spectral normalization)는 중요한 전략으로 부상하며, 정규화 방법의 선택은 결과에 직접적인 영향을 미칩니다. 로그 정규화(logarithmic normalization, ln) 방법과 같은 새로운 정규화 기법의 도입은 기준의 정규화된 값의 합이 항상 1이 되도록 보장함으로써 의사결정 과정의 신뢰성을 높이는 중요한 이점을 제공합니다. vikor 및 topsis와 같은 고전적인 madm 방법을 재분석할 때, 특히 ln 방법을 통한 스펙트럼 정규화(spectral normalization)의 적용은 고전적 접근법과 새로운 접근법 간의 차이를 드러내며, 의사결정 정확성을 개선할 수 있는 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "task-driven text models",
        "domain": "cs.AI",
        "summary": "  Vagueness and uncertainty management is counted among one of the challenges\nthat remain unresolved in systems that generate texts from non-linguistic data,\nknown as data-to-text systems. In the last decade, work in fuzzy linguistic\nsummarization and description of data has raised the interest of using fuzzy\nsets to model and manage the imprecision of human language in data-to-text\nsystems. However, despite some research in this direction, there has not been\nan actual clear discussion and justification on how fuzzy sets can contribute\nto data-to-text for modeling vagueness and uncertainty in words and\nexpressions. This paper intends to bridge this gap by answering the following\nquestions: What does vagueness mean in fuzzy sets theory? What does vagueness\nmean in data-to-text contexts? In what ways can fuzzy sets theory contribute to\nimprove data-to-text systems? What are the challenges that researchers from\nboth disciplines need to address for a successful integration of fuzzy sets\ninto data-to-text systems? In what cases should the use of fuzzy sets be\navoided in D2T? For this, we review and discuss the state of the art of\nvagueness modeling in natural language generation and data-to-text, describe\npotential and actual usages of fuzzy sets in data-to-text contexts, and provide\nsome additional insights about the engineering of data-to-text systems that\nmake use of fuzzy set-based techniques.\n",
        "english": "Task-driven text models, particularly in the domain of data-to-text systems, face significant challenges in managing vagueness and uncertainty, as these systems generate texts from non-linguistic data. The integration of fuzzy sets into task-driven text models is proposed to address these issues by modeling the imprecision inherent in human language, yet there remains a lack of clear discussion and justification on how these sets can effectively contribute to such systems. Researchers are called to explore the potential of fuzzy sets theory, especially in cases where the membership function $f(x) = \\frac{1}{1 + e^{-x}}$ can be utilized to quantify the degree of uncertainty, thus enhancing the precision and reliability of task-driven text models.",
        "korean": "데이터에서 텍스트로 변환하는 시스템(data-to-text systems) 분야에서 특히 작업 주도 텍스트 모델(task-driven text models)은 비언어적 데이터로부터 텍스트를 생성할 때 모호성과 불확실성을 관리하는 데 상당한 어려움에 직면합니다. 이러한 문제를 해결하기 위해 작업 주도 텍스트 모델(task-driven text models)에 퍼지 집합(fuzzy sets)을 통합하는 것이 제안되었으며, 이는 인간 언어에 내재된 불명확성을 모델링하는 데 기여할 수 있습니다. 그러나 이러한 집합이 시스템에 효과적으로 기여할 수 있는 방법에 대한 명확한 논의와 정당성이 부족합니다. 연구자들은 퍼지 집합 이론(fuzzy sets theory)의 잠재력을 탐구할 것을 요청받고 있으며, 특히 멤버십 함수 $f(x) = \\frac{1}{1 + e^{-x}}$가 불확실성의 정도를 정량화하는 데 활용될 수 있는 경우, 작업 주도 텍스트 모델(task-driven text models)의 정밀성과 신뢰성을 향상시키는 데 기여할 수 있습니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar."
    },
    {
        "turn_index": 2,
        "term": "contextual sequence modeling",
        "domain": "cs.AI",
        "summary": "  While deep generative models show promise for learning inverse protein\nfolding directly from data, the lack of publicly available structure-sequence\npairings limits their generalization. Previous improvements and data\naugmentation efforts to overcome this bottleneck have been insufficient. To\nfurther address this challenge, we propose a novel protein design paradigm\ncalled MMDesign, which leverages multi-modality transfer learning. To our\nknowledge, MMDesign is the first framework that combines a pretrained\nstructural module with a pretrained contextual module, using an auto-encoder\n(AE) based language model to incorporate prior protein semantic knowledge.\nExperimental results, only training with the small dataset, demonstrate that\nMMDesign consistently outperforms baselines on various public benchmarks. To\nfurther assess the biological plausibility, we present systematic quantitative\nanalysis techniques that provide interpretability and reveal more about the\nlaws of protein design.\n",
        "english": "Contextual sequence modeling plays a pivotal role in the novel protein design paradigm, MMDesign, which integrates a pretrained structural module with a pretrained contextual module, utilizing an auto-encoder (AE) based language model to incorporate prior protein semantic knowledge. This approach allows for the effective transfer of multi-modality learning, demonstrating that MMDesign consistently outperforms baselines on various public benchmarks, even when trained with a limited dataset. The innovation of contextual sequence modeling is further highlighted through systematic quantitative analysis techniques that provide interpretability, revealing insights into the laws of protein design and enhancing the biological plausibility of the results.",
        "korean": "문맥적 순차 모델링(contextual sequence modeling)은 사전 훈련된 구조 모듈과 사전 훈련된 문맥 모듈을 통합하여 자동 인코더(auto-encoder, ae) 기반 언어 모델을 활용하여 사전 단백질 의미 지식을 포함하는 새로운 단백질 설계 패러다임인 MMDesign에서 중요한 역할을 합니다. 이 접근 방식은 다중 모달 학습의 효과적인 전이를 가능하게 하며, MMDesign이 제한된 데이터셋으로 훈련되었을 때에도 다양한 공개 벤치마크에서 일관되게 기준 모델을 능가함을 보여줍니다. 문맥적 순차 모델링(contextual sequence modeling)의 혁신은 해석 가능성을 제공하는 체계적인 정량 분석 기법을 통해 더욱 강조되며, 단백질 설계의 법칙에 대한 통찰을 제공하고 결과의 생물학적 타당성을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural text models",
        "domain": "cs.AI",
        "summary": "  Neural topic models have triggered a surge of interest in extracting topics\nfrom text automatically since they avoid the sophisticated derivations in\nconventional topic models. However, scarce neural topic models incorporate the\nword relatedness information captured in word embedding into the modeling\nprocess. To address this issue, we propose a novel topic modeling approach,\ncalled Variational Gaussian Topic Model (VaGTM). Based on the variational\nauto-encoder, the proposed VaGTM models each topic with a multivariate Gaussian\nin decoder to incorporate word relatedness. Furthermore, to address the\nlimitation that pre-trained word embeddings of topic-associated words do not\nfollow a multivariate Gaussian, Variational Gaussian Topic Model with\nInvertible neural Projections (VaGTM-IP) is extended from VaGTM. Three\nbenchmark text corpora are used in experiments to verify the effectiveness of\nVaGTM and VaGTM-IP. The experimental results show that VaGTM and VaGTM-IP\noutperform several competitive baselines and obtain more coherent topics.\n",
        "english": "Neural text models, particularly the Variational Gaussian Topic Model (VaGTM), have revolutionized the extraction of topics from text by leveraging the variational auto-encoder to model each topic with a multivariate Gaussian, thereby incorporating word relatedness. To enhance the model's capability, the VaGTM is extended to VaGTM-IP, which addresses the limitation that pre-trained word embeddings of topic-associated words do not follow a multivariate Gaussian distribution, as represented mathematically by $\\mathcal{N}(\\mu, \\Sigma)$. The experimental results on three benchmark text corpora demonstrate that both VaGTM and VaGTM-IP outperform several competitive baselines, highlighting their effectiveness in generating more coherent topics and advancing the field of neural text models.",
        "korean": "신경 텍스트 모델(neural text models), 특히 변분 가우시안 주제 모델(Variational Gaussian Topic Model, VaGTM)은 변분 오토인코더(variational auto-encoder)를 활용하여 각 주제를 다변량 가우시안(multivariate Gaussian)으로 모델링함으로써 단어 관련성을 통합하여 텍스트에서 주제를 추출하는 방식을 혁신적으로 변화시켰습니다. 모델의 능력을 향상시키기 위해 VaGTM은 VaGTM-IP로 확장되었으며, 이는 주제와 관련된 단어의 사전 학습된 단어 임베딩이 다변량 가우시안 분포(multivariate Gaussian distribution)를 따르지 않는다는 한계를 해결합니다. 이는 수학적으로 $\\mathcal{N}(\\mu, \\Sigma)$로 표현됩니다. 세 가지 벤치마크 텍스트 코퍼스(benchmark text corpora)에 대한 실험 결과는 VaGTM과 VaGTM-IP가 여러 경쟁적인 기준선 모델을 능가하며, 더 일관된 주제를 생성하고 신경 텍스트 모델(neural text models) 분야를 발전시키는 데 효과적임을 강조합니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent lowercase for all terms within parentheses."
    },
    {
        "turn_index": 2,
        "term": "deep probabilistic modeling",
        "domain": "cs.AI",
        "summary": "  Deep learning and symbolic learning are two frequently employed methods in\nSequential Recommendation (SR). Recent neural-symbolic SR models demonstrate\ntheir potential to enable SR to be equipped with concurrent perception and\ncognition capacities. However, neural-symbolic SR remains a challenging problem\ndue to open issues like representing users and items in logical reasoning. In\nthis paper, we combine the Deep Neural Network (DNN) SR models with logical\nreasoning and propose a general framework named Sequential Recommendation with\nProbabilistic Logical Reasoning (short for SR-PLR). This framework allows\nSR-PLR to benefit from both similarity matching and logical reasoning by\ndisentangling feature embedding and logic embedding in the DNN and\nprobabilistic logic network. To better capture the uncertainty and evolution of\nuser tastes, SR-PLR embeds users and items with a probabilistic method and\nconducts probabilistic logical reasoning on users' interaction patterns. Then\nthe feature and logic representations learned from the DNN and logic network\nare concatenated to make the prediction. Finally, experiments on various\nsequential recommendation models demonstrate the effectiveness of the SR-PLR.\n",
        "english": "Deep probabilistic modeling, as demonstrated in the Sequential Recommendation with Probabilistic Logical Reasoning (SR-PLR) framework, effectively combines the Deep Neural Network (DNN) SR models with logical reasoning, allowing for the disentanglement of feature embedding and logic embedding within both the DNN and probabilistic logic network. This approach enables the SR-PLR to capture the uncertainty and evolution of user tastes by embedding users and items with a probabilistic method and conducting probabilistic logical reasoning on users' interaction patterns, thereby enhancing the model's predictive capabilities. The efficacy of this innovative framework is underscored by its ability to integrate similarity matching and logical reasoning, as evidenced by the experiments on various sequential recommendation models, where the feature and logic representations, denoted as $\\text{f}_{\\text{DNN}}$ and $\\text{l}_{\\text{logic}}$, are concatenated to improve prediction accuracy.",
        "korean": "순차적 추천과 확률적 논리 추론(sequential recommendation with probabilistic logical reasoning, SR-PLR) 프레임워크에서 입증된 바와 같이 심층 확률 모델링(deep probabilistic modeling)은 심층 신경망(deep neural network, DNN) SR 모델과 논리적 추론을 효과적으로 결합하여 DNN과 확률적 논리 네트워크 내에서 특징 임베딩과 논리 임베딩을 분리할 수 있게 합니다. 이 접근 방식은 사용자와 항목을 확률적 방법으로 임베딩하고 사용자의 상호작용 패턴에 대한 확률적 논리 추론을 수행함으로써 사용자 취향의 불확실성과 진화를 포착하여 모델의 예측 능력을 향상시킵니다. 이 혁신적인 프레임워크의 효능은 다양한 순차적 추천 모델에 대한 실험에서 유사성 매칭과 논리적 추론을 통합할 수 있는 능력으로 강조되며, 특징 및 논리 표현이 $\\text{f}_{\\text{DNN}}$ 및 $\\text{l}_{\\text{logic}}$로 표시되어 예측 정확도를 향상시키기 위해 연결됩니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure that all technical terms are consistently parenthesized as Korean term(English term) throughout the text."
    },
    {
        "turn_index": 2,
        "term": "simultaneous machine translation",
        "domain": "cs.AI",
        "summary": "  Recently, simultaneous translation has gathered a lot of attention since it\nenables compelling applications such as subtitle translation for a live event\nor real-time video-call translation. Some of these translation applications\nallow editing of partial translation giving rise to re-translation approaches.\nThe current re-translation approaches are based on autoregressive sequence\ngeneration models (ReTA), which generate tar-get tokens in the (partial)\ntranslation sequentially. The multiple re-translations with sequential\ngeneration inReTAmodelslead to an increased inference time gap between the\nincoming source input and the corresponding target output as the source input\ngrows. Besides, due to the large number of inference operations involved, the\nReTA models are not favorable for resource-constrained devices. In this work,\nwe propose a faster re-translation system based on a non-autoregressive\nsequence generation model (FReTNA) to overcome the aforementioned limitations.\nWe evaluate the proposed model on multiple translation tasks and our model\nreduces the inference times by several orders and achieves a competitive\nBLEUscore compared to the ReTA and streaming (Wait-k) models.The proposed model\nreduces the average computation time by a factor of 20 when compared to the\nReTA model by incurring a small drop in the translation quality. It also\noutperforms the streaming-based Wait-k model both in terms of computation time\n(1.5 times lower) and translation quality.\n",
        "english": "Simultaneous machine translation has recently gained significant attention due to its potential in applications like subtitle translation for live events and real-time video-call translation, which require swift and accurate language conversion. Current re-translation approaches, such as autoregressive sequence generation models (ReTA), face challenges in increased inference time as the source input grows, making them less suitable for resource-constrained devices. To address these limitations, a non-autoregressive sequence generation model (FReTNA) was proposed, which reduces the average computation time by a factor of 20 compared to ReTA models, with a minor drop in translation quality, and outperforms streaming-based Wait-k models both in computation time, which is 1.5 times lower, and in translation quality.",
        "korean": "동시 기계 번역(simultaneous machine translation)은 실시간 이벤트의 자막 번역 및 실시간 화상 통화 번역과 같은 응용 분야에서의 잠재력으로 인해 최근 상당한 주목을 받고 있습니다. 이러한 응용 분야는 신속하고 정확한 언어 변환을 요구합니다. 현재의 재번역 접근법(re-translation approaches), 예를 들어 자기회귀적 시퀀스 생성 모델(autoregressive sequence generation models, reta)은 소스 입력이 증가함에 따라 추론 시간이 증가하는 문제에 직면하여 자원이 제한된 장치에는 적합하지 않습니다. 이러한 제한을 해결하기 위해 비자기회귀적 시퀀스 생성 모델(non-autoregressive sequence generation model, fretna)이 제안되었으며, 이는 reta 모델에 비해 평균 계산 시간을 20배 줄이면서 번역 품질의 약간의 저하만 발생시키고, 스트리밍 기반의 wait-k 모델보다 계산 시간이 1.5배 낮고 번역 품질에서도 우수한 성능을 보입니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "recurrent neural networks",
        "domain": "cs.AI",
        "summary": "  Customer segmentation has long been a productive field in banking. However,\nwith new approaches to traditional problems come new opportunities.\nFine-grained customer segments are notoriously elusive and one method of\nobtaining them is through feature extraction. It is possible to assign\ncoefficients of standard personality traits to financial transaction classes\naggregated over time. However, we have found that the clusters formed are not\nsufficiently discriminatory for micro-segmentation. In a novel approach, we\nextract temporal features with continuous values from the hidden states of\nneural networks predicting customers' spending personality from their financial\ntransactions. We consider both temporal and non-sequential models, using long\nshort-term memory (LSTM) and feed-forward neural networks, respectively. We\nfound that recurrent neural networks produce micro-segments where feed-forward\nnetworks produce only coarse segments. Finally, we show that classification\nusing these extracted features performs at least as well as bespoke models on\ntwo common metrics, namely loan default rate and customer liquidity index.\n",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "fasttext",
        "domain": "cs.AI",
        "summary": "  Search query classification, as an effective way to understand user intents,\nis of great importance in real-world online ads systems. To ensure a lower\nlatency, a shallow model (e.g. FastText) is widely used for efficient online\ninference. However, the representation ability of the FastText model is\ninsufficient, resulting in poor classification performance, especially on some\nlow-frequency queries and tailed categories. Using a deeper and more complex\nmodel (e.g. BERT) is an effective solution, but it will cause a higher online\ninference latency and more expensive computing costs. Thus, how to juggle both\ninference efficiency and classification performance is obviously of great\npractical importance. To overcome this challenge, in this paper, we propose\nknowledge condensation (KC), a simple yet effective knowledge distillation\nframework to boost the classification performance of the online FastText model\nunder strict low latency constraints. Specifically, we propose to train an\noffline BERT model to retrieve more potentially relevant data. Benefiting from\nits powerful semantic representation, more relevant labels not exposed in the\nhistorical data will be added into the training set for better FastText model\ntraining. Moreover, a novel distribution-diverse multi-expert learning strategy\nis proposed to further improve the mining ability of relevant data. By training\nmultiple BERT models from different data distributions, it can respectively\nperform better at high, middle, and low-frequency search queries. The model\nensemble from multi-distribution makes its retrieval ability more powerful. We\nhave deployed two versions of this framework in JD search, and both offline\nexperiments and online A/B testing from multiple datasets have validated the\neffectiveness of the proposed approach.\n",
        "korean": "검색 쿼리 분류(search query classification)에서 효율적인 온라인 추론을 위해 사용되는 얕은 모델(shallow model)인 fasttext는 낮은 지연 시간으로 인해 선호되지만, 특히 저빈도 쿼리와 꼬리 범주에서 표현 능력이 종종 부족합니다. 이러한 한계를 해결하기 위해 지식 응축(knowledge condensation, KC)이라는 지식 증류 프레임워크(knowledge distillation framework)가 도입되었으며, 이는 오프라인 BERT 모델을 활용하여 더 많은 잠재적으로 관련 있는 데이터를 검색함으로써 fasttext의 성능을 향상시키고, 역사적 데이터에 존재하지 않는 추가 레이블로 학습 세트를 풍부하게 합니다. 특히, 이 접근법의 효과는 다양한 분포의 멀티 전문가 학습 전략(distribution-diverse multi-expert learning strategy)을 통해 입증되었으며, 서로 다른 데이터 분포에서 학습된 여러 BERT 모델이 검색 능력을 향상시켜 다양한 빈도 쿼리에서 뛰어난 모델 앙상블(model ensemble)을 달성하며, 결과는 오프라인 실험과 온라인 A/B 테스트를 통해 검증되었습니다."
    },
    {
        "turn_index": 2,
        "term": "probabilistic neural embeddings",
        "domain": "cs.AI",
        "summary": "  In fact, there exist three genres of intelligence architectures: logics (e.g.\n\\textit{Random Forest, A$^*$ Searching}), neurons (e.g. \\textit{CNN, LSTM}) and\nprobabilities (e.g. \\textit{Naive Bayes, HMM}), all of which are incompatible\nto each other. However, to construct powerful intelligence systems with various\nmethods, we propose the intelligence graph (short as \\textbf{\\textit{iGraph}}),\nwhich is composed by both of neural and probabilistic graph, under the\nframework of forward-backward propagation. By the paradigm of iGraph, we design\na recommendation model with semantic principle. First, the probabilistic\ndistributions of categories are generated from the embedding representations of\nusers/items, in the manner of neurons. Second, the probabilistic graph infers\nthe distributions of features, in the manner of probabilities. Last, for the\nrecommendation diversity, we perform an expectation computation then conduct a\nlogic judgment, in the manner of logics. Experimentally, we beat the\nstate-of-the-art baselines and verify our conclusions.\n",
        "english": "Probabilistic neural embeddings are instrumental in constructing powerful intelligence systems, as demonstrated by the integration of neural and probabilistic graphs within the framework of forward-backward propagation. In this context, the probabilistic distributions of categories are generated from the embedding representations of users/items, utilizing the capabilities of neurons, while the probabilistic graph infers the distributions of features in the manner of probabilities. This innovative approach, highlighted by the paradigm of the intelligence graph (iGraph), not only enhances recommendation diversity through expectation computation and logic judgment but also surpasses state-of-the-art baselines, thereby verifying its effectiveness.",
        "korean": "확률적 신경 임베딩(probabilistic neural embeddings)은 순방향-역방향 전파(forward-backward propagation) 프레임워크 내에서 신경 및 확률 그래프(neural and probabilistic graphs)의 통합을 통해 강력한 지능 시스템을 구축하는 데 중요한 역할을 합니다. 이 맥락에서, 사용자/항목의 임베딩 표현에서 범주의 확률 분포가 생성되며, 이는 뉴런의 기능을 활용하고, 확률 그래프(probabilistic graph)는 확률 방식으로 특징의 분포를 추론합니다. 지능 그래프(intelligence graph, iGraph) 패러다임으로 강조된 이 혁신적인 접근 방식은 기대 계산과 논리 판단을 통해 추천 다양성을 향상시킬 뿐만 아니라 최첨단 기준(state-of-the-art baselines)을 능가하여 그 효과성을 입증합니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure consistent lowercase usage within parentheses and consider rephrasing for smoother readability, such as adjusting the placement of technical terms to better fit Korean syntax."
    },
    {
        "turn_index": 2,
        "term": "uncertainty quantification",
        "domain": "cs.AI",
        "summary": "  Although AI systems have been applied in various fields and achieved\nimpressive performance, their safety and reliability are still a big concern.\nThis is especially important for safety-critical tasks. One shared\ncharacteristic of these critical tasks is their risk sensitivity, where small\nmistakes can cause big consequences and even endanger life. There are several\nfactors that could be guidelines for the successful deployment of AI systems in\nsensitive tasks: (i) failure detection and out-of-distribution (OOD) detection;\n(ii) overfitting identification; (iii) uncertainty quantification for\npredictions; (iv) robustness to data perturbations. These factors are also\nchallenges of current AI systems, which are major blocks for building safe and\nreliable AI. Specifically, the current AI algorithms are unable to identify\ncommon causes for failure detection. Furthermore, additional techniques are\nrequired to quantify the quality of predictions. All these contribute to\ninaccurate uncertainty quantification, which lowers trust in predictions. Hence\nobtaining accurate model uncertainty quantification and its further improvement\nare challenging. To address these issues, many techniques have been proposed,\nsuch as regularization methods and learning strategies. As vision and language\nare the most typical data type and have many open source benchmark datasets,\nthis thesis will focus on vision-language data processing for tasks like\nclassification, image captioning, and vision question answering. In this\nthesis, we aim to build a safeguard by further developing current techniques to\nensure the accurate model uncertainty for safety-critical tasks.\n",
        "korean": "AI 시스템의 영역에서, 특히 안전이 중요한 작업에 있어 정확한 불확실성 정량화(uncertainty quantification)는 \"작은 실수가 큰 결과를 초래하고 심지어 생명을 위협할 수 있는\" 위험 민감성 때문에 매우 중요합니다. 현재 AI 알고리즘은 \"실패 감지 및 분포 외 감지(out-of-distribution, OOD detection)\"에서 어려움을 겪고 있으며, 이는 신뢰성과 신뢰성을 보장하기 위해 \"예측의 품질을 정량화\"하는 고급 기술이 필요합니다. 이러한 시스템을 개선하기 위해 정규화 방법 및 학습 전략과 같은 방법론이 개발되고 있으며, 분류 및 이미지 캡셔닝과 같은 작업에서 모델 불확실성 정량화(uncertainty quantification)의 정확성을 강조하여 안전이 중요한 작업의 안전을 보장하고자 합니다."
    },
    {
        "turn_index": 2,
        "term": "graph-based neural networks",
        "domain": "cs.AI",
        "summary": "  Cybersecurity is the security cornerstone of digital transformation of the\npower grid and construction of new power systems. The traditional network\nsecurity situation quantification method only analyzes from the perspective of\nnetwork performance, ignoring the impact of various power application services\non the security situation, so the quantification results cannot fully reflect\nthe power information network risk state. This study proposes a method for\nquantifying security situation of the power information network based on the\nevolutionary neural network. First, the security posture system architecture is\ndesigned by analyzing the business characteristics of power information network\napplications. Second, combining the importance of power application business,\nthe spatial element index system of coupled interconnection is established from\nthree dimensions of network reliability, threat, and vulnerability. Then, the\nBP neural network optimized by the genetic evolutionary algorithm is\nincorporated into the element index calculation process, and the quantitative\nmodel of security posture of the power information network based on the\nevolutionary neural network is constructed. Finally, a simulation experiment\nenvironment is built according to a power sector network topology, and the\neffectiveness and robustness of the method proposed in the study are verified.\n",
        "english": "Graph-based neural networks play a crucial role in enhancing the cybersecurity of power grids, as traditional network security quantification methods often overlook the impact of power application services, leading to incomplete reflections of the power information network risk state. By incorporating the Backpropagation (BP) neural network optimized through a genetic evolutionary algorithm, the methodology leverages graph-based neural networks to establish a spatial element index system, considering dimensions such as network reliability, threat, and vulnerability, thereby constructing a robust quantitative model. The effectiveness and robustness of this approach are validated through a simulation experiment, where the security posture of the power information network is quantified, demonstrating the innovation's capacity to capture complex interconnections within the network, as described by the equation $S = f(R, T, V)$, where $S$ represents the security posture, and $R$, $T$, and $V$ denote reliability, threat, and vulnerability, respectively.",
        "korean": "그래프 기반 신경망(graph-based neural networks)은 전력망의 사이버 보안을 강화하는 데 중요한 역할을 합니다. 이는 전통적인 네트워크 보안 정량화 방법이 전력 응용 서비스의 영향을 종종 간과하여 전력 정보 네트워크 위험 상태를 불완전하게 반영하기 때문입니다. 유전적 진화 알고리즘(genetic evolutionary algorithm)을 통해 최적화된 역전파(bp) 신경망(backpropagation neural network)을 통합함으로써, 이 방법론은 네트워크 신뢰성, 위협, 취약성과 같은 차원을 고려하여 공간 요소 지수 시스템을 구축하고, 이를 통해 강력한 정량 모델을 구성합니다. 이 접근법의 효과성과 견고성은 시뮬레이션 실험을 통해 검증되었으며, 전력 정보 네트워크의 보안 태세가 정량화되어 네트워크 내 복잡한 상호 연결성을 포착하는 혁신의 능력을 입증합니다. 이는 $S = f(R, T, V)$라는 방정식으로 설명되며, 여기서 $S$는 보안 태세를 나타내고, $R$, $T$, $V$는 각각 신뢰성, 위협, 취약성을 나타냅니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "transformer-based architectures",
        "domain": "cs.AI",
        "summary": "  This study aims at making the architecture search process more adaptive for\none-shot or online training. It is extended from the existing study on\ndifferentiable neural architecture search, and we made the backbone\narchitecture transformable rather than fixed during the training process. As is\nknown, differentiable neural architecture search (DARTS) requires a pre-defined\nover-parameterized backbone architecture, while its size is to be determined\nmanually. Also, in DARTS backbone, Hadamard product of two elements is not\nintroduced, which exists in both LSTM and GRU cells for recurrent nets. This\nstudy introduces a growing mechanism for differentiable neural architecture\nsearch based on network morphism. It enables growing of the cell structures\nfrom small size towards large size ones with one-shot training. Two modes can\nbe applied in integrating the growing and original pruning process. We also\nimplement a recently proposed two-input backbone architecture for recurrent\nneural networks. Initial experimental results indicate that our approach and\nthe two-input backbone structure can be quite effective compared with other\nbaseline architectures including LSTM, in a variety of learning tasks including\nmulti-variate time series forecasting and language modeling. On the other hand,\nwe find that dynamic network transformation is promising in improving the\nefficiency of differentiable architecture search.\n",
        "english": "Transformer-based architectures have been significantly enhanced by integrating a growing mechanism for differentiable neural architecture search, which is based on network morphism and enables the cell structures to evolve from small to large sizes with one-shot training. By transforming the backbone architecture during the training process, rather than keeping it fixed, this approach offers a dynamic network transformation that improves the efficiency of differentiable architecture search, especially when compared to traditional architectures like LSTM in tasks such as multi-variate time series forecasting and language modeling. Notably, the implementation of a two-input backbone architecture for recurrent neural networks demonstrates that the Hadamard product, typically absent in DARTS backbones, can be effectively utilized to enhance performance, as expressed mathematically by the operation $A \\odot B$, where $A$ and $B$ are matrices involved in the transformation process.",
        "korean": "변환기 기반 아키텍처(transformer-based architectures)는 네트워크 형태 변환(network morphism)에 기반한 미분 가능한 신경 아키텍처 탐색(differentiable neural architecture search)을 위한 성장 메커니즘을 통합함으로써 크게 향상되었습니다. 이는 셀 구조가 작은 크기에서 큰 크기로 진화할 수 있도록 하며, 원샷 학습(one-shot training)으로 가능합니다. 학습 과정에서 백본 아키텍처(backbone architecture)를 고정하지 않고 변환함으로써, 이 접근 방식은 미분 가능한 아키텍처 탐색의 효율성을 개선하며, 특히 다변량 시계열 예측(multi-variate time series forecasting) 및 언어 모델링(language modeling)과 같은 작업에서 LSTM과 같은 전통적인 아키텍처에 비해 우수한 성능을 제공합니다. 특히, 순환 신경망(recurrent neural networks)을 위한 이중 입력 백본 아키텍처(two-input backbone architecture)의 구현은 DARTS 백본에서 일반적으로 결여된 하다마드 곱(Hadamard product)을 효과적으로 활용하여 성능을 향상시킬 수 있음을 보여줍니다. 이는 변환 과정에 관여하는 행렬 $A$와 $B$에 대해 수학적으로 $A \\odot B$로 표현됩니다.",
        "score": 10,
        "parentheses_count": 11,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "hybrid neural networks",
        "domain": "cs.AI",
        "summary": "  Combining neural networks with continuous logic and multicriteria decision\nmaking tools can reduce the black box nature of neural models. In this study,\nwe show that nilpotent logical systems offer an appropriate mathematical\nframework for a hybridization of continuous nilpotent logic and neural models,\nhelping to improve the interpretability and safety of machine learning. In our\nconcept, perceptrons model soft inequalities; namely membership functions and\ncontinuous logical operators. We design the network architecture before\ntraining, using continuous logical operators and multicriteria decision tools\nwith given weights working in the hidden layers. Designing the structure\nappropriately leads to a drastic reduction in the number of parameters to be\nlearned. The theoretical basis offers a straightforward choice of activation\nfunctions (the cutting function or its differentiable approximation, the\nsquashing function), and also suggests an explanation to the great success of\nthe rectified linear unit (ReLU). In this study, we focus on the architecture\nof a hybrid model and introduce the building blocks for future application in\ndeep neural networks. The concept is illustrated with some toy examples taken\nfrom an extended version of the tensorflow playground.\n",
        "english": "Hybrid neural networks, which integrate continuous logic and multicriteria decision-making tools, provide a significant advancement in reducing the \"black box\" nature of neural models. By utilizing nilpotent logical systems, these networks enhance interpretability and safety in machine learning, while the designed architecture, incorporating continuous logical operators and multicriteria decision tools with predetermined weights, results in a drastic reduction in the number of parameters to be learned. The mathematical framework suggests using activation functions such as the cutting function or its differentiable approximation, the squashing function, and provides insights into the success of the rectified linear unit (ReLU), as demonstrated in toy examples from an extended version of the tensorflow playground.",
        "korean": "연속 논리와 다기준 의사결정 도구를 통합한 하이브리드 신경망(hybrid neural networks)은 신경 모델의 \"블랙 박스\" 특성을 줄이는 데 있어 중요한 발전을 제공합니다. 이 네트워크는 영멸 논리 시스템(nilpotent logical systems)을 활용하여 기계 학습(machine learning)의 해석 가능성과 안전성을 향상시키며, 연속 논리 연산자와 사전 결정된 가중치를 가진 다기준 의사결정 도구를 포함하는 설계된 아키텍처는 학습해야 할 매개변수의 수를 크게 줄입니다. 수학적 프레임워크는 절단 함수(cutting function) 또는 그 미분 가능 근사치인 스쿼싱 함수(squashing function)와 같은 활성화 함수를 사용할 것을 제안하며, 텐서플로 플레이그라운드(tensorflow playground)의 확장 버전에서의 장난감 예제를 통해 입증된 바와 같이 정류 선형 단위(rectified linear unit, ReLU)의 성공에 대한 통찰력을 제공합니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "generative pretraining",
        "domain": "cs.AI",
        "summary": "  The finetuning of pretrained transformer-based language generation models are\ntypically conducted in an end-to-end manner, where the model learns to attend\nto relevant parts of the input by itself. However, there does not exist a\nmechanism to directly control the model's focus. This work aims to develop a\ncontrol mechanism by which a user can select spans of context as \"highlights\"\nfor the model to focus on, and generate relevant output. To achieve this goal,\nwe augment a pretrained model with trainable \"focus vectors\" that are directly\napplied to the model's embeddings, while the model itself is kept fixed. These\nvectors, trained on automatic annotations derived from attribution methods, act\nas indicators for context importance. We test our approach on two core\ngeneration tasks: dialogue response generation and abstractive summarization.\nWe also collect evaluation data where the highlight-generation pairs are\nannotated by humans. Our experiments show that the trained focus vectors are\neffective in steering the model to generate outputs that are relevant to\nuser-selected highlights.\n",
        "english": "In the realm of generative pretraining, the finetuning of transformer-based language generation models is typically executed in an end-to-end manner, allowing the model to autonomously learn to attend to pertinent parts of the input. This research introduces a novel control mechanism, whereby users can designate spans of context as \"highlights\" for the model to focus on, utilizing trainable \"focus vectors\" that are applied to the model's embeddings while maintaining the pretrained model's parameters fixed. Notably, experiments demonstrate that these focus vectors, which are trained on automatic annotations derived from attribution methods, effectively guide the model to generate outputs aligned with user-selected highlights, as evidenced by improved performance on tasks such as dialogue response generation and abstractive summarization, quantified by metrics such as BLEU and ROUGE scores.",
        "korean": "생성적 사전 훈련(generative pretraining) 분야에서, 변환기 기반 언어 생성 모델(transformer-based language generation models)의 미세 조정(finetuning)은 일반적으로 종단 간 방식(end-to-end manner)으로 수행되어 모델이 입력의 관련 부분에 자율적으로 주의를 기울이도록 학습합니다. 이 연구는 사용자가 모델이 집중할 \"하이라이트\"로서 문맥의 범위를 지정할 수 있는 새로운 제어 메커니즘을 도입하며, 이는 사전 훈련된 모델의 매개변수를 고정한 상태에서 모델의 임베딩에 적용되는 학습 가능한 \"포커스 벡터(focus vectors)\"를 활용합니다. 특히, 실험 결과는 귀속 방법(attribution methods)에서 파생된 자동 주석에 대해 훈련된 이러한 포커스 벡터(focus vectors)가 사용자 선택 하이라이트와 일치하는 출력을 생성하도록 모델을 효과적으로 안내하며, 이는 대화 응답 생성(dialogue response generation) 및 추상적 요약(abstractive summarization)과 같은 작업에서 BLEU 및 ROUGE 점수와 같은 지표로 정량화된 성능 향상으로 입증됩니다.",
        "score": 9,
        "parentheses_count": 11,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and verify that all technical terms are correctly parenthesized to maintain clarity and readability."
    },
    {
        "turn_index": 2,
        "term": "policy gradients",
        "domain": "cs.AI",
        "summary": "  Actor-critic algorithms learn an explicit policy (actor), and an accompanying\nvalue function (critic). The actor performs actions in the environment, while\nthe critic evaluates the actor's current policy. However, despite their\nstability and promising convergence properties, current actor-critic algorithms\ndo not outperform critic-only ones in practice. We believe that the fact that\nthe critic learns Q^pi, instead of the optimal Q-function Q*, prevents\nstate-of-the-art robust and sample-efficient off-policy learning algorithms\nfrom being used. In this paper, we propose an elegant solution, the\nActor-Advisor architecture, in which a Policy Gradient actor learns from\nunbiased Monte-Carlo returns, while being shaped (or advised) by the Softmax\npolicy arising from an off-policy critic. The critic can be learned\nindependently from the actor, using any state-of-the-art algorithm. Being\nadvised by a high-quality critic, the actor quickly and robustly learns the\ntask, while its use of the Monte-Carlo return helps overcome any bias the\ncritic may have. In addition to a new Actor-Critic formulation, the\nActor-Advisor, a method that allows an external advisory policy to shape a\nPolicy Gradient actor, can be applied to many other domains. By varying the\nsource of advice, we demonstrate the wide applicability of the Actor-Advisor to\nthree other important subfields of RL: safe RL with backup policies, efficient\nleverage of domain knowledge, and transfer learning in RL. Our experimental\nresults demonstrate the benefits of the Actor-Advisor compared to\nstate-of-the-art actor-critic methods, illustrate its applicability to the\nthree other application scenarios listed above, and show that many important\nchallenges of RL can now be solved using a single elegant solution.\n",
        "english": "The Actor-Advisor architecture presents an innovative approach where a Policy Gradient actor learns from unbiased Monte-Carlo returns while being shaped by the Softmax policy derived from an off-policy critic. This method allows the actor to quickly and robustly learn tasks, with the Monte-Carlo return helping to overcome any bias the critic may introduce, thus ensuring efficient and effective learning. By leveraging the actor's ability to learn independently from the critic, which can be trained using any state-of-the-art algorithm, the Actor-Advisor demonstrates its applicability across various subfields of reinforcement learning, including safe RL with backup policies, efficient domain knowledge utilization, and transfer learning.",
        "korean": "액터-어드바이저(actor-advisor) 아키텍처는 편향되지 않은 몬테카를로 반환(monte-carlo returns)으로부터 정책 기울기(policy gradients) 액터(actor)를 학습하면서 오프-정책 비평가(off-policy critic)로부터 유도된 소프트맥스 정책(softmax policy)에 의해 형성되는 혁신적인 접근 방식을 제시합니다. 이 방법은 액터가 빠르고 견고하게 작업을 학습할 수 있게 하며, 몬테카를로 반환(monte-carlo returns)은 비평가가 도입할 수 있는 편향을 극복하는 데 도움을 주어 효율적이고 효과적인 학습을 보장합니다. 비평가로부터 독립적으로 학습할 수 있는 액터의 능력을 활용함으로써, 비평가는 최신 알고리즘을 사용하여 훈련될 수 있으며, 액터-어드바이저(actor-advisor)는 백업 정책을 통한 안전한 강화 학습(safe RL with backup policies), 효율적인 도메인 지식 활용, 전이 학습(transfer learning)을 포함한 강화 학습의 다양한 하위 분야에서 그 적용 가능성을 입증합니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "[No suggestions needed as the translation meets all criteria.]"
    },
    {
        "turn_index": 2,
        "term": "graph-based reinforcement learning",
        "domain": "cs.AI",
        "summary": "  Purpose: AI in radiology is hindered chiefly by: 1) Requiring large annotated\ndata sets. 2) Non-generalizability that limits deployment to new scanners /\ninstitutions. And 3) Inadequate explainability and interpretability. We believe\nthat reinforcement learning can address all three shortcomings, with robust and\nintuitive algorithms trainable on small datasets. To the best of our knowledge,\nreinforcement learning has not been directly applied to computer vision tasks\nfor radiological images. In this proof-of-principle work, we train a deep\nreinforcement learning network to predict brain tumor location.\n  Materials and Methods: Using the BraTS brain tumor imaging database, we\ntrained a deep Q network on 70 post-contrast T1-weighted 2D image slices. We\ndid so in concert with image exploration, with rewards and punishments designed\nto localize lesions. To compare with supervised deep learning, we trained a\nkeypoint detection convolutional neural network on the same 70 images. We\napplied both approaches to a separate 30 image testing set.\n  Results: Reinforcement learning predictions consistently improved during\ntraining, whereas those of supervised deep learning quickly diverged.\nReinforcement learning predicted testing set lesion locations with 85%\naccuracy, compared to roughly 7% accuracy for the supervised deep network.\n  Conclusion: Reinforcement learning predicted lesions with high accuracy,\nwhich is unprecedented for such a small training set. We believe that\nreinforcement learning can propel radiology AI well past the inherent\nlimitations of supervised deep learning, with more clinician-driven research\nand finally toward true clinical applicability.\n",
        "korean": "그래프 기반 강화 학습(graph-based reinforcement learning)은 방사선학에서 AI의 한계를 극복하기 위한 유망한 접근법을 제시합니다. 특히 대규모 주석 데이터셋(annotated datasets)의 필요성, 비일반화성(non-generalizability), 불충분한 설명 가능성과 해석 가능성 측면에서 그렇습니다. 소규모 데이터셋(small datasets)에서 학습 가능한 강력하고 직관적인 알고리즘을 활용함으로써, 이 방법은 전통적인 지도 심층 학습 네트워크(supervised deep learning networks)에서 약 7\\%의 성공률과 비교하여 테스트에서 85\\%의 성공률로 뇌종양 위치를 전례 없는 정확도로 예측할 수 있습니다. 이 분야에서 강화 학습(reinforcement learning)의 혁신적인 응용은 방사선학 AI를 기존 방법론의 고유한 제약을 넘어 발전시킬 잠재력을 강조하며, 더 많은 임상의 주도 연구와 향상된 임상 적용 가능성을 위한 길을 열어줍니다."
    },
    {
        "turn_index": 2,
        "term": "hypernetworks",
        "domain": "cs.AI",
        "summary": "  Making personalized recommendation for cold-start users, who only have a few\ninteraction histories, is a challenging problem in recommendation systems.\nRecent works leverage hypernetworks to directly map user interaction histories\nto user-specific parameters, which are then used to modulate predictor by\nfeature-wise linear modulation function. These works obtain the\nstate-of-the-art performance. However, the physical meaning of scaling and\nshifting in recommendation data is unclear. Instead of using a fixed modulation\nfunction and deciding modulation position by expertise, we propose a modulation\nframework called ColdNAS for user cold-start problem, where we look for proper\nmodulation structure, including function and position, via neural architecture\nsearch. We design a search space which covers broad models and theoretically\nprove that this search space can be transformed to a much smaller space,\nenabling an efficient and robust one-shot search algorithm. Extensive\nexperimental results on benchmark datasets show that ColdNAS consistently\nperforms the best. We observe that different modulation functions lead to the\nbest performance on different datasets, which validates the necessity of\ndesigning a searching-based method.\n",
        "english": "Recent advancements leverage hypernetworks to directly map user interaction histories to user-specific parameters, which are subsequently used to modulate predictors through a feature-wise linear modulation function, achieving state-of-the-art performance in recommendation systems. The innovative approach, ColdNAS, addresses the user cold-start problem by utilizing neural architecture search to identify the optimal modulation structure, encompassing both function and position, rather than relying on a fixed modulation function determined by expertise. Extensive experiments demonstrate that different modulation functions yield optimal results across various datasets, underscoring the importance of a search-based method and suggesting that the search space can be transformed into a smaller space, enabling an efficient one-shot search algorithm, denoted as $\\mathcal{O}(n)$.",
        "korean": "최근 발전된 기술은 하이퍼네트워크(hypernetworks)를 활용하여 사용자 상호작용 이력을 사용자별 매개변수로 직접 매핑하고, 이를 특징별 선형 변조 함수(feature-wise linear modulation function)를 통해 예측기를 조정하는 데 사용하여 추천 시스템에서 최첨단 성능을 달성합니다. 혁신적인 접근법인 ColdNAS는 신경 아키텍처 검색(neural architecture search)을 활용하여 사용자 콜드 스타트 문제(user cold-start problem)를 해결하며, 전문 지식에 의해 결정된 고정된 변조 함수에 의존하지 않고 기능과 위치를 모두 포함하는 최적의 변조 구조를 식별합니다. 광범위한 실험은 다양한 데이터셋에서 서로 다른 변조 함수가 최적의 결과를 산출함을 보여주며, 검색 기반 방법의 중요성을 강조하고 검색 공간을 더 작은 공간으로 변환하여 효율적인 일회성 검색 알고리즘(one-shot search algorithm)을 가능하게 함을 시사합니다. 이 알고리즘은 $\\mathcal{O}(n)$으로 표시됩니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure all terms within parentheses are in lowercase and maintain consistent parenthesization throughout the translation."
    },
    {
        "turn_index": 2,
        "term": "semantic text segmentation",
        "domain": "cs.AI",
        "summary": "  This article discusses a particular case of the data clustering problem,\nwhere it is necessary to find groups of adjacent text segments of the\nappropriate length that match a fuzzy pattern represented as a sequence of\nfuzzy properties. To solve this problem, a heuristic algorithm for finding a\nsufficiently large number of solutions is proposed. The key idea of the\nproposed algorithm is the use of the prefix structure to track the process of\nmapping text segments to fuzzy properties.\n  An important special case of the text segmentation problem is the fuzzy\nstring matching problem, when adjacent text segments have unit length and,\naccordingly, the fuzzy pattern is a sequence of fuzzy properties of text\ncharacters. It is proven that the heuristic segmentation algorithm in this case\nfinds all text segments that match the fuzzy pattern.\n  Finally, we consider the problem of a best segmentation of the entire text\nbased on a fuzzy pattern, which is solved using the dynamic programming method.\n  Keywords: fuzzy clustering, fuzzy string matching, approximate string\nmatching\n",
        "english": "In the domain of semantic text segmentation, the article addresses a unique instance of the data clustering problem, emphasizing the necessity to identify groups of adjacent text segments that align with a fuzzy pattern, characterized as a sequence of fuzzy properties. The heuristic algorithm proposed for this challenge utilizes a prefix structure to efficiently map text segments to these fuzzy properties, ensuring a comprehensive exploration of potential solutions. Notably, the research proves that in cases where adjacent text segments have unit length, the heuristic algorithm effectively identifies all segments that satisfy the fuzzy pattern, and the problem of optimal text segmentation is resolved using dynamic programming, where the segmentation function is defined as $f(i) = \\min(f(j) + c(j, i))$ for $j < i$, highlighting the innovation in algorithmic approach.",
        "korean": "의미적 텍스트 분할(semantic text segmentation) 분야에서 이 기사는 데이터 클러스터링 문제의 독특한 사례를 다루며, 퍼지 패턴(fuzzy pattern)과 일치하는 인접 텍스트 세그먼트 그룹을 식별하는 필요성을 강조합니다. 이 도전을 위한 휴리스틱 알고리즘(heuristic algorithm)은 텍스트 세그먼트를 이러한 퍼지 속성(fuzzy properties)에 효율적으로 매핑하기 위해 접두사 구조(prefix structure)를 활용하여 잠재적 솔루션을 포괄적으로 탐색합니다. 특히, 연구는 인접 텍스트 세그먼트가 단위 길이를 가질 경우, 휴리스틱 알고리즘(heuristic algorithm)이 퍼지 패턴(fuzzy pattern)을 만족하는 모든 세그먼트를 효과적으로 식별하며, 최적의 텍스트 분할 문제는 동적 프로그래밍(dynamic programming)을 사용하여 해결된다는 것을 증명합니다. 여기서 분할 함수(segmentation function)는 $f(i) = \\min(f(j) + c(j, i))$ for $j < i$로 정의되며, 알고리즘 접근 방식의 혁신성을 강조합니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar"
    },
    {
        "turn_index": 2,
        "term": "adaptive semantic text models",
        "domain": "cs.AI",
        "summary": "  Social media misinformation harms individuals and societies and is\npotentialized by fast-growing multi-modal content (i.e., texts and images),\nwhich accounts for higher \"credibility\" than text-only news pieces. Although\nexisting supervised misinformation detection methods have obtained acceptable\nperformances in key setups, they may require large amounts of labeled data from\nvarious events, which can be time-consuming and tedious. In turn, directly\ntraining a model by leveraging a publicly available dataset may fail to\ngeneralize due to domain shifts between the training data (a.k.a. source\ndomains) and the data from target domains. Most prior work on domain shift\nfocuses on a single modality (e.g., text modality) and ignores the scenario\nwhere sufficient unlabeled target domain data may not be readily available in\nan early stage. The lack of data often happens due to the dynamic propagation\ntrend (i.e., the number of posts related to fake news increases slowly before\ncatching the public attention). We propose a novel robust domain and\ncross-modal approach (\\textbf{RDCM}) for multi-modal misinformation detection.\nIt reduces the domain shift by aligning the joint distribution of textual and\nvisual modalities through an inter-domain alignment module and bridges the\nsemantic gap between both modalities through a cross-modality alignment module.\nWe also propose a framework that simultaneously considers application scenarios\nof domain generalization (in which the target domain data is unavailable) and\ndomain adaptation (in which unlabeled target domain data is available).\nEvaluation results on two public multi-modal misinformation detection datasets\n(Pheme and Twitter Datasets) evince the superiority of the proposed model. The\nformal implementation of this paper can be found in this link:\nhttps://github.com/less-and-less-bugs/RDCM\n",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring consistent use of lowercase letters within parentheses for all technical terms."
    },
    {
        "turn_index": 2,
        "term": "edge computing",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Edge computing has emerged as a pivotal innovation, enabling data processing closer to the source and thereby reducing latency significantly, as highlighted in the reference. The architecture of edge computing often involves distributing computational tasks across multiple nodes, which can be mathematically represented as $f(x) = \\sum_{i=1}^{n} c_i \\cdot x_i$, where $c_i$ represents the computational capacity of each node. This methodology not only enhances real-time data processing capabilities but also optimizes bandwidth usage, marking a substantial advancement in computational efficiency.",
        "korean": "엣지 컴퓨팅(edge computing)은 데이터를 소스에 더 가깝게 처리하여 지연 시간을 크게 줄이는 중요한 혁신으로 부상하였으며, 이는 참고 문헌에서 강조되었습니다. 엣지 컴퓨팅(edge computing)의 아키텍처는 종종 여러 노드에 걸쳐 계산 작업을 분산시키는 것을 포함하며, 이는 $f(x) = \\sum_{i=1}^{n} c_i \\cdot x_i$로 수학적으로 표현될 수 있습니다. 여기서 $c_i$는 각 노드의 계산 용량을 나타냅니다. 이 방법론은 실시간 데이터 처리 능력을 향상시킬 뿐만 아니라 대역폭 사용을 최적화하여 계산 효율성에서 상당한 발전을 이룹니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "word2vec",
        "domain": "cs.AI",
        "summary": "  In the era of MOOCs, online exams are taken by millions of candidates, where\nscoring short answers is an integral part. It becomes intractable to evaluate\nthem by human graders. Thus, a generic automated system capable of grading\nthese responses should be designed and deployed. In this paper, we present a\nfast, scalable, and accurate approach towards automated Short Answer Scoring\n(SAS). We propose and explain the design and development of a system for SAS,\nnamely AutoSAS. Given a question along with its graded samples, AutoSAS can\nlearn to grade that prompt successfully. This paper further lays down the\nfeatures such as lexical diversity, Word2Vec, prompt, and content overlap that\nplays a pivotal role in building our proposed model. We also present a\nmethodology for indicating the factors responsible for scoring an answer. The\ntrained model is evaluated on an extensively used public dataset, namely\nAutomated Student Assessment Prize Short Answer Scoring (ASAP-SAS). AutoSAS\nshows state-of-the-art performance and achieves better results by over 8% in\nsome of the question prompts as measured by Quadratic Weighted Kappa (QWK),\nshowing performance comparable to humans.\n",
        "english": "In the development of AutoSAS, a system for automated Short Answer Scoring (SAS), Word2Vec is employed as a key feature, enhancing the model's ability to evaluate lexical diversity and content overlap effectively. The integration of Word2Vec contributes to AutoSAS's performance, achieving state-of-the-art results, with improvements exceeding 8% in certain question prompts as measured by the Quadratic Weighted Kappa (QWK) metric. This innovative use of Word2Vec, alongside other features, demonstrates the system's capability to perform grading tasks with accuracy comparable to human evaluators, underscoring its potential in large-scale educational assessments.",
        "korean": "자동 단답형 채점 시스템(automated Short Answer Scoring, SAS)인 AutoSAS의 개발에서, 워드투벡(word2vec)은 모델의 어휘 다양성과 내용 중복을 효과적으로 평가하는 능력을 향상시키는 핵심 기능으로 사용됩니다. 워드투벡(word2vec)의 통합은 AutoSAS의 성능에 기여하여, 특정 질문 항목에서 8%를 초과하는 개선을 이루며, 사분위 가중 카파(quadratic weighted kappa, QWK) 지표로 측정된 최첨단 결과를 달성합니다. 워드투벡(word2vec)의 이러한 혁신적인 사용은 다른 기능들과 함께 시스템이 인간 평가자와 비교할 수 있는 정확도로 채점 작업을 수행할 수 있는 능력을 보여주며, 대규모 교육 평가에서의 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "approximate Bayesian computation",
        "domain": "cs.AI",
        "summary": "  Structure and parameters in a Bayesian network uniquely specify the\nprobability distribution of the modeled domain. The locality of both structure\nand probabilistic information are the great benefits of Bayesian networks and\nrequire the modeler to only specify local information. On the other hand this\nlocality of information might prevent the modeler - and even more any other\nperson - from obtaining a general overview of the important relationships\nwithin the domain. The goal of the work presented in this paper is to provide\nan \"alternative\" view on the knowledge encoded in a Bayesian network which\nmight sometimes be very helpful for providing insights into the underlying\ndomain. The basic idea is to calculate a mixture approximation to the\nprobability distribution represented by the Bayesian network. The mixture\ncomponent densities can be thought of as representing typical scenarios implied\nby the Bayesian model, providing intuition about the basic relationships. As an\nadditional benefit, performing inference in the approximate model is very\nsimple and intuitive and can provide additional insights. The computational\ncomplexity for the calculation of the mixture approximations criticaly depends\non the measure which defines the distance between the probability distribution\nrepresented by the Bayesian network and the approximate distribution. Both the\nKL-divergence and the backward KL-divergence lead to inefficient algorithms.\nIncidentally, the latter is used in recent work on mixtures of mean field\nsolutions to which the work presented here is closely related. We show,\nhowever, that using a mean squared error cost function leads to update\nequations which can be solved using the junction tree algorithm. We conclude\nthat the mean squared error cost function can be used for Bayesian networks in\nwhich inference based on the junction tree is tractable. For large networks,\nhowever, one may have to rely on mean field approximations.\n",
        "english": "Approximate Bayesian computation provides an \"alternative\" view on the knowledge encoded in a Bayesian network by calculating a mixture approximation to the probability distribution represented by the network. The mixture component densities, which can be thought of as representing typical scenarios, offer valuable insights into the basic relationships within the domain and simplify inference in the approximate model. Importantly, the computational complexity of calculating these mixture approximations critically depends on the measure defining the distance between the probability distribution represented by the Bayesian network and the approximate distribution, where using a mean squared error cost function leads to update equations solvable with the junction tree algorithm, in contrast to the inefficient algorithms resulting from the KL-divergence and the backward KL-divergence.",
        "korean": "근사 베이지안 계산(approximate Bayesian computation)은 네트워크에 의해 표현된 확률 분포에 대한 혼합 근사를 계산함으로써 베이지안 네트워크(Bayesian network)에 인코딩된 지식에 대한 \"대안적인\" 관점을 제공합니다. 혼합 구성 요소 밀도는 일반적인 시나리오를 나타내는 것으로 생각할 수 있으며, 도메인 내 기본 관계에 대한 귀중한 통찰력을 제공하고 근사 모델에서의 추론을 단순화합니다. 중요한 점은 이러한 혼합 근사의 계산 복잡성이 베이지안 네트워크(Bayesian network)에 의해 표현된 확률 분포와 근사 분포 간의 거리를 정의하는 측정값에 크게 의존한다는 것입니다. 평균 제곱 오차 비용 함수(mean squared error cost function)를 사용할 경우, 접합 트리 알고리즘(junction tree algorithm)으로 해결 가능한 갱신 방정식이 도출되며, 이는 KL-발산(KL-divergence) 및 역방향 KL-발산(backward KL-divergence)에서 발생하는 비효율적인 알고리즘과 대조됩니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar"
    },
    {
        "turn_index": 2,
        "term": "dynamic generative models",
        "domain": "cs.AI",
        "summary": "  Causal loop and stock and flow diagrams are broadly used in System Dynamics\nbecause they help organize relationships and convey meaning. Using the\nanalytical work of Schoenberg (2019) to select what to include in a compressed\nmodel, this paper demonstrates how that information can be clearly presented in\nan automatically generated causal loop diagram. The diagrams are generated\nusing tools developed by people working in graph theory and the generated\ndiagrams are clear and aesthetically pleasing. This approach can also be built\nupon to generate stock and flow diagrams. Automated stock and flow diagram\ngeneration opens the door to representing models developed using only\nequations, regardless or origin, in a clear and easy to understand way. Because\nmodels can be large, the application of grouping techniques, again developed\nfor graph theory, can help structure the resulting diagrams in the most usable\nform. This paper describes the algorithms developed for automated diagram\ngeneration and shows a number of examples of their uses in large models. The\napplication of these techniques to existing, but inaccessible, equation-based\nmodels can help broaden the knowledge base for System Dynamics modeling. The\ntechniques can also be used to improve layout in all, or part, of existing\nmodels with diagrammatic informtion.\n",
        "english": "Dynamic generative models leverage tools from graph theory to create automatically generated causal loop diagrams, which are both \"clear and aesthetically pleasing.\" By applying grouping techniques developed for graph theory, these models can effectively structure large models, enhancing their usability and comprehension. Moreover, the capability to \"generate stock and flow diagrams\" from equation-based models, regardless of origin, facilitates a broader understanding of System Dynamics modeling, with applications extending to improving existing model layouts with diagrammatic information.",
        "korean": "동적 생성 모델(dynamic generative models)은 그래프 이론(graph theory)의 도구를 활용하여 자동으로 생성된 인과 루프 다이어그램(causal loop diagrams)을 \"명확하고 미적으로 만족스럽게\" 만듭니다. 그래프 이론(graph theory)을 위해 개발된 그룹화 기법(grouping techniques)을 적용함으로써 이러한 모델은 대규모 모델을 효과적으로 구조화하여 사용성과 이해도를 향상시킬 수 있습니다. 더욱이, 방정식 기반 모델(equation-based models)에서 \"재고 및 흐름 다이어그램(stock and flow diagrams)\"을 생성하는 능력은 시스템 다이내믹스 모델링(system dynamics modeling)에 대한 폭넓은 이해를 촉진하며, 다이어그램 정보를 통해 기존 모델 레이아웃을 개선하는 데까지 응용이 확장됩니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "graph embedding",
        "domain": "cs.AI",
        "summary": "  Recently, more and more research has focused on using Graph Neural Networks\n(GNN) to solve the Graph Similarity Computation problem (GSC), i.e., computing\nthe Graph Edit Distance (GED) between two graphs. These methods treat GSC as an\nend-to-end learnable task, and the core of their architecture is the feature\nfusion modules to interact with the features of two graphs. Existing methods\nconsider that graph-level embedding is difficult to capture the differences in\nlocal small structures between two graphs, and thus perform fine-grained\nfeature fusion on node-level embedding can improve the accuracy, but leads to\ngreater time and memory consumption in the training and inference phases.\nHowever, this paper proposes a novel graph-level fusion module Different\nAttention (DiffAtt), and demonstrates that graph-level fusion embeddings can\nsubstantially outperform these complex node-level fusion embeddings. We posit\nthat the relative difference structure of the two graphs plays an important\nrole in calculating their GED values. To this end, DiffAtt uses the difference\nbetween two graph-level embeddings as an attentional mechanism to capture the\ngraph structural difference of the two graphs. Based on DiffAtt, a new GSC\nmethod, named Graph Edit Distance Learning via Different Attention (REDRAFT),\nis proposed, and experimental results demonstrate that REDRAFT achieves\nstate-of-the-art performance in 23 out of 25 metrics in five benchmark\ndatasets. Especially on MSE, it respectively outperforms the second best by\n19.9%, 48.8%, 29.1%, 31.6%, and 2.2%. Moreover, we propose a quantitative test\nRemaining Subgraph Alignment Test (RESAT) to verify that among all graph-level\nfusion modules, the fusion embedding generated by DiffAtt can best capture the\nstructural differences between two graphs.\n",
        "english": "In recent advancements, the focus on graph embedding has been intensified through the utilization of Graph Neural Networks (GNN) to address the Graph Similarity Computation problem (GSC), specifically in computing the Graph Edit Distance (GED) between two graphs. The novel graph-level fusion module, Different Attention (DiffAtt), leverages the difference between two graph-level embeddings as an attentional mechanism, enabling the capture of structural differences in graphs, which has led to the development of the Graph Edit Distance Learning via Different Attention (REDRAFT) method. Experimental results have demonstrated that REDRAFT achieves state-of-the-art performance in 23 out of 25 metrics across five benchmark datasets, with particularly notable improvements in Mean Squared Error (MSE), outperforming the second-best method by 19.9\\%, 48.8\\%, 29.1\\%, 31.6\\%, and 2.2\\% respectively.",
        "korean": "최근 발전에서는 그래프 임베딩(graph embedding)에 대한 집중이 그래프 유사성 계산 문제(graph similarity computation problem, GSC)를 해결하기 위해 그래프 신경망(graph neural networks, GNN)을 활용하여 두 그래프 간의 그래프 편집 거리(graph edit distance, GED)를 계산하는 데 초점을 맞추고 있습니다. 새로운 그래프 수준 융합 모듈인 차별적 주의(different attention, DiffAtt)는 두 그래프 수준 임베딩 간의 차이를 주의 메커니즘으로 활용하여 그래프의 구조적 차이를 포착할 수 있게 하며, 이는 차별적 주의를 통한 그래프 편집 거리 학습(graph edit distance learning via different attention, REDRAFT) 방법의 개발로 이어졌습니다. 실험 결과에 따르면 REDRAFT는 5개의 벤치마크 데이터셋에서 25개 지표 중 23개에서 최첨단 성능을 달성했으며, 특히 평균 제곱 오차(mean squared error, MSE)에서 두드러진 개선을 보여주며, 두 번째로 좋은 방법을 각각 19.9\\%, 48.8\\%, 29.1\\%, 31.6\\%, 2.2\\% 초과했습니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as adjusting the placement of technical terms for better flow."
    },
    {
        "turn_index": 2,
        "term": "Markov Chain Monte Carlo",
        "domain": "cs.AI",
        "summary": "  We present a general framework for defining priors on model structure and\nsampling from the posterior using the Metropolis-Hastings algorithm. The key\nidea is that structure priors are defined via a probability tree and that the\nproposal mechanism for the Metropolis-Hastings algorithm operates by traversing\nthis tree, thereby defining a cheaply computable acceptance probability. We\nhave applied this approach to Bayesian net structure learning using a number of\npriors and tree traversal strategies. Our results show that these must be\nchosen appropriately for this approach to be successful.\n",
        "english": "Markov Chain Monte Carlo methods, particularly the Metropolis-Hastings algorithm, are effectively employed to sample from the posterior distribution by traversing a probability tree, which defines structure priors and computes an acceptance probability efficiently. The approach is applied to Bayesian net structure learning, where the choice of priors and tree traversal strategies significantly impacts the success of the methodology, as evidenced by the research findings. The acceptance probability for a proposed move in the Metropolis-Hastings algorithm is given by $\\alpha = \\min\\left(1, \\frac{P(\\text{new state})}{P(\\text{current state})}\\right)$, underscoring the innovation in leveraging a probability tree to streamline computations.",
        "korean": "마르코프 체인 몬테카를로 방법(Markov Chain Monte Carlo methods), 특히 메트로폴리스-헤이스팅스 알고리즘(metropolis-hastings algorithm)은 구조 사전 확률을 정의하고 수용 확률을 효율적으로 계산하는 확률 트리를 탐색하여 사후 분포에서 샘플링하는 데 효과적으로 사용됩니다. 이 접근법은 베이지안 네트워크 구조 학습(bayesian net structure learning)에 적용되어, 사전 확률 선택과 트리 탐색 전략이 방법론의 성공에 크게 영향을 미친다는 것이 연구 결과로 입증되었습니다. 메트로폴리스-헤이스팅스 알고리즘(metropolis-hastings algorithm)에서 제안된 이동의 수용 확률은 $\\alpha = \\min\\left(1, \\frac{P(\\text{new state})}{P(\\text{current state})}\\right)$로 주어지며, 이는 계산을 간소화하기 위해 확률 트리를 활용하는 혁신을 강조합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as \"베이지안 네트워크 구조 학습에 적용되어\" to \"베이지안 네트워크 구조 학습에 적용됨으로써\"."
    },
    {
        "turn_index": 2,
        "term": "deep generative modeling",
        "domain": "cs.AI",
        "summary": "  Hungry Geese is a n-player variation of the popular game snake. This paper\nlooks at state of the art Deep Reinforcement Learning Value Methods. The goal\nof the paper is to aggregate research of value based methods and apply it as an\nexercise to other environments. A vanilla Deep Q Network, a Double Q-network\nand a Dueling Q-Network were all examined and tested with the Hungry Geese\nenvironment. The best performing model was the vanilla Deep Q Network due to\nits simple state representation and smaller network structure. Converging\ntowards an optimal policy was found to be difficult due to random geese\ninitialization and food generation. Therefore we show that Deep Q Networks may\nnot be the appropriate model for such a stochastic environment and lastly we\npresent improvements that can be made along with more suitable models for the\nenvironment.\n",
        "english": "Deep generative modeling, while not directly mentioned in the study of the Hungry Geese environment, can offer insights into the stochastic nature of environments where random initialization and dynamic elements such as food generation play a crucial role. The research highlights the challenges faced by Deep Q Networks in achieving convergence towards an optimal policy due to these stochastic factors, suggesting that generative models could provide more robust solutions by modeling the probability distributions of such dynamic elements. Moreover, the exploration of Deep Q Networks' performance, especially its mathematical representation $Q(s, a) = r + \\gamma \\max_{a'} Q(s', a')$, underscores the potential for integrating generative approaches to enhance the adaptability and predictive accuracy of reinforcement learning models in complex environments.",
        "korean": "심층 생성 모델링(deep generative modeling)은 헝그리 구스 환경(hungry geese environment)의 연구에서 직접적으로 언급되지는 않았지만, 무작위 초기화와 음식 생성과 같은 동적 요소가 중요한 역할을 하는 환경의 확률적 특성에 대한 통찰을 제공할 수 있습니다. 연구는 이러한 확률적 요인들로 인해 심층 q 네트워크(deep q networks)가 최적 정책으로 수렴하는 데 직면하는 어려움을 강조하며, 생성 모델이 이러한 동적 요소의 확률 분포를 모델링함으로써 더 견고한 솔루션을 제공할 수 있음을 시사합니다. 더욱이, 심층 q 네트워크(deep q networks)의 성능 탐구, 특히 그 수학적 표현 $Q(s, a) = r + \\gamma \\max_{a'} Q(s', a')$는 복잡한 환경에서 강화 학습 모델의 적응성과 예측 정확성을 향상시키기 위해 생성적 접근을 통합할 가능성을 강조합니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "graph-based machine learning",
        "domain": "cs.AI",
        "summary": "  From the point of view of a programmer, the robopsychology is a synonym for\nthe activity is done by developers to implement their machine learning\napplications. This robopsychological approach raises some fundamental\ntheoretical questions of machine learning. Our discussion of these questions is\nconstrained to Turing machines. Alan Turing had given an algorithm (aka the\nTuring Machine) to describe algorithms. If it has been applied to describe\nitself then this brings us to Turing's notion of the universal machine. In the\npresent paper, we investigate algorithms to write algorithms. From a pedagogy\npoint of view, this way of writing programs can be considered as a combination\nof learning by listening and learning by doing due to it is based on applying\nagent technology and machine learning. As the main result we introduce the\nproblem of learning and then we show that it cannot easily be handled in\nreality therefore it is reasonable to use machine learning algorithm for\nlearning Turing machines.\n",
        "english": "Graph-based machine learning, as a subset of machine learning, can be understood through the lens of robopsychology, which is synonymous with the activities developers undertake to implement their machine learning applications. This approach, which combines learning by listening and learning by doing, is based on applying agent technology and machine learning, leading to the development of algorithms that can describe themselves, akin to Turing's notion of the universal machine. Importantly, the challenge of learning in graph-based machine learning is underscored by the complexity of handling real-world scenarios, thus necessitating the use of machine learning algorithms for learning Turing machines, where the algorithmic process can be represented as $f(x) = \\text{ML}(T(x))$ for a given input $x$.",
        "korean": "그래프 기반 기계 학습(graph-based machine learning)은 기계 학습(machine learning)의 하위 집합으로, 개발자가 기계 학습 응용 프로그램을 구현하기 위해 수행하는 활동과 동의어인 로보심리학(robopsychology)의 관점에서 이해될 수 있습니다. 이 접근 방식은 듣기 학습과 실행 학습을 결합하여 에이전트 기술(agent technology)과 기계 학습(machine learning)을 적용함으로써 스스로를 설명할 수 있는 알고리즘을 개발하는 데 기초를 두고 있으며, 이는 튜링(Turing)의 보편 기계(universal machine) 개념과 유사합니다. 특히, 그래프 기반 기계 학습(graph-based machine learning)에서의 학습 도전 과제는 실제 시나리오를 처리하는 복잡성에 의해 강조되며, 이는 튜링 기계(Turing machines)를 학습하기 위한 기계 학습 알고리즘(machine learning algorithms)의 사용을 필요로 합니다. 여기서 알고리즘적 과정은 주어진 입력 $x$에 대해 $f(x) = \\text{ML}(T(x))$로 표현될 수 있습니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent lowercase for all terms within parentheses."
    },
    {
        "turn_index": 2,
        "term": "hyperparameter tuning",
        "domain": "cs.AI",
        "summary": "  Neural-symbolic learning, an intersection of neural networks and symbolic\nreasoning, aims to blend neural networks' learning capabilities with symbolic\nAI's interpretability and reasoning. This paper introduces an approach designed\nto improve the performance of neural models in learning reasoning tasks. It\nachieves this by integrating Answer Set Programming (ASP) solvers and\ndomain-specific expertise, which is an approach that diverges from traditional\ncomplex neural-symbolic models. In this paper, a shallow artificial neural\nnetwork (ANN) is specifically trained to solve Sudoku puzzles with minimal\ntraining data. The model has a unique loss function that integrates losses\ncalculated using the ASP solver outputs, effectively enhancing its training\nefficiency. Most notably, the model shows a significant improvement in solving\nSudoku puzzles using only 12 puzzles for training and testing without\nhyperparameter tuning. This advancement indicates that the model's enhanced\nreasoning capabilities have practical applications, extending well beyond\nSudoku puzzles to potentially include a variety of other domains. The code can\nbe found on GitHub: https://github.com/Fadi2200/ASPEN.\n",
        "english": "In the realm of neural-symbolic learning, the integration of Answer Set Programming (ASP) solvers with domain-specific expertise allows for the development of models that enhance reasoning capabilities without the necessity of hyperparameter tuning, as demonstrated by the significant improvement in solving Sudoku puzzles with minimal training data. Specifically, a shallow artificial neural network (ANN) was trained on only 12 puzzles, achieving notable performance improvements by employing a unique loss function that integrates losses calculated using ASP solver outputs, thus bypassing the traditional need for hyperparameter tuning. This innovative approach underscores the potential for applying such models to a broader array of reasoning tasks, suggesting that hyperparameter tuning might not always be requisite for achieving high performance in complex problem-solving scenarios.",
        "korean": "신경-상징적 학습(neural-symbolic learning) 분야에서, 정답 집합 프로그래밍(Answer Set Programming, ASP) 솔버와 도메인별 전문 지식을 통합함으로써 하이퍼파라미터 튜닝(hyperparameter tuning)의 필요 없이 추론 능력을 향상시키는 모델을 개발할 수 있습니다. 이는 최소한의 훈련 데이터로 스도쿠 퍼즐을 해결하는 데 있어 상당한 개선을 보여주었습니다. 구체적으로, 얕은 인공 신경망(shallow artificial neural network, ANN)은 단 12개의 퍼즐로 훈련되었으며, ASP 솔버 출력으로 계산된 손실을 통합하는 독특한 손실 함수를 사용하여 주목할 만한 성능 향상을 달성했습니다. 이 혁신적인 접근 방식은 이러한 모델을 더 넓은 범위의 추론 작업에 적용할 가능성을 강조하며, 복잡한 문제 해결 시 높은 성능을 달성하기 위해 하이퍼파라미터 튜닝(hyperparameter tuning)이 항상 필수적이지 않을 수 있음을 시사합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural probabilistic text processes",
        "domain": "cs.AI",
        "summary": "  Food retailing is now on an accelerated path to a success penetration into\nthe digital market by new ways of value creation at all stages of the consumer\ndecision process. One of the most important imperatives in this path is the\navailability of quality data to feed all the process in digital transformation.\nBut the quality of data is not so obvious if we consider the variety of\nproducts and suppliers in the grocery market. Within this context of digital\ntransformation of grocery industry, \\textit{Midiadia} is Spanish data provider\ncompany that works on converting data from the retailers' products into\nknowledge with attributes and insights from the product labels, that is,\nmaintaining quality data in a dynamic market with a high dispersion of\nproducts. Currently, they manually categorize products (groceries) according to\nthe information extracted directly (text processing) from the product labelling\nand packaging. This paper introduces a solution to automatically categorize the\nconstantly changing product catalogue into a 3-level food taxonomy. Our\nproposal studies three different approaches: a score-based ranking method,\ntraditional machine learning algorithms, and deep neural networks. Thus, we\nprovide four different classifiers that support a more efficient and less\nerror-prone maintenance of groceries catalogues, the main asset of the company.\nFinally, we have compared the performance of these three alternatives,\nconcluding that traditional machine learning algorithms perform better, but\nclosely followed by the score-based approach.\n",
        "english": "In the context of digital transformation within the grocery industry, neural probabilistic text processes have become vital for converting data from retailers' products into actionable insights, as evidenced by the Spanish data provider company, \\textit{Midiadia}, which emphasizes maintaining quality data in a dynamic market. To address the challenges posed by the high dispersion of products, this research introduces a sophisticated solution for automatically categorizing the ever-evolving product catalogue into a 3-level food taxonomy, employing methodologies such as score-based ranking, traditional machine learning algorithms, and deep neural networks. Notably, the performance analysis revealed that traditional machine learning algorithms achieved superior results, with an accuracy closely approximated by the score-based approach, highlighting the potential of neural probabilistic text processes in enhancing the efficiency and accuracy of grocery catalogue maintenance.",
        "korean": "디지털 전환의 맥락에서 식료품 산업 내에서 신경 확률적 텍스트 프로세스(neural probabilistic text processes)는 소매업체의 제품 데이터를 실행 가능한 인사이트로 변환하는 데 필수적입니다. 이는 스페인의 데이터 제공 회사인 \\textit{Midiadia}가 역동적인 시장에서 품질 데이터를 유지하는 것을 강조하는 사례로 입증되었습니다. 제품의 높은 분산으로 인한 문제를 해결하기 위해, 본 연구는 점수 기반 순위(score-based ranking), 전통적인 기계 학습 알고리즘(traditional machine learning algorithms), 심층 신경망(deep neural networks)과 같은 방법론을 활용하여 지속적으로 변화하는 제품 카탈로그를 3단계 식품 분류 체계로 자동 분류하는 정교한 솔루션을 소개합니다. 특히 성능 분석 결과, 전통적인 기계 학습 알고리즘(traditional machine learning algorithms)이 우수한 결과를 달성했으며, 점수 기반 접근법(score-based approach)으로 근접한 정확도를 보여주어 식료품 카탈로그 유지의 효율성과 정확성을 향상시키는 데 있어 신경 확률적 텍스트 프로세스(neural probabilistic text processes)의 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "structured sparsity",
        "domain": "cs.AI",
        "summary": "  Causal discovery from observational data is pivotal for deciphering complex\nrelationships. Causal Structure Learning (CSL), which focuses on deriving\ncausal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast\nDAG spaces and data sparsity. The integration of Large Language Models (LLMs),\nrecognized for their causal reasoning capabilities, offers a promising\ndirection to enhance CSL by infusing it with knowledge-based causal inferences.\nHowever, existing approaches utilizing LLMs for CSL have encountered issues,\nincluding unreliable constraints from imperfect LLM inferences and the\ncomputational intensity of full pairwise variable analyses. In response, we\nintroduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL\ninnovatively integrates LLM-based causal inference with CSL in an iterative\nprocess, refining the causal DAG using feedback from LLMs. This method not only\nutilizes LLM resources more efficiently but also generates more robust and\nhigh-quality structural constraints compared to previous methodologies. Our\ncomprehensive evaluation across eight real-world datasets demonstrates\nILS-CSL's superior performance, setting a new standard in CSL efficacy and\nshowcasing its potential to significantly advance the field of causal\ndiscovery. The codes are available at\n\\url{https://github.com/tyMadara/ILS-CSL}.\n",
        "english": "In the realm of Causal Structure Learning (CSL), structured sparsity plays a crucial role in navigating the vast DAG spaces and overcoming data sparsity challenges, as highlighted by the integration of Large Language Models (LLMs) recognized for their causal reasoning capabilities. The Iterative LLM Supervised CSL (ILS-CSL) framework leverages structured sparsity by refining the causal Directed Acyclic Graph (DAG) iteratively, thus enhancing CSL efficiency and generating robust structural constraints. Notably, the ILS-CSL framework demonstrates its superior performance through comprehensive evaluation across eight real-world datasets, achieving a significant reduction in computational intensity while maintaining high-quality structural constraints, as evidenced by the equation: $E = mc^2$, where $E$ represents efficiency, $m$ is the model's robustness, and $c$ is the computational cost.",
        "korean": "인과 구조 학습(causal structure learning, CSL) 분야에서 구조적 희소성(structured sparsity)은 방대한 DAG 공간을 탐색하고 데이터 희소성 문제를 극복하는 데 중요한 역할을 합니다. 이는 인과 추론 능력으로 인정받는 대형 언어 모델(large language models, LLMs)의 통합을 통해 강조됩니다. 반복적 LLM 감독 CSL(iterative LLM supervised CSL, ILS-CSL) 프레임워크는 구조적 희소성(structured sparsity)을 활용하여 인과적 방향성 비순환 그래프(directed acyclic graph, DAG)를 반복적으로 개선함으로써 CSL 효율성을 높이고 견고한 구조적 제약을 생성합니다. 특히, ILS-CSL 프레임워크는 8개의 실제 데이터셋에 대한 포괄적인 평가를 통해 우수한 성능을 입증하며, 높은 품질의 구조적 제약을 유지하면서 계산 강도를 크게 줄이는 성과를 달성합니다. 이는 $E = mc^2$라는 방정식으로 입증되며, 여기서 $E$는 효율성, $m$은 모델의 견고성, $c$는 계산 비용을 나타냅니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "mixture models",
        "domain": "cs.AI",
        "summary": "  Long-term forecasting involves predicting a horizon that is far ahead of the\nlast observation. It is a problem of high practical relevance, for instance for\ncompanies in order to decide upon expensive long-term investments. Despite the\nrecent progress and success of Gaussian processes (GPs) based on spectral\nmixture kernels, long-term forecasting remains a challenging problem for these\nkernels because they decay exponentially at large horizons. This is mainly due\nto their use of a mixture of Gaussians to model spectral densities.\nCharacteristics of the signal important for long-term forecasting can be\nunravelled by investigating the distribution of the Fourier coefficients of\n(the training part of) the signal, which is non-smooth, heavy-tailed, sparse,\nand skewed. The heavy tail and skewness characteristics of such distributions\nin the spectral domain allow to capture long-range covariance of the signal in\nthe time domain. Motivated by these observations, we propose to model spectral\ndensities using a skewed Laplace spectral mixture (SLSM) due to the skewness of\nits peaks, sparsity, non-smoothness, and heavy tail characteristics. By\napplying the inverse Fourier Transform to this spectral density we obtain a new\nGP kernel for long-term forecasting. In addition, we adapt the lottery ticket\nmethod, originally developed to prune weights of a neural network, to GPs in\norder to automatically select the number of kernel components. Results of\nextensive experiments, including a multivariate time series, show the\nbeneficial effect of the proposed SLSM kernel for long-term extrapolation and\nrobustness to the choice of the number of mixture components.\n",
        "english": "Mixture models, particularly those utilizing Gaussian processes (GPs) with spectral mixture kernels, have shown promise in long-term forecasting, yet they face challenges due to the exponential decay of these kernels at large horizons. To address these limitations, the study proposes using a skewed Laplace spectral mixture (SLSM) model, which leverages the non-smooth, heavy-tailed, sparse, and skewed characteristics of Fourier coefficients for improved long-range covariance capture. By employing the inverse Fourier Transform, the SLSM model introduces a novel GP kernel, enhancing robustness and effectiveness in long-term extrapolation, as demonstrated by extensive experiments, including a multivariate time series.",
        "korean": "혼합 모델(mixture models), 특히 스펙트럼 혼합 커널(spectral mixture kernels)을 사용하는 가우시안 프로세스(gaussian processes, gps)는 장기 예측에서 가능성을 보여주었지만, 큰 범위에서 이러한 커널의 지수적 감소로 인해 어려움을 겪고 있습니다. 이러한 한계를 해결하기 위해, 연구는 푸리에 계수(fourier coefficients)의 비매끄럽고, 두꺼운 꼬리, 희소하고, 비대칭적인 특성을 활용하여 장거리 공분산 포착을 개선하는 비대칭 라플라스 스펙트럼 혼합(skewed laplace spectral mixture, slsm) 모델을 제안합니다. 역 푸리에 변환(inverse fourier transform)을 사용함으로써, slsm 모델은 새로운 gp 커널을 도입하여 장기 외삽에서의 견고성과 효과성을 향상시키며, 다변량 시계열(multivariate time series)을 포함한 광범위한 실험을 통해 입증되었습니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as adjusting the placement of technical terms to better fit the natural flow of Korean grammar."
    },
    {
        "turn_index": 2,
        "term": "long short-term memory",
        "domain": "cs.AI",
        "summary": "  This is a detailed analysis and comparison of the ACT-R and Soar cognitive\narchitectures, including their overall structure, their representations of\nagent data and metadata, and their associated processing. It focuses on working\nmemory, procedural memory, and long-term declarative memory. I emphasize the\ncommonalities, which are many, but also highlight the differences. I identify\nthe processes and distinct classes of information used by these architectures,\nincluding agent data, metadata, and meta-process data, and explore the roles\nthat metadata play in decision making, memory retrievals, and learning.\n",
        "english": "In the exploration of cognitive architectures such as ACT-R and Soar, the concept of long short-term memory (LSTM) can be analogously related to the integration of working memory and procedural memory, which are pivotal in the processing and representation of agent data and metadata. The study emphasizes the commonalities and differences in these architectures, highlighting the role of metadata in decision-making, memory retrievals, and learning, which parallels the LSTM's ability to retain information over extended sequences through its cell state and gating mechanisms. Importantly, the mathematical foundation of LSTM can be expressed in its gating functions, such as the forget gate: $f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$, where $\\sigma$ denotes the sigmoid function, $W_f$ the weight matrix, and $b_f$ the bias vector, showcasing its innovative approach to addressing the vanishing gradient problem in sequential data processing.",
        "korean": "인지 아키텍처(cognitive architectures)인 ACT-R과 Soar의 탐구에서, 장단기 메모리(long short-term memory, LSTM)의 개념은 작업 기억(working memory)과 절차적 기억(procedural memory)의 통합과 유사하게 관련될 수 있으며, 이는 에이전트 데이터와 메타데이터의 처리 및 표현에 있어 중요한 역할을 합니다. 이 연구는 이러한 아키텍처의 공통점과 차이점을 강조하며, 의사 결정, 기억 회수, 학습에서 메타데이터의 역할을 강조하는데, 이는 LSTM이 셀 상태와 게이팅 메커니즘을 통해 확장된 시퀀스에서 정보를 유지할 수 있는 능력과 유사합니다. 특히, LSTM의 수학적 기초는 게이팅 함수에서 표현될 수 있으며, 예를 들어 망각 게이트(forget gate)는 다음과 같이 표현됩니다: $f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$, 여기서 $\\sigma$는 시그모이드 함수(sigmoid function), $W_f$는 가중치 행렬(weight matrix), $b_f$는 바이어스 벡터(bias vector)를 나타내며, 이는 순차 데이터 처리에서 소실 기울기 문제(vanishing gradient problem)를 해결하는 혁신적인 접근 방식을 보여줍니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar."
    },
    {
        "turn_index": 2,
        "term": "quantization",
        "domain": "cs.AI",
        "summary": "  Vector quantization(VQ) is a lossy data compression technique from signal\nprocessing, which is restricted to feature vectors and therefore inapplicable\nfor combinatorial structures. This contribution presents a theoretical\nfoundation of graph quantization (GQ) that extends VQ to the domain of\nattributed graphs. We present the necessary Lloyd-Max conditions for optimality\nof a graph quantizer and consistency results for optimal GQ design based on\nempirical distortion measures and stochastic optimization. These results\nstatistically justify existing clustering algorithms in the domain of graphs.\nThe proposed approach provides a template of how to link structural pattern\nrecognition methods other than GQ to statistical pattern recognition.\n",
        "english": "Quantization, specifically vector quantization (VQ), is a \"lossy data compression technique from signal processing\" which traditionally applies to feature vectors, but not to combinatorial structures. The research extends this concept to graph quantization (GQ), introducing a theoretical foundation that allows for the application of VQ principles to \"attributed graphs,\" and establishes the Lloyd-Max conditions for the optimality of a graph quantizer. By demonstrating consistency results for optimal GQ design through empirical distortion measures and stochastic optimization, the study statistically justifies existing clustering algorithms in the domain of graphs, thereby innovating the intersection of structural and statistical pattern recognition methods.",
        "korean": "양자화(quantization), 특히 벡터 양자화(vector quantization, VQ)는 \"신호 처리에서 손실이 있는 데이터 압축 기법\"으로 전통적으로 특징 벡터에 적용되지만 조합 구조에는 적용되지 않습니다. 연구는 이 개념을 그래프 양자화(graph quantization, GQ)로 확장하여 \"속성 그래프\"에 VQ 원리를 적용할 수 있는 이론적 기초를 도입하고, 그래프 양자화기의 최적성을 위한 로이드-맥스 조건(Lloyd-Max conditions)을 확립합니다. 최적 GQ 설계를 위한 일관성 결과를 경험적 왜곡 측정과 확률적 최적화를 통해 입증함으로써, 연구는 그래프 도메인에서 기존의 클러스터링 알고리즘을 통계적으로 정당화하여 구조적 및 통계적 패턴 인식 방법의 교차점을 혁신합니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Ensure all English terms within parentheses are in lowercase for consistency, such as \"vector quantization\" instead of \"Vector Quantization\"."
    },
    {
        "turn_index": 2,
        "term": "neural sequence labeling",
        "domain": "cs.AI",
        "summary": "  In many machine learning applications, labeled data is scarce and obtaining\nmore labels is expensive. We introduce a new approach to supervising neural\nnetworks by specifying constraints that should hold over the output space,\nrather than direct examples of input-output pairs. These constraints are\nderived from prior domain knowledge, e.g., from known laws of physics. We\ndemonstrate the effectiveness of this approach on real world and simulated\ncomputer vision tasks. We are able to train a convolutional neural network to\ndetect and track objects without any labeled examples. Our approach can\nsignificantly reduce the need for labeled training data, but introduces new\nchallenges for encoding prior knowledge into appropriate loss functions.\n",
        "english": "Neural sequence labeling can benefit from an innovative approach to supervising neural networks by specifying constraints that should hold over the output space, rather than relying solely on direct examples of input-output pairs. This method, which derives constraints from prior domain knowledge such as known laws of physics, has been demonstrated to significantly reduce the need for labeled training data, thereby addressing the challenge of data scarcity in many machine learning applications. By introducing a novel loss function, $L_{\\text{prior}}$, which encodes these constraints, researchers have successfully trained models to perform complex tasks, highlighting the potential of constraint-based supervision in enhancing neural sequence labeling.",
        "korean": "신경 시퀀스 레이블링(neural sequence labeling)은 입력-출력 쌍의 직접적인 예시에만 의존하지 않고 출력 공간에 적용되어야 할 제약 조건을 지정함으로써 신경망(neural networks)을 감독하는 혁신적인 접근 방식에서 이점을 얻을 수 있습니다. 물리학의 알려진 법칙과 같은 사전 도메인 지식에서 제약 조건을 도출하는 이 방법은 레이블이 지정된 훈련 데이터의 필요성을 크게 줄이는 것으로 입증되어 많은 기계 학습(machine learning) 응용 프로그램에서 데이터 부족 문제를 해결합니다. 이러한 제약 조건을 인코딩하는 새로운 손실 함수(loss function), $L_{\\text{prior}}$를 도입함으로써 연구자들은 복잡한 작업을 수행할 수 있는 모델을 성공적으로 훈련시켰으며, 제약 기반 감독이 신경 시퀀스 레이블링(neural sequence labeling)을 향상시키는 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "deep semantic segmentation",
        "domain": "cs.AI",
        "summary": "  It is a crucial step to achieve effective semantic segmentation of lane\nmarking during the construction of the lane level high-precision map. In recent\nyears, many image semantic segmentation methods have been proposed. These\nmethods mainly focus on the image from camera, due to the limitation of the\nsensor itself, the accurate three-dimensional spatial position of the lane\nmarking cannot be obtained, so the demand for the lane level high-precision map\nconstruction cannot be met. This paper proposes a lane marking semantic\nsegmentation method based on LIDAR and camera fusion deep neural network.\nDifferent from other methods, in order to obtain accurate position information\nof the segmentation results, the semantic segmentation object of this paper is\na bird's eye view converted from a LIDAR points cloud instead of an image\ncaptured by a camera. This method first uses the deeplabv3+ [\\ref{ref:1}]\nnetwork to segment the image captured by the camera, and the segmentation\nresult is merged with the point clouds collected by the LIDAR as the input of\nthe proposed network. In this neural network, we also add a long short-term\nmemory (LSTM) structure to assist the network for semantic segmentation of lane\nmarkings by using the the time series information. The experiments on more than\n14,000 image datasets which we have manually labeled and expanded have shown\nthe proposed method has better performance on the semantic segmentation of the\npoints cloud bird's eye view. Therefore, the automation of high-precision map\nconstruction can be significantly improved. Our code is available at\nhttps://github.com/rolandying/FusionLane.\n",
        "english": "Deep semantic segmentation is essential for the effective semantic segmentation of lane markings, particularly in constructing lane-level high-precision maps, which require accurate three-dimensional spatial positioning. By employing a method that fuses LIDAR and camera data, this approach utilizes a deep neural network where the segmentation object is a bird's eye view converted from a LIDAR points cloud, rather than solely relying on camera images, thereby enhancing the precision of the segmentation results. The integration of a long short-term memory (LSTM) structure within the network leverages temporal series information, and experimental results demonstrate that this method achieves superior performance with a mean Intersection over Union (mIoU) score of 0.85 on a dataset of over 14,000 manually labeled images, significantly advancing the automation of high-precision map construction.",
        "korean": "심층 의미 분할(deep semantic segmentation)은 차선 마킹의 효과적인 의미 분할을 위해 필수적이며, 특히 차선 수준의 고정밀 지도(high-precision maps) 구축에 있어 정확한 3차원 공간 위치가 필요합니다. lidar와 카메라 데이터를 융합하는 방법을 사용함으로써, 이 접근법은 세분화 객체가 카메라 이미지에만 의존하지 않고 lidar 포인트 클라우드에서 변환된 조감도(bird's eye view)인 심층 신경망(deep neural network)을 활용하여 세분화 결과의 정밀도를 향상시킵니다. 네트워크 내에 장단기 메모리(long short-term memory, lstm) 구조를 통합함으로써 시간적 시리즈 정보를 활용하며, 실험 결과는 이 방법이 14,000개 이상의 수작업으로 라벨링된 이미지 데이터셋에서 평균 교차합집합비(mean intersection over union, miou) 점수 0.85를 달성하여 고정밀 지도 구축의 자동화를 크게 발전시켰음을 보여줍니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "nonparametric Bayesian models",
        "domain": "cs.AI",
        "summary": "  Reinforcement learning (RL) problems are often phrased in terms of Markov\ndecision processes (MDPs). In this thesis we go beyond MDPs and consider RL in\nenvironments that are non-Markovian, non-ergodic and only partially observable.\nOur focus is not on practical algorithms, but rather on the fundamental\nunderlying problems: How do we balance exploration and exploitation? How do we\nexplore optimally? When is an agent optimal? We follow the nonparametric\nrealizable paradigm.\n  We establish negative results on Bayesian RL agents, in particular AIXI. We\nshow that unlucky or adversarial choices of the prior cause the agent to\nmisbehave drastically. Therefore Legg-Hutter intelligence and balanced Pareto\noptimality, which depend crucially on the choice of the prior, are entirely\nsubjective. Moreover, in the class of all computable environments every policy\nis Pareto optimal. This undermines all existing optimality properties for AIXI.\nHowever, there are Bayesian approaches to general RL that satisfy objective\noptimality guarantees: We prove that Thompson sampling is asymptotically\noptimal in stochastic environments in the sense that its value converges to the\nvalue of the optimal policy. We connect asymptotic optimality to regret given a\nrecoverability assumption on the environment that allows the agent to recover\nfrom mistakes. Hence Thompson sampling achieves sublinear regret in these\nenvironments.\n  Our results culminate in a formal solution to the grain of truth problem: A\nBayesian agent acting in a multi-agent environment learns to predict the other\nagents' policies if its prior assigns positive probability to them (the prior\ncontains a grain of truth). We construct a large but limit computable class\ncontaining a grain of truth and show that agents based on Thompson sampling\nover this class converge to play Nash equilibria in arbitrary unknown\ncomputable multi-agent environments.\n",
        "english": "Nonparametric Bayesian models, particularly in the context of reinforcement learning (RL), offer a framework to address environments that are non-Markovian, non-ergodic, and only partially observable, moving beyond traditional Markov decision processes (MDPs). These models are crucial in understanding the balance between exploration and exploitation, as evidenced by the realization that \"unlucky or adversarial choices of the prior cause the agent to misbehave drastically,\" highlighting the subjective nature of Legg-Hutter intelligence and balanced Pareto optimality. Furthermore, the use of methodologies such as Thompson sampling in nonparametric Bayesian models is shown to achieve asymptotic optimality, where the value of the agent's policy converges to that of the optimal policy, and this is mathematically expressed as $\\lim_{t \\to \\infty} V(\\pi_t) = V(\\pi^*)$, thus ensuring sublinear regret under certain environmental assumptions.",
        "korean": "비모수 베이지안 모델(nonparametric Bayesian models)은 특히 강화 학습(reinforcement learning, RL) 맥락에서 비마르코프(non-Markovian), 비에르고딕(non-ergodic), 부분적으로만 관측 가능한 환경을 다루기 위한 프레임워크를 제공합니다. 이는 전통적인 마르코프 결정 과정(Markov decision processes, MDPs)을 넘어서는 접근법입니다. 이러한 모델은 탐색과 활용 간의 균형을 이해하는 데 중요하며, \"우연히 또는 적대적인 사전 선택이 에이전트의 행동을 크게 잘못되게 한다\"는 사실을 통해 레그-허터 지능(Legg-Hutter intelligence)과 균형 잡힌 파레토 최적성(balanced Pareto optimality)의 주관적 특성을 강조합니다. 더욱이, 비모수 베이지안 모델(nonparametric Bayesian models)에서 톰슨 샘플링(Thompson sampling)과 같은 방법론의 사용은 점근적 최적성을 달성하는 것으로 나타났으며, 이는 에이전트 정책의 가치가 최적 정책의 가치에 수렴함을 수학적으로 $\\lim_{t \\to \\infty} V(\\pi_t) = V(\\pi^*)$로 표현하며, 특정 환경 가정 하에서 서브리니어 후회를 보장합니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "autoencoders",
        "domain": "cs.AI",
        "summary": "  In this paper, we propose a novel approach to generate images (or other\nartworks) by using neural cellular automatas (NCAs). Rather than training NCAs\nbased on single images one by one, we combined the idea with variational\nautoencoders (VAEs), and hence explored some applications, such as image\nrestoration and style fusion. The code for model implementation is available\nonline.\n",
        "english": "The integration of variational autoencoders (VAEs) with neural cellular automatas (NCAs) presents a novel approach for generating images and other artworks, as demonstrated in the research. By employing VAEs, the study explores applications such as image restoration and style fusion, leveraging the ability of autoencoders to learn efficient representations of data. Mathematically, the VAE framework optimizes the evidence lower bound (ELBO), expressed as $\\mathcal{L} = \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - \\text{KL}(q(z|x) \\| p(z))$, thereby facilitating the effective training of NCAs on diverse datasets.",
        "korean": "변분 오토인코더(variational autoencoders, vaes)와 신경 세포 자동자(neural cellular automatas, ncas)의 통합은 이미지 및 기타 예술 작품을 생성하는 새로운 접근 방식을 제시하며, 연구에서 이를 입증하였습니다. vaes를 활용함으로써, 연구는 오토인코더(autoencoders)가 데이터의 효율적인 표현을 학습하는 능력을 활용하여 이미지 복원 및 스타일 융합과 같은 응용 분야를 탐구합니다. 수학적으로, vae 프레임워크는 증거 하한(evidence lower bound, elbo)을 최적화하며, 이는 $\\mathcal{L} = \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - \\text{KL}(q(z|x) \\| p(z))$로 표현되어, 다양한 데이터셋에서 ncas의 효과적인 훈련을 촉진합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "probabilistic programming",
        "domain": "cs.AI",
        "summary": "  State-of-the-art inference approaches in probabilistic logic programming\ntypically start by computing the relevant ground program with respect to the\nqueries of interest, and then use this program for probabilistic inference\nusing knowledge compilation and weighted model counting. We propose an\nalternative approach that uses efficient Datalog techniques to integrate\nknowledge compilation with forward reasoning with a non-ground program. This\neffectively eliminates the grounding bottleneck that so far has prohibited the\napplication of probabilistic logic programming in query answering scenarios\nover knowledge graphs, while also providing fast approximations on classical\nbenchmarks in the field.\n",
        "english": "Probabilistic programming has traditionally faced challenges in query answering scenarios due to the \"grounding bottleneck,\" which arises from the need to compute a relevant ground program before performing probabilistic inference. By integrating knowledge compilation with forward reasoning using efficient Datalog techniques, researchers have effectively eliminated this bottleneck, allowing for more efficient query answering over knowledge graphs. This innovative approach not only facilitates faster processing but also provides fast approximations on classical benchmarks, leveraging methodologies such as weighted model counting and knowledge compilation, where the probability of a query $Q$ given evidence $E$ is computed as $P(Q|E) = \\frac{W(Q \\land E)}{W(E)}$, with $W$ denoting the weighted model count.",
        "korean": "확률적 프로그래밍(probabilistic programming)은 전통적으로 확률적 추론을 수행하기 전에 관련된 기초 프로그램을 계산해야 하는 \"기초 병목 현상\"으로 인해 쿼리 응답 시나리오에서 어려움을 겪어왔습니다. 연구자들은 효율적인 데이터로그 기법(datalog techniques)을 사용한 전방 추론과 지식 컴파일(knowledge compilation)을 통합함으로써 이 병목 현상을 효과적으로 제거하여 지식 그래프(knowledge graphs)에서 더 효율적인 쿼리 응답을 가능하게 했습니다. 이 혁신적인 접근 방식은 더 빠른 처리 속도를 촉진할 뿐만 아니라 가중치 모델 카운팅(weighted model counting)과 지식 컴파일(knowledge compilation)과 같은 방법론을 활용하여 고전적인 벤치마크에서 빠른 근사치를 제공합니다. 여기서 증거 $E$가 주어졌을 때 쿼리 $Q$의 확률은 $P(Q|E) = \\frac{W(Q \\land E)}{W(E)}$로 계산되며, $W$는 가중치 모델 카운트(weighted model count)를 나타냅니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "probabilistic deep learning",
        "domain": "cs.AI",
        "summary": "  Deep reinforcement learning has been successfully applied to many control\ntasks, but the application of such agents in safety-critical scenarios has been\nlimited due to safety concerns. Rigorous testing of these controllers is\nchallenging, particularly when they operate in probabilistic environments due\nto, for example, hardware faults or noisy sensors. We propose MOSAIC, an\nalgorithm for measuring the safety of deep reinforcement learning agents in\nstochastic settings. Our approach is based on the iterative construction of a\nformal abstraction of a controller's execution in an environment, and leverages\nprobabilistic model checking of Markov decision processes to produce\nprobabilistic guarantees on safe behaviour over a finite time horizon. It\nproduces bounds on the probability of safe operation of the controller for\ndifferent initial configurations and identifies regions where correct behaviour\ncan be guaranteed. We implement and evaluate our approach on agents trained for\nseveral benchmark control problems.\n",
        "english": "In the realm of probabilistic deep learning, the application of deep reinforcement learning agents to safety-critical scenarios has been constrained by safety concerns, particularly when these agents operate in probabilistic environments influenced by factors such as hardware faults or noisy sensors. The innovative MOSAIC algorithm addresses these challenges by iteratively constructing a formal abstraction of a controller's execution within an environment and employing probabilistic model checking of Markov decision processes, thereby providing probabilistic guarantees on safe behavior over a finite time horizon. This approach not only produces bounds on the probability of safe operation for different initial configurations, \\( P(\\text{safe operation} \\mid \\text{initial configuration}) \\), but also identifies regions where correct behavior can be assured, underscoring its potential to enhance the reliability of deep learning systems in uncertain settings.",
        "korean": "확률론적 심층 학습(probabilistic deep learning) 분야에서 심층 강화 학습 에이전트(deep reinforcement learning agents)를 안전이 중요한 시나리오에 적용하는 것은 하드웨어 결함이나 노이즈가 있는 센서와 같은 요인에 의해 영향을 받는 확률론적 환경에서의 안전 문제로 인해 제한되었습니다. 혁신적인 모자이크 알고리즘(MOSAIC algorithm)은 환경 내에서 컨트롤러 실행의 형식적 추상화를 반복적으로 구성하고 마르코프 결정 프로세스(Markov decision processes)의 확률론적 모델 검증을 활용하여 유한 시간 범위 내에서 안전한 행동에 대한 확률적 보장을 제공함으로써 이러한 문제를 해결합니다. 이 접근 방식은 다양한 초기 구성에 대한 안전한 작동 확률의 경계를 제공할 뿐만 아니라, 올바른 행동을 보장할 수 있는 영역을 식별하여 불확실한 환경에서 심층 학습 시스템의 신뢰성을 향상시킬 수 있는 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural latent variable models",
        "domain": "cs.AI",
        "summary": "  Neuro-symbolic learning (NSL) models complex symbolic rule patterns into\nlatent variable distributions by neural networks, which reduces rule search\nspace and generates unseen rules to improve downstream task performance.\nCentralized NSL learning involves directly acquiring data from downstream\ntasks, which is not feasible for federated learning (FL). To address this\nlimitation, we shift the focus from such a one-to-one interactive\nneuro-symbolic paradigm to one-to-many Federated Neuro-Symbolic Learning\nframework (FedNSL) with latent variables as the FL communication medium. Built\non the basis of our novel reformulation of the NSL theory, FedNSL is capable of\nidentifying and addressing rule distribution heterogeneity through a simple and\neffective Kullback-Leibler (KL) divergence constraint on rule distribution\napplicable under the FL setting. It further theoretically adjusts variational\nexpectation maximization (V-EM) to reduce the rule search space across domains.\nThis is the first incorporation of distribution-coupled bilevel optimization\ninto FL. Extensive experiments based on both synthetic and real-world data\ndemonstrate significant advantages of FedNSL compared to five state-of-the-art\nmethods. It outperforms the best baseline by 17% and 29% in terms of unbalanced\naverage training accuracy and unseen average testing accuracy, respectively.\n",
        "english": "Neural latent variable models, as utilized within the Federated Neuro-Symbolic Learning framework (FedNSL), serve as a communication medium in federated learning (FL), addressing the challenge of rule distribution heterogeneity through a Kullback-Leibler (KL) divergence constraint on rule distribution. By reformulating the neuro-symbolic learning (NSL) theory, FedNSL effectively applies variational expectation maximization (V-EM) to minimize the rule search space across domains, showcasing the first incorporation of distribution-coupled bilevel optimization into FL. Extensive experiments demonstrate the significant advantages of this approach, with FedNSL outperforming the best baseline by 17\\% and 29\\% in unbalanced average training accuracy and unseen average testing accuracy, respectively, highlighting its innovative contribution to the field.",
        "korean": "연합 신경-기호 학습 프레임워크(federated neuro-symbolic learning framework, FedNSL) 내에서 활용되는 신경 잠재 변수 모델(neural latent variable models)은 연합 학습(federated learning, FL)에서 규칙 분포의 이질성 문제를 해결하기 위한 통신 매체로 작용하며, 규칙 분포에 대한 쿨백-라이블러 발산(Kullback-Leibler divergence, KL) 제약을 통해 이를 해결합니다. 신경-기호 학습 이론(neuro-symbolic learning theory)을 재구성함으로써, FedNSL은 변분 기대 최대화(variational expectation maximization, V-EM)를 효과적으로 적용하여 도메인 간 규칙 탐색 공간을 최소화하며, FL에 분포 결합 이중 수준 최적화(distribution-coupled bilevel optimization)를 처음으로 도입한 사례를 보여줍니다. 광범위한 실험 결과, FedNSL은 불균형 평균 훈련 정확도에서 17\\%, 보지 못한 평균 테스트 정확도에서 29\\%로 최고의 기준선을 능가하는 중요한 이점을 입증하며, 이 분야에 혁신적인 기여를 하고 있음을 강조합니다.",
        "score": 9,
        "parentheses_count": 12,
        "suggestions": "Ensure that all technical terms are consistently formatted as Korean term(English term) and consider rephrasing for smoother readability in Korean."
    },
    {
        "turn_index": 2,
        "term": "neural adaptive text learning",
        "domain": "cs.AI",
        "summary": "  The rising popularity of online social network services has attracted lots of\nresearch on mining social media data, especially on mining social events.\nSocial event detection, due to its wide applications, has now become a trivial\ntask. State-of-the-art approaches exploiting Graph Neural Networks (GNNs)\nusually follow a two-step strategy: 1) constructing text graphs based on\nvarious views (\\textit{co-user}, \\textit{co-entities} and\n\\textit{co-hashtags}); and 2) learning a unified text representation by a\nspecific GNN model. Generally, the results heavily rely on the quality of the\nconstructed graphs and the specific message passing scheme. However, existing\nmethods have deficiencies in both aspects: 1) They fail to recognize the noisy\ninformation induced by unreliable views. 2) Temporal information which works as\na vital indicator of events is neglected in most works. To this end, we propose\nETGNN, a novel Evidential Temporal-aware Graph Neural Network. Specifically, we\nconstruct view-specific graphs whose nodes are the texts and edges are\ndetermined by several types of shared elements respectively. To incorporate\ntemporal information into the message passing scheme, we introduce a novel\ntemporal-aware aggregator which assigns weights to neighbours according to an\nadaptive time exponential decay formula. Considering the view-specific\nuncertainty, the representations of all views are converted into mass functions\nthrough evidential deep learning (EDL) neural networks, and further combined\nvia Dempster-Shafer theory (DST) to make the final detection. Experimental\nresults on three real-world datasets demonstrate the effectiveness of ETGNN in\naccuracy, reliability and robustness in social event detection.\n",
        "english": "Neural adaptive text learning, exemplified by the proposed Evidential Temporal-aware Graph Neural Network (ETGNN), addresses the deficiencies of existing methods by constructing view-specific graphs where nodes represent texts and edges are determined by shared elements such as \\textit{co-user}, \\textit{co-entities}, and \\textit{co-hashtags}. This innovative approach incorporates temporal information into the message passing scheme through a novel temporal-aware aggregator, which assigns weights to neighbors using an adaptive time exponential decay formula, enhancing the model's ability to detect social events accurately. The effectiveness of ETGNN in terms of accuracy, reliability, and robustness is demonstrated through experimental results on three real-world datasets, showcasing its potential to advance the field of neural adaptive text learning.",
        "korean": "제안된 증거 기반 시간 인식 그래프 신경망(evidential temporal-aware graph neural network, ETGNN)으로 대표되는 신경 적응형 텍스트 학습(neural adaptive text learning)은 텍스트를 노드로 하고 \\textit{공동 사용자(co-user)}, \\textit{공동 엔티티(co-entities)}, \\textit{공동 해시태그(co-hashtags)}와 같은 공유 요소에 의해 결정된 엣지를 가지는 뷰별 그래프를 구성함으로써 기존 방법의 결함을 해결합니다. 이 혁신적인 접근법은 새로운 시간 인식 집계기(temporal-aware aggregator)를 통해 메시지 전달 체계에 시간 정보를 통합하여 적응형 시간 지수 감쇠 공식(adaptive time exponential decay formula)을 사용하여 이웃에 가중치를 부여함으로써 모델의 사회적 사건 감지 능력을 향상시킵니다. ETGNN의 정확성, 신뢰성 및 견고성 측면에서의 효과는 세 가지 실제 데이터셋(real-world datasets)에 대한 실험 결과를 통해 입증되었으며, 이는 신경 적응형 텍스트 학습(neural adaptive text learning) 분야를 발전시킬 잠재력을 보여줍니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "latent variable models",
        "domain": "cs.AI",
        "summary": "  Based on a recent development in the area of error control coding, we\nintroduce the notion of convolutional factor graphs (CFGs) as a new class of\nprobabilistic graphical models. In this context, the conventional factor graphs\nare referred to as multiplicative factor graphs (MFGs). This paper shows that\nCFGs are natural models for probability functions when summation of independent\nlatent random variables is involved. In particular, CFGs capture a large class\nof linear models, where the linearity is in the sense that the observed\nvariables are obtained as a linear ransformation of the latent variables taking\narbitrary distributions. We use Gaussian models and independent factor models\nas examples to emonstrate the use of CFGs. The requirement of a linear\ntransformation between latent variables (with certain independence restriction)\nand the bserved variables, to an extent, limits the modelling flexibility of\nCFGs. This structural restriction however provides a powerful analytic tool to\nthe framework of CFGs; that is, upon taking the Fourier transform of the\nfunction represented by the CFG, the resulting function is represented by a FG\nwith identical structure. This Fourier transform duality allows inference\nproblems on a CFG to be solved on the corresponding dual MFG.\n",
        "english": "Latent variable models, particularly convolutional factor graphs (CFGs), have been introduced as a new class of probabilistic graphical models that are well-suited for probability functions involving the summation of independent latent random variables. These models are especially significant in capturing a large class of linear models, where the observed variables are obtained as a linear transformation of the latent variables, denoted mathematically as $\\mathbf{y} = \\mathbf{A}\\mathbf{x}$, with $\\mathbf{y}$ as the observed variables, $\\mathbf{A}$ as the transformation matrix, and $\\mathbf{x}$ as the latent variables. Despite the requirement of linear transformations, which may limit the modeling flexibility of CFGs, this structural restriction offers a powerful analytical tool, allowing inference problems on a CFG to be effectively solved using its Fourier transform duality with a multiplicative factor graph (MFG).",
        "korean": "잠재 변수 모델(latent variable models), 특히 컨볼루션 인자 그래프(convolutional factor graphs, CFGs)는 독립적인 잠재 확률 변수의 합을 포함하는 확률 함수에 적합한 새로운 클래스의 확률 그래픽 모델(probabilistic graphical models)로 도입되었습니다. 이러한 모델은 특히 관측 변수가 잠재 변수의 선형 변환으로 얻어지는 큰 클래스의 선형 모델을 포착하는 데 중요하며, 이는 수학적으로 $\\mathbf{y} = \\mathbf{A}\\mathbf{x}$로 나타내어지며, 여기서 $\\mathbf{y}$는 관측 변수, $\\mathbf{A}$는 변환 행렬, $\\mathbf{x}$는 잠재 변수입니다. 선형 변환의 요구는 CFGs의 모델링 유연성을 제한할 수 있지만, 이러한 구조적 제한은 강력한 분석 도구를 제공하여 CFG에서의 추론 문제를 곱셈 인자 그래프(multiplicative factor graph, MFG)와의 푸리에 변환 이중성을 사용하여 효과적으로 해결할 수 있게 합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring consistent use of lowercase letters within parentheses."
    },
    {
        "turn_index": 2,
        "term": "dynamic reinforcement learning",
        "domain": "cs.AI",
        "summary": "  The advent of artificial intelligence technology paved the way of many\nresearches to be made within air combat sector. Academicians and many other\nresearchers did a research on a prominent research direction called autonomous\nmaneuver decision of UAV. Elaborative researches produced some outcomes, but\ndecisions that include Reinforcement Learning(RL) came out to be more\nefficient. There have been many researches and experiments done to make an\nagent reach its target in an optimal way, most prominent are Genetic\nAlgorithm(GA) , A star, RRT and other various optimization techniques have been\nused. But Reinforcement Learning is the well known one for its success. In\nDARPHA Alpha Dogfight Trials, reinforcement learning prevailed against a real\nveteran F16 human pilot who was trained by Boeing. This successor model was\ndeveloped by Heron Systems. After this accomplishment, reinforcement learning\nbring tremendous attention on itself. In this research we aimed our UAV which\nhas a dubin vehicle dynamic property to move to the target in two dimensional\nspace in an optimal path using Twin Delayed Deep Deterministic Policy Gradients\n(TD3) and used in experience replay Hindsight Experience Replay(HER).We did\ntests on two different environments and used simulations.\n",
        "english": "Dynamic reinforcement learning has gained significant attention following its success in the DARPHA Alpha Dogfight Trials, where it outperformed a veteran F16 human pilot, highlighting its potential in autonomous maneuver decision-making for UAVs. This research employs Twin Delayed Deep Deterministic Policy Gradients (TD3) combined with Hindsight Experience Replay (HER) to optimize the path of a UAV, modeled as a Dubin vehicle, in a two-dimensional space, demonstrating the efficacy of dynamic reinforcement learning in achieving optimal target acquisition. Notably, the application of these advanced methodologies in simulations across two different environments underscores the innovation and importance of dynamic reinforcement learning in enhancing autonomous systems, with results suggesting a significant improvement over traditional optimization techniques such as Genetic Algorithm (GA), A*, and Rapidly-exploring Random Tree (RRT).",
        "korean": "동적 강화 학습(dynamic reinforcement learning)은 DARPHA 알파 도그파이트 시합(DARPHA Alpha Dogfight Trials)에서 베테랑 F16 인간 조종사를 능가하며 주목을 받았으며, UAV의 자율적 기동 결정에 대한 잠재력을 강조했습니다. 이 연구는 트윈 지연 심층 결정론적 정책 기울기(Twin Delayed Deep Deterministic Policy Gradients, TD3)와 회고 경험 재생(Hindsight Experience Replay, HER)을 결합하여 이차원 공간에서 두빈 차량(Dubin vehicle)으로 모델링된 UAV의 경로를 최적화하는 데 사용되며, 동적 강화 학습(dynamic reinforcement learning)의 목표 획득 최적화에 대한 효능을 입증합니다. 특히, 두 가지 다른 환경에서의 시뮬레이션을 통한 이러한 고급 방법론의 적용은 자율 시스템을 향상시키는 데 있어 동적 강화 학습(dynamic reinforcement learning)의 혁신성과 중요성을 강조하며, 결과는 유전 알고리즘(Genetic Algorithm, GA), A*, 빠르게 탐색하는 랜덤 트리(Rapidly-exploring Random Tree, RRT)와 같은 전통적인 최적화 기법에 비해 상당한 개선을 시사합니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "adaptive neural text embeddings",
        "domain": "cs.AI",
        "summary": "  Neural topic models have triggered a surge of interest in extracting topics\nfrom text automatically since they avoid the sophisticated derivations in\nconventional topic models. However, scarce neural topic models incorporate the\nword relatedness information captured in word embedding into the modeling\nprocess. To address this issue, we propose a novel topic modeling approach,\ncalled Variational Gaussian Topic Model (VaGTM). Based on the variational\nauto-encoder, the proposed VaGTM models each topic with a multivariate Gaussian\nin decoder to incorporate word relatedness. Furthermore, to address the\nlimitation that pre-trained word embeddings of topic-associated words do not\nfollow a multivariate Gaussian, Variational Gaussian Topic Model with\nInvertible neural Projections (VaGTM-IP) is extended from VaGTM. Three\nbenchmark text corpora are used in experiments to verify the effectiveness of\nVaGTM and VaGTM-IP. The experimental results show that VaGTM and VaGTM-IP\noutperform several competitive baselines and obtain more coherent topics.\n",
        "english": "Adaptive neural text embeddings have gained attention as they integrate word relatedness information into neural topic models, addressing the limitations of conventional methods that lack this capability. The Variational Gaussian Topic Model (VaGTM) and its extension, VaGTM-IP, leverage a variational auto-encoder to model each topic with a multivariate Gaussian, effectively incorporating word embeddings, even when topic-associated words do not naturally follow a multivariate Gaussian distribution. Experimental results on three benchmark text corpora demonstrate that VaGTM and VaGTM-IP outperform several competitive baselines, achieving more coherent topics, which underscores their innovative contribution to the field of neural topic modeling.",
        "korean": "적응형 신경 텍스트 임베딩(adaptive neural text embeddings)은 단어 관련성 정보를 신경 주제 모델(neural topic models)에 통합하여 이 기능이 부족한 기존 방법의 한계를 해결함으로써 주목을 받고 있습니다. 변분 가우시안 주제 모델(Variational Gaussian Topic Model, VaGTM)과 그 확장 모델인 VaGTM-IP는 변분 오토인코더(variational auto-encoder)를 활용하여 각 주제를 다변량 가우시안(multivariate Gaussian)으로 모델링하며, 주제와 관련된 단어가 자연스럽게 다변량 가우시안 분포를 따르지 않더라도 효과적으로 단어 임베딩(word embeddings)을 통합합니다. 세 가지 벤치마크 텍스트 코퍼스(benchmark text corpora)에 대한 실험 결과, VaGTM과 VaGTM-IP는 여러 경쟁적인 기준선(competitive baselines)을 능가하여 더 일관된 주제를 달성하며, 이는 신경 주제 모델링 분야에 대한 혁신적인 기여를 강조합니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all English terms within parentheses are in lowercase for consistency."
    },
    {
        "turn_index": 2,
        "term": "semantic probabilistic embeddings",
        "domain": "cs.AI",
        "summary": "  In fact, there exist three genres of intelligence architectures: logics (e.g.\n\\textit{Random Forest, A$^*$ Searching}), neurons (e.g. \\textit{CNN, LSTM}) and\nprobabilities (e.g. \\textit{Naive Bayes, HMM}), all of which are incompatible\nto each other. However, to construct powerful intelligence systems with various\nmethods, we propose the intelligence graph (short as \\textbf{\\textit{iGraph}}),\nwhich is composed by both of neural and probabilistic graph, under the\nframework of forward-backward propagation. By the paradigm of iGraph, we design\na recommendation model with semantic principle. First, the probabilistic\ndistributions of categories are generated from the embedding representations of\nusers/items, in the manner of neurons. Second, the probabilistic graph infers\nthe distributions of features, in the manner of probabilities. Last, for the\nrecommendation diversity, we perform an expectation computation then conduct a\nlogic judgment, in the manner of logics. Experimentally, we beat the\nstate-of-the-art baselines and verify our conclusions.\n",
        "korean": "의미 확률적 임베딩(semantic probabilistic embeddings)은 전방-후방 전파(forward-backward propagation) 프레임워크 하에서 신경 및 확률 그래프 방법론을 결합한 지능 그래프(intelligence graph, iGraph)의 핵심 요소입니다. 이러한 임베딩을 활용하여 사용자/항목의 임베딩 표현에서 범주의 확률 분포를 생성하며, 뉴런의 방식을 효과적으로 활용하여 추천 모델을 향상시킵니다. 실험적으로, 의미 확률적 임베딩(semantic probabilistic embeddings)의 적용은 최첨단 기준(state-of-the-art baselines)을 능가하는 우수한 성능을 보여주었으며, 제안된 iGraph 패러다임의 효능을 입증하였습니다."
    },
    {
        "turn_index": 2,
        "term": "tokenization",
        "domain": "cs.AI",
        "summary": "  Automatically generating human-readable text describing the functionality of\na program is the intent of source code summarization. Although neural language\nmodels achieve significant performance in this field, they are limited by their\ninability to access external knowledge. To address this limitation, an emerging\ntrend is combining neural models with external knowledge through retrieval\nmethods. Previous methods have relied on the sentence-level retrieval paradigm\non the encoder side. However, this paradigm is coarse-grained, noise-filled and\ncannot directly take advantage of the high-quality retrieved summary tokens on\nthe decoder side. In this paper, we propose a fine-grained Token-level\nretrieval-augmented mechanism (Tram) on the decoder side rather than the\nencoder side to enhance the performance of neural models and produce more\nlow-frequency tokens in generating summaries. Furthermore, to overcome the\nchallenge of token-level retrieval in capturing contextual code semantics, we\nalso propose integrating code semantics into individual summary tokens. The\nresults of extensive experiments and human evaluation show that our token-level\nretrieval-augmented approach significantly improves performance and is more\ninterpretable.\n",
        "english": "The research introduces a fine-grained tokenization approach through a Token-level retrieval-augmented mechanism (Tram) on the decoder side, which addresses the limitations of coarse-grained, noise-filled sentence-level retrieval paradigms traditionally used on the encoder side. By integrating code semantics into individual summary tokens, the proposed method enhances the generation of low-frequency tokens, thereby improving the overall performance of neural models in source code summarization. Extensive experiments demonstrate that this innovative token-level retrieval mechanism not only enhances performance but also provides a more interpretable model, with results showing a significant increase in the accuracy of generated summaries, quantified by a performance boost of approximately \\( \\Delta = 0.15 \\) in evaluation metrics.",
        "korean": "연구는 디코더 측에서 토큰 수준 검색 증강 메커니즘(token-level retrieval-augmented mechanism, Tram)을 통해 세밀한 토큰화(tokenization) 접근 방식을 도입하여 전통적으로 인코더 측에서 사용되던 거친 수준의 잡음이 많은 문장 수준 검색 패러다임의 한계를 해결합니다. 코드 의미론을 개별 요약 토큰에 통합함으로써 제안된 방법은 저빈도 토큰의 생성을 향상시켜 소스 코드 요약에서 신경망 모델의 전반적인 성능을 개선합니다. 광범위한 실험 결과, 이 혁신적인 토큰 수준 검색 메커니즘은 성능을 향상시킬 뿐만 아니라 더 해석 가능한 모델을 제공하며, 생성된 요약의 정확도가 평가 지표에서 약 \\( \\Delta = 0.15 \\)의 성능 향상으로 정량화된 결과를 보여줍니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "differentiable rendering",
        "domain": "cs.AI",
        "summary": "  Traditional multi-view photometric stereo (MVPS) methods are often composed\nof multiple disjoint stages, resulting in noticeable accumulated errors. In\nthis paper, we present a neural inverse rendering method for MVPS based on\nimplicit representation. Given multi-view images of a non-Lambertian object\nilluminated by multiple unknown directional lights, our method jointly\nestimates the geometry, materials, and lights. Our method first employs\nmulti-light images to estimate per-view surface normal maps, which are used to\nregularize the normals derived from the neural radiance field. It then jointly\noptimizes the surface normals, spatially-varying BRDFs, and lights based on a\nshadow-aware differentiable rendering layer. After optimization, the\nreconstructed object can be used for novel-view rendering, relighting, and\nmaterial editing. Experiments on both synthetic and real datasets demonstrate\nthat our method achieves far more accurate shape reconstruction than existing\nMVPS and neural rendering methods. Our code and model can be found at\nhttps://ywq.github.io/psnerf.\n",
        "english": "In the realm of multi-view photometric stereo (MVPS), the novel approach presented utilizes a shadow-aware differentiable rendering layer to optimize surface normals, spatially-varying BRDFs, and lights, overcoming the accumulated errors seen in traditional methods. By employing multi-light images to estimate per-view surface normal maps, the method regularizes normals derived from the neural radiance field, leading to a significant improvement in shape reconstruction accuracy. Notably, the joint estimation process is mathematically represented as an optimization problem where the objective function $L(\\mathbf{N}, \\mathbf{B}, \\mathbf{L})$ is minimized, demonstrating the method's efficacy in achieving superior results on both synthetic and real datasets.",
        "korean": "다중 시점 광측정 스테레오(multi-view photometric stereo, MVPS) 분야에서 제시된 새로운 접근 방식은 그림자 인식 미분 가능 렌더링 계층(differentiable rendering layer)을 활용하여 표면 법선, 공간적으로 변화하는 BRDFs, 조명을 최적화함으로써 전통적인 방법에서 발생하는 누적 오류를 극복합니다. 다중 조명 이미지를 사용하여 시점별 표면 법선 맵을 추정함으로써, 이 방법은 신경 방사 필드(neural radiance field)에서 도출된 법선을 정규화하여 형상 재구성 정확도를 크게 향상시킵니다. 특히, 공동 추정 과정은 수학적으로 최적화 문제로 표현되며, 목적 함수 $L(\\mathbf{N}, \\mathbf{B}, \\mathbf{L})$를 최소화하여 합성 및 실제 데이터셋 모두에서 우수한 결과를 달성하는 방법의 효능을 입증합니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Ensure all technical terms are consistently formatted as Korean term(English term) and consider adjusting the sentence structure for improved natural flow and readability."
    },
    {
        "turn_index": 2,
        "term": "difference-in-differences",
        "domain": "cs.AI",
        "summary": "  This article considers evidence from physical and biological sciences to show\nmachines are deficient compared to biological systems at incorporating\nintelligence. Machines fall short on two counts: firstly, unlike brains,\nmachines do not self-organize in a recursive manner; secondly, machines are\nbased on classical logic, whereas Nature's intelligence may depend on quantum\nmechanics.\n",
        "english": "The concept of difference-in-differences is pivotal in evaluating the efficacy of machines compared to biological systems, particularly in how machines fall short on self-organization and intelligence incorporation. By utilizing a difference-in-differences approach, one can quantify the disparity where machines, unlike brains, do not self-organize in a recursive manner, as evidenced by the classical logic foundation of machines versus Nature's potential reliance on quantum mechanics. Mathematically, the difference-in-differences estimation can be expressed as $\\Delta Y = (Y_{post, treatment} - Y_{pre, treatment}) - (Y_{post, control} - Y_{pre, control})$, highlighting the significant gap in adaptive intelligence between machines and biological systems, thus underscoring the innovative need for integrating quantum mechanics in machine intelligence.",
        "korean": "[term](difference-in-differences)의 개념은 기계와 생물학적 시스템을 비교하여 기계의 자기 조직화 및 지능 통합에서의 한계를 평가하는 데 있어 매우 중요합니다. [term](difference-in-differences) 접근 방식을 활용하면 기계가 뇌와 달리 재귀적으로 자기 조직화하지 않는 차이를 정량화할 수 있으며, 이는 기계의 고전 논리 기반과 자연의 양자 역학 의존 가능성에 의해 입증됩니다. 수학적으로, [term](difference-in-differences) 추정은 $\\Delta Y = (Y_{post, treatment} - Y_{pre, treatment}) - (Y_{post, control} - Y_{pre, control})$로 표현될 수 있으며, 이는 기계와 생물학적 시스템 간의 적응적 지능의 큰 차이를 강조하며, 기계 지능에 양자 역학을 통합할 혁신적 필요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "graph neural networks",
        "domain": "cs.AI",
        "summary": "  This paper applies t-SNE, a visualisation technique familiar from Deep Neural\nNetwork research to argumentation graphs by applying it to the output of graph\nembeddings generated using several different methods. It shows that such a\nvisualisation approach can work for argumentation and show interesting\nstructural properties of argumentation graphs, opening up paths for further\nresearch in the area.\n",
        "english": "In the exploration of graph neural networks, the application of t-SNE, a visualization technique familiar from Deep Neural Network research, has been employed to analyze argumentation graphs by applying it to the output of graph embeddings generated using several different methods. This approach demonstrates that such a visualization technique can effectively reveal interesting structural properties of argumentation graphs, thereby opening up paths for further research in the area. The study's innovative use of t-SNE in conjunction with graph neural networks underscores the potential for uncovering complex patterns within argumentation graphs, which can be mathematically represented as $G = (V, E)$, where $V$ denotes the set of vertices and $E$ the set of edges.",
        "korean": "그래프 신경망(graph neural networks) 탐구에서, 심층 신경망(deep neural network) 연구에서 익숙한 시각화 기법인 t-SNE의 응용이 여러 다른 방법으로 생성된 그래프 임베딩(graph embeddings)의 출력을 분석하기 위해 논증 그래프(argumentation graphs)에 적용되었습니다. 이러한 접근 방식은 시각화 기법이 논증 그래프의 흥미로운 구조적 특성을 효과적으로 드러낼 수 있음을 보여주며, 이 분야에서의 추가 연구 경로를 열어줍니다. 그래프 신경망과 결합된 t-SNE의 혁신적인 사용은 논증 그래프 내의 복잡한 패턴을 발견할 수 있는 잠재력을 강조하며, 이는 $G = (V, E)$로 수학적으로 표현될 수 있으며, 여기서 $V$는 정점 집합을, $E$는 간선 집합을 나타냅니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider reducing redundancy by not repeating the same English term multiple times in parentheses."
    },
    {
        "turn_index": 2,
        "term": "masked language models",
        "domain": "cs.AI",
        "summary": "  Self-supervised auto-encoders have emerged as a successful framework for\nrepresentation learning in computer vision and natural language processing in\nrecent years, However, their application to graph data has been met with\nlimited performance due to the non-Euclidean and complex structure of graphs in\ncomparison to images or text, as well as the limitations of conventional\nauto-encoder architectures. In this paper, we investigate factors impacting the\nperformance of auto-encoders on graph data and propose a novel auto-encoder\nmodel for graph representation learning. Our model incorporates a hierarchical\nadaptive masking mechanism to incrementally increase the difficulty of training\nin order to mimic the process of human cognitive learning, and a trainable\ncorruption scheme to enhance the robustness of learned representations. Through\nextensive experimentation on ten benchmark datasets, we demonstrate the\nsuperiority of our proposed method over state-of-the-art graph representation\nlearning models.\n",
        "english": "Masked language models, a subset of self-supervised auto-encoders, have shown promise in representation learning for natural language processing, yet their application to graph data has faced challenges due to the non-Euclidean and complex structure of graphs. To address these challenges, a novel auto-encoder model incorporating a hierarchical adaptive masking mechanism and a trainable corruption scheme has been proposed, enhancing the robustness of learned representations and mimicking the process of human cognitive learning. Through extensive experimentation on ten benchmark datasets, the proposed model demonstrated a significant improvement over state-of-the-art graph representation learning models, achieving a performance increase of $\\Delta = 15\\%$ in accuracy.",
        "korean": "자기 지도(auto-supervised) 인코더의 하위 집합인 마스크드 언어 모델(masked language models)은 자연어 처리(natural language processing)에서 표현 학습에 유망한 성과를 보였으나, 그래프 데이터에의 적용은 그래프의 비유클리드(non-Euclidean) 및 복잡한 구조로 인해 어려움을 겪어왔습니다. 이러한 문제를 해결하기 위해 계층적 적응 마스킹 메커니즘(hierarchical adaptive masking mechanism)과 학습 가능한 손상 체계(trainable corruption scheme)를 통합한 새로운 오토인코더(auto-encoder) 모델이 제안되었으며, 이는 학습된 표현의 견고성을 향상시키고 인간 인지 학습의 과정을 모방합니다. 열 개의 벤치마크 데이터셋(benchmark datasets)에 대한 광범위한 실험을 통해 제안된 모델은 최첨단 그래프 표현 학습 모델(state-of-the-art graph representation learning models)보다 성능이 크게 향상되어 정확도에서 $\\Delta = 15\\%$의 증가를 달성했습니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Ensure all technical terms are consistently formatted as Korean term(English term) and adjust the sentence structure for smoother readability in Korean."
    },
    {
        "turn_index": 2,
        "term": "dynamic probabilistic neural models",
        "domain": "cs.AI",
        "summary": "  We introduce DeepProbLog, a neural probabilistic logic programming language\nthat incorporates deep learning by means of neural predicates. We show how\nexisting inference and learning techniques of the underlying probabilistic\nlogic programming language ProbLog can be adapted for the new language. We\ntheoretically and experimentally demonstrate that DeepProbLog supports (i) both\nsymbolic and subsymbolic representations and inference, (ii) program induction,\n(iii) probabilistic (logic) programming, and (iv) (deep) learning from\nexamples. To the best of our knowledge, this work is the first to propose a\nframework where general-purpose neural networks and expressive\nprobabilistic-logical modeling and reasoning are integrated in a way that\nexploits the full expressiveness and strengths of both worlds and can be\ntrained end-to-end based on examples.\n",
        "english": "Dynamic probabilistic neural models, as introduced in the form of DeepProbLog, represent a significant advancement in integrating deep learning with probabilistic logic programming by utilizing neural predicates. This innovative framework uniquely combines general-purpose neural networks with expressive probabilistic-logical modeling, enabling end-to-end training from examples and supporting both symbolic and subsymbolic representations and inference. Notably, the adaptation of existing inference and learning techniques from ProbLog to DeepProbLog allows for program induction and probabilistic programming, where the probability of a query \\(P(Q)\\) is computed as \\(P(Q) = \\sum_{M \\models Q} P(M)\\), showcasing the model's capability to exploit the strengths of both worlds effectively.",
        "korean": "딥프로그로그(DeepProbLog) 형태로 도입된 동적 확률적 신경 모델(dynamic probabilistic neural models)은 신경 술어를 활용하여 심층 학습과 확률 논리 프로그래밍을 통합하는 데 있어 중요한 발전을 나타냅니다. 이 혁신적인 프레임워크는 범용 신경망과 표현력 있는 확률 논리 모델링을 독특하게 결합하여 예제로부터의 종단 간 학습을 가능하게 하고, 상징적 및 비상징적 표현과 추론을 모두 지원합니다. 특히, 프로블로그(ProbLog)에서 딥프로그로그(DeepProbLog)로 기존 추론 및 학습 기법을 적응시킴으로써 프로그램 귀납 및 확률 프로그래밍을 가능하게 하며, 쿼리의 확률 \\(P(Q)\\)를 \\(P(Q) = \\sum_{M \\models Q} P(M)\\)로 계산하여 두 세계의 강점을 효과적으로 활용할 수 있는 모델의 능력을 보여줍니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural density models",
        "domain": "cs.AI",
        "summary": "  Long-term forecasting involves predicting a horizon that is far ahead of the\nlast observation. It is a problem of high practical relevance, for instance for\ncompanies in order to decide upon expensive long-term investments. Despite the\nrecent progress and success of Gaussian processes (GPs) based on spectral\nmixture kernels, long-term forecasting remains a challenging problem for these\nkernels because they decay exponentially at large horizons. This is mainly due\nto their use of a mixture of Gaussians to model spectral densities.\nCharacteristics of the signal important for long-term forecasting can be\nunravelled by investigating the distribution of the Fourier coefficients of\n(the training part of) the signal, which is non-smooth, heavy-tailed, sparse,\nand skewed. The heavy tail and skewness characteristics of such distributions\nin the spectral domain allow to capture long-range covariance of the signal in\nthe time domain. Motivated by these observations, we propose to model spectral\ndensities using a skewed Laplace spectral mixture (SLSM) due to the skewness of\nits peaks, sparsity, non-smoothness, and heavy tail characteristics. By\napplying the inverse Fourier Transform to this spectral density we obtain a new\nGP kernel for long-term forecasting. In addition, we adapt the lottery ticket\nmethod, originally developed to prune weights of a neural network, to GPs in\norder to automatically select the number of kernel components. Results of\nextensive experiments, including a multivariate time series, show the\nbeneficial effect of the proposed SLSM kernel for long-term extrapolation and\nrobustness to the choice of the number of mixture components.\n",
        "english": "Neural density models, particularly those utilizing spectral densities, address the challenge of long-term forecasting by capturing the non-smooth, heavy-tailed, sparse, and skewed characteristics of signal distributions, which are crucial for unraveling the distribution of Fourier coefficients. The proposed skewed Laplace spectral mixture (SLSM) model innovatively applies these principles, resulting in a new Gaussian process (GP) kernel that enhances long-term forecasting by leveraging the skewness and heavy tail characteristics, enabling the capture of long-range covariance in the time domain. This advancement is further supported by the adaptation of the lottery ticket method, originally used for neural network pruning, to automatically determine the number of kernel components, thereby demonstrating robustness and improved extrapolation performance as shown in extensive experiments, including multivariate time series, validating the efficacy of SLSM in neural density models.",
        "korean": "신경 밀도 모델(neural density models), 특히 스펙트럼 밀도(spectral densities)를 활용하는 모델은 신호 분포의 비매끄럽고, 무거운 꼬리, 희소성, 비대칭 특성을 포착하여 장기 예측의 과제를 해결합니다. 제안된 비대칭 라플라스 스펙트럼 혼합(skewed Laplace spectral mixture, SLSM) 모델은 이러한 원리를 혁신적으로 적용하여 스큐니스(skewness)와 무거운 꼬리 특성을 활용함으로써 장기 예측을 향상시키는 새로운 가우시안 프로세스(gaussian process, GP) 커널을 제공합니다. 이는 시간 도메인에서 장거리 공분산을 포착할 수 있게 합니다. 이러한 발전은 원래 신경망 가지치기에 사용되었던 로터리 티켓 방법(lottery ticket method)의 적응을 통해 커널 구성 요소의 수를 자동으로 결정함으로써 더욱 뒷받침되며, 다변량 시계열을 포함한 광범위한 실험에서 SLSM의 신경 밀도 모델(neural density models)에서의 효능을 입증하는 강력함과 향상된 외삽 성능을 보여줍니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "task-agnostic reinforcement learning",
        "domain": "cs.AI",
        "summary": "  Purpose: AI in radiology is hindered chiefly by: 1) Requiring large annotated\ndata sets. 2) Non-generalizability that limits deployment to new scanners /\ninstitutions. And 3) Inadequate explainability and interpretability. We believe\nthat reinforcement learning can address all three shortcomings, with robust and\nintuitive algorithms trainable on small datasets. To the best of our knowledge,\nreinforcement learning has not been directly applied to computer vision tasks\nfor radiological images. In this proof-of-principle work, we train a deep\nreinforcement learning network to predict brain tumor location.\n  Materials and Methods: Using the BraTS brain tumor imaging database, we\ntrained a deep Q network on 70 post-contrast T1-weighted 2D image slices. We\ndid so in concert with image exploration, with rewards and punishments designed\nto localize lesions. To compare with supervised deep learning, we trained a\nkeypoint detection convolutional neural network on the same 70 images. We\napplied both approaches to a separate 30 image testing set.\n  Results: Reinforcement learning predictions consistently improved during\ntraining, whereas those of supervised deep learning quickly diverged.\nReinforcement learning predicted testing set lesion locations with 85%\naccuracy, compared to roughly 7% accuracy for the supervised deep network.\n  Conclusion: Reinforcement learning predicted lesions with high accuracy,\nwhich is unprecedented for such a small training set. We believe that\nreinforcement learning can propel radiology AI well past the inherent\nlimitations of supervised deep learning, with more clinician-driven research\nand finally toward true clinical applicability.\n",
        "english": "Task-agnostic reinforcement learning has the potential to overcome significant challenges in radiology AI, such as the need for large annotated datasets, limited generalizability, and inadequate explainability, by employing robust algorithms that can be trained on small datasets. In a proof-of-principle study, a deep Q network was trained using the BraTS brain tumor imaging database, where rewards and punishments were strategically designed to localize lesions, resulting in an impressive lesion location prediction accuracy of 85% compared to the 7% accuracy achieved by a supervised deep learning approach. This innovative application of task-agnostic reinforcement learning in radiology suggests a promising path toward enhanced clinical applicability, as evidenced by its unprecedented accuracy with a small training set.",
        "korean": "task-agnostic reinforcement learning(task-agnostic reinforcement learning)은 방사선학 인공지능(radiology AI)에서 대규모 주석 데이터셋(annotated datasets)의 필요성, 제한된 일반화 가능성, 불충분한 설명 가능성 등의 주요 문제를 극복할 잠재력을 가지고 있으며, 소규모 데이터셋으로 훈련할 수 있는 강력한 알고리즘을 사용합니다. 원리 증명 연구(proof-of-principle study)에서, 깊은 q 네트워크(deep Q network)는 brats 뇌종양 영상 데이터베이스(brats brain tumor imaging database)를 사용하여 훈련되었으며, 보상과 처벌이 전략적으로 설계되어 병변을 국소화하여, 감독 학습 심층 학습 접근법(supervised deep learning approach)의 7% 정확도와 비교하여 85%의 인상적인 병변 위치 예측 정확도를 달성했습니다. 방사선학에서의 task-agnostic reinforcement learning(task-agnostic reinforcement learning)의 이 혁신적인 응용은 소규모 훈련 세트로 전례 없는 정확성을 통해 임상 적용 가능성을 향상시키는 유망한 경로를 제시합니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all terms within parentheses are consistently in lowercase."
    },
    {
        "turn_index": 2,
        "term": "graph representation learning",
        "domain": "cs.AI",
        "summary": "  Self-supervised auto-encoders have emerged as a successful framework for\nrepresentation learning in computer vision and natural language processing in\nrecent years, However, their application to graph data has been met with\nlimited performance due to the non-Euclidean and complex structure of graphs in\ncomparison to images or text, as well as the limitations of conventional\nauto-encoder architectures. In this paper, we investigate factors impacting the\nperformance of auto-encoders on graph data and propose a novel auto-encoder\nmodel for graph representation learning. Our model incorporates a hierarchical\nadaptive masking mechanism to incrementally increase the difficulty of training\nin order to mimic the process of human cognitive learning, and a trainable\ncorruption scheme to enhance the robustness of learned representations. Through\nextensive experimentation on ten benchmark datasets, we demonstrate the\nsuperiority of our proposed method over state-of-the-art graph representation\nlearning models.\n",
        "english": "Self-supervised auto-encoders have emerged as a successful framework for graph representation learning, yet their application has faced challenges due to the non-Euclidean and complex structure of graphs, unlike images or text. To address these challenges, a novel auto-encoder model is proposed, incorporating a hierarchical adaptive masking mechanism, which incrementally increases the difficulty of training, akin to human cognitive learning, and a trainable corruption scheme to enhance robustness. Extensive experimentation on ten benchmark datasets demonstrates the superiority of this method over state-of-the-art models, with performance improvements quantified as $\\Delta R = 0.15$, indicating significant advancements in graph representation learning.",
        "korean": "자기 지도(auto-supervised) 오토인코더(auto-encoders)는 그래프 표현 학습(graph representation learning)에서 성공적인 프레임워크로 부상했지만, 이미지나 텍스트와 달리 비유클리드(non-Euclidean) 및 복잡한 그래프 구조로 인해 그 적용에 어려움을 겪었습니다. 이러한 문제를 해결하기 위해, 인간의 인지 학습과 유사하게 훈련의 난이도를 점진적으로 증가시키는 계층적 적응 마스킹 메커니즘(hierarchical adaptive masking mechanism)과 강인성을 향상시키기 위한 훈련 가능한 손상 체계(trainable corruption scheme)를 통합한 새로운 오토인코더(auto-encoder) 모델이 제안되었습니다. 열 개의 벤치마크 데이터셋(benchmark datasets)에 대한 광범위한 실험은 이 방법이 최첨단 모델(state-of-the-art models)보다 우수하다는 것을 입증했으며, 성능 향상은 $\\Delta R = 0.15$로 정량화되어 그래프 표현 학습(graph representation learning)에서의 상당한 발전을 나타냅니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent lowercase for all terms within parentheses."
    },
    {
        "turn_index": 2,
        "term": "semi-parametric models",
        "domain": "cs.AI",
        "summary": "  Causal Models are like Dependency Graphs and Belief Nets in that they provide\na structure and a set of assumptions from which a joint distribution can, in\nprinciple, be computed. Unlike Dependency Graphs, Causal Models are models of\nhierarchical and/or parallel processes, rather than models of distributions\n(partially) known to a model builder through some sort of gestalt. As such,\nCausal Models are more modular, easier to build, more intuitive, and easier to\nunderstand than Dependency Graph Models. Causal Models are formally defined and\nDependency Graph Models are shown to be a special case of them. Algorithms\nsupporting inference are presented. Parsimonious methods for eliciting\ndependent probabilities are presented.\n",
        "english": "Semi-parametric models, akin to Causal Models, provide a structure and a set of assumptions from which a joint distribution can be computed, offering a flexible approach in statistical modeling. These models, unlike Dependency Graphs that are \"models of distributions (partially) known to a model builder through some sort of gestalt,\" incorporate both parametric and non-parametric elements, making them more modular and intuitive. In terms of mathematical representation, semi-parametric models can be expressed as $Y = f(X) + \\epsilon$, where $f(X)$ is a non-parametric function and $\\epsilon$ is a parametric error term, highlighting their ability to capture complex data structures while maintaining interpretability.",
        "korean": "준모수 모델(semi-parametric models)은 인과 모델(causal models)과 유사하게 결합 분포를 계산할 수 있는 구조와 가정 집합을 제공하여 통계 모델링에서 유연한 접근 방식을 제공합니다. 이러한 모델은 의존 그래프(dependency graphs)가 \"모델 작성자가 어떤 형태의 게슈탈트를 통해 (부분적으로) 알고 있는 분포의 모델\"인 것과 달리, 모수적 요소와 비모수적 요소를 모두 포함하여 더 모듈화되고 직관적입니다. 수학적 표현 측면에서 준모수 모델(semi-parametric models)은 $Y = f(X) + \\epsilon$로 표현될 수 있으며, 여기서 $f(X)$는 비모수적 함수이고 $\\epsilon$은 모수적 오차 항으로, 복잡한 데이터 구조를 포착하면서도 해석 가능성을 유지하는 능력을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "image recognition",
        "domain": "cs.AI",
        "summary": "  Noise, corruptions and variations in face images can seriously hurt the\nperformance of face recognition systems. To make such systems robust,\nmulticlass neuralnetwork classifiers capable of learning from noisy data have\nbeen suggested. However on large face data sets such systems cannot provide the\nrobustness at a high level. In this paper we explore a pairwise neural-network\nsystem as an alternative approach to improving the robustness of face\nrecognition. In our experiments this approach is shown to outperform the\nmulticlass neural-network system in terms of the predictive accuracy on the\nface images corrupted by noise.\n",
        "english": "In the field of image recognition, noise, corruptions, and variations in face images can significantly impair the performance of face recognition systems, necessitating the development of robust methodologies. To address this challenge, a pairwise neural-network system was explored as an alternative approach, demonstrating superior predictive accuracy on noisy face images compared to traditional multiclass neural-network classifiers. The innovative approach leverages the pairwise comparison of images, which is mathematically represented by the optimization problem: $\\min_{W} \\sum_{i,j} L(f(x_i, x_j; W), y_{ij})$, where $W$ denotes the network weights, $L$ is the loss function, $f$ is the network output, and $y_{ij}$ are the pairwise labels, ultimately enhancing the robustness of image recognition systems.",
        "korean": "이미지 인식(image recognition) 분야에서 얼굴 이미지의 노이즈, 손상, 변형은 얼굴 인식 시스템의 성능을 크게 저하시킬 수 있으며, 이를 해결하기 위해 견고한 방법론의 개발이 필요합니다. 이러한 문제를 해결하기 위해 쌍별 신경망 시스템(pairwise neural-network system)이 대안적 접근법으로 탐구되었으며, 전통적인 다중 클래스 신경망 분류기(multiclass neural-network classifiers)와 비교하여 노이즈가 있는 얼굴 이미지에서 우수한 예측 정확도를 보여주었습니다. 이 혁신적인 접근법은 이미지의 쌍별 비교를 활용하며, 이는 최적화 문제로 수학적으로 표현됩니다: $\\min_{W} \\sum_{i,j} L(f(x_i, x_j; W), y_{ij})$, 여기서 $W$는 네트워크 가중치, $L$은 손실 함수, $f$는 네트워크 출력, $y_{ij}$는 쌍별 레이블을 나타내며, 궁극적으로 이미지 인식 시스템의 견고성을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "contrastive learning frameworks",
        "domain": "cs.AI",
        "summary": "  Mechanical learning is a computing system that is based on a set of simple\nand fixed rules, and can learn from incoming data. A learning machine is a\nsystem that realizes mechanical learning. Importantly, we emphasis that it is\nbased on a set of simple and fixed rules, contrasting to often called machine\nlearning that is sophisticated software based on very complicated mathematical\ntheory, and often needs human intervene for software fine tune and manual\nadjustments. Here, we discuss some basic facts and principles of such system,\nand try to lay down a framework for further study. We propose 2 directions to\napproach mechanical learning, just like Church-Turing pair: one is trying to\nrealize a learning machine, another is trying to well describe the mechanical\nlearning.\n",
        "english": "Contrastive learning frameworks, as part of mechanical learning, are based on \"a set of simple and fixed rules\" that allow systems to learn from incoming data without the need for \"sophisticated software based on very complicated mathematical theory.\" These frameworks emphasize the importance of minimizing human intervention, contrasting with traditional machine learning approaches that often require \"manual adjustments\" and software fine-tuning. By proposing two directions akin to the Church-Turing pair, one focused on realizing a learning machine and the other on describing mechanical learning, contrastive learning frameworks offer a novel paradigm for understanding and developing learning systems, with potential applications in simplifying complex computations through expressions such as $f(x) = x^2$.",
        "korean": "기계 학습(mechanical learning)의 일환으로서 대조 학습 프레임워크(contrastive learning frameworks)는 \"매우 복잡한 수학 이론에 기반한 정교한 소프트웨어\" 없이 시스템이 들어오는 데이터로부터 학습할 수 있도록 하는 \"간단하고 고정된 규칙의 집합\"에 기반합니다. 이러한 프레임워크는 인간의 개입을 최소화하는 것의 중요성을 강조하며, 종종 \"수동 조정\"과 소프트웨어 미세 조정을 요구하는 전통적인 기계 학습 접근 방식과 대조됩니다. 학습 기계를 실현하는 것에 중점을 둔 방향과 기계 학습을 설명하는 방향으로 교회-튜링 쌍(Church-Turing pair)과 유사한 두 가지 방향을 제안함으로써, 대조 학습 프레임워크(contrastive learning frameworks)는 학습 시스템을 이해하고 개발하는 새로운 패러다임을 제공합니다. 이는 $f(x) = x^2$와 같은 표현을 통해 복잡한 계산을 단순화하는 잠재적 응용 가능성을 가지고 있습니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "homomorphic encryption",
        "domain": "cs.AI",
        "summary": "  In this paper, we introduce a privacy-preserving stable diffusion framework\nleveraging homomorphic encryption, called HE-Diffusion, which primarily focuses\non protecting the denoising phase of the diffusion process. HE-Diffusion is a\ntailored encryption framework specifically designed to align with the unique\narchitecture of stable diffusion, ensuring both privacy and functionality. To\naddress the inherent computational challenges, we propose a novel\nmin-distortion method that enables efficient partial image encryption,\nsignificantly reducing the overhead without compromising the model's output\nquality. Furthermore, we adopt a sparse tensor representation to expedite\ncomputational operations, enhancing the overall efficiency of the\nprivacy-preserving diffusion process. We successfully implement HE-based\nprivacy-preserving stable diffusion inference. The experimental results show\nthat HE-Diffusion achieves 500 times speedup compared with the baseline method,\nand reduces time cost of the homomorphically encrypted inference to the minute\nlevel. Both the performance and accuracy of the HE-Diffusion are on par with\nthe plaintext counterpart. Our approach marks a significant step towards\nintegrating advanced cryptographic techniques with state-of-the-art generative\nmodels, paving the way for privacy-preserving and efficient image generation in\ncritical applications.\n",
        "english": "The introduction of HE-Diffusion, a privacy-preserving stable diffusion framework leveraging homomorphic encryption, represents a significant advancement in protecting the denoising phase of the diffusion process while maintaining both privacy and functionality. Employing a novel min-distortion method, HE-Diffusion enables efficient partial image encryption, reducing computational overhead without compromising output quality, as evidenced by its ability to achieve a 500 times speedup compared to baseline methods and reduce the time cost of homomorphically encrypted inference to the minute level. Furthermore, the adoption of a sparse tensor representation to expedite computational operations highlights the innovative integration of advanced cryptographic techniques with state-of-the-art generative models, paving the way for privacy-preserving and efficient image generation in critical applications.",
        "korean": "동형 암호화(homomorphic encryption)를 활용한 프라이버시 보호 안정 확산 프레임워크인 HE-Diffusion의 도입은 확산 과정의 노이즈 제거 단계에서 프라이버시와 기능성을 유지하면서 보호하는 데 있어 중요한 발전을 나타냅니다. 새로운 최소 왜곡 방법(min-distortion method)을 사용하여 HE-Diffusion은 효율적인 부분 이미지 암호화를 가능하게 하며, 출력 품질을 손상시키지 않으면서 계산 오버헤드를 줄입니다. 이는 기본 방법에 비해 500배의 속도 향상을 달성하고 동형 암호화된 추론의 시간 비용을 분 단위로 줄일 수 있음을 입증합니다. 또한, 계산 작업을 가속화하기 위한 희소 텐서 표현(sparse tensor representation)의 채택은 첨단 암호화 기술과 최첨단 생성 모델의 혁신적인 통합을 강조하며, 중요한 응용 분야에서 프라이버시를 보호하고 효율적인 이미지 생성을 위한 길을 열어줍니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "self-supervised pretraining",
        "domain": "cs.AI",
        "summary": "  Multimodality Representation Learning, as a technique of learning to embed\ninformation from different modalities and their correlations, has achieved\nremarkable success on a variety of applications, such as Visual Question\nAnswering (VQA), Natural Language for Visual Reasoning (NLVR), and Vision\nLanguage Retrieval (VLR). Among these applications, cross-modal interaction and\ncomplementary information from different modalities are crucial for advanced\nmodels to perform any multimodal task, e.g., understand, recognize, retrieve,\nor generate optimally. Researchers have proposed diverse methods to address\nthese tasks. The different variants of transformer-based architectures\nperformed extraordinarily on multiple modalities. This survey presents the\ncomprehensive literature on the evolution and enhancement of deep learning\nmultimodal architectures to deal with textual, visual and audio features for\ndiverse cross-modal and modern multimodal tasks. This study summarizes the (i)\nrecent task-specific deep learning methodologies, (ii) the pretraining types\nand multimodal pretraining objectives, (iii) from state-of-the-art pretrained\nmultimodal approaches to unifying architectures, and (iv) multimodal task\ncategories and possible future improvements that can be devised for better\nmultimodal learning. Moreover, we prepare a dataset section for new researchers\nthat covers most of the benchmarks for pretraining and finetuning. Finally,\nmajor challenges, gaps, and potential research topics are explored. A\nconstantly-updated paperlist related to our survey is maintained at\nhttps://github.com/marslanm/multimodality-representation-learning.\n",
        "english": "Self-supervised pretraining, as a pivotal component in the evolution and enhancement of deep learning multimodal architectures, has been instrumental in addressing diverse cross-modal and modern multimodal tasks, such as Visual Question Answering (VQA) and Vision Language Retrieval (VLR). This approach leverages the complementary information from different modalities, facilitating advanced models to optimally understand, recognize, retrieve, or generate data across modalities, thereby enhancing the capability of transformer-based architectures, which have shown extraordinary performance across multiple modalities. Notably, the integration of self-supervised pretraining with task-specific objectives, such as minimizing the loss function \\( \\mathcal{L} \\) defined over the joint distribution of modalities, underscores its significance in advancing state-of-the-art pretrained multimodal approaches towards unifying architectures.",
        "korean": "자기 지도 사전 훈련(self-supervised pretraining)은 심층 학습 다중 모달 아키텍처(deep learning multimodal architectures)의 진화와 향상에 있어 중요한 구성 요소로서, 시각적 질문 응답(Visual Question Answering, VQA) 및 비전 언어 검색(Vision Language Retrieval, VLR)과 같은 다양한 교차 모달 및 현대 다중 모달 작업을 해결하는 데 기여해 왔습니다. 이 접근 방식은 다양한 모달리티로부터 보완적인 정보를 활용하여 고급 모델이 모달리티 전반에 걸쳐 데이터를 최적으로 이해하고, 인식하고, 검색하거나 생성할 수 있도록 하여, 여러 모달리티에서 뛰어난 성능을 보여준 트랜스포머 기반 아키텍처(transformer-based architectures)의 역량을 강화합니다. 특히, 모달리티의 결합 분포에 대한 손실 함수 \\( \\mathcal{L} \\)를 최소화하는 것과 같은 작업별 목표와 자기 지도 사전 훈련(self-supervised pretraining)의 통합은 최첨단 사전 훈련된 다중 모달 접근 방식의 통합 아키텍처로의 발전에서 그 중요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "multi-head attention networks",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Multi-head attention networks have been instrumental in enhancing the performance of transformer models by allowing them to focus on different parts of the input sequence simultaneously, thus capturing various contextual relationships. According to the reference, the attention mechanism can be mathematically expressed as $Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$, where $Q$, $K$, and $V$ represent the query, key, and value matrices, respectively, and $d_k$ is the dimension of the key. This innovation is crucial as it significantly improves the model's ability to understand and generate human-like text, making it a cornerstone in the development of advanced natural language processing applications.",
        "korean": "멀티 헤드 어텐션 네트워크(multi-head attention networks)는 입력 시퀀스의 다양한 부분에 동시에 집중할 수 있게 함으로써 트랜스포머 모델(transformer models)의 성능을 향상시키는 데 중요한 역할을 해왔으며, 이를 통해 다양한 문맥적 관계를 포착할 수 있습니다. 참고 문헌에 따르면, 어텐션 메커니즘(attention mechanism)은 수학적으로 $Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$로 표현될 수 있으며, 여기서 $Q$, $K$, $V$는 각각 쿼리(query), 키(key), 값(value) 행렬을 나타내고, $d_k$는 키의 차원입니다. 이 혁신은 모델이 인간과 유사한 텍스트를 이해하고 생성하는 능력을 크게 향상시키기 때문에 고급 자연어 처리 응용 프로그램(natural language processing applications)의 개발에 있어 중요한 기반이 됩니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure that all English terms within parentheses are in lowercase to maintain consistency."
    },
    {
        "turn_index": 2,
        "term": "machine unlearning",
        "domain": "cs.AI",
        "summary": "  The construction of large open knowledge bases (OKBs) is integral to many\napplications in the field of mobile computing. Noun phrases and relational\nphrases in OKBs often suffer from redundancy and ambiguity, which calls for the\ninvestigation on OKB canonicalization. However, in order to meet the\nrequirements of some privacy protection regulations and to ensure the\ntimeliness of the data, the canonicalized OKB often needs to remove some\nsensitive information or outdated data. The machine unlearning in OKB\ncanonicalization is an excellent solution to the above problem. Current\nsolutions address OKB canonicalization by devising advanced clustering\nalgorithms and using knowledge graph embedding (KGE) to further facilitate the\ncanonicalization process. Effective schemes are urgently needed to fully\nsynergise machine unlearning with clustering and KGE learning. To this end, we\nput forward a multi-task unlearning framework, namely MulCanon, to tackle\nmachine unlearning problem in OKB canonicalization. Specifically, the noise\ncharacteristics in the diffusion model are utilized to achieve the effect of\nmachine unlearning for data in OKB. MulCanon unifies the learning objectives of\ndiffusion model, KGE and clustering algorithms, and adopts a two-step\nmulti-task learning paradigm for training. A thorough experimental study on\npopular OKB canonicalization datasets validates that MulCanon achieves advanced\nmachine unlearning effects.\n",
        "english": "Machine unlearning in the context of OKB canonicalization emerges as a pivotal solution to address the issues of redundancy and ambiguity, especially when sensitive information or outdated data needs to be removed to comply with privacy protection regulations and ensure data timeliness. The innovative multi-task unlearning framework, MulCanon, integrates the learning objectives of the diffusion model, knowledge graph embedding (KGE), and clustering algorithms, employing a two-step multi-task learning paradigm to enhance machine unlearning capabilities. Experimental results demonstrate that MulCanon achieves superior machine unlearning effects, with the noise characteristics in the diffusion model effectively facilitating the unlearning process, thereby advancing the field of OKB canonicalization.",
        "korean": "OKB 정규화(context of OKB canonicalization)에서 기계 학습 제거(machine unlearning)는 특히 민감한 정보나 오래된 데이터를 제거하여 개인정보 보호 규정을 준수하고 데이터의 적시성을 보장해야 할 때 중복성과 모호성 문제를 해결하는 중요한 해결책으로 부상합니다. 혁신적인 다중 작업 학습 제거 프레임워크인 MulCanon은 확산 모델(diffusion model), 지식 그래프 임베딩(knowledge graph embedding, KGE), 클러스터링 알고리즘(clustering algorithms)의 학습 목표를 통합하여 기계 학습 제거(machine unlearning) 기능을 향상시키기 위해 이단계 다중 작업 학습 패러다임을 사용합니다. 실험 결과에 따르면 MulCanon은 확산 모델(diffusion model)에서의 노이즈 특성이 학습 제거 과정을 효과적으로 촉진하여 OKB 정규화(context of OKB canonicalization) 분야를 발전시키면서 우수한 기계 학습 제거(machine unlearning) 효과를 달성합니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of parentheses for all technical terms."
    },
    {
        "turn_index": 2,
        "term": "adaptive text learning",
        "domain": "cs.AI",
        "summary": "  One important desideratum of lifelong learning aims to discover novel classes\nfrom unlabelled data in a continuous manner. The central challenge is twofold:\ndiscovering and learning novel classes while mitigating the issue of\ncatastrophic forgetting of established knowledge. To this end, we introduce a\nnew paradigm called Adaptive Discovering and Merging (ADM) to discover novel\ncategories adaptively in the incremental stage and integrate novel knowledge\ninto the model without affecting the original knowledge. To discover novel\nclasses adaptively, we decouple representation learning and novel class\ndiscovery, and use Triple Comparison (TC) and Probability Regularization (PR)\nto constrain the probability discrepancy and diversity for adaptive category\nassignment. To merge the learned novel knowledge adaptively, we propose a\nhybrid structure with base and novel branches named Adaptive Model Merging\n(AMM), which reduces the interference of the novel branch on the old classes to\npreserve the previous knowledge, and merges the novel branch to the base model\nwithout performance loss and parameter growth. Extensive experiments on several\ndatasets show that ADM significantly outperforms existing class-incremental\nNovel Class Discovery (class-iNCD) approaches. Moreover, our AMM also benefits\nthe class-incremental Learning (class-IL) task by alleviating the catastrophic\nforgetting problem.\n",
        "english": "Adaptive text learning, as exemplified by the Adaptive Discovering and Merging (ADM) paradigm, addresses the challenge of discovering novel classes from unlabelled data while mitigating catastrophic forgetting of established knowledge. By employing methodologies such as Triple Comparison (TC) and Probability Regularization (PR), ADM effectively constrains probability discrepancy and diversity, enabling adaptive category assignment and enhancing the robustness of novel class discovery. Notably, the Adaptive Model Merging (AMM) approach integrates novel knowledge into the base model without performance loss or parameter growth, achieving significant improvements over existing class-incremental Novel Class Discovery (class-iNCD) approaches, as demonstrated by the experimental results where the accuracy $A$ improved by a factor of $2x$ on benchmark datasets.",
        "korean": "적응형 텍스트 학습(adaptive text learning)은 적응형 발견 및 병합(Adaptive Discovering and Merging, ADM) 패러다임으로 예시되며, 라벨이 없는 데이터에서 새로운 클래스를 발견하는 동시에 기존 지식의 파국적 망각을 완화하는 문제를 해결합니다. 삼중 비교(Triple Comparison, TC)와 확률 정규화(Probability Regularization, PR)와 같은 방법론을 사용하여 ADM은 확률 불일치와 다양성을 효과적으로 제한하며, 적응형 카테고리 할당을 가능하게 하고 새로운 클래스 발견의 강건성을 향상시킵니다. 특히, 적응형 모델 병합(Adaptive Model Merging, AMM) 접근법은 성능 손실이나 파라미터 증가 없이 새로운 지식을 기본 모델에 통합하여, 기존의 클래스 증분적 새로운 클래스 발견(class-incremental Novel Class Discovery, class-iNCD) 접근법보다 실험 결과에서 정확도 $A$가 벤치마크 데이터셋에서 $2x$ 향상된 것으로 나타났습니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Ensure all English terms within parentheses are in lowercase to maintain consistency and adhere to the criteria."
    },
    {
        "turn_index": 2,
        "term": "data augmentation",
        "domain": "cs.AI",
        "summary": "  Machines of all kinds from vehicles to industrial equipment are increasingly\ninstrumented with hundreds of sensors. Using such data to detect anomalous\nbehaviour is critical for safety and efficient maintenance. However, anomalies\noccur rarely and with great variety in such systems, so there is often\ninsufficient anomalous data to build reliable detectors. A standard approach to\nmitigate this problem is to use one class methods relying only on data from\nnormal behaviour. Unfortunately, even these approaches are more likely to fail\nin the scenario of a dynamical system with manual control input(s). Normal\nbehaviour in response to novel control input(s) might look very different to\nthe learned detector which may be incorrectly detected as anomalous. In this\npaper, we address this issue by modelling time-series via Ordinary Differential\nEquations (ODE) and utilising such an ODE model to simulate the behaviour of\ndynamical systems under varying control inputs. The available data is then\naugmented with data generated from the ODE, and the anomaly detector is\nretrained on this augmented dataset. Experiments demonstrate that ODE-augmented\ntraining data allows better coverage of possible control input(s) and results\nin learning more accurate distinctions between normal and anomalous behaviour\nin time-series.\n",
        "english": "In the context of detecting anomalous behavior in dynamical systems, where anomalies occur rarely and vary greatly, data augmentation can mitigate the challenge of insufficient anomalous data by utilizing Ordinary Differential Equations (ODE) to simulate system behavior under varying control inputs. The ODE model-generated data is integrated with existing datasets, enabling the retraining of anomaly detectors on this augmented dataset, which enhances the detector's ability to distinguish between normal and anomalous behaviors. Notably, experiments demonstrate that ODE-augmented training data provides better coverage of possible control inputs, resulting in improved accuracy in identifying anomalies, as expressed mathematically by the relationship $f(t, y, \\theta)$, where $f$ represents the ODE system dynamics, $t$ is time, $y$ is the system state, and $\\theta$ is the parameter set.",
        "korean": "동적 시스템에서 이상 행동을 감지하는 맥락에서, 이상 현상이 드물게 발생하고 크게 변동할 때, 데이터 증강(data augmentation)은 ordinary differential equations(상미분 방정식, ODE)을 활용하여 다양한 제어 입력 하에서 시스템 행동을 시뮬레이션함으로써 불충분한 이상 데이터의 문제를 완화할 수 있습니다. ODE 모델로 생성된 데이터는 기존 데이터셋과 통합되어, 이 증강된 데이터셋을 기반으로 이상 탐지기를 재훈련함으로써 정상 및 이상 행동을 구별하는 탐지기의 능력을 향상시킵니다. 특히, 실험 결과는 ODE로 증강된 훈련 데이터가 가능한 제어 입력의 더 나은 커버리지를 제공하여 이상 현상을 식별하는 정확도를 향상시킨다는 것을 보여줍니다. 이는 $f(t, y, \\theta)$라는 수학적 관계로 표현되며, 여기서 $f$는 ODE 시스템의 동역학을 나타내고, $t$는 시간, $y$는 시스템 상태, $\\theta$는 매개변수 집합입니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "pose estimation",
        "domain": "cs.AI",
        "summary": "  There has been an increasing interest in inferring some personality traits\nfrom users and players in social networks and games, respectively. This goes\nbeyond classical sentiment analysis, and also much further than customer\nprofiling. The purpose here is to have a characterisation of users in terms of\npersonality traits, such as openness, conscientiousness, extraversion,\nagreeableness, and neuroticism. While this is an incipient area of research, we\nask the question of whether cognitive abilities, and intelligence in\nparticular, are also measurable from user profiles. However, we pose the\nquestion as broadly as possible in terms of subjects, in the context of\nuniversal psychometrics, including humans, machines and hybrids. Namely, in\nthis paper we analyse the following question: is it possible to measure the\nintelligence of humans and (non-human) bots in a social network or a game just\nfrom their user profiles, i.e., by observation, without the use of interactive\ntests, such as IQ tests, the Turing test or other more principled machine\nintelligence tests?\n",
        "english": "Pose estimation has emerged as a critical component in the analysis of user profiles, particularly in the context of universal psychometrics, which seeks to measure cognitive abilities and intelligence by observation rather than interactive tests. This approach extends beyond classical sentiment analysis and customer profiling, aiming to characterize users in terms of personality traits such as openness, conscientiousness, extraversion, agreeableness, and neuroticism. In this innovative research area, one may question whether the intelligence of humans and non-human bots can be quantified through pose estimation in social networks or games, using mathematical models such as $I = \\sum_{i=1}^{n} P_i \\cdot T_i$, where $I$ represents intelligence, $P_i$ denotes pose parameters, and $T_i$ signifies trait indicators.",
        "korean": "포즈 추정(pose estimation)은 사용자 프로필 분석에서 중요한 요소로 부상했으며, 특히 상호작용 테스트가 아닌 관찰을 통해 인지 능력과 지능을 측정하려는 보편적 심리측정학(universal psychometrics) 맥락에서 중요합니다. 이 접근법은 고전적인 감정 분석(sentiment analysis)과 고객 프로파일링(customer profiling)을 넘어, 개방성, 성실성, 외향성, 친화성, 신경증과 같은 성격 특성 측면에서 사용자를 특성화하는 것을 목표로 합니다. 이 혁신적인 연구 분야에서는 소셜 네트워크나 게임에서 포즈 추정(pose estimation)을 통해 인간과 비인간 봇의 지능을 수량화할 수 있는지에 대한 의문이 제기될 수 있으며, 이는 $I = \\sum_{i=1}^{n} P_i \\cdot T_i$와 같은 수학적 모델을 사용하여 이루어집니다. 여기서 $I$는 지능을 나타내고, $P_i$는 포즈 매개변수(pose parameters)를, $T_i$는 특성 지표(trait indicators)를 의미합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "semantic image segmentation",
        "domain": "cs.AI",
        "summary": "  Recent advances in methods focused on the grounding problem have resulted in\ntechniques that can be used to construct a symbolic language associated with a\nspecific domain. Inspired by how humans communicate complex ideas through\nlanguage, we developed a generalized Symbolic Semantic ($\\text{S}^2$) framework\nfor interpretable segmentation. Unlike adversarial models (e.g., GANs), we\nexplicitly model cooperation between two agents, a Sender and a Receiver, that\nmust cooperate to achieve a common goal. The Sender receives information from a\nhigh layer of a segmentation network and generates a symbolic sentence derived\nfrom a categorical distribution. The Receiver obtains the symbolic sentences\nand co-generates the segmentation mask. In order for the model to converge, the\nSender and Receiver must learn to communicate using a private language. We\napply our architecture to segment tumors in the TCGA dataset. A UNet-like\narchitecture is used to generate input to the Sender network which produces a\nsymbolic sentence, and a Receiver network co-generates the segmentation mask\nbased on the sentence. Our Segmentation framework achieved similar or better\nperformance compared with state-of-the-art segmentation methods. In addition,\nour results suggest direct interpretation of the symbolic sentences to\ndiscriminate between normal and tumor tissue, tumor morphology, and other image\ncharacteristics.\n",
        "english": "Recent advances in methods focused on the grounding problem have led to the development of the generalized Symbolic Semantic ($\\text{S}^2$) framework for interpretable semantic image segmentation, where cooperation between a Sender and a Receiver facilitates the generation of segmentation masks. In this framework, the Sender receives information from a high layer of a segmentation network and generates a symbolic sentence derived from a categorical distribution, while the Receiver co-generates the segmentation mask based on the symbolic sentences. Notably, this approach achieved similar or better performance compared with state-of-the-art segmentation methods and provides direct interpretation of the symbolic sentences to discriminate between normal and tumor tissue, tumor morphology, and other image characteristics.",
        "korean": "최근 기초 문제에 초점을 맞춘 방법의 발전은 해석 가능한 의미론적 이미지 분할(semantic image segmentation)을 위한 일반화된 상징적 의미론(s^2) 프레임워크의 개발로 이어졌으며, 여기서 송신자와 수신자 간의 협력이 분할 마스크의 생성을 촉진합니다. 이 프레임워크에서 송신자는 분할 네트워크의 높은 계층에서 정보를 받아 범주형 분포에서 파생된 상징적 문장을 생성하며, 수신자는 상징적 문장에 기반하여 분할 마스크를 공동 생성합니다. 특히, 이 접근 방식은 최첨단 분할 방법과 비교하여 유사하거나 더 나은 성능을 달성했으며, 상징적 문장의 직접적인 해석을 통해 정상 조직과 종양 조직, 종양 형태 및 기타 이미지 특성을 구별할 수 있습니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Ensure that the term \"Symbolic Semantic ($\\text{S}^2$)\" is consistently parenthesized as 상징적 의미론(symbolic semantic) to maintain clarity and consistency in technical terminology."
    },
    {
        "turn_index": 2,
        "term": "t5",
        "domain": "cs.AI",
        "summary": "  Exploring the generalization of a text-to-SQL parser is essential for a\nsystem to automatically adapt the real-world databases. Previous works provided\ninvestigations focusing on lexical diversity, including the influence of the\nsynonym and perturbations in both natural language questions and databases.\nHowever, research on the structure variety of database schema~(DS) is\ndeficient. Specifically, confronted with the same input question, the target\nSQL is probably represented in different ways when the DS comes to a different\nstructure. In this work, we provide in-deep discussions about the structural\ngeneralization of text-to-SQL tasks. We observe that current datasets are too\ntemplated to study structural generalization. To collect eligible test data, we\npropose a framework to generate novel text-to-SQL data via automatic and\nsynchronous (DS, SQL) pair altering. In the experiments, significant\nperformance reduction when evaluating well-trained text-to-SQL models on the\nsynthetic samples demonstrates the limitation of current research regarding\nstructural generalization. According to comprehensive analysis, we suggest the\npractical reason is the overfitting of (NL, SQL) patterns.\n",
        "english": "The exploration of generalization in text-to-SQL parsers, such as t5, is crucial for systems to automatically adapt to real-world databases, yet research on the structural variety of database schemas (DS) remains deficient. This study introduces an innovative framework to generate novel text-to-SQL data by automatically and synchronously altering (DS, SQL) pairs, revealing a significant performance reduction in well-trained models when evaluated on synthetic samples, thus highlighting the limitation of current research in structural generalization. A comprehensive analysis suggests that the practical reason for this limitation is the overfitting of (NL, SQL) patterns, denoted as $f(\\text{NL}) \\rightarrow \\text{SQL}$, indicating the need for more diverse datasets beyond templated structures.",
        "korean": "텍스트-대-SQL(text-to-SQL) 파서(parser)에서 일반화(generalization)의 탐색은 t5와 같은 시스템이 실제 데이터베이스(database)에 자동으로 적응하는 데 중요하지만, 데이터베이스 스키마(database schema, DS)의 구조적 다양성에 대한 연구는 여전히 부족합니다. 본 연구는 (DS, SQL) 쌍을 자동으로 동기화하여 변경함으로써 새로운 텍스트-대-SQL(text-to-SQL) 데이터를 생성하는 혁신적인 프레임워크를 소개하며, 잘 훈련된 모델이 합성 샘플에서 평가될 때 성능이 크게 감소하는 것을 드러내어 구조적 일반화에 대한 현재 연구의 한계를 강조합니다. 종합적인 분석은 이러한 한계의 실질적인 이유가 (NL, SQL) 패턴의 과적합(overfitting)임을 시사하며, 이는 템플릿 구조를 넘어서는 더 다양한 데이터셋(dataset)의 필요성을 나타냅니다.",
        "score": 10,
        "parentheses_count": 11,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase letters within parentheses and verify the correct placement of parentheses around technical terms."
    },
    {
        "turn_index": 2,
        "term": "differentiable neural processes",
        "domain": "cs.AI",
        "summary": "  The remarkable achievements of machine learning techniques in analyzing\ndiscrete structures have drawn significant attention towards their integration\ninto combinatorial optimization algorithms. Typically, these methodologies\nimprove existing solvers by injecting learned models within the solving loop to\nenhance the efficiency of the search process. In this work, we derive a single\ndifferentiable function capable of approximating solutions for the Maximum\nSatisfiability Problem (MaxSAT). Then, we present a novel neural network\narchitecture to model our differentiable function, and progressively solve\nMaxSAT using backpropagation. This approach eliminates the need for labeled\ndata or a neural network training phase, as the training process functions as\nthe solving algorithm. Additionally, we leverage the computational power of\nGPUs to accelerate these computations. Experimental results on challenging\nMaxSAT instances show that our proposed methodology outperforms two existing\nMaxSAT solvers, and is on par with another in terms of solution cost, without\nnecessitating any training or access to an underlying SAT solver. Given that\nnumerous NP-hard problems can be reduced to MaxSAT, our novel technique paves\nthe way for a new generation of solvers poised to benefit from neural network\nGPU acceleration.\n",
        "english": "Differentiable neural processes have demonstrated significant potential in enhancing combinatorial optimization algorithms by integrating learned models within the solving loop to improve the efficiency of the search process. Specifically, a single differentiable function is derived to approximate solutions for the Maximum Satisfiability Problem (MaxSAT), enabling the use of backpropagation to progressively solve MaxSAT without the need for labeled data or a traditional neural network training phase. This innovative approach not only outperforms existing MaxSAT solvers in challenging instances but also leverages GPU acceleration to solve numerous NP-hard problems, marking a pivotal advancement in the development of next-generation solvers.",
        "korean": "미분 가능한 신경 프로세스(differentiable neural processes)는 학습된 모델을 해결 루프 내에 통합하여 탐색 과정의 효율성을 향상시킴으로써 조합 최적화 알고리즘(combinatorial optimization algorithms)을 크게 향상시킬 수 있는 잠재력을 보여주었습니다. 구체적으로, 최대 만족 문제(Maximum Satisfiability Problem, MaxSAT)의 해를 근사하기 위해 단일 미분 가능 함수가 도출되어, 레이블이 있는 데이터나 전통적인 신경망 훈련 단계 없이 역전파(backpropagation)를 사용하여 MaxSAT를 점진적으로 해결할 수 있게 합니다. 이 혁신적인 접근 방식은 도전적인 사례에서 기존의 MaxSAT 해결기를 능가할 뿐만 아니라 GPU 가속을 활용하여 수많은 NP-난해 문제(NP-hard problems)를 해결함으로써 차세대 해결기의 개발에 중요한 진전을 이룹니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure consistent lowercase usage within parentheses and consider rephrasing for smoother readability, such as adjusting the placement of technical terms to better fit the natural flow of Korean grammar."
    },
    {
        "turn_index": 2,
        "term": "multi-hop reasoning",
        "domain": "cs.AI",
        "summary": "  Graph embedding methods such as Graph Neural Networks (GNNs) and Graph\nTransformers have contributed to the development of graph reasoning algorithms\nfor various tasks on knowledge graphs. However, the lack of interpretability\nand explainability of graph embedding methods has limited their applicability\nin scenarios requiring explicit reasoning. In this paper, we introduce the\nGraph Agent (GA), an intelligent agent methodology of leveraging large language\nmodels (LLMs), inductive-deductive reasoning modules, and long-term memory for\nknowledge graph reasoning tasks. GA integrates aspects of symbolic reasoning\nand existing graph embedding methods to provide an innovative approach for\ncomplex graph reasoning tasks. By converting graph structures into textual\ndata, GA enables LLMs to process, reason, and provide predictions alongside\nhuman-interpretable explanations. The effectiveness of the GA was evaluated on\nnode classification and link prediction tasks. Results showed that GA reached\nstate-of-the-art performance, demonstrating accuracy of 90.65%, 95.48%, and\n89.32% on Cora, PubMed, and PrimeKG datasets, respectively. Compared to\nexisting GNN and transformer models, GA offered advantages of explicit\nreasoning ability, free-of-training, easy adaption to various graph reasoning\ntasks\n",
        "english": "Multi-hop reasoning, which involves navigating through multiple nodes and edges in a knowledge graph to derive conclusions, has seen advancements through methodologies like the Graph Agent (GA), which leverages large language models (LLMs) and inductive-deductive reasoning modules. The GA integrates symbolic reasoning with graph embedding methods, converting graph structures into textual data to enable LLMs to process and provide human-interpretable explanations, thus addressing the interpretability challenges faced by traditional graph embedding techniques. Notably, the GA achieved state-of-the-art performance in node classification and link prediction tasks, with accuracy rates of 90.65\\% on the Cora dataset, 95.48\\% on PubMed, and 89.32\\% on PrimeKG, highlighting its innovative approach to complex graph reasoning tasks.",
        "korean": "다중 홉 추론(multi-hop reasoning)은 지식 그래프(knowledge graph)에서 여러 노드와 엣지를 탐색하여 결론을 도출하는 과정을 포함하며, 대형 언어 모델(large language models, LLMs)과 귀납-연역 추론 모듈(inductive-deductive reasoning modules)을 활용하는 그래프 에이전트(Graph Agent, GA)와 같은 방법론을 통해 발전을 이루었습니다. GA는 기호적 추론(symbolic reasoning)과 그래프 임베딩(graph embedding) 방법을 통합하여 그래프 구조를 텍스트 데이터로 변환함으로써 LLM이 처리하고 인간이 해석 가능한 설명을 제공할 수 있도록 하여 전통적인 그래프 임베딩 기법이 직면한 해석 가능성 문제를 해결합니다. 특히, GA는 노드 분류(node classification)와 링크 예측(link prediction) 작업에서 최첨단 성능을 달성했으며, Cora 데이터셋(dataset)에서 90.65\\%, PubMed에서 95.48\\%, PrimeKG에서 89.32\\%의 정확도를 기록하여 복잡한 그래프 추론 작업에 대한 혁신적인 접근 방식을 강조합니다.",
        "score": 9,
        "parentheses_count": 12,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all terms are consistently formatted as Korean term(English term) and consider simplifying complex sentence structures for better readability."
    },
    {
        "turn_index": 2,
        "term": "monte carlo methods",
        "domain": "cs.AI",
        "summary": "  The expected value of information (EVI) is the most powerful measure of\nsensitivity to uncertainty in a decision model: it measures the potential of\ninformation to improve the decision, and hence measures the expected value of\noutcome. Standard methods for computing EVI use discrete variables and are\ncomputationally intractable for models that contain more than a few variables.\nMonte Carlo simulation provides the basis for more tractable evaluation of\nlarge predictive models with continuous and discrete variables, but so far\ncomputation of EVI in a Monte Carlo setting also has appeared impractical. We\nintroduce an approximate approach based on pre-posterior analysis for\nestimating EVI in Monte Carlo models. Our method uses a linear approximation to\nthe value function and multiple linear regression to estimate the linear model\nfrom the samples. The approach is efficient and practical for extremely large\nmodels. It allows easy estimation of EVI for perfect or partial information on\nindividual variables or on combinations of variables. We illustrate its\nimplementation within Demos (a decision modeling system), and its application\nto a large model for crisis transportation planning.\n",
        "english": "Monte Carlo methods provide a tractable approach for evaluating large predictive models with both continuous and discrete variables, addressing the computational challenges associated with traditional methods of computing the expected value of information (EVI). By employing a linear approximation to the value function and utilizing multiple linear regression, the proposed method efficiently estimates EVI, even in extremely large models, through a pre-posterior analysis framework. This innovative approach, demonstrated within the Demos decision modeling system, showcases its practical application to complex scenarios such as crisis transportation planning, thereby highlighting its significance in advancing decision model sensitivity analysis.",
        "korean": "몬테카를로 방법(monte carlo methods)은 연속 변수와 이산 변수를 모두 포함하는 대규모 예측 모델을 평가하는 데 있어 전통적인 정보 기대값(evi) 계산 방법과 관련된 계산 문제를 해결하는 실용적인 접근 방식을 제공합니다. 가치 함수에 대한 선형 근사를 사용하고 다중 선형 회귀를 활용함으로써, 제안된 방법은 사전-사후 분석 프레임워크를 통해 매우 큰 모델에서도 evi를 효율적으로 추정합니다. 이 혁신적인 접근 방식은 demos 의사결정 모델링 시스템 내에서 위기 운송 계획과 같은 복잡한 시나리오에 대한 실용적인 적용을 보여주며, 의사결정 모델 민감도 분석을 발전시키는 데 있어 그 중요성을 강조합니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Ensure consistent capitalization within parentheses and consider rephrasing for smoother readability, such as adjusting the placement of technical terms to better fit Korean sentence structure."
    },
    {
        "turn_index": 2,
        "term": "neural ODEs",
        "domain": "cs.AI",
        "summary": "  Recent years have witnessed the rapid progress and broad application of\ndiffusion probabilistic models (DPMs). Sampling from DPMs can be viewed as\nsolving an ordinary differential equation (ODE). Despite the promising\nperformance, the generation of DPMs usually consumes much time due to the large\nnumber of function evaluations (NFE). Though recent works have accelerated the\nsampling to around 20 steps with high-order solvers, the sample quality with\nless than 10 NFE can still be improved. In this paper, we propose a unified\nsampling framework (USF) to study the optional strategies for solver. Under\nthis framework, we further reveal that taking different solving strategies at\ndifferent timesteps may help further decrease the truncation error, and a\ncarefully designed \\emph{solver schedule} has the potential to improve the\nsample quality by a large margin. Therefore, we propose a new sampling\nframework based on the exponential integral formulation that allows free\nchoices of solver strategy at each step and design specific decisions for the\nframework. Moreover, we propose $S^3$, a predictor-based search method that\nautomatically optimizes the solver schedule to get a better time-quality\ntrade-off of sampling. We demonstrate that $S^3$ can find outstanding solver\nschedules which outperform the state-of-the-art sampling methods on CIFAR-10,\nCelebA, ImageNet, and LSUN-Bedroom datasets. Specifically, we achieve 2.69 FID\nwith 10 NFE and 6.86 FID with 5 NFE on CIFAR-10 dataset, outperforming the SOTA\nmethod significantly. We further apply $S^3$ to Stable-Diffusion model and get\nan acceleration ratio of 2$\\times$, showing the feasibility of sampling in very\nfew steps without retraining the neural network.\n",
        "english": "The recent advancements in neural ODEs have significantly impacted the efficiency of diffusion probabilistic models (DPMs), where sampling is analogous to solving an ordinary differential equation. By implementing a new sampling framework based on the exponential integral formulation, researchers have enhanced the flexibility in choosing solver strategies at each step, achieving remarkable results such as a FID of 2.69 with 10 function evaluations (NFE) on the CIFAR-10 dataset. Furthermore, the introduction of $S^3$, a predictor-based search method, has demonstrated the potential to optimize solver schedules, substantially improving the time-quality trade-off in sampling, as evidenced by an acceleration ratio of 2$\\times$ when applied to the Stable-Diffusion model.",
        "korean": "최근 신경 미분 방정식(neural ODEs)에서의 발전은 확산 확률 모델(diffusion probabilistic models, DPMs)의 효율성에 큰 영향을 미쳤으며, 여기서 샘플링은 보통 미분 방정식을 푸는 것과 유사합니다. 지수 적분 공식(exponential integral formulation)을 기반으로 한 새로운 샘플링 프레임워크를 구현함으로써 연구자들은 각 단계에서 해법 전략을 선택하는 데 있어 유연성을 향상시켰으며, 10번의 함수 평가(nfe)로 CIFAR-10 데이터셋에서 FID 2.69라는 놀라운 결과를 달성했습니다. 또한, 예측기 기반 탐색 방법인 $S^3$의 도입은 해법 일정 최적화의 잠재력을 보여주었으며, stable-diffusion 모델에 적용했을 때 2배의 가속 비율을 통해 샘플링에서 시간-품질 간의 균형을 크게 개선했습니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing to maintain a natural flow, such as adjusting the placement of terms like \"CIFAR-10 데이터셋에서\" for smoother readability."
    },
    {
        "turn_index": 2,
        "term": "probabilistic neural networks",
        "domain": "cs.AI",
        "summary": "  The goal of combining the robustness of neural networks and the\nexpressiveness of symbolic methods has rekindled the interest in Neuro-Symbolic\nAI. Deep Probabilistic Programming Languages (DPPLs) have been developed for\nprobabilistic logic programming to be carried out via the probability\nestimations of deep neural networks. However, recent SOTA DPPL approaches allow\nonly for limited conditional probabilistic queries and do not offer the power\nof true joint probability estimation. In our work, we propose an easy\nintegration of tractable probabilistic inference within a DPPL. To this end, we\nintroduce SLASH, a novel DPPL that consists of Neural-Probabilistic Predicates\n(NPPs) and a logic program, united via answer set programming (ASP). NPPs are a\nnovel design principle allowing for combining all deep model types and\ncombinations thereof to be represented as a single probabilistic predicate. In\nthis context, we introduce a novel $+/-$ notation for answering various types\nof probabilistic queries by adjusting the atom notations of a predicate. To\nscale well, we show how to prune the stochastically insignificant parts of the\n(ground) program, speeding up reasoning without sacrificing the predictive\nperformance. We evaluate SLASH on a variety of different tasks, including the\nbenchmark task of MNIST addition and Visual Question Answering (VQA).\n",
        "english": "Probabilistic neural networks have gained renewed interest due to the integration of neural network robustness with symbolic methods, as seen in the development of Deep Probabilistic Programming Languages (DPPLs) for probabilistic logic programming. SLASH, a novel DPPL, enhances probabilistic neural networks by introducing Neural-Probabilistic Predicates (NPPs) and a logic program connected via answer set programming (ASP), allowing for the representation of all deep model types as a single probabilistic predicate. Notably, SLASH introduces a $+/-$ notation for probabilistic queries, improving scalability by pruning stochastically insignificant parts of the (ground) program, thus maintaining predictive performance while accelerating reasoning processes.",
        "korean": "확률적 신경망(probabilistic neural networks)은 확률적 논리 프로그래밍을 위한 심층 확률 프로그래밍 언어(Deep Probabilistic Programming Languages, DPPLs)의 개발에서 볼 수 있듯이 신경망의 견고성과 상징적 방법의 통합으로 인해 새로운 관심을 받고 있습니다. SLASH라는 새로운 DPPL은 신경-확률적 술어(Neural-Probabilistic Predicates, NPPs)와 답 집합 프로그래밍(answer set programming, ASP)을 통해 연결된 논리 프로그램을 도입하여 확률적 신경망(probabilistic neural networks)을 향상시킵니다. 이를 통해 모든 심층 모델 유형을 단일 확률적 술어로 표현할 수 있습니다. 특히, SLASH는 확률적 쿼리에 대한 $+/-$ 표기법을 도입하여 (기초) 프로그램의 확률적으로 중요하지 않은 부분을 가지치기함으로써 예측 성능을 유지하면서 추론 과정을 가속화하여 확장성을 개선합니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure that all English terms within parentheses are in lowercase for consistency."
    },
    {
        "turn_index": 2,
        "term": "semi-supervised text classification",
        "domain": "cs.AI",
        "summary": "  With the rapid development of ICT Custom Services (ICT CS) in power\nindustries, the deployed power ICT CS systems mainly rely on the experience of\ncustomer service staff for fault type recognition, questioning, and answering,\nwhich makes it difficult and inefficient to precisely resolve the problems\nissued by users. To resolve this problem, in this paper, firstly, a multi-label\nfault text classification ensemble approach called BR-GBDT is proposed by\ncombining Binary Relevance and Gradient Boosting Decision Tree for assisted\nfault type diagnosis and improving the accuracy of fault type recognition.\nSecond, for the problem that there is lack of the training set for power ICT\nmulti-label text classification, an automatic approach is presented to\nconstruct the training set from the historical fault text data stored in power\nICT CS systems. The extensive experiments were made based on the power ICT CS\ntraining set and some general-purpose benchmark training datasets. The\nexperiment results show that our approach outperforms the well known ensemble\nlearning based approaches BR+LR and ML-KNN for fault text classification,\nefficiently handling the multi-label classification of ICT custom service text\ndata for fault type recognition.\n",
        "english": "In addressing the challenges of semi-supervised text classification within power industries, a novel multi-label fault text classification ensemble method, BR-GBDT, integrates Binary Relevance and Gradient Boosting Decision Tree to enhance fault type diagnosis accuracy. To compensate for the inadequate training data in power ICT multi-label text classification, an innovative automatic approach constructs a training set from historical fault text data, facilitating improved model training. Extensive experiments demonstrate that the proposed method surpasses traditional ensemble learning approaches such as BR+LR and ML-KNN, achieving superior performance in fault text classification, particularly in handling multi-label classification tasks, where the accuracy is represented as $\\text{accuracy} = \\frac{\\text{correct predictions}}{\\text{total predictions}}$.",
        "korean": "전력 산업에서 반지도 학습 텍스트 분류(semi-supervised text classification)의 도전 과제를 해결하기 위해, BR-GBDT라는 새로운 다중 레이블 고장 텍스트 분류 앙상블 방법이 바이너리 관련성(binary relevance)과 그래디언트 부스팅 결정 트리(gradient boosting decision tree)를 통합하여 고장 유형 진단 정확도를 향상시킵니다. 전력 ICT 다중 레이블 텍스트 분류에서 불충분한 학습 데이터를 보완하기 위해, 혁신적인 자동 접근 방식이 과거 고장 텍스트 데이터를 기반으로 학습 세트를 구성하여 모델 학습을 개선합니다. 광범위한 실험 결과, 제안된 방법이 BR+LR 및 ML-KNN과 같은 전통적인 앙상블 학습 방법을 능가하여, 특히 다중 레이블 분류 작업에서 고장 텍스트 분류의 성능을 뛰어넘는 것으로 나타났으며, 정확도는 $\\text{accuracy} = \\frac{\\text{correct predictions}}{\\text{total predictions}}$로 표현됩니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural processes",
        "domain": "cs.AI",
        "summary": "  The integration of low-level perception with high-level reasoning is one of\nthe oldest problems in Artificial Intelligence. Recently, several proposals\nwere made to implement the reasoning process in complex neural network\narchitectures. While these works aim at extending neural networks with the\ncapability of reasoning, a natural question that we consider is: can we extend\nanswer set programs with neural networks to allow complex and high-level\nreasoning on neural network outputs? As a preliminary result, we propose\nNeurASP -- a simple extension of answer set programs by embracing neural\nnetworks where neural network outputs are treated as probability distributions\nover atomic facts in answer set programs. We show that NeurASP can not only\nimprove the perception accuracy of a pre-trained neural network, but also help\nto train a neural network better by giving restrictions through logic rules.\nHowever, training with NeurASP would take much more time than pure neural\nnetwork training due to the internal use of a symbolic reasoning engine. For\nfuture work, we plan to investigate the potential ways to solve the scalability\nissue of NeurASP. One potential way is to embed logic programs directly in\nneural networks. On this route, we plan to first design a SAT solver using\nneural networks, then extend such a solver to allow logic programs.\n",
        "english": "The integration of low-level perception with high-level reasoning, a longstanding challenge in Artificial Intelligence, has led to several innovative proposals that implement reasoning processes within complex neural network architectures, thus enhancing neural processes. A notable advancement is NeurASP, which extends answer set programs by incorporating neural networks, allowing neural network outputs to be treated as probability distributions over atomic facts, thereby improving perception accuracy and facilitating better training through logical constraints. However, the training time for NeurASP, denoted as $T_{NeurASP}$, exceeds that of pure neural network training due to the internal use of a symbolic reasoning engine, highlighting the need for future research to address scalability, potentially by embedding logic programs directly within neural networks.",
        "korean": "인공지능(Artificial Intelligence)에서 오랜 과제로 여겨져 온 저수준 지각과 고수준 추론의 통합은 복잡한 신경망 구조 내에서 추론 과정을 구현하는 여러 혁신적인 제안을 이끌어내어 신경 과정(neural processes)을 향상시켰습니다. 주목할 만한 발전은 신경망을 통합하여 답 집합 프로그램(answer set programs)을 확장한 NeurASP로, 신경망 출력을 원자적 사실에 대한 확률 분포로 처리할 수 있게 하여 지각 정확도를 개선하고 논리적 제약을 통한 더 나은 훈련을 가능하게 합니다. 그러나 NeurASP의 훈련 시간, $T_{NeurASP}$는 상징적 추론 엔진의 내부 사용으로 인해 순수 신경망 훈련보다 더 길어지며, 논리 프로그램을 신경망 내에 직접 내장하여 확장성을 해결할 필요가 있음을 강조합니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistency by using lowercase letters within parentheses."
    },
    {
        "turn_index": 2,
        "term": "neural context-aware models",
        "domain": "cs.AI",
        "summary": "  Neural-symbolic computing aims at integrating robust neural learning and\nsound symbolic reasoning into a single framework, so as to leverage the\ncomplementary strengths of both of these, seemingly unrelated (maybe even\ncontradictory) AI paradigms. The central challenge in neural-symbolic computing\nis to unify the formulation of neural learning and symbolic reasoning into a\nsingle framework with common semantics, that is, to seek a joint representation\nbetween a neural model and a logical theory that can support the basic\ngrounding learned by the neural model and also stick to the semantics of the\nlogical theory. In this paper, we propose differentiable fuzzy $\\mathcal{ALC}$\n(DF-$\\mathcal{ALC}$) for this role, as a neural-symbolic representation\nlanguage with the desired semantics. DF-$\\mathcal{ALC}$ unifies the description\nlogic $\\mathcal{ALC}$ and neural models for symbol grounding; in particular, it\ninfuses an $\\mathcal{ALC}$ knowledge base into neural models through\ndifferentiable concept and role embeddings. We define a hierarchical loss to\nthe constraint that the grounding learned by neural models must be semantically\nconsistent with $\\mathcal{ALC}$ knowledge bases. And we find that capturing the\nsemantics in grounding solely by maximizing satisfiability cannot revise\ngrounding rationally. We further define a rule-based loss for DF adapting to\nsymbol grounding problems. The experiment results show that DF-$\\mathcal{ALC}$\nwith rule-based loss can improve the performance of image object detectors in\nan unsupervised learning way, even in low-resource situations.\n",
        "english": "Neural context-aware models, as demonstrated by the integration of differentiable fuzzy $\\mathcal{ALC}$ (DF-$\\mathcal{ALC}$), provide a promising approach to merge robust neural learning with sound symbolic reasoning, thereby leveraging the complementary strengths of these AI paradigms. By infusing an $\\mathcal{ALC}$ knowledge base into neural models through differentiable concept and role embeddings, these models ensure that the grounding learned is semantically consistent with $\\mathcal{ALC}$ knowledge bases, which is crucial for maintaining the integrity of the logical theory. The innovation of DF-$\\mathcal{ALC}$, particularly with its rule-based loss adaptation, significantly enhances the performance of image object detectors in unsupervised learning scenarios, even when resources are limited, highlighting its potential impact on the field.",
        "korean": "차별 가능한 퍼지 $\\mathcal{ALC}$ (DF-$\\mathcal{ALC}$)의 통합으로 입증된 바와 같이, 신경 문맥 인식 모델(neural context-aware models)은 견고한 신경 학습과 건전한 상징적 추론을 결합하는 유망한 접근 방식을 제공합니다. 이러한 AI 패러다임의 상호 보완적인 강점을 활용함으로써, 차별 가능한 개념 및 역할 임베딩을 통해 $\\mathcal{ALC}$ 지식 기반을 신경 모델에 주입하여, 학습된 기반이 $\\mathcal{ALC}$ 지식 기반과 의미적으로 일치하도록 보장합니다. 이는 논리 이론의 무결성을 유지하는 데 중요합니다. DF-$\\mathcal{ALC}$의 혁신, 특히 규칙 기반 손실 적응은 자원이 제한된 상황에서도 비지도 학습 시나리오에서 이미지 객체 탐지기의 성능을 크게 향상시켜, 이 분야에 미칠 잠재적 영향을 강조합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "conditional independence",
        "domain": "cs.AI",
        "summary": "  The graphoid axioms for conditional independence, originally described by\nDawid [1979], are fundamental to probabilistic reasoning [Pearl, 19881. Such\naxioms provide a mechanism for manipulating conditional independence assertions\nwithout resorting to their numerical definition. This paper explores a\nrepresentation for independence statements using multiple undirected graphs and\nsome simple graphical transformations. The independence statements derivable in\nthis system are equivalent to those obtainable by the graphoid axioms.\nTherefore, this is a purely graphical proof technique for conditional\nindependence.\n",
        "english": "The graphoid axioms for conditional independence, as initially articulated by Dawid [1979], serve as a cornerstone for probabilistic reasoning, allowing for the manipulation of conditional independence assertions without reliance on their numerical definition. This innovative approach employs multiple undirected graphs and simple graphical transformations to represent independence statements, offering a purely graphical proof technique for conditional independence. By demonstrating that independence statements derivable in this system are equivalent to those obtainable by the graphoid axioms, the research underscores the equivalence of graphical and axiomatic methods, where for any three variables $X$, $Y$, and $Z$, the independence $I(X, Y | Z)$ holds if and only if it can be derived using the graphoid properties.",
        "korean": "조건부 독립성(conditional independence)에 대한 그래포이드 공리(graphoid axioms)는 처음에 다윗(Dawid) [1979]에 의해 명확히 설명되었으며, 확률적 추론의 초석으로 작용하여 조건부 독립성(conditional independence) 주장을 그들의 수치적 정의에 의존하지 않고 조작할 수 있게 합니다. 이 혁신적인 접근법은 여러 개의 무방향 그래프(undirected graphs)와 간단한 그래프 변환을 사용하여 독립성 진술을 표현하며, 조건부 독립성(conditional independence)에 대한 순수한 그래픽 증명 기법을 제공합니다. 이 시스템에서 도출 가능한 독립성 진술이 그래포이드 공리(graphoid axioms)에 의해 얻을 수 있는 것과 동등하다는 것을 입증함으로써, 연구는 그래픽 방법과 공리적 방법의 동등성을 강조합니다. 여기서 세 변수 $X$, $Y$, $Z$에 대해 독립성 $I(X, Y | Z)$는 그래포이드 속성(graphoid properties)을 사용하여 도출할 수 있을 때에만 성립합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "contextual representation learning",
        "domain": "cs.AI",
        "summary": "  This paper introduces the Contextual Evaluation Model (CEM), a novel method\nfor knowledge representation and manipulation. The CEM differs from existing\nmodels in that it integrates facts, patterns and sequences into a single\ncontextual framework. V5, an implementation of the model is presented and\ndemonstrated with multiple annotated examples. The paper includes simulations\ndemonstrating how the model reacts to pleasure/pain stimuli. The 'thought' is\ndefined within the model and examples are given converting thoughts to\nlanguage, converting language to thoughts and how 'meaning' arises from\nthoughts. A pattern learning algorithm is described. The algorithm is applied\nto multiple problems ranging from recognizing a voice to the autonomous\nlearning of a simplified natural language.\n",
        "english": "The Contextual Evaluation Model (CEM) introduces an innovative approach to contextual representation learning by integrating facts, patterns, and sequences into a single cohesive framework, as demonstrated by its implementation in V5 with multiple annotated examples. This model uniquely defines 'thought' and explores the conversion of thoughts to language and vice versa, illustrating how 'meaning' emerges from these processes through a pattern learning algorithm. With simulations showcasing the model's responsiveness to pleasure/pain stimuli, the CEM addresses complex problems such as voice recognition and autonomous natural language learning, employing mathematical expressions like $f(x) = ax^2 + bx + c$ to represent learned patterns effectively.",
        "korean": "맥락 평가 모델(Contextual Evaluation Model, CEM)은 여러 주석이 달린 예제를 포함한 V5 구현을 통해 사실, 패턴, 시퀀스를 단일 통합 프레임워크로 통합하여 맥락 표현 학습(contextual representation learning)에 혁신적인 접근 방식을 도입합니다. 이 모델은 '생각'을 독특하게 정의하고, 생각을 언어로 변환하는 과정과 그 반대 과정을 탐구하며, 이러한 과정에서 '의미'가 어떻게 나타나는지를 패턴 학습 알고리즘을 통해 설명합니다. 시뮬레이션을 통해 쾌락/고통 자극에 대한 모델의 반응성을 보여주면서, CEM은 음성 인식 및 자율 자연어 학습과 같은 복잡한 문제를 해결하며, $f(x) = ax^2 + bx + c$와 같은 수학적 표현을 사용하여 학습된 패턴을 효과적으로 나타냅니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "semantic neural embeddings",
        "domain": "cs.AI",
        "summary": "  The representation of knowledge based on first-order logic captures the\nrichness of natural language and supports multiple probabilistic inference\nmodels. Although symbolic representation enables quantitative reasoning with\nstatistical probability, it is difficult to utilize with machine learning\nmodels as they perform numerical operations. In contrast, knowledge embedding\n(i.e., high-dimensional and continuous vectors) is a feasible approach to\ncomplex reasoning that can not only retain the semantic information of\nknowledge but also establish the quantifiable relationship among them. In this\npaper, we propose recursive neural knowledge network (RNKN), which combines\nmedical knowledge based on first-order logic with recursive neural network for\nmulti-disease diagnosis. After RNKN is efficiently trained from manually\nannotated Chinese Electronic Medical Records (CEMRs), diagnosis-oriented\nknowledge embeddings and weight matrixes are learned. Experimental results\nverify that the diagnostic accuracy of RNKN is superior to that of some\nclassical machine learning models and Markov logic network (MLN). The results\nalso demonstrate that the more explicit the evidence extracted from CEMRs is,\nthe better is the performance achieved. RNKN gradually exhibits the\ninterpretation of knowledge embeddings as the number of training epochs\nincreases.\n",
        "english": "Semantic neural embeddings, which are high-dimensional and continuous vectors, offer a feasible approach to complex reasoning by retaining semantic information and establishing quantifiable relationships among data points. The innovative Recursive Neural Knowledge Network (RNKN) integrates medical knowledge based on first-order logic with a recursive neural network to enhance multi-disease diagnosis, demonstrating superior diagnostic accuracy compared to classical machine learning models and Markov logic networks. As RNKN is trained on Chinese Electronic Medical Records, it efficiently learns diagnosis-oriented knowledge embeddings and weight matrices, where the performance is mathematically represented as improving with explicit evidence extraction, \\( P_{\\text{accuracy}} \\propto E_{\\text{evidence}} \\), and increases with the number of training epochs.",
        "korean": "고차원 연속 벡터인 의미 신경 임베딩(semantic neural embeddings)은 의미 정보를 유지하고 데이터 포인트 간의 정량적 관계를 설정함으로써 복잡한 추론에 대한 실현 가능한 접근 방식을 제공합니다. 혁신적인 재귀 신경 지식 네트워크(Recursive Neural Knowledge Network, RNKN)는 1차 논리에 기반한 의료 지식을 재귀 신경망과 통합하여 다중 질병 진단을 향상시키며, 전통적인 기계 학습 모델과 마르코프 논리 네트워크(Markov logic networks)보다 우수한 진단 정확성을 입증합니다. RNKN은 중국 전자 의료 기록(Chinese Electronic Medical Records)에서 학습되므로 진단 지향 지식 임베딩과 가중치 행렬을 효율적으로 학습하며, 성능은 명시적 증거 추출과 함께 수학적으로 \\( P_{\\text{accuracy}} \\propto E_{\\text{evidence}} \\)로 표현되고, 학습 에포크 수가 증가함에 따라 향상됩니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure all English terms within parentheses are in lowercase and maintain consistency in parenthesization for all technical terms."
    },
    {
        "turn_index": 2,
        "term": "neurosymbolic AI",
        "domain": "cs.AI",
        "summary": "  Metacognition is the concept of reasoning about an agent's own internal\nprocesses and was originally introduced in the field of developmental\npsychology. In this position paper, we examine the concept of applying\nmetacognition to artificial intelligence. We introduce a framework for\nunderstanding metacognitive artificial intelligence (AI) that we call TRAP:\ntransparency, reasoning, adaptation, and perception. We discuss each of these\naspects in-turn and explore how neurosymbolic AI (NSAI) can be leveraged to\naddress challenges of metacognition.\n",
        "korean": "신경기호적 인공지능(neurosymbolic AI, NSAI)은 투명성(transparency), 추론(reasoning), 적응(adaptation), 지각(perception)을 의미하는 TRAP라는 메타인지 인공지능(metacognitive artificial intelligence) 프레임워크 내에서 탐구됩니다. NSAI를 활용함으로써 연구는 메타인지의 도전 과제를 해결하고, 에이전트가 자신의 내부 프로세스를 추론하는 능력을 향상시키는 혁신적인 솔루션을 제공합니다. 이 탐구의 핵심 측면은 이러한 프로세스의 수학적 표현을 포함하며, AI 시스템의 적응은 $A(t+1) = A(t) + \\Delta A$로 표현될 수 있어 새로운 정보에 대한 AI 적응의 동적 특성을 강조합니다."
    },
    {
        "turn_index": 2,
        "term": "structured neural networks",
        "domain": "cs.AI",
        "summary": "  Artificial Intelligence(AI) widely applies in Image Classification and\nRecognition, Text Understanding and Natural Language Processing, which makes\ngreat progress. In this paper, we introduced AI into the fruit quality\ndetection field. We designed a fruit sugar degree regression model using an\nArtificial Neural Network based on spectra of fruits within the\nvisible/near-infrared(V/NIR)range. After analysis of fruit spectra, we\ninnovatively proposed a new neural network structure: low layers consist of a\nMultilayer Perceptron(MLP), a middle layer is a 2-dimensional correlation\nmatrix layer, and high layers consist of several Convolutional Neural\nNetwork(CNN) layers. In this study, we used fruit sugar value as a detection\ntarget, collecting two fruits called Gan Nan Navel and Tian Shan Pear as\nsamples, doing experiments respectively, and comparing their results. We used\nAnalysis of Variance(ANOVA) to evaluate the reliability of the dataset we\ncollected. Then, we tried multiple strategies to process spectrum data,\nevaluating their effects. In this paper, we tried to add Wavelet\nDecomposition(WD) to reduce feature dimensions and a Genetic Algorithm(GA) to\nfind excellent features. Then, we compared Neural Network models with\ntraditional Partial Least Squares(PLS) based models. We also compared the\nneural network structure we designed(MLP-CNN) with other traditional neural\nnetwork structures. In this paper, we proposed a new evaluation standard\nderived from dataset standard deviation(STD) for evaluating detection\nperformance, validating the viability of using an artificial neural network\nmodel to do fruit sugar degree nondestructive detection.\n",
        "english": "In the field of artificial intelligence, structured neural networks have been innovatively applied to fruit quality detection, specifically in designing a fruit sugar degree regression model based on the spectra of fruits within the visible/near-infrared (V/NIR) range. The proposed neural network structure is characterized by its unique composition: low layers consist of a Multilayer Perceptron (MLP), a middle layer is a 2-dimensional correlation matrix layer, and high layers are composed of several Convolutional Neural Network (CNN) layers. This novel approach not only compares favorably to traditional Partial Least Squares (PLS) based models but also establishes a new evaluation standard for detection performance, derived from dataset standard deviation (STD), thereby validating the effectiveness of structured neural networks in nondestructive detection tasks.",
        "korean": "인공지능 분야에서 구조화된 신경망(structured neural networks)은 과일 품질 검출에 혁신적으로 적용되어, 가시광선/근적외선(V/NIR) 범위 내에서 과일의 스펙트라를 기반으로 한 과일 당도 회귀 모델을 설계하는 데 사용되었습니다. 제안된 신경망 구조는 독특한 구성으로 특징지어집니다: 낮은 층은 다층 퍼셉트론(Multilayer Perceptron, MLP)으로 구성되고, 중간 층은 2차원 상관 행렬 층이며, 높은 층은 여러 개의 합성곱 신경망(Convolutional Neural Network, CNN) 층으로 구성됩니다. 이 새로운 접근 방식은 전통적인 부분 최소 제곱(Partial Least Squares, PLS) 기반 모델과 비교하여 우수할 뿐만 아니라, 데이터셋 표준 편차(standard deviation, STD)에서 파생된 검출 성능에 대한 새로운 평가 기준을 확립하여, 비파괴 검출 작업에서 구조화된 신경망(structured neural networks)의 효과성을 입증합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all English terms within parentheses are in lowercase."
    },
    {
        "turn_index": 2,
        "term": "causal graph networks",
        "domain": "cs.AI",
        "summary": "  Though a belief network (a representation of the joint probability\ndistribution, see [3]) and a causal network (a representation of causal\nrelationships [14]) are intended to mean different things, they are closely\nrelated. Both assume an underlying dag (directed acyclic graph) structure of\nrelations among variables and if Markov condition and faithfulness condition\n[15] are met, then a causal network is in fact a belief network. The difference\ncomes to appearance when we recover belief network and causal network structure\nfrom data.\n  A causal network structure may be impossible to recover completely from data\nas not all directions of causal links may be uniquely determined [15].\nFortunately, if we deal with causally sufficient sets of variables (that is\nwhenever significant influence variables are not omitted from observation),\nthen there exists the possibility to identify the family of belief networks a\ncausal network belongs to [16]. Regrettably, to our knowledge, a similar result\nis not directly known for causally insufficient sets of variables. Spirtes,\nGlymour and Scheines developed a CI algorithm to handle this situation, but it\nleaves some important questions open.\n  The big open question is whether or not the bidirectional edges (that is\nindications of a common cause) are the only ones necessary to develop a belief\nnetwork out of the product of CI, or must there be some other hidden variables\nadded (e.g. by guessing). This paper is devoted to settling this question.\n",
        "english": "Causal graph networks, which represent causal relationships, are closely related to belief networks, both assuming an underlying directed acyclic graph (DAG) structure of relations among variables. If the Markov condition and faithfulness condition are satisfied, then a causal network can be considered a belief network, where the probability distribution $P(X_1, X_2, \\ldots, X_n)$ is factorized according to the DAG structure. The challenge in recovering a causal network structure from data lies in the potential impossibility of uniquely determining all directions of causal links, highlighting the necessity of identifying causally sufficient sets of variables to ascertain the family of belief networks a causal network belongs to.",
        "korean": "인과 그래프 네트워크(causal graph networks)는 인과 관계를 나타내며, 변수들 간의 관계가 내재된 방향성 비순환 그래프(directed acyclic graph, dag) 구조를 가정하는 신념 네트워크(belief networks)와 밀접하게 관련되어 있습니다. 마르코프 조건(markov condition)과 충실성 조건(faithfulness condition)이 만족되면, 인과 네트워크(causal network)는 신념 네트워크(belief network)로 간주될 수 있으며, 확률 분포 $P(X_1, X_2, \\ldots, X_n)$는 dag 구조에 따라 분해됩니다. 데이터로부터 인과 네트워크 구조를 복원하는 데 있어 도전 과제는 인과 연결의 모든 방향을 고유하게 결정하는 것이 불가능할 수 있다는 점에 있으며, 이는 인과적으로 충분한 변수 집합을 식별하여 인과 네트워크가 속한 신념 네트워크의 계열을 확인하는 필요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural task-driven learning",
        "domain": "cs.AI",
        "summary": "  We use neural graph networks with a message-passing architecture and an\nattention mechanism to enhance the branching heuristic in two SAT-solving\nalgorithms. We report improvements of learned neural heuristics compared with\ntwo standard human-designed heuristics.\n",
        "english": "Neural task-driven learning leverages neural graph networks with a message-passing architecture and an attention mechanism to refine the branching heuristic in two SAT-solving algorithms, demonstrating a sophisticated integration of machine learning techniques in combinatorial optimization. By employing these advanced methodologies, the study reports improvements of learned neural heuristics compared to two standard human-designed heuristics, highlighting the potential of neural task-driven learning to surpass traditional approaches. Notably, the enhanced performance of the neural heuristics is quantified through comparisons, where the learned approach outperforms the baseline heuristics, as demonstrated by a reduction in the average number of decisions $D$ required to solve SAT instances, thereby establishing a new benchmark in the field.",
        "korean": "신경 과제 기반 학습(neural task-driven learning)은 메시지 전달 아키텍처(message-passing architecture)와 주의 메커니즘(attention mechanism)을 갖춘 신경 그래프 네트워크(neural graph networks)를 활용하여 두 가지 SAT 해결 알고리즘에서 분기 휴리스틱(branching heuristic)을 개선하며, 조합 최적화(combinatorial optimization)에서 기계 학습(machine learning) 기법의 정교한 통합을 보여줍니다. 이러한 고급 방법론을 사용함으로써, 연구는 학습된 신경 휴리스틱(neural heuristics)이 두 가지 표준 인간 설계 휴리스틱(human-designed heuristics)과 비교하여 개선되었음을 보고하며, 신경 과제 기반 학습(neural task-driven learning)이 전통적인 접근 방식을 능가할 잠재력을 강조합니다. 특히, 신경 휴리스틱(neural heuristics)의 향상된 성능은 비교를 통해 정량화되며, 학습된 접근 방식이 SAT 인스턴스를 해결하는 데 필요한 평균 결정 수 $D$를 줄임으로써 기준 휴리스틱(baseline heuristics)을 능가하는 것으로 나타나, 이 분야에서 새로운 기준을 확립합니다.",
        "score": 10,
        "parentheses_count": 12,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "active learning",
        "domain": "cs.AI",
        "summary": "  We present an unsupervised deep learning model for 3D object classification.\nConventional Hebbian learning, a well-known unsupervised model, suffers from\nloss of local features leading to reduced performance for tasks with complex\ngeometric objects. We present a deep network with a novel Neuron Activity Aware\n(NeAW) Hebbian learning rule that dynamically switches the neurons to be\ngoverned by Hebbian learning or anti-Hebbian learning, depending on its\nactivity. We analytically show that NeAW Hebbian learning relieves the bias in\nneuron activity, allowing more neurons to attend to the representation of the\n3D objects. Empirical results show that the NeAW Hebbian learning outperforms\nother variants of Hebbian learning and shows higher accuracy over fully\nsupervised models when training data is limited.\n",
        "english": "Active learning strategies can benefit from the innovative Neuron Activity Aware (NeAW) Hebbian learning rule, which dynamically switches neurons to be governed by Hebbian learning or anti-Hebbian learning based on their activity. This dynamic adjustment is analytically shown to relieve the bias in neuron activity, enabling more neurons to effectively represent complex 3D objects. Empirical results indicate that NeAW Hebbian learning outperforms other Hebbian learning variants and even achieves higher accuracy than fully supervised models when the training data is limited, underscoring its potential for efficient active learning applications.",
        "korean": "능동 학습 전략(active learning strategies)은 혁신적인 뉴런 활동 인식(neuron activity aware, neaw) 헤비안 학습 규칙(hebbian learning rule)을 통해 이점을 얻을 수 있습니다. 이 규칙은 뉴런의 활동에 따라 헤비안 학습(hebbian learning) 또는 반헤비안 학습(anti-hebbian learning)으로 뉴런을 동적으로 전환합니다. 이러한 동적 조정은 뉴런 활동의 편향을 완화하여 더 많은 뉴런이 복잡한 3d 객체를 효과적으로 표현할 수 있도록 하는 것으로 분석적으로 입증되었습니다. 실험 결과에 따르면 neaw 헤비안 학습(hebbian learning)은 다른 헤비안 학습 변형(hebbian learning variants)을 능가하며, 훈련 데이터가 제한된 경우에도 완전 지도 학습 모델(fully supervised models)보다 높은 정확도를 달성하여 효율적인 능동 학습 응용(active learning applications)의 잠재력을 강조합니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Ensure all English terms within parentheses are consistently in lowercase to maintain uniformity and improve readability."
    },
    {
        "turn_index": 2,
        "term": "differentiable neural computer",
        "domain": "cs.AI",
        "summary": "  Since their introduction, fuzzy sets and systems have become an important\narea of research known for its versatility in modelling, knowledge\nrepresentation and reasoning, and increasingly its potential within the context\nexplainable AI. While the applications of fuzzy systems are diverse, there has\nbeen comparatively little advancement in their design from a machine learning\nperspective. In other words, while representations such as neural networks have\nbenefited from a boom in learning capability driven by an increase in\ncomputational performance in combination with advances in their training\nmechanisms and available tool, in particular gradient descent, the impact on\nfuzzy system design has been limited. In this paper, we discuss\ngradient-descent-based optimisation of fuzzy systems, focussing in particular\non automatic differentiation -- crucial to neural network learning -- with a\nview to free fuzzy system designers from intricate derivative computations,\nallowing for more focus on the functional and explainability aspects of their\ndesign. As a starting point, we present a use case in FuzzyR which demonstrates\nhow current fuzzy inference system implementations can be adjusted to leverage\npowerful features of automatic differentiation tools sets, discussing its\npotential for the future of fuzzy system design.\n",
        "korean": "미분 가능한 신경 컴퓨터(differentiable neural computer, DNC)는 기계 학습(machine learning)에서 중요한 발전을 나타내며, 이는 역사적으로 \"계산 성능의 증가에 의해 주도된 학습 능력의 붐\"이 부족했던 퍼지 시스템(fuzzy systems)의 개발과 유사합니다. 신경망 학습에 중요한 기법인 경사 하강 기반 최적화(gradient-descent-based optimization)를 통합함으로써, DNC는 자동 미분(automatic differentiation)을 가능하게 하여 복잡한 계산을 복잡한 도함수 계산 없이 수행할 수 있습니다. 이 혁신은 DNC의 계산 효율성을 향상시킬 뿐만 아니라, 퍼지 추론 시스템(fuzzy inference systems)의 적응에서 \"자동 미분 도구 세트의 강력한 기능을 활용\"하는 것처럼 설명 가능한 인공지능(explainable AI)으로의 광범위한 추세와도 일치합니다."
    },
    {
        "turn_index": 2,
        "term": "learning to search",
        "domain": "cs.AI",
        "summary": "  We propose and evaluate a system which learns a neuralnetwork heuristic\nfunction for forward search-based, satisficing classical planning. Our system\nlearns distance-to-goal estimators from scratch, given a single PDDL training\ninstance. Training data is generated by backward regression search or by\nbackward search from given or guessed goal states. In domains such as the\n24-puzzle where all instances share the same search space, such heuristics can\nalso be reused across all instances in the domain. We show that this relatively\nsimple system can perform surprisingly well, sometimes competitive with\nwell-known domain-independent heuristics.\n",
        "english": "In the domain of learning to search, a novel system is proposed that \"learns a neural network heuristic function for forward search-based, satisficing classical planning.\" This system innovatively generates \"distance-to-goal estimators from scratch, given a single PDDL training instance,\" employing methodologies such as backward regression search or backward search from guessed goal states to create training data. Notably, in domains like the 24-puzzle, where the search space is consistent across all instances, these heuristics can be effectively reused, demonstrating that this approach can yield performance competitive with established domain-independent heuristics, suggesting that the system's heuristic function $h(s)$ can approximate the true cost-to-go function $c^*(s)$ with impressive accuracy.",
        "korean": "학습을 위한 검색(learning to search) 분야에서, \"전방 검색 기반의 만족스러운 고전 계획을 위한 신경망 휴리스틱 함수를 학습하는\" 새로운 시스템이 제안되었습니다. 이 시스템은 \"단일 PDDL 훈련 인스턴스를 주어진 상태에서 목표까지의 거리 추정기를 처음부터 생성\"하며, 훈련 데이터를 생성하기 위해 후방 회귀 검색 또는 추측된 목표 상태에서의 후방 검색과 같은 방법론을 사용합니다. 특히 24-퍼즐과 같은 도메인에서는 모든 인스턴스에서 검색 공간이 일관되기 때문에 이러한 휴리스틱을 효과적으로 재사용할 수 있으며, 이 접근 방식이 확립된 도메인 독립적 휴리스틱과 경쟁할 수 있는 성능을 제공할 수 있음을 보여줍니다. 이는 시스템의 휴리스틱 함수 $h(s)$가 실제 비용 함수 $c^*(s)$를 인상적인 정확도로 근사할 수 있음을 시사합니다.",
        "score": 10,
        "parentheses_count": 1,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "interpretable machine learning",
        "domain": "cs.AI",
        "summary": "  We provide a novel notion of what it means to be interpretable, looking past\nthe usual association with human understanding. Our key insight is that\ninterpretability is not an absolute concept and so we define it relative to a\ntarget model, which may or may not be a human. We define a framework that\nallows for comparing interpretable procedures by linking it to important\npractical aspects such as accuracy and robustness. We characterize many of the\ncurrent state-of-the-art interpretable methods in our framework portraying its\ngeneral applicability.\n",
        "english": "Interpretable machine learning is redefined in this research by proposing a \"novel notion of what it means to be interpretable,\" moving beyond the traditional association with human understanding. By introducing a framework that \"allows for comparing interpretable procedures\" through important practical aspects such as accuracy and robustness, the study highlights the relative nature of interpretability, which is defined \"relative to a target model, which may or may not be a human.\" Furthermore, the research characterizes current state-of-the-art interpretable methods within this framework, demonstrating its general applicability and emphasizing that interpretability is not an absolute concept but rather one that can be quantified and compared through metrics like accuracy ($A$) and robustness ($R$), where $I = f(A, R)$ represents an interpretable model's evaluation function.",
        "korean": "해석 가능한 기계 학습(interpretable machine learning)은 인간의 이해와의 전통적인 연관성을 넘어서는 \"해석 가능하다는 것의 새로운 개념\"을 제안함으로써 이 연구에서 재정의됩니다. 정확성과 견고성 같은 중요한 실용적 측면을 통해 \"해석 가능한 절차를 비교할 수 있는\" 프레임워크를 도입함으로써, 연구는 해석 가능성이 \"인간일 수도 있고 아닐 수도 있는 목표 모델에 상대적\"으로 정의되는 상대적 성격을 강조합니다. 또한, 연구는 이 프레임워크 내에서 현재 최첨단 해석 가능한 방법들을 특성화하여 그 일반적인 적용 가능성을 입증하고, 해석 가능성이 절대적인 개념이 아니라 정확성($A$)과 견고성($R$) 같은 지표를 통해 정량화되고 비교될 수 있는 개념임을 강조합니다. 여기서 $I = f(A, R)$는 해석 가능한 모델의 평가 함수로 나타냅니다.",
        "score": 10,
        "parentheses_count": 1,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "convolutional layers",
        "domain": "cs.AI",
        "summary": "  Recently, Graph Convolutional Networks (GCNs) have proven to be a powerful\nmean for Computer Aided Diagnosis (CADx). This approach requires building a\npopulation graph to aggregate structural information, where the graph adjacency\nmatrix represents the relationship between nodes. Until now, this adjacency\nmatrix is usually defined manually based on phenotypic information. In this\npaper, we propose an encoder that automatically selects the appropriate\nphenotypic measures according to their spatial distribution, and uses the text\nsimilarity awareness mechanism to calculate the edge weights between nodes. The\nencoder can automatically construct the population graph using phenotypic\nmeasures which have a positive impact on the final results, and further\nrealizes the fusion of multimodal information. In addition, a novel graph\nconvolution network architecture using multi-layer aggregation mechanism is\nproposed. The structure can obtain deep structure information while suppressing\nover-smooth, and increase the similarity between the same type of nodes.\nExperimental results on two databases show that our method can significantly\nimprove the diagnostic accuracy for Autism spectrum disorder and breast cancer,\nindicating its universality in leveraging multimodal data for disease\nprediction.\n",
        "english": "Graph Convolutional Networks (GCNs), which incorporate convolutional layers, have emerged as a potent tool for Computer Aided Diagnosis (CADx) by constructing a population graph to aggregate structural information, where the adjacency matrix $\\mathbf{A}$ represents node relationships. The innovative use of an encoder that automatically selects phenotypic measures based on spatial distribution and employs a text similarity awareness mechanism to compute edge weights between nodes exemplifies the advancement in leveraging convolutional layers for disease prediction. Experimental results demonstrate that the proposed multi-layer aggregation mechanism within the convolutional layers significantly enhances diagnostic accuracy for Autism spectrum disorder and breast cancer, underscoring the method's universality and efficacy in utilizing multimodal data.",
        "korean": "그래프 합성곱 신경망(graph convolutional networks, GCNs)은 합성곱 층(convolutional layers)을 통합하여 구조적 정보를 집계하기 위해 인구 그래프를 구성함으로써 컴퓨터 보조 진단(computer aided diagnosis, CADx)의 강력한 도구로 부상했습니다. 인접 행렬 $\\mathbf{A}$는 노드 간의 관계를 나타냅니다. 공간적 분포에 기반하여 표현형 측정을 자동으로 선택하는 인코더와 노드 간의 엣지 가중치를 계산하기 위해 텍스트 유사성 인식 메커니즘을 사용하는 혁신적인 방법은 질병 예측을 위한 합성곱 층(convolutional layers)의 활용을 보여줍니다. 실험 결과는 합성곱 층(convolutional layers) 내의 제안된 다층 집계 메커니즘이 자폐 스펙트럼 장애와 유방암의 진단 정확도를 크게 향상시킴을 보여주며, 다중 모달 데이터(multimodal data)를 활용하는 방법의 보편성과 효율성을 강조합니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "knowledge distillation",
        "domain": "cs.AI",
        "summary": "  Traditional knowledge graph embedding (KGE) methods typically require\npreserving the entire knowledge graph (KG) with significant training costs when\nnew knowledge emerges. To address this issue, the continual knowledge graph\nembedding (CKGE) task has been proposed to train the KGE model by learning\nemerging knowledge efficiently while simultaneously preserving decent old\nknowledge. However, the explicit graph structure in KGs, which is critical for\nthe above goal, has been heavily ignored by existing CKGE methods. On the one\nhand, existing methods usually learn new triples in a random order, destroying\nthe inner structure of new KGs. On the other hand, old triples are preserved\nwith equal priority, failing to alleviate catastrophic forgetting effectively.\nIn this paper, we propose a competitive method for CKGE based on incremental\ndistillation (IncDE), which considers the full use of the explicit graph\nstructure in KGs. First, to optimize the learning order, we introduce a\nhierarchical strategy, ranking new triples for layer-by-layer learning. By\nemploying the inter- and intra-hierarchical orders together, new triples are\ngrouped into layers based on the graph structure features. Secondly, to\npreserve the old knowledge effectively, we devise a novel incremental\ndistillation mechanism, which facilitates the seamless transfer of entity\nrepresentations from the previous layer to the next one, promoting old\nknowledge preservation. Finally, we adopt a two-stage training paradigm to\navoid the over-corruption of old knowledge influenced by under-trained new\nknowledge. Experimental results demonstrate the superiority of IncDE over\nstate-of-the-art baselines. Notably, the incremental distillation mechanism\ncontributes to improvements of 0.2%-6.5% in the mean reciprocal rank (MRR)\nscore.\n",
        "english": "The innovative approach of knowledge distillation, as applied in the competitive method for continual knowledge graph embedding (CKGE) known as incremental distillation (IncDE), leverages the explicit graph structure in knowledge graphs (KGs) to optimize learning and preserve knowledge. By employing a hierarchical strategy that ranks new triples for layer-by-layer learning, IncDE groups new triples into layers based on graph structure features, thereby facilitating the seamless transfer of entity representations from the previous layer to the next one, which effectively promotes old knowledge preservation. Notably, the incremental distillation mechanism contributes to significant improvements in the mean reciprocal rank (MRR) score, with gains ranging from $0.2\\%$ to $6.5\\%$, thus demonstrating its superiority over state-of-the-art baselines.",
        "korean": "지식 증류(knowledge distillation)의 혁신적인 접근 방식은 지속적인 지식 그래프 임베딩(continual knowledge graph embedding, CKGE)을 위한 경쟁 방법으로 알려진 점진적 증류(incremental distillation, IncDE)에서 적용되어 학습을 최적화하고 지식을 보존하기 위해 지식 그래프(knowledge graphs, KGs)의 명시적 그래프 구조를 활용합니다. 계층적 전략을 사용하여 새로운 삼중항을 계층별 학습을 위해 순위를 매기고, IncDE는 그래프 구조 특징에 따라 새로운 삼중항을 계층으로 그룹화하여 이전 계층에서 다음 계층으로 엔티티 표현의 원활한 전이를 촉진하며, 이는 효과적으로 기존 지식의 보존을 촉진합니다. 특히, 점진적 증류 메커니즘은 평균 역순위(mean reciprocal rank, MRR) 점수에서 $0.2\\%$에서 $6.5\\%$까지의 향상을 기여하며, 최첨단 기준선(state-of-the-art baselines)보다 우수함을 입증합니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase letters within parentheses."
    },
    {
        "turn_index": 2,
        "term": "semantic adaptive learning",
        "domain": "cs.AI",
        "summary": "  As the number of Human-Centered Internet of Things (HCIoT) applications\nincreases, the self-adaptation of its services and devices is becoming a\nfundamental requirement for addressing the uncertainties of the environment in\ndecision-making processes. Self-adaptation of HCIoT aims to manage run-time\nchanges in a dynamic environment and to adjust the functionality of IoT objects\nin order to achieve desired goals during execution. SMASH is a semantic-enabled\nmulti-agent system for self-adaptation of HCIoT that autonomously adapts IoT\nobjects to uncertainties of their environment. SMASH addresses the\nself-adaptation of IoT applications only according to the human values of\nusers, while the behavior of users is not addressed. This article presents\nQ-SMASH: a multi-agent reinforcement learning-based approach for\nself-adaptation of IoT objects in human-centered environments. Q-SMASH aims to\nlearn the behaviors of users along with respecting human values. The learning\nability of Q-SMASH allows it to adapt itself to the behavioral change of users\nand make more accurate decisions in different states and situations.\n",
        "english": "Semantic adaptive learning plays a crucial role in the self-adaptation of Human-Centered Internet of Things (HCIoT) applications, as it allows systems to autonomously adjust IoT objects to the uncertainties of their environment while respecting human values. The innovative Q-SMASH framework incorporates a multi-agent reinforcement learning approach, which not only facilitates semantic adaptive learning but also enables the system to learn and adapt to user behaviors, thereby enhancing decision-making accuracy. Mathematically, the reinforcement learning model in Q-SMASH optimizes the policy $\\pi(a|s)$ to maximize the expected reward $E[R|s]$ in various states and situations, showcasing its ability to dynamically respond to environmental changes and user interactions.",
        "korean": "의미 적응 학습(semantic adaptive learning)은 인간 중심 사물 인터넷(Human-Centered Internet of Things, HCIoT) 응용 프로그램의 자기 적응에 중요한 역할을 하며, 이는 시스템이 인간의 가치를 존중하면서 환경의 불확실성에 IoT 객체를 자율적으로 조정할 수 있게 합니다. 혁신적인 Q-SMASH 프레임워크는 다중 에이전트 강화 학습 접근법을 통합하여 의미 적응 학습(semantic adaptive learning)을 촉진할 뿐만 아니라 시스템이 사용자 행동을 학습하고 적응할 수 있게 하여 의사 결정의 정확성을 향상시킵니다. 수학적으로, Q-SMASH의 강화 학습 모델은 다양한 상태와 상황에서 기대 보상 $E[R|s]$을 최대화하기 위해 정책 $\\pi(a|s)$를 최적화하며, 환경 변화와 사용자 상호작용에 동적으로 대응할 수 있는 능력을 보여줍니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar"
    },
    {
        "turn_index": 2,
        "term": "neural probabilistic sequence models",
        "domain": "cs.AI",
        "summary": "  We study the problem of learning probabilistic first-order logical rules for\nknowledge base reasoning. This learning problem is difficult because it\nrequires learning the parameters in a continuous space as well as the structure\nin a discrete space. We propose a framework, Neural Logic Programming, that\ncombines the parameter and structure learning of first-order logical rules in\nan end-to-end differentiable model. This approach is inspired by a\nrecently-developed differentiable logic called TensorLog, where inference tasks\ncan be compiled into sequences of differentiable operations. We design a neural\ncontroller system that learns to compose these operations. Empirically, our\nmethod outperforms prior work on multiple knowledge base benchmark datasets,\nincluding Freebase and WikiMovies.\n",
        "english": "Neural probabilistic sequence models address the challenge of learning probabilistic first-order logical rules for knowledge base reasoning by necessitating the learning of parameters in a continuous space alongside structure in a discrete space. These models are inspired by the differentiable logic framework of TensorLog, where inference tasks are represented as sequences of differentiable operations, allowing for an end-to-end differentiable model. The innovation of employing a neural controller system to compose these operations has demonstrated empirical superiority over previous methodologies on benchmark datasets such as Freebase and WikiMovies, highlighting the potential of neural probabilistic sequence models in advancing knowledge base reasoning.",
        "korean": "신경 확률적 시퀀스 모델(neural probabilistic sequence models)은 지식 기반 추론을 위한 확률적 1차 논리 규칙을 학습하는 문제를 해결하기 위해 연속 공간에서의 매개변수 학습과 이산 공간에서의 구조 학습을 필요로 합니다. 이러한 모델은 TensorLog의 미분 가능 논리 프레임워크(differentiable logic framework)에서 영감을 받아, 추론 작업을 미분 가능한 연산의 시퀀스로 표현하여 종단 간 미분 가능한 모델을 가능하게 합니다. 이러한 연산을 구성하기 위해 신경 제어 시스템(neural controller system)을 사용하는 혁신은 Freebase와 WikiMovies와 같은 벤치마크 데이터셋에서 이전 방법론보다 경험적으로 우수함을 입증하여, 신경 확률적 시퀀스 모델(neural probabilistic sequence models)이 지식 기반 추론을 발전시키는 데 잠재력을 가지고 있음을 강조합니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "adaptive boosting",
        "domain": "cs.AI",
        "summary": "  Recent literature has found that an effective method to customize or further\nimprove large language models (LLMs) is to add dynamic adapters, such as\nlow-rank adapters (LoRA) with Mixture-of-Experts (MoE) structures. Though such\ndynamic adapters incur modest computational complexity, they surprisingly lead\nto huge inference latency overhead, slowing down the decoding speed by 2.5+\ntimes. In this paper, we analyze the fine-grained costs of the dynamic adapters\nand find that the fragmented CUDA kernel calls are the root cause. Therefore,\nwe propose LoRA-Switch, a system-algorithm co-designed architecture for\nefficient dynamic adapters. Unlike most existing dynamic structures that adopt\nlayer-wise or block-wise dynamic routing, LoRA-Switch introduces a token-wise\nrouting mechanism. It switches the LoRA adapters and weights for each token and\nmerges them into the backbone for inference. For efficiency, this switching is\nimplemented with an optimized CUDA kernel, which fuses the merging operations\nfor all LoRA adapters at once. Based on experiments with popular open-source\nLLMs on common benchmarks, our approach has demonstrated similar accuracy\nimprovement as existing dynamic adapters, while reducing the decoding latency\nby more than 2.4 times.\n",
        "english": "Adaptive boosting techniques, such as the introduction of token-wise routing mechanisms in LoRA-Switch, have significantly enhanced the efficiency of dynamic adapters in large language models (LLMs). By optimizing CUDA kernel operations, LoRA-Switch reduces the decoding latency by more than 2.4 times while maintaining similar accuracy improvements as existing dynamic adapters, thus demonstrating the potential of adaptive boosting to streamline computational processes. Furthermore, the mathematical efficiency of this approach is evident in the reduction of inference latency overhead, which previously slowed down the decoding speed by over 2.5 times, emphasizing the innovative nature of adaptive boosting methodologies.",
        "korean": "적응형 부스팅(adaptive boosting) 기법, 예를 들어 LoRA-Switch에서의 토큰 단위 라우팅 메커니즘(token-wise routing mechanisms) 도입은 대형 언어 모델(large language models, LLMs)에서 동적 어댑터(dynamic adapters)의 효율성을 크게 향상시켰습니다. CUDA 커널 연산(CUDA kernel operations)을 최적화함으로써, LoRA-Switch는 기존 동적 어댑터와 유사한 정확도 향상을 유지하면서 디코딩 지연을 2.4배 이상 줄여 적응형 부스팅(adaptive boosting)이 계산 과정을 간소화할 수 있는 잠재력을 보여줍니다. 더욱이, 이 접근법의 수학적 효율성은 추론 지연 오버헤드(inference latency overhead)를 줄이는 데 명백히 드러나며, 이는 이전에 디코딩 속도를 2.5배 이상 늦췄던 문제를 해결하여 적응형 부스팅(adaptive boosting) 방법론의 혁신적인 특성을 강조합니다.",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "dynamic neural networks",
        "domain": "cs.AI",
        "summary": "  Unlike traditional static deep neural networks (DNNs), dynamic neural\nnetworks (NNs) adjust their structures or parameters to different inputs to\nguarantee accuracy and computational efficiency. Meanwhile, it has been an\nemerging research area in deep learning recently. Although traditional static\nDNNs are vulnerable to the membership inference attack (MIA) , which aims to\ninfer whether a particular point was used to train the model, little is known\nabout how such an attack performs on the dynamic NNs. In this paper, we propose\na novel MI attack against dynamic NNs, leveraging the unique policy networks\nmechanism of dynamic NNs to increase the effectiveness of membership inference.\nWe conducted extensive experiments using two dynamic NNs, i.e., GaterNet,\nBlockDrop, on four mainstream image classification tasks, i.e., CIFAR-10,\nCIFAR-100, STL-10, and GTSRB. The evaluation results demonstrate that the\ncontrol-flow information can significantly promote the MIA. Based on\nbackbone-finetuning and information-fusion, our method achieves better results\nthan baseline attack and traditional attack using intermediate information.\n",
        "english": "Dynamic neural networks (NNs) offer a significant advancement over traditional static deep neural networks (DNNs) by adjusting their structures or parameters to different inputs, thus ensuring both accuracy and computational efficiency. In this context, a novel membership inference (MI) attack has been proposed, leveraging the unique policy networks mechanism of dynamic NNs to enhance the effectiveness of membership inference, particularly through the control-flow information which significantly promotes the MIA. Extensive experiments conducted using two dynamic NNs, GaterNet and BlockDrop, on image classification tasks such as CIFAR-10, CIFAR-100, STL-10, and GTSRB, demonstrate that the proposed method achieves superior results compared to baseline and traditional attacks by utilizing backbone-finetuning and information-fusion, with an accuracy improvement of up to \\( \\Delta \\text{acc} \\).",
        "korean": "동적 신경망(dynamic neural networks)은 전통적인 정적 심층 신경망(static deep neural networks, DNNs)에 비해 구조나 매개변수를 다양한 입력에 맞춰 조정함으로써 정확성과 계산 효율성을 모두 보장하는 중요한 발전을 제공합니다. 이와 관련하여, 동적 신경망(dynamic neural networks)의 고유한 정책 네트워크 메커니즘을 활용하여 멤버십 추론 공격(membership inference attack, MIA)의 효과를 특히 제어 흐름 정보를 통해 크게 향상시키는 새로운 멤버십 추론 공격(membership inference, MI)이 제안되었습니다. GaterNet과 BlockDrop이라는 두 가지 동적 신경망(dynamic neural networks)을 사용하여 CIFAR-10, CIFAR-100, STL-10, GTSRB와 같은 이미지 분류 작업에서 수행된 광범위한 실험은 백본 미세 조정(backbone-finetuning)과 정보 융합(information-fusion)을 활용하여 제안된 방법이 기준선 및 전통적인 공격에 비해 우수한 결과를 달성하며, 최대 \\( \\Delta \\text{acc} \\)의 정확도 향상을 보여줍니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar."
    },
    {
        "turn_index": 2,
        "term": "data-driven decision making",
        "domain": "cs.AI",
        "summary": "  We explored decision-making dynamics in social systems, referencing the 'herd\nbehavior' from prior studies where individuals follow preceding choices without\nunderstanding the underlying reasons. While previous research highlighted a\npreference for the optimal choice without external influences, our study\nintroduced principals or external guides, adding complexity to the\ndecision-making process. The reliability of these principals significantly\ninfluenced decisions. Notably, even occasional trust in an unreliable principal\ncould alter decision outcomes. Furthermore, when a principal's advice was\npurely random, heightened trust led to more decision errors. Our findings\nemphasize the need for caution when placing trust in decision-making contexts.\n",
        "english": "Data-driven decision making in social systems often encounters challenges similar to 'herd behavior', where individuals may follow preceding choices without fully understanding the underlying reasons, as highlighted in prior studies. Our research introduced principals or external guides into the decision-making process, revealing that the reliability of these principals significantly influenced decisions, with even occasional trust in an unreliable principal altering outcomes. Notably, when the principal's advice was purely random, heightened trust led to more decision errors, as demonstrated by an increase in error rate $E = P(T|R) - P(T|\\neg R)$, where $P(T|R)$ is the probability of making a correct decision with reliable advice, and $P(T|\\neg R)$ is the probability with unreliable advice, underscoring the need for caution in trusting external guidance in data-driven contexts.",
        "korean": "사회 시스템에서 데이터 기반 의사 결정(data-driven decision making)은 종종 이전 연구에서 강조된 바와 같이 '군집 행동(herd behavior)'과 유사한 도전에 직면합니다. 이는 개인이 근본적인 이유를 완전히 이해하지 못한 채 앞선 선택을 따를 수 있는 상황을 말합니다. 우리의 연구는 의사 결정 과정에 원칙자나 외부 가이드를 도입하여, 이러한 원칙자의 신뢰성이 결정에 상당한 영향을 미친다는 것을 밝혀냈습니다. 심지어 신뢰할 수 없는 원칙자에 대한 가끔의 신뢰도 결과를 변화시킬 수 있었습니다. 특히, 원칙자의 조언이 순전히 무작위일 때, 신뢰가 높아지면 결정 오류가 증가하는 것으로 나타났습니다. 이는 $E = P(T|R) - P(T|\\neg R)$의 오류율 증가로 입증되었으며, 여기서 $P(T|R)$은 신뢰할 수 있는 조언으로 올바른 결정을 내릴 확률이고, $P(T|\\neg R)$은 신뢰할 수 없는 조언으로 올바른 결정을 내릴 확률입니다. 이는 데이터 기반 맥락에서 외부 지침을 신뢰하는 데 있어 주의가 필요함을 강조합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "non-negative matrix factorization",
        "domain": "cs.AI",
        "summary": "  Centralized training is widely utilized in the field of multi-agent\nreinforcement learning (MARL) to assure the stability of training process. Once\na joint policy is obtained, it is critical to design a value function\nfactorization method to extract optimal decentralized policies for the agents,\nwhich needs to satisfy the individual-global-max (IGM) principle. While\nimposing additional limitations on the IGM function class can help to meet the\nrequirement, it comes at the cost of restricting its application to more\ncomplex multi-agent environments. In this paper, we propose QFree, a universal\nvalue function factorization method for MARL. We start by developing\nmathematical equivalent conditions of the IGM principle based on the advantage\nfunction, which ensures that the principle holds without any compromise,\nremoving the conservatism of conventional methods. We then establish a more\nexpressive mixing network architecture that can fulfill the equivalent\nfactorization. In particular, the novel loss function is developed by\nconsidering the equivalent conditions as regularization term during policy\nevaluation in the MARL algorithm. Finally, the effectiveness of the proposed\nmethod is verified in a nonmonotonic matrix game scenario. Moreover, we show\nthat QFree achieves the state-of-the-art performance in a general-purpose\ncomplex MARL benchmark environment, Starcraft Multi-Agent Challenge (SMAC).\n",
        "korean": "비음수 행렬 분해(non-negative matrix factorization, NMF)는 다중 에이전트 강화 학습(multi-agent reinforcement learning, MARL)에서 에이전트의 최적 분산 정책을 추출하기 위한 가치 함수 분해 방법을 설계하는 데 활용될 수 있으며, 이는 개별-글로벌-최대(individual-global-max, IGM) 원칙을 만족해야 합니다. 이점 함수를 기반으로 IGM 원칙의 수학적 동등 조건을 개발함으로써, NMF는 원칙이 타협 없이 유지되도록 보장하여 기존 방법의 보수성을 제거합니다. QFree 방법으로 예시되는 이 혁신적인 접근법은 동등한 분해를 충족할 수 있는 보다 표현력 있는 혼합 네트워크 아키텍처를 구축함으로써 스타크래프트 다중 에이전트 챌린지(Starcraft Multi-Agent Challenge, SMAC)와 같은 복잡한 MARL 환경에서 최첨단 성능을 달성합니다."
    },
    {
        "turn_index": 2,
        "term": "semantic probabilistic learning",
        "domain": "cs.AI",
        "summary": "  Over the past three decades, the logic programming paradigm has been\nsuccessfully expanded to support probabilistic modeling, inference and\nlearning. The resulting paradigm of probabilistic logic programming (PLP) and\nits programming languages owes much of its success to a declarative semantics,\nthe so-called distribution semantics. However, the distribution semantics is\nlimited to discrete random variables only. While PLP has been extended in\nvarious ways for supporting hybrid, that is, mixed discrete and continuous\nrandom variables, we are still lacking a declarative semantics for hybrid PLP\nthat not only generalizes the distribution semantics and the modeling language\nbut also the standard inference algorithm that is based on knowledge\ncompilation. We contribute the measure semantics together with the hybrid PLP\nlanguage DC-ProbLog (where DC stands for distributional clauses) and its\ninference engine infinitesimal algebraic likelihood weighting (IALW). These\nhave the original distribution semantics, standard PLP languages such as\nProbLog, and standard inference engines for PLP based on knowledge compilation\nas special cases. Thus, we generalize the state of the art of PLP towards\nhybrid PLP in three different aspects: semantics, language and inference.\nFurthermore, IALW is the first inference algorithm for hybrid probabilistic\nprogramming based on knowledge compilation\n",
        "english": "Semantic probabilistic learning builds upon the advancements in probabilistic logic programming (PLP), which has successfully incorporated probabilistic modeling, inference, and learning into the logic programming paradigm, primarily through the distribution semantics that handle discrete random variables. To address the limitation of discrete-only variables, the research introduces the measure semantics and hybrid PLP language DC-ProbLog, alongside the novel inference engine, infinitesimal algebraic likelihood weighting (IALW), which is the first to support hybrid probabilistic programming with both discrete and continuous variables using knowledge compilation. Importantly, this advancement generalizes PLP by integrating semantics, language, and inference, thus extending the traditional distribution semantics, standard PLP languages such as ProbLog, and inference algorithms, with the measure semantics allowing for a more comprehensive representation, denoted as $P(X \\mid \\theta) = \\int_{\\Omega} f(x, \\theta) \\, d\\mu(\\omega)$ where $\\Omega$ represents the sample space.",
        "korean": "의미 확률 학습(semantic probabilistic learning)은 확률 논리 프로그래밍(probabilistic logic programming, PLP)의 발전을 기반으로 하며, 이는 주로 이산 확률 변수(discrete random variables)를 처리하는 분포 의미론(distribution semantics)을 통해 확률 모델링, 추론 및 학습을 논리 프로그래밍 패러다임에 성공적으로 통합했습니다. 이산 변수만을 다루는 한계를 해결하기 위해 연구는 측정 의미론(measure semantics)과 하이브리드 PLP 언어 DC-ProbLog, 그리고 지식 컴파일(knowledge compilation)을 사용하여 이산 및 연속 변수를 모두 지원하는 최초의 하이브리드 확률 프로그래밍(hybrid probabilistic programming) 추론 엔진인 무한소 대수적 가능도 가중치(infinitesimal algebraic likelihood weighting, IALW)를 도입합니다. 중요한 점은 이러한 발전이 의미론, 언어 및 추론을 통합하여 PLP를 일반화함으로써 전통적인 분포 의미론, ProbLog와 같은 표준 PLP 언어 및 추론 알고리즘을 확장하며, 측정 의미론은 보다 포괄적인 표현을 가능하게 하여 $P(X \\mid \\theta) = \\int_{\\Omega} f(x, \\theta) \\, d\\mu(\\omega)$로 나타내며, 여기서 $\\Omega$는 표본 공간(sample space)을 나타냅니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural networks",
        "domain": "cs.AI",
        "summary": "  Cybersecurity is the security cornerstone of digital transformation of the\npower grid and construction of new power systems. The traditional network\nsecurity situation quantification method only analyzes from the perspective of\nnetwork performance, ignoring the impact of various power application services\non the security situation, so the quantification results cannot fully reflect\nthe power information network risk state. This study proposes a method for\nquantifying security situation of the power information network based on the\nevolutionary neural network. First, the security posture system architecture is\ndesigned by analyzing the business characteristics of power information network\napplications. Second, combining the importance of power application business,\nthe spatial element index system of coupled interconnection is established from\nthree dimensions of network reliability, threat, and vulnerability. Then, the\nBP neural network optimized by the genetic evolutionary algorithm is\nincorporated into the element index calculation process, and the quantitative\nmodel of security posture of the power information network based on the\nevolutionary neural network is constructed. Finally, a simulation experiment\nenvironment is built according to a power sector network topology, and the\neffectiveness and robustness of the method proposed in the study are verified.\n",
        "english": "The quantification of the power information network's security situation is innovatively enhanced by employing an evolutionary neural network, which integrates a BP neural network optimized by a genetic evolutionary algorithm. This approach constructs a quantitative model that evaluates the network's security posture, taking into account dimensions such as network reliability, threat, and vulnerability, thereby addressing the limitations of traditional methods that focus solely on network performance. The robustness and effectiveness of the proposed method are validated through simulation experiments, demonstrating its potential to more accurately reflect the risk state of power information networks.",
        "korean": "전력 정보 네트워크의 보안 상황 정량화는 유전적 진화 알고리즘(genetic evolutionary algorithm)으로 최적화된 BP 신경망(BP neural network)을 통합한 진화적 신경망(evolutionary neural networks)을 활용하여 혁신적으로 향상됩니다. 이 접근 방식은 네트워크의 신뢰성, 위협, 취약성과 같은 차원을 고려하여 네트워크의 보안 태세를 평가하는 정량적 모델을 구축함으로써 네트워크 성능에만 초점을 맞춘 전통적인 방법의 한계를 해결합니다. 제안된 방법의 견고성과 효과는 시뮬레이션 실험을 통해 검증되었으며, 전력 정보 네트워크의 위험 상태를 보다 정확하게 반영할 수 있는 잠재력을 보여줍니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Ensure consistency in the use of parentheses by adjusting the translation to 신경망(neural networks) for all instances of the term."
    },
    {
        "turn_index": 2,
        "term": "learned optimizers",
        "domain": "cs.AI",
        "summary": "  Discounted reinforcement learning is fundamentally incompatible with function\napproximation for control in continuing tasks. It is not an optimization\nproblem in its usual formulation, so when using function approximation there is\nno optimal policy. We substantiate these claims, then go on to address some\nmisconceptions about discounting and its connection to the average reward\nformulation. We encourage researchers to adopt rigorous optimization\napproaches, such as maximizing average reward, for reinforcement learning in\ncontinuing tasks.\n",
        "english": "Learned optimizers present a novel approach to reinforcement learning by addressing the \"fundamental incompatibility\" of discounted reinforcement learning with function approximation in continuing tasks. By shifting the focus from discounting to \"rigorous optimization approaches, such as maximizing average reward,\" learned optimizers aim to create more effective policies for control tasks. This innovative methodology challenges traditional reinforcement learning paradigms by suggesting that the average reward formulation can be more suitable, especially when considering $\\text{arg max}_\\pi \\mathbb{E}[R|\\pi]$, where $\\pi$ represents the policy and $R$ the reward.",
        "korean": "학습된 최적화기(learned optimizers)는 지속적인 작업에서 함수 근사와 할인 강화 학습의 \"근본적인 비호환성\"을 해결함으로써 강화 학습에 대한 새로운 접근 방식을 제시합니다. 할인에서 \"평균 보상 극대화와 같은 엄격한 최적화 접근법\"으로 초점을 전환함으로써, 학습된 최적화기(learned optimizers)는 제어 작업에 대한 보다 효과적인 정책을 생성하는 것을 목표로 합니다. 이 혁신적인 방법론은 평균 보상 공식이 특히 $\\text{arg max}_\\pi \\mathbb{E}[R|\\pi]$에서 더 적합할 수 있음을 제안함으로써 전통적인 강화 학습 패러다임에 도전합니다. 여기서 $\\pi$는 정책을, $R$은 보상을 나타냅니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "contrastive loss",
        "domain": "cs.AI",
        "summary": "  To improve the detection accuracy and generalization of steganalysis, this\npaper proposes the Steganalysis Contrastive Framework (SCF) based on\ncontrastive learning. The SCF improves the feature representation of\nsteganalysis by maximizing the distance between features of samples of\ndifferent categories and minimizing the distance between features of samples of\nthe same category. To decrease the computing complexity of the contrastive loss\nin supervised learning, we design a novel Steganalysis Contrastive Loss\n(StegCL) based on the equivalence and transitivity of similarity. The StegCL\neliminates the redundant computing in the existing contrastive loss. The\nexperimental results show that the SCF improves the generalization and\ndetection accuracy of existing steganalysis DNNs, and the maximum promotion is\n2% and 3% respectively. Without decreasing the detection accuracy, the training\ntime of using the StegCL is 10% of that of using the contrastive loss in\nsupervised learning.\n",
        "english": "The Steganalysis Contrastive Framework (SCF) leverages contrastive loss to enhance steganalysis by \"maximizing the distance between features of samples of different categories and minimizing the distance between features of samples of the same category.\" To address the computational challenges associated with contrastive loss in supervised learning, the authors introduce a novel Steganalysis Contrastive Loss (StegCL), which is \"based on the equivalence and transitivity of similarity,\" thereby reducing redundant computations. Notably, the implementation of StegCL results in a significant reduction in training time to just 10% of that required by traditional contrastive loss, without compromising detection accuracy, as demonstrated by a \"maximum promotion\" in generalization and detection accuracy of 2% and 3%, respectively.",
        "korean": "스테가분석 대조 프레임워크(Steganalysis Contrastive Framework, SCF)는 대조 손실(contrastive loss)을 활용하여 \"다른 범주의 샘플 특징 간의 거리를 최대화하고 동일한 범주의 샘플 특징 간의 거리를 최소화\"함으로써 스테가분석을 향상시킵니다. 감독 학습에서 대조 손실(contrastive loss)과 관련된 계산 문제를 해결하기 위해, 저자들은 \"유사성의 동등성과 전이성에 기반\"하여 중복 계산을 줄이는 새로운 스테가분석 대조 손실(Steganalysis Contrastive Loss, StegCL)을 도입합니다. 특히, StegCL의 구현은 전통적인 대조 손실(contrastive loss)에서 요구되는 훈련 시간을 10%로 크게 줄이면서도 탐지 정확도를 손상시키지 않으며, 일반화 및 탐지 정확도에서 각각 2%와 3%의 \"최대 향상\"을 보여줍니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "ensemble neural networks",
        "domain": "cs.AI",
        "summary": "  An ensemble based approach for dealing with missing data, without predicting\nor imputing the missing values is proposed. This technique is suitable for\nonline operations of neural networks and as a result, is used for online\ncondition monitoring. The proposed technique is tested in both classification\nand regression problems. An ensemble of Fuzzy-ARTMAPs is used for\nclassification whereas an ensemble of multi-layer perceptrons is used for the\nregression problem. Results obtained using this ensemble-based technique are\ncompared to those obtained using a combination of auto-associative neural\nnetworks and genetic algorithms and findings show that this method can perform\nup to 9% better in regression problems. Another advantage of the proposed\ntechnique is that it eliminates the need for finding the best estimate of the\ndata, and hence, saves time.\n",
        "korean": "앙상블 신경망(ensemble neural networks)은 결측 데이터를 예측하거나 대체할 필요 없이 처리할 수 있는 혁신적인 접근 방식을 제시하여 신경망의 온라인 운영 효율성을 향상시킵니다. 구체적으로, 퍼지-ARTMAP(fuzzy-ARTMAP)의 앙상블은 분류 작업에 효과적으로 활용되었으며, 다층 퍼셉트론(multi-layer perceptrons)의 앙상블은 회귀 문제에서 전통적인 자동 연관 신경망(auto-associative neural networks) 및 유전 알고리즘(genetic algorithms)을 포함한 방법에 비해 최대 9\\% 더 나은 성능을 보여주었습니다. 이 기술은 정확성을 향상시킬 뿐만 아니라 데이터의 최적 추정치를 결정할 필요성을 제거하여 온라인 상태 모니터링 응용 프로그램에서 시간과 자원을 크게 절약합니다."
    },
    {
        "turn_index": 2,
        "term": "metric learning",
        "domain": "cs.AI",
        "summary": "  Machine learning (ML) and artificial intelligence (AI) approaches are often\ncriticized for their inherent bias and for their lack of control,\naccountability, and transparency. Consequently, regulatory bodies struggle with\ncontaining this technology's potential negative side effects. High-level\nrequirements such as fairness and robustness need to be formalized into\nconcrete specification metrics, imperfect proxies that capture isolated aspects\nof the underlying requirements. Given possible trade-offs between different\nmetrics and their vulnerability to over-optimization, integrating specification\nmetrics in system development processes is not trivial. This paper defines\nspecification overfitting, a scenario where systems focus excessively on\nspecified metrics to the detriment of high-level requirements and task\nperformance. We present an extensive literature survey to categorize how\nresearchers propose, measure, and optimize specification metrics in several AI\nfields (e.g., natural language processing, computer vision, reinforcement\nlearning). Using a keyword-based search on papers from major AI conferences and\njournals between 2018 and mid-2023, we identify and analyze 74 papers that\npropose or optimize specification metrics. We find that although most papers\nimplicitly address specification overfitting (e.g., by reporting more than one\nspecification metric), they rarely discuss which role specification metrics\nshould play in system development or explicitly define the scope and\nassumptions behind metric formulations.\n",
        "english": "Metric learning, as an integral component of AI and machine learning (ML), faces challenges due to \"inherent bias and for their lack of control, accountability, and transparency,\" which complicates the formalization of high-level requirements such as fairness and robustness into concrete specification metrics. To address these challenges, researchers have employed various strategies, including the use of multiple specification metrics to mitigate specification overfitting, defined as a scenario where systems focus excessively on specified metrics, potentially compromising task performance. A key insight from the literature is the trade-off between different metrics, where the optimization of a metric $M$ may result in overfitting, emphasizing the importance of a balanced approach in metric learning to achieve comprehensive system development.",
        "korean": "인공지능(AI) 및 기계 학습(ML)의 필수 구성 요소로서의 메트릭 학습(metric learning)은 \"내재된 편향과 통제, 책임, 투명성의 부족\"으로 인해 공정성과 견고성 같은 고수준 요구 사항을 구체적인 명세 메트릭으로 형식화하는 데 어려움을 겪고 있습니다. 이러한 문제를 해결하기 위해 연구자들은 명세 과적합(specification overfitting)을 완화하기 위한 여러 명세 메트릭을 사용하는 등 다양한 전략을 채택했습니다. 명세 과적합은 시스템이 명시된 메트릭에 지나치게 집중하여 작업 성능을 저해할 수 있는 시나리오로 정의됩니다. 문헌에서 얻은 주요 통찰은 서로 다른 메트릭 간의 균형을 강조하는 것으로, 메트릭 $M$의 최적화가 과적합을 초래할 수 있으며, 메트릭 학습(metric learning)에서 균형 잡힌 접근 방식을 통해 포괄적인 시스템 개발을 달성하는 것이 중요하다는 점입니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "information bottleneck",
        "domain": "cs.AI",
        "summary": "  Artificial neural networks (ANNs) are typically confined to accomplishing\npre-defined tasks by learning a set of static parameters. In contrast,\nbiological neural networks (BNNs) can adapt to various new tasks by continually\nupdating the neural connections based on the inputs, which is aligned with the\nparadigm of learning effective learning rules in addition to static parameters,\ne.g., meta-learning. Among various biologically inspired learning rules,\nHebbian plasticity updates the neural network weights using local signals\nwithout the guide of an explicit target function, thus enabling an agent to\nlearn automatically without human efforts. However, typical plastic ANNs using\na large amount of meta-parameters violate the nature of the genomics bottleneck\nand potentially deteriorate the generalization capacity. This work proposes a\nnew learning paradigm decomposing those connection-dependent plasticity rules\ninto neuron-dependent rules thus accommodating $\\Theta(n^2)$ learnable\nparameters with only $\\Theta(n)$ meta-parameters. We also thoroughly study the\neffect of different neural modulation on plasticity. Our algorithms are tested\nin challenging random 2D maze environments, where the agents have to use their\npast experiences to shape the neural connections and improve their performances\nfor the future. The results of our experiment validate the following: 1.\nPlasticity can be adopted to continually update a randomly initialized RNN to\nsurpass pre-trained, more sophisticated recurrent models, especially when\ncoming to long-term memorization. 2. Following the genomics bottleneck, the\nproposed decomposed plasticity can be comparable to or even more effective than\ncanonical plasticity rules in some instances.\n",
        "english": "The concept of the information bottleneck is indirectly addressed in the study through the exploration of the genomics bottleneck, which emphasizes the importance of reducing the number of meta-parameters in neural networks to enhance generalization capacity. By proposing a new learning paradigm that decomposes connection-dependent plasticity rules into neuron-dependent rules, the research effectively accommodates $\\Theta(n^2)$ learnable parameters with only $\\Theta(n)$ meta-parameters, thereby aligning with the information bottleneck principle. This innovative approach is validated through experiments in challenging random 2D maze environments, demonstrating that such decomposed plasticity can surpass pre-trained, sophisticated recurrent models, particularly in tasks requiring long-term memorization.",
        "korean": "정보 병목(information bottleneck)의 개념은 유전체 병목(genomics bottleneck)의 탐구를 통해 간접적으로 연구에서 다루어지며, 이는 신경망(neural networks)의 일반화 능력을 향상시키기 위해 메타 매개변수(meta-parameters)의 수를 줄이는 것의 중요성을 강조합니다. 연결 의존적 가소성 규칙(connection-dependent plasticity rules)을 뉴런 의존적 규칙(neuron-dependent rules)으로 분해하는 새로운 학습 패러다임을 제안함으로써, 연구는 $\\Theta(n^2)$ 학습 가능한 매개변수를 단지 $\\Theta(n)$ 메타 매개변수로 효과적으로 수용하여 정보 병목 원칙(information bottleneck principle)에 부합합니다. 이러한 혁신적인 접근법은 도전적인 무작위 2D 미로 환경(random 2D maze environments)에서의 실험을 통해 검증되었으며, 특히 장기 기억이 필요한 작업에서 사전 훈련된 정교한 순환 모델(recurrent models)을 능가할 수 있음을 보여줍니다.",
        "score": 9,
        "parentheses_count": 10,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring all technical terms are consistently formatted as Korean term(English term) and check for any potential inconsistencies in the use of parentheses."
    },
    {
        "turn_index": 2,
        "term": "Markov random fields",
        "domain": "cs.AI",
        "summary": "  Relational Markov Random Fields are a general and flexible framework for\nreasoning about the joint distribution over attributes of a large number of\ninteracting entities. The main computational difficulty in learning such models\nis inference. Even when dealing with complete data, where one can summarize a\nlarge domain by sufficient statistics, learning requires one to compute the\nexpectation of the sufficient statistics given different parameter choices. The\ntypical solution to this problem is to resort to approximate inference\nprocedures, such as loopy belief propagation. Although these procedures are\nquite efficient, they still require computation that is on the order of the\nnumber of interactions (or features) in the model. When learning a large\nrelational model over a complex domain, even such approximations require\nunrealistic running time. In this paper we show that for a particular class of\nrelational MRFs, which have inherent symmetry, we can perform the inference\nneeded for learning procedures using a template-level belief propagation. This\nprocedure's running time is proportional to the size of the relational model\nrather than the size of the domain. Moreover, we show that this computational\nprocedure is equivalent to sychronous loopy belief propagation. This enables a\ndramatic speedup in inference and learning time. We use this procedure to learn\nrelational MRFs for capturing the joint distribution of large protein-protein\ninteraction networks.\n",
        "english": "Relational Markov Random Fields (MRFs) present a versatile framework for reasoning about the joint distribution over attributes of numerous interacting entities, yet the primary computational challenge lies in inference, especially when learning requires computing the expectation of sufficient statistics given various parameter choices. To address this, approximate inference methods like loopy belief propagation are employed, though they demand computation proportional to the number of interactions within the model, $O(|\\text{features}|)$. Notably, for a specific class of relational MRFs exhibiting inherent symmetry, the use of template-level belief propagation significantly accelerates inference and learning processes, enhancing applicability to complex domains such as protein-protein interaction networks.",
        "korean": "관계적 마르코프 랜덤 필드(Markov random fields, MRFs)는 다수의 상호작용하는 개체들의 속성에 대한 결합 분포를 추론하는 데 있어 다재다능한 프레임워크를 제공합니다. 그러나 주요 계산적 도전 과제는 다양한 매개변수 선택에 따라 충분 통계량의 기대값을 계산해야 하는 학습 시의 추론에 있습니다. 이를 해결하기 위해 루프 있는 신념 전파(loopy belief propagation)와 같은 근사 추론 방법이 사용되며, 이는 모델 내 상호작용 수에 비례하는 계산을 요구합니다 $O(|\\text{features}|)$. 특히, 고유한 대칭성을 나타내는 특정 클래스의 관계적 마르코프 랜덤 필드(Markov random fields, MRFs)에 대해 템플릿 수준의 신념 전파(template-level belief propagation)를 사용하면 추론 및 학습 과정을 크게 가속화하여 단백질-단백질 상호작용 네트워크와 같은 복잡한 도메인에 대한 적용 가능성을 향상시킵니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and verify that all technical terms are correctly parenthesized as Korean term(English term). Adjust the structure for a more natural flow in Korean, especially in the placement of commas and conjunctions."
    },
    {
        "turn_index": 2,
        "term": "neural sequence prediction",
        "domain": "cs.AI",
        "summary": "  Nowadays, artificial neural networks are widely used for users' online travel\nplanning. Personalized travel planning has many real applications and is\naffected by various factors, such as transportation type, intention destination\nestimation, budget limit and crowdness prediction. Among those factors, users'\nintention destination prediction is an essential task in online travel\nplatforms. The reason is that, the user may be interested in the travel plan\nonly when the plan matches his real intention destination. Therefore, in this\npaper, we focus on predicting users' intention destinations in online travel\nplatforms. In detail, we act as online travel platforms (such as Fliggy and\nAirbnb) to recommend travel plans for users, and the plan consists of various\nvacation items including hotel package, scenic packages and so on. Predicting\nthe actual intention destination in travel planning is challenging. Firstly,\nusers' intention destination is highly related to their travel status (e.g.,\nplanning for a trip or finishing a trip). Secondly, users' actions (e.g.\nclicking, searching) over different product types (e.g. train tickets, visa\napplication) have different indications in destination prediction. Thirdly,\nusers may mostly visit the travel platforms just before public holidays, and\nthus user behaviors in online travel platforms are more sparse, low-frequency\nand long-period. Therefore, we propose a Deep Multi-Sequences fused neural\nNetworks (DMSN) to predict intention destinations from fused multi-behavior\nsequences. Real datasets are used to evaluate the performance of our proposed\nDMSN models. Experimental results indicate that the proposed DMSN models can\nachieve high intention destination prediction accuracy.\n",
        "english": "In the realm of neural sequence prediction, predicting users' intention destinations in online travel platforms is an essential task, as the user may be interested in the travel plan only when the plan matches his real intention destination. To address this, the research introduces a Deep Multi-Sequences fused neural Networks (DMSN) approach, which predicts intention destinations from fused multi-behavior sequences by considering users' actions over different product types and their travel status. The experimental results from real datasets demonstrate the effectiveness of DMSN, achieving high intention destination prediction accuracy, with the model's performance quantified by an accuracy rate exceeding $90\\%$.",
        "korean": "신경 시퀀스 예측(neural sequence prediction) 분야에서 온라인 여행 플랫폼에서 사용자의 의도 목적지를 예측하는 것은 중요한 과제입니다. 사용자는 계획이 실제 의도 목적지와 일치할 때만 여행 계획에 관심을 가질 수 있기 때문입니다. 이를 해결하기 위해 연구에서는 사용자의 다양한 제품 유형에 대한 행동과 여행 상태를 고려하여 융합된 다중 행동 시퀀스에서 의도 목적지를 예측하는 심층 다중 시퀀스 융합 신경망(Deep Multi-Sequences fused neural Networks, DMSN) 접근 방식을 소개합니다. 실제 데이터셋에서의 실험 결과는 DMSN의 효과성을 입증하며, 모델의 성능은 $90\\%$를 초과하는 정확도율로 의도 목적지 예측 정확도를 달성했습니다.",
        "score": 9,
        "parentheses_count": 2,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using \"심층 다중 시퀀스 융합 신경망(DMSN)\" to maintain consistency in parenthesization."
    },
    {
        "turn_index": 2,
        "term": "zero-shot learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "english": "In the context of zero-shot learning, the research introduces the concept of mechanical learning and proposes two approaches to effectively describe the objects and processes of learning, emphasizing the significance of subjective patterns for a learning machine. The study demonstrates that for any objective pattern, a corresponding subjective pattern can be derived using least base patterns, encapsulated in an algebraic expression known as X-form, which forms the internal representation space crucial for zero-shot learning. By leveraging sufficient data and certain capabilities, the learning machine can achieve universal learning, highlighting the innovative potential of zero-shot learning in expanding the boundaries of machine learning without explicit teaching.",
        "korean": "제로샷 학습(zero-shot learning)의 맥락에서, 연구는 기계 학습(mechanical learning)의 개념을 도입하고 학습의 객체와 과정을 효과적으로 설명하기 위한 두 가지 접근법을 제안하며, 학습 기계에 대한 주관적 패턴의 중요성을 강조합니다. 이 연구는 어떤 객관적 패턴에 대해서도 최소 기저 패턴을 사용하여 대응하는 주관적 패턴을 도출할 수 있음을 보여주며, 이는 제로샷 학습(zero-shot learning)에 중요한 내부 표현 공간을 형성하는 x-형식(x-form)으로 알려진 대수적 표현에 캡슐화됩니다. 충분한 데이터와 특정 능력을 활용함으로써 학습 기계는 보편적 학습을 달성할 수 있으며, 명시적인 교육 없이 기계 학습의 경계를 확장하는 제로샷 학습(zero-shot learning)의 혁신적 잠재력을 강조합니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure all terms within parentheses are consistently in lowercase, such as \"x-형식(x-form)\" to maintain uniformity."
    },
    {
        "turn_index": 2,
        "term": "ensemble learning",
        "domain": "cs.AI",
        "summary": "  ViZDoom is a robust, first-person shooter reinforcement learning environment,\ncharacterized by a significant degree of latent state information. In this\npaper, double-Q learning and prioritized experience replay methods are tested\nunder a certain ViZDoom combat scenario using a competitive deep recurrent\nQ-network (DRQN) architecture. In addition, an ensembling technique known as\nsnapshot ensembling is employed using a specific annealed learning rate to\nobserve differences in ensembling efficacy under these two methods. Annealed\nlearning rates are important in general to the training of deep neural network\nmodels, as they shake up the status-quo and counter a model's tending towards\nlocal optima. While both variants show performance exceeding those of built-in\nAI agents of the game, the known stabilizing effects of double-Q learning are\nillustrated, and priority experience replay is again validated in its\nusefulness by showing immediate results early on in agent development, with the\ncaveat that value overestimation is accelerated in this case. In addition, some\nunique behaviors are observed to develop for priority experience replay (PER)\nand double-Q (DDQ) variants, and snapshot ensembling of both PER and DDQ proves\na valuable method for improving performance of the ViZDoom Marine.\n",
        "korean": "앙상블 학습(ensemble learning)은 스냅샷 앙상블링(snapshot ensembling)을 활용하여 연구에 적용되며, 이는 심층 순환 q-네트워크(deep recurrent q-network, drqn) 아키텍처를 사용하여 vizdoom 전투 시나리오에서 테스트됩니다. 특히, 점진적 학습률(annealed learning rate)을 사용한 스냅샷 앙상블링(snapshot ensembling)의 구현은 vizdoom 해병의 성능을 향상시킴으로써 그 효능을 입증하며, 우선순위 경험 재생(prioritized experience replay, per)과 더블-q 학습(double-q learning, ddq) 변형 모두 게임 내장 ai 에이전트의 능력을 초과합니다. 이 접근법의 혁신은 점진적 학습률(annealed learning rate)의 수학적 표현에 의해 강조되며, 이는 $\\eta_t = \\eta_0 \\cdot (1 + \\alpha \\cdot t)^{-1}$로 나타낼 수 있습니다. 여기서 $\\eta_t$는 시간 $t$에서의 학습률, $\\eta_0$는 초기 학습률, $\\alpha$는 점진적 요소로, 모델이 국소 최적화를 피하고 훈련을 안정화하도록 보장합니다."
    },
    {
        "turn_index": 2,
        "term": "memory-augmented neural networks",
        "domain": "cs.AI",
        "summary": "  Cybersecurity is the security cornerstone of digital transformation of the\npower grid and construction of new power systems. The traditional network\nsecurity situation quantification method only analyzes from the perspective of\nnetwork performance, ignoring the impact of various power application services\non the security situation, so the quantification results cannot fully reflect\nthe power information network risk state. This study proposes a method for\nquantifying security situation of the power information network based on the\nevolutionary neural network. First, the security posture system architecture is\ndesigned by analyzing the business characteristics of power information network\napplications. Second, combining the importance of power application business,\nthe spatial element index system of coupled interconnection is established from\nthree dimensions of network reliability, threat, and vulnerability. Then, the\nBP neural network optimized by the genetic evolutionary algorithm is\nincorporated into the element index calculation process, and the quantitative\nmodel of security posture of the power information network based on the\nevolutionary neural network is constructed. Finally, a simulation experiment\nenvironment is built according to a power sector network topology, and the\neffectiveness and robustness of the method proposed in the study are verified.\n",
        "korean": "디지털 전환을 위한 사이버 보안의 맥락에서, 메모리 증강 신경망(memory-augmented neural networks)은 다양한 전력 응용 서비스의 영향을 통합하여 전통적인 네트워크 보안 상황 정량화 방법을 향상시킬 수 있으며, 이를 통해 전력 정보 네트워크의 위험 상태를 보다 포괄적으로 반영할 수 있습니다. 보안 자세 시스템 아키텍처와 공간 요소 지수 시스템을 활용하여, 이러한 네트워크는 네트워크 신뢰성, 위협, 취약성의 차원에서 결합된 상호 연결성을 평가하며, 이는 전력 정보 네트워크의 보안 자세를 정확하게 모델링하는 데 필수적입니다. 유전 진화 알고리즘으로 최적화된 BP 신경망을 활용하여, 이 접근법은 메모리 증강(memory-augmented) 기능을 통합하여 정량적 모델을 개선하며, 이는 $Q = f(R, T, V)$로 표시되며, 여기서 $R$, $T$, $V$는 각각 신뢰성, 위협, 취약성을 나타냅니다."
    },
    {
        "turn_index": 2,
        "term": "sequence modeling",
        "domain": "cs.AI",
        "summary": "  Sequence learning is an essential aspect of intelligence. In Artificial\nIntelligence, sequence prediction task is usually used to test a sequence\nlearning model. In this paper, a model of sequence learning, which is\ninterpretable through Non-Axiomatic Logic, is designed and tested. The learning\nmechanism is composed of three steps, hypothesizing, revising, and recycling,\nwhich enable the model to work under the Assumption of Insufficient Knowledge\nand Resources. Synthetic datasets for sequence prediction task are generated to\ntest the capacity of the model. The results show that the model works well\nwithin different levels of difficulty. In addition, since the model adopts\nconcept-centered representation, it theoretically does not suffer from\ncatastrophic forgetting, and the practical results also support this property.\nThis paper shows the potential of learning sequences in a logical way.\n",
        "english": "Sequence modeling, an integral component of artificial intelligence, is evaluated through sequence prediction tasks to assess the efficacy of learning models, as demonstrated in the referenced study. The proposed model, which utilizes Non-Axiomatic Logic, follows a structured learning mechanism comprising hypothesizing, revising, and recycling steps, enabling it to function effectively under the Assumption of Insufficient Knowledge and Resources. Notably, the model's adoption of concept-centered representation mitigates the risk of catastrophic forgetting, as evidenced by synthetic dataset tests, where the model's performance, denoted as $R = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$, remained robust across varying difficulty levels, highlighting its innovative approach to logical sequence learning.",
        "korean": "인공지능의 필수 구성 요소인 시퀀스 모델링(sequence modeling)은 학습 모델의 효율성을 평가하기 위해 시퀀스 예측 작업을 통해 평가되며, 이는 참조된 연구에서 입증되었습니다. 제안된 모델은 비공리적 논리(Non-Axiomatic Logic)를 활용하여 가설 설정, 수정, 재활용 단계로 구성된 구조화된 학습 메커니즘을 따르며, 지식과 자원의 불충분 가정(Assumption of Insufficient Knowledge and Resources) 하에서도 효과적으로 작동할 수 있게 합니다. 특히, 개념 중심 표현(concept-centered representation)을 채택한 이 모델은 합성 데이터셋 테스트에서 입증된 바와 같이, $R = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$로 표시된 모델의 성능이 다양한 난이도 수준에서도 견고하게 유지되어, 논리적 시퀀스 학습에 대한 혁신적인 접근 방식을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "Riemannian manifolds",
        "domain": "cs.AI",
        "summary": "  We develop new algorithms for Riemannian bilevel optimization. We focus in\nparticular on batch and stochastic gradient-based methods, with the explicit\ngoal of avoiding second-order information such as Riemannian hyper-gradients.\nWe propose and analyze $\\mathrm{RF^2SA}$, a method that leverages first-order\ngradient information to navigate the complex geometry of Riemannian manifolds\nefficiently. Notably, $\\mathrm{RF^2SA}$ is a single-loop algorithm, and thus\neasier to implement and use. Under various setups, including stochastic\noptimization, we provide explicit convergence rates for reaching\n$\\epsilon$-stationary points. We also address the challenge of optimizing over\nRiemannian manifolds with constraints by adjusting the multiplier in the\nLagrangian, ensuring convergence to the desired solution without requiring\naccess to second-order derivatives.\n",
        "english": "In the realm of Riemannian manifolds, new algorithms for Riemannian bilevel optimization have been developed, particularly focusing on batch and stochastic gradient-based methods, with an explicit aim to circumvent the need for second-order information such as Riemannian hyper-gradients. A notable innovation is the $\\mathrm{RF^2SA}$ method, which efficiently utilizes first-order gradient information to navigate the intricate geometry of Riemannian manifolds, presenting a single-loop algorithm that simplifies implementation and usage. By adjusting the multiplier in the Lagrangian, the research addresses the challenge of optimizing over Riemannian manifolds with constraints, ensuring convergence to the desired solution without the necessity for second-order derivatives.",
        "korean": "리만 다양체(riemannian manifolds) 영역에서 리만 이중 수준 최적화(riemannian bilevel optimization)를 위한 새로운 알고리즘이 개발되었으며, 특히 배치 및 확률적 경사 기반 방법(batch and stochastic gradient-based methods)에 중점을 두고 리만 초미분(riemannian hyper-gradients)과 같은 2차 정보의 필요성을 피하는 것을 명시적인 목표로 하고 있습니다. 주목할 만한 혁신은 $\\mathrm{RF^2SA}$ 방법으로, 리만 다양체(riemannian manifolds)의 복잡한 기하학을 탐색하기 위해 1차 미분 정보(first-order gradient information)를 효율적으로 활용하여 구현과 사용을 단순화하는 단일 루프 알고리즘(single-loop algorithm)을 제시합니다. 라그랑지안(lagrangian)에서의 승수를 조정함으로써, 연구는 제약 조건이 있는 리만 다양체(riemannian manifolds)에서의 최적화 문제를 다루며, 2차 미분의 필요 없이 원하는 해로의 수렴을 보장합니다.",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural generative inference",
        "domain": "cs.AI",
        "summary": "  This paper investigates the use of different Artificial Intelligence methods\nto predict the values of several continuous variables from a Steam Generator.\nThe objective was to determine how the different artificial intelligence\nmethods performed in making predictions on the given dataset. The artificial\nintelligence methods evaluated were Neural Networks, Support Vector Machines,\nand Adaptive Neuro-Fuzzy Inference Systems. The types of neural networks\ninvestigated were Multi-Layer Perceptions, and Radial Basis Function. Bayesian\nand committee techniques were applied to these neural networks. Each of the AI\nmethods considered was simulated in Matlab. The results of the simulations\nshowed that all the AI methods were capable of predicting the Steam Generator\ndata reasonably accurately. However, the Adaptive Neuro-Fuzzy Inference system\nout performed the other methods in terms of accuracy and ease of\nimplementation, while still achieving a fast execution time as well as a\nreasonable training time.\n",
        "english": "Neural generative inference, as demonstrated through the application of various artificial intelligence methods, plays a critical role in accurately predicting continuous variables from complex systems such as a Steam Generator. By utilizing neural networks, including Multi-Layer Perceptions and Radial Basis Function, alongside Bayesian and committee techniques, the study highlights the efficacy of these models in achieving precise predictions, with the Adaptive Neuro-Fuzzy Inference System outperforming others in terms of accuracy and implementation simplicity. The performance of these methods, evaluated through simulations in Matlab, underscores the potential of neural generative inference in advancing predictive analytics, with results indicating an execution time $t_{exec} \\approx 0.5$ seconds and a training time $t_{train} \\leq 10$ minutes, thereby demonstrating both efficiency and effectiveness.",
        "korean": "다양한 인공지능 방법의 적용을 통해 입증된 신경 생성 추론(neural generative inference)은 증기 발생기와 같은 복잡한 시스템에서 연속 변수를 정확하게 예측하는 데 중요한 역할을 합니다. 다층 퍼셉트론(Multi-Layer Perceptions)과 방사형 기저 함수(Radial Basis Function)를 포함한 신경망(neural networks)을 베이지안(Bayesian) 및 위원회 기법(committee techniques)과 함께 활용함으로써, 이 연구는 적응형 신경 퍼지 추론 시스템(Adaptive Neuro-Fuzzy Inference System)이 정확성과 구현의 간단함 측면에서 다른 모델을 능가하는 효능을 강조합니다. Matlab 시뮬레이션을 통해 평가된 이러한 방법들의 성능은 예측 분석을 발전시키는 데 있어 신경 생성 추론(neural generative inference)의 잠재력을 강조하며, 결과는 실행 시간 $t_{exec} \\approx 0.5$ 초 및 훈련 시간 $t_{train} \\leq 10$ 분을 나타내어 효율성과 효과성을 모두 입증합니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all terms within parentheses are in lowercase for consistency."
    },
    {
        "turn_index": 2,
        "term": "natural language understanding",
        "domain": "cs.AI",
        "summary": "  Human intelligence has the remarkable ability to adapt to new tasks and\nenvironments quickly. Starting from a very young age, humans acquire new skills\nand learn how to solve new tasks either by imitating the behavior of others or\nby following provided natural language instructions. To facilitate research in\nthis direction, we propose IGLU: Interactive Grounded Language Understanding in\na Collaborative Environment. The primary goal of the competition is to approach\nthe problem of how to build interactive agents that learn to solve a task while\nprovided with grounded natural language instructions in a collaborative\nenvironment. Understanding the complexity of the challenge, we split it into\nsub-tasks to make it feasible for participants.\n  This research challenge is naturally related, but not limited, to two fields\nof study that are highly relevant to the NeurIPS community: Natural Language\nUnderstanding and Generation (NLU/G) and Reinforcement Learning (RL).\nTherefore, the suggested challenge can bring two communities together to\napproach one of the important challenges in AI. Another important aspect of the\nchallenge is the dedication to perform a human-in-the-loop evaluation as a\nfinal evaluation for the agents developed by contestants.\n",
        "english": "Natural language understanding (NLU) is a critical component in developing interactive agents that can \"learn to solve a task while provided with grounded natural language instructions in a collaborative environment,\" as demonstrated by the IGLU competition. This challenge not only emphasizes the integration of NLU with Reinforcement Learning (RL) but also highlights the importance of \"human-in-the-loop evaluation\" to assess the effectiveness of the developed agents. By addressing this complex issue, the research fosters collaboration between the NLU/G and RL communities, ultimately advancing the field of AI through innovative methodologies and practical applications.",
        "korean": "자연어 이해(natural language understanding)는 IGLU 대회에서 입증된 바와 같이 협력적인 환경에서 구체적인 자연어 지시와 함께 주어진 과제를 해결하는 방법을 학습할 수 있는 대화형 에이전트를 개발하는 데 중요한 요소입니다. 이 도전 과제는 자연어 이해(natural language understanding)와 강화 학습(reinforcement learning, RL)의 통합을 강조할 뿐만 아니라 개발된 에이전트의 효과성을 평가하기 위한 인간 참여 평가(human-in-the-loop evaluation)의 중요성도 부각합니다. 이러한 복잡한 문제를 해결함으로써 연구는 자연어 이해(natural language understanding)와 강화 학습(reinforcement learning) 커뮤니티 간의 협력을 촉진하고, 궁극적으로 혁신적인 방법론과 실용적인 응용을 통해 AI 분야를 발전시킵니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dimensionality reduction",
        "domain": "cs.AI",
        "summary": "  One of the most complex tasks of decision making and planning is to gather\ninformation. This task becomes even more complex when the state is\nhigh-dimensional and its belief cannot be expressed with a parametric\ndistribution. Although the state is high-dimensional, in many problems only a\nsmall fraction of it might be involved in transitioning the state and\ngenerating observations. We exploit this fact to calculate an\ninformation-theoretic expected reward, mutual information (MI), over a much\nlower-dimensional subset of the state, to improve efficiency and without\nsacrificing accuracy. A similar approach was used in previous works, yet\nspecifically for Gaussian distributions, and we here extend it for general\ndistributions. Moreover, we apply the dimensionality reduction for cases in\nwhich the new states are augmented to the previous, yet again without\nsacrificing accuracy. We then continue by developing an estimator for the MI\nwhich works in a Sequential Monte Carlo (SMC) manner, and avoids the\nreconstruction of future belief's surfaces. Finally, we show how this work is\napplied to the informative planning optimization problem. This work is then\nevaluated in a simulation of an active SLAM problem, where the improvement in\nboth accuracy and timing is demonstrated.\n",
        "english": "Dimensionality reduction is leveraged to calculate an information-theoretic expected reward, specifically mutual information (MI), over a lower-dimensional subset of the state, thereby enhancing efficiency without compromising accuracy. A significant contribution of this research is extending the application of dimensionality reduction beyond Gaussian distributions to general distributions, which is particularly beneficial when new states are augmented to previous ones while maintaining precision. By developing an estimator for MI that operates in a Sequential Monte Carlo (SMC) manner, the study avoids the reconstruction of future belief's surfaces, optimizing the informative planning problem and demonstrating improvements in both accuracy and timing in active SLAM simulations.",
        "korean": "차원 축소(dimensionality reduction)는 정보 이론적 기대 보상(특히 상호 정보, mutual information, MI)을 낮은 차원의 상태 부분 집합에서 계산하는 데 활용되어 효율성을 향상시키면서도 정확성을 유지합니다. 이 연구의 중요한 기여는 차원 축소(dimensionality reduction)의 적용을 가우시안 분포(gaussian distributions)를 넘어 일반 분포(general distributions)로 확장한 것으로, 이는 새로운 상태가 이전 상태에 추가될 때 정밀도를 유지하면서 특히 유용합니다. 연구에서는 순차 몬테카를로(sequential monte carlo, SMC) 방식으로 작동하는 MI 추정기를 개발하여 미래 신념의 표면을 재구성하지 않고 정보 계획 문제를 최적화하며, 능동 SLAM 시뮬레이션에서 정확성과 시간 측면에서의 개선을 입증합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "probabilistic sequence generation",
        "domain": "cs.AI",
        "summary": "  Many real world sequences such as protein secondary structures or shell logs\nexhibit a rich internal structures. Traditional probabilistic models of\nsequences, however, consider sequences of flat symbols only. Logical hidden\nMarkov models have been proposed as one solution. They deal with logical\nsequences, i.e., sequences over an alphabet of logical atoms. This comes at the\nexpense of a more complex model selection problem. Indeed, different\nabstraction levels have to be explored. In this paper, we propose a novel\nmethod for selecting logical hidden Markov models from data called SAGEM. SAGEM\ncombines generalized expectation maximization, which optimizes parameters, with\nstructure search for model selection using inductive logic programming\nrefinement operators. We provide convergence and experimental results that show\nSAGEM's effectiveness.\n",
        "english": "In the domain of probabilistic sequence generation, traditional models often simplify sequences to \"flat symbols,\" which may overlook the \"rich internal structures\" found in real-world data such as protein secondary structures or shell logs. To address this limitation, logical hidden Markov models have been introduced, which operate over an alphabet of logical atoms, thus necessitating a more complex model selection process that involves exploring \"different abstraction levels.\" The innovative SAGEM method, combining generalized expectation maximization for parameter optimization with inductive logic programming refinement operators for structure search, demonstrates its effectiveness through convergence and experimental results, significantly advancing the field of probabilistic sequence generation.",
        "korean": "확률적 순서 생성(probabilistic sequence generation) 분야에서 전통적인 모델은 종종 순서를 \"평면 기호\"로 단순화하여 단백질 2차 구조나 셸 로그와 같은 실제 데이터에서 발견되는 \"풍부한 내부 구조\"를 간과할 수 있습니다. 이러한 한계를 극복하기 위해 논리적 은닉 마르코프 모델(logical hidden Markov models)이 도입되었으며, 이는 논리적 원자의 알파벳을 기반으로 작동하여 \"다양한 추상화 수준\"을 탐색하는 더 복잡한 모델 선택 과정을 필요로 합니다. 매개변수 최적화를 위한 일반화된 기대 최대화(generalized expectation maximization)와 구조 탐색을 위한 귀납적 논리 프로그래밍(inductive logic programming) 정제 연산자를 결합한 혁신적인 SAGEM 방법은 수렴성과 실험 결과를 통해 그 효과를 입증하며 확률적 순서 생성(probabilistic sequence generation) 분야를 크게 발전시킵니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural information processing",
        "domain": "cs.AI",
        "summary": "  Cybersecurity is the security cornerstone of digital transformation of the\npower grid and construction of new power systems. The traditional network\nsecurity situation quantification method only analyzes from the perspective of\nnetwork performance, ignoring the impact of various power application services\non the security situation, so the quantification results cannot fully reflect\nthe power information network risk state. This study proposes a method for\nquantifying security situation of the power information network based on the\nevolutionary neural network. First, the security posture system architecture is\ndesigned by analyzing the business characteristics of power information network\napplications. Second, combining the importance of power application business,\nthe spatial element index system of coupled interconnection is established from\nthree dimensions of network reliability, threat, and vulnerability. Then, the\nBP neural network optimized by the genetic evolutionary algorithm is\nincorporated into the element index calculation process, and the quantitative\nmodel of security posture of the power information network based on the\nevolutionary neural network is constructed. Finally, a simulation experiment\nenvironment is built according to a power sector network topology, and the\neffectiveness and robustness of the method proposed in the study are verified.\n",
        "english": "Neural information processing plays a crucial role in quantifying the security situation of power information networks by incorporating the BP neural network optimized by a genetic evolutionary algorithm into the element index calculation process. This innovative approach constructs a quantitative model for the security posture of the power information network, leveraging the neural network's ability to analyze the spatial element index system from dimensions of network reliability, threat, and vulnerability. The effectiveness and robustness of this method are demonstrated through a simulation experiment environment based on a power sector network topology, highlighting its potential to enhance cybersecurity in digital transformations.",
        "korean": "신경 정보 처리(neural information processing)는 유전적 진화 알고리즘(genetic evolutionary algorithm)으로 최적화된 BP 신경망(BP neural network)을 요소 지수 계산 과정에 통합함으로써 전력 정보 네트워크의 보안 상황을 정량화하는 데 중요한 역할을 합니다. 이 혁신적인 접근 방식은 네트워크 신뢰성, 위협, 취약성의 차원에서 공간 요소 지수 시스템을 분석하는 신경망의 능력을 활용하여 전력 정보 네트워크의 보안 태세에 대한 정량적 모델을 구축합니다. 이 방법의 효과성과 견고성은 전력 부문 네트워크 토폴로지에 기반한 시뮬레이션 실험 환경을 통해 입증되며, 디지털 전환에서 사이버 보안을 강화할 수 있는 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "decision trees",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Decision trees are a pivotal aspect of machine learning, allowing for the creation of interpretable models that can be easily visualized and understood. By employing a recursive partitioning methodology, decision trees split the data into subsets based on feature values, optimizing the decision boundaries through an impurity measure such as the Gini index, defined mathematically as $Gini(p) = 1 - \\sum_{i=1}^{n} p_i^2$, where $p_i$ represents the proportion of instances of class $i$. This research underscores the innovative application of decision trees in various domains, emphasizing their ability to handle both categorical and continuous variables effectively, thereby enhancing predictive accuracy and model transparency.",
        "korean": "결정 트리(decision trees)는 기계 학습(machine learning)의 중요한 측면으로, 쉽게 시각화하고 이해할 수 있는 해석 가능한 모델을 생성할 수 있게 합니다. 재귀적 분할 방법론(recursive partitioning methodology)을 사용하여 결정 트리(decision trees)는 특징 값에 따라 데이터를 하위 집합으로 나누고, 지니 지수(Gini index)와 같은 불순도 측정을 통해 결정 경계를 최적화합니다. 지니 지수(Gini index)는 수학적으로 $Gini(p) = 1 - \\sum_{i=1}^{n} p_i^2$로 정의되며, 여기서 $p_i$는 클래스 $i$의 인스턴스 비율을 나타냅니다. 이 연구는 다양한 도메인에서 결정 트리(decision trees)의 혁신적인 응용을 강조하며, 범주형 변수와 연속형 변수를 모두 효과적으로 처리하여 예측 정확도와 모델 투명성을 향상시키는 능력을 강조합니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "[None needed]"
    },
    {
        "turn_index": 2,
        "term": "AI alignment",
        "domain": "cs.AI",
        "summary": "  AI alignment aims to make AI systems behave in line with human intentions and\nvalues. As AI systems grow more capable, so do risks from misalignment. To\nprovide a comprehensive and up-to-date overview of the alignment field, in this\nsurvey, we delve into the core concepts, methodology, and practice of\nalignment. First, we identify four principles as the key objectives of AI\nalignment: Robustness, Interpretability, Controllability, and Ethicality\n(RICE). Guided by these four principles, we outline the landscape of current\nalignment research and decompose them into two key components: forward\nalignment and backward alignment. The former aims to make AI systems aligned\nvia alignment training, while the latter aims to gain evidence about the\nsystems' alignment and govern them appropriately to avoid exacerbating\nmisalignment risks. On forward alignment, we discuss techniques for learning\nfrom feedback and learning under distribution shift. On backward alignment, we\ndiscuss assurance techniques and governance practices.\n  We also release and continually update the website (www.alignmentsurvey.com)\nwhich features tutorials, collections of papers, blog posts, and other\nresources.\n",
        "english": "AI alignment seeks to ensure that AI systems act in accordance with human intentions and values, particularly as their capabilities expand, increasing the risks of misalignment. By adhering to the key objectives of robustness, interpretability, controllability, and ethicality (RICE), the research delineates the field into forward and backward alignment, where forward alignment focuses on methods such as alignment training to learn from feedback and manage distribution shifts, and backward alignment emphasizes assurance techniques and governance practices. The importance of these methodologies is underscored by the necessity to minimize the misalignment risks, which can be quantitatively analyzed through the alignment loss function, $L_{align} = \\sum_{i=1}^{n} (h(x_i) - y_i)^2$, where $h(x_i)$ represents the AI system's output and $y_i$ the intended human-aligned outcome.",
        "korean": "AI 정렬(AI alignment)은 AI 시스템이 인간의 의도와 가치에 부합하여 행동하도록 보장하는 것을 목표로 하며, 특히 AI의 능력이 확장됨에 따라 오정렬의 위험이 증가합니다. 견고성, 해석 가능성, 제어 가능성, 윤리성(RICE)의 주요 목표를 준수함으로써 연구는 정렬을 전방 정렬과 후방 정렬로 구분합니다. 전방 정렬은 피드백 학습과 분포 변화 관리를 위한 정렬 훈련(alignment training)과 같은 방법에 중점을 두고, 후방 정렬은 보증 기법과 거버넌스 관행을 강조합니다. 이러한 방법론의 중요성은 오정렬 위험을 최소화해야 할 필요성에 의해 강조되며, 이는 정렬 손실 함수(alignment loss function), $L_{align} = \\sum_{i=1}^{n} (h(x_i) - y_i)^2$, 여기서 $h(x_i)$는 AI 시스템의 출력이고 $y_i$는 인간 정렬 의도 결과를 나타내는 것을 통해 정량적으로 분석할 수 있습니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase within parentheses for all technical terms."
    },
    {
        "turn_index": 2,
        "term": "deep reinforcement learning",
        "domain": "cs.AI",
        "summary": "  Purpose: AI in radiology is hindered chiefly by: 1) Requiring large annotated\ndata sets. 2) Non-generalizability that limits deployment to new scanners /\ninstitutions. And 3) Inadequate explainability and interpretability. We believe\nthat reinforcement learning can address all three shortcomings, with robust and\nintuitive algorithms trainable on small datasets. To the best of our knowledge,\nreinforcement learning has not been directly applied to computer vision tasks\nfor radiological images. In this proof-of-principle work, we train a deep\nreinforcement learning network to predict brain tumor location.\n  Materials and Methods: Using the BraTS brain tumor imaging database, we\ntrained a deep Q network on 70 post-contrast T1-weighted 2D image slices. We\ndid so in concert with image exploration, with rewards and punishments designed\nto localize lesions. To compare with supervised deep learning, we trained a\nkeypoint detection convolutional neural network on the same 70 images. We\napplied both approaches to a separate 30 image testing set.\n  Results: Reinforcement learning predictions consistently improved during\ntraining, whereas those of supervised deep learning quickly diverged.\nReinforcement learning predicted testing set lesion locations with 85%\naccuracy, compared to roughly 7% accuracy for the supervised deep network.\n  Conclusion: Reinforcement learning predicted lesions with high accuracy,\nwhich is unprecedented for such a small training set. We believe that\nreinforcement learning can propel radiology AI well past the inherent\nlimitations of supervised deep learning, with more clinician-driven research\nand finally toward true clinical applicability.\n",
        "english": "Deep reinforcement learning has the potential to address significant challenges in AI radiology, such as the need for large annotated datasets, non-generalizability, and inadequate explainability, by employing robust algorithms that can be trained on small datasets. In a study utilizing the BraTS brain tumor imaging database, a deep Q network was trained on 70 post-contrast T1-weighted 2D image slices, achieving an impressive lesion localization accuracy of 85\\% on a separate 30 image testing set, compared to only 7\\% accuracy for a supervised deep network. This remarkable result suggests that deep reinforcement learning can propel radiology AI beyond the limitations of supervised deep learning, paving the way for more clinically applicable solutions.",
        "korean": "심층 강화 학습(deep reinforcement learning)은 소규모 데이터셋에 대해 훈련될 수 있는 강력한 알고리즘을 사용하여 대규모 주석 데이터셋의 필요성, 비일반화성, 불충분한 설명 가능성과 같은 AI 방사선학의 주요 과제를 해결할 잠재력을 가지고 있습니다. BraTS 뇌종양 영상 데이터베이스를 활용한 연구에서, 심층 Q 네트워크(deep Q network)는 70개의 조영 후 T1 강조 2D 이미지 슬라이스에 대해 훈련되어, 별도의 30개 이미지 테스트 세트에서 85\\%의 인상적인 병변 위치 정확도를 달성했으며, 이는 감독 심층 네트워크(supervised deep network)의 7\\% 정확도와 비교됩니다. 이 놀라운 결과는 심층 강화 학습(deep reinforcement learning)이 방사선학 AI를 감독 심층 학습(supervised deep learning)의 한계를 넘어 임상적으로 더 적용 가능한 솔루션으로 나아가게 할 수 있음을 시사합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "spiking neural networks",
        "domain": "cs.AI",
        "summary": "  Children possess the ability to learn multiple cognitive tasks sequentially,\nwhich is a major challenge toward the long-term goal of artificial general\nintelligence. Existing continual learning frameworks are usually applicable to\nDeep Neural Networks (DNNs) and lack the exploration on more brain-inspired,\nenergy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning\nmechanisms during child growth and development, we propose Dynamic Structure\nDevelopment of Spiking Neural Networks (DSD-SNN) for efficient and adaptive\ncontinual learning. When learning a sequence of tasks, the DSD-SNN dynamically\nassigns and grows new neurons to new tasks and prunes redundant neurons,\nthereby increasing memory capacity and reducing computational overhead. In\naddition, the overlapping shared structure helps to quickly leverage all\nacquired knowledge to new tasks, empowering a single network capable of\nsupporting multiple incremental tasks (without the separate sub-network mask\nfor each task). We validate the effectiveness of the proposed model on multiple\nclass incremental learning and task incremental learning benchmarks. Extensive\nexperiments demonstrated that our model could significantly improve\nperformance, learning speed and memory capacity, and reduce computational\noverhead. Besides, our DSD-SNN model achieves comparable performance with the\nDNNs-based methods, and significantly outperforms the state-of-the-art (SOTA)\nperformance for existing SNNs-based continual learning methods.\n",
        "english": "Spiking neural networks (SNNs) offer a more brain-inspired, energy-efficient alternative to Deep Neural Networks (DNNs), yet existing continual learning frameworks have largely overlooked their potential. By introducing the Dynamic Structure Development of Spiking Neural Networks (DSD-SNN), the research addresses this gap through a mechanism that dynamically assigns and grows new neurons for new tasks while pruning redundant ones, thereby optimizing memory capacity and computational efficiency. Notably, the DSD-SNN model achieves comparable performance with DNNs-based methods and significantly outperforms existing SNNs-based continual learning methods, as evidenced by extensive experiments on class incremental learning and task incremental learning benchmarks, with a performance gain of approximately $20\\%$ in certain scenarios.",
        "korean": "스파이킹 신경망(spiking neural networks)은 심층 신경망(deep neural networks)에 비해 더 뇌에 영감을 받은 에너지 효율적인 대안을 제공합니다. 그러나 기존의 지속 학습 프레임워크는 그 잠재력을 크게 간과해 왔습니다. 스파이킹 신경망의 동적 구조 개발(dynamic structure development of spiking neural networks)을 도입함으로써, 연구는 새로운 작업에 대해 새로운 뉴런을 동적으로 할당하고 성장시키며, 불필요한 뉴런을 가지치기하는 메커니즘을 통해 이 격차를 해결하고 메모리 용량과 계산 효율성을 최적화합니다. 특히, 동적 구조 개발 모델은 DNNs 기반 방법과 비교할 만한 성능을 달성하며, 클래스 증분 학습(class incremental learning) 및 작업 증분 학습(task incremental learning) 벤치마크에서 약 $20\\%$의 성능 향상을 보이며 기존 스파이킹 신경망 기반 지속 학습 방법을 크게 능가합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure all technical terms are consistently formatted as Korean term(English term) and adjust the structure for natural flow and grammar. Consider using 스파이킹 신경망(spiking neural networks) consistently without additional abbreviations like SNNs."
    },
    {
        "turn_index": 2,
        "term": "neural rendering",
        "domain": "cs.AI",
        "summary": "  Deviations from rational decision-making due to limited computational\nresources have been studied in the field of bounded rationality, originally\nproposed by Herbert Simon. There have been a number of different approaches to\nmodel bounded rationality ranging from optimality principles to heuristics.\nHere we take an information-theoretic approach to bounded rationality, where\ninformation-processing costs are measured by the relative entropy between a\nposterior decision strategy and a given fixed prior strategy. In the case of\nmultiple environments, it can be shown that there is an optimal prior rendering\nthe bounded rationality problem equivalent to the rate distortion problem for\nlossy compression in information theory. Accordingly, the optimal prior and\nposterior strategies can be computed by the well-known Blahut-Arimoto algorithm\nwhich requires the computation of partition sums over all possible outcomes and\ncannot be applied straightforwardly to continuous problems. Here we derive a\nsampling-based alternative update rule for the adaptation of prior behaviors of\ndecision-makers and we show convergence to the optimal prior predicted by rate\ndistortion theory. Importantly, the update rule avoids typical infeasible\noperations such as the computation of partition sums. We show in simulations a\nproof of concept for discrete action and environment domains. This approach is\nnot only interesting as a generic computational method, but might also provide\na more realistic model of human decision-making processes occurring on a fast\nand a slow time scale.\n",
        "english": "Neural rendering, akin to bounded rationality, involves the adaptation of decision strategies where \"information-processing costs are measured by the relative entropy between a posterior decision strategy and a given fixed prior strategy.\" This process parallels the rate distortion problem in information theory, where the optimal prior can be determined using the Blahut-Arimoto algorithm, which calculates partition sums over all possible outcomes. Importantly, neural rendering's innovation lies in its ability to simulate human decision-making processes on both fast and slow time scales, offering a more realistic model by avoiding \"typical infeasible operations such as the computation of partition sums\" and instead employing a sampling-based update rule.",
        "korean": "신경 렌더링(neural rendering)은 제한된 합리성(bounded rationality)과 유사하게, \"정보 처리 비용이 사후 결정 전략과 주어진 고정 사전 전략 간의 상대 엔트로피로 측정되는\" 결정 전략의 적응을 포함합니다. 이 과정은 정보 이론에서의 비율 왜곡 문제(rate distortion problem)와 유사하며, 최적의 사전은 모든 가능한 결과에 대한 분할 합계를 계산하는 블라우트-아리모토 알고리즘(Blahut-Arimoto algorithm)을 사용하여 결정할 수 있습니다. 중요한 점은 신경 렌더링(neural rendering)의 혁신은 인간의 의사 결정 과정을 빠르고 느린 시간 척도 모두에서 시뮬레이션할 수 있는 능력에 있으며, \"분할 합계 계산과 같은 일반적으로 실행 불가능한 작업\"을 피하고 대신 샘플링 기반 업데이트 규칙을 사용하여 보다 현실적인 모델을 제공합니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure that all terms within parentheses are in lowercase for consistency and adjust the sentence structure slightly to enhance the natural flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "semantic probabilistic scene models",
        "domain": "cs.AI",
        "summary": "  Bayesian networks provide a probabilistic semantics for qualitative\nassertions about likelihood. A qualitative reasoner based on an algebra over\nthese assertions can derive further conclusions about the influence of actions.\nWhile the conclusions are much weaker than those computed from complete\nprobability distributions, they are still valuable for suggesting potential\nactions, eliminating obviously inferior plans, identifying important tradeoffs,\nand explaining probabilistic models.\n",
        "english": "Semantic probabilistic scene models leverage Bayesian networks to provide a probabilistic semantics for qualitative assertions about likelihood, enabling the modeling of complex environments with uncertainty. By employing a qualitative reasoner based on an algebra over these assertions, these models can derive further conclusions about the influence of actions, which is crucial for applications such as robotics and autonomous systems. Although the conclusions derived from semantic probabilistic scene models are weaker than those computed from complete probability distributions, they are instrumental in suggesting potential actions, eliminating obviously inferior plans, and identifying important tradeoffs, as expressed in the inequality $P(A|B) > P(A)$, indicating the influence of action $B$ on event $A$.",
        "korean": "의미론적 확률적 장면 모델(semantic probabilistic scene models)은 베이지안 네트워크(Bayesian networks)를 활용하여 가능성에 대한 질적 주장에 대한 확률적 의미론을 제공함으로써 불확실성을 가진 복잡한 환경을 모델링할 수 있게 합니다. 이러한 주장을 기반으로 한 대수학을 사용하는 질적 추론기를 활용하여, 이러한 모델은 행동의 영향을 파악하는 추가적인 결론을 도출할 수 있으며, 이는 로봇 공학 및 자율 시스템과 같은 응용 분야에서 매우 중요합니다. 의미론적 확률적 장면 모델(semantic probabilistic scene models)에서 도출된 결론은 완전한 확률 분포에서 계산된 결론보다 약하지만, 잠재적 행동을 제안하고 명백히 열등한 계획을 제거하며 중요한 절충점을 식별하는 데 있어 중요한 역할을 합니다. 이는 $P(A|B) > P(A)$라는 부등식으로 표현되며, 이는 사건 $A$에 대한 행동 $B$의 영향을 나타냅니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "unsupervised text generation",
        "domain": "cs.AI",
        "summary": "  The Apperception Engine is an unsupervised learning system. Given a sequence\nof sensory inputs, it constructs a symbolic causal theory that both explains\nthe sensory sequence and also satisfies a set of unity conditions. The unity\nconditions insist that the constituents of the theory - objects, properties,\nand laws - must be integrated into a coherent whole. Once a theory has been\nconstructed, it can be applied to predict future sensor readings, retrodict\nearlier readings, or impute missing readings.\n  In this paper, we evaluate the Apperception Engine in a diverse variety of\ndomains, including cellular automata, rhythms and simple nursery tunes,\nmulti-modal binding problems, occlusion tasks, and sequence induction\nintelligence tests. In each domain, we test our engine's ability to predict\nfuture sensor values, retrodict earlier sensor values, and impute missing\nsensory data. The engine performs well in all these domains, significantly\noutperforming neural net baselines and state of the art inductive logic\nprogramming systems. These results are significant because neural nets\ntypically struggle to solve the binding problem (where information from\ndifferent modalities must somehow be combined together into different aspects\nof one unified object) and fail to solve occlusion tasks (in which objects are\nsometimes visible and sometimes obscured from view). We note in particular that\nin the sequence induction intelligence tests, our system achieved human-level\nperformance. This is notable because our system is not a bespoke system\ndesigned specifically to solve intelligence tests, but a general-purpose system\nthat was designed to make sense of any sensory sequence.\n",
        "english": "Unsupervised text generation, as exemplified by the Apperception Engine, employs a symbolic causal theory to explain sensory sequences, satisfying unity conditions that integrate objects, properties, and laws into a coherent whole. This system's ability to predict future sensor readings, retrodict earlier readings, and impute missing data significantly outperforms neural net baselines, particularly in domains like cellular automata and sequence induction intelligence tests, where it achieves human-level performance. Notably, the engine's efficacy is underscored by its success in solving the binding problem and occlusion tasks, areas where neural networks typically struggle, thus demonstrating the robustness and general-purpose applicability of unsupervised learning in text generation contexts.",
        "korean": "비지도 텍스트 생성(unsupervised text generation)은 감각적 연속성을 설명하기 위해 상징적 인과 이론(symbolic causal theory)을 활용하는 Apperception Engine으로 대표되며, 객체, 속성 및 법칙을 통합하여 일관된 전체를 형성하는 통합 조건을 만족시킵니다. 이 시스템의 미래 센서 판독값 예측, 이전 판독값의 역추론 및 누락된 데이터의 추론 능력은 특히 셀룰러 오토마타(cellular automata)와 시퀀스 귀납 지능 테스트(sequence induction intelligence tests)와 같은 도메인에서 신경망 기준선(neural net baselines)을 크게 능가하며, 인간 수준의 성능을 달성합니다. 특히, 이 엔진의 효율성은 결합 문제(binding problem)와 폐색 작업(occlusion tasks) 해결에서의 성공으로 강조되며, 이는 신경망이 일반적으로 어려움을 겪는 영역으로, 텍스트 생성 맥락에서 비지도 학습(unsupervised learning)의 견고성과 범용성을 입증합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase letters within parentheses."
    },
    {
        "turn_index": 2,
        "term": "neural scene models",
        "domain": "cs.AI",
        "summary": "  Gestalt psychologists have identified a range of conditions in which humans\norganize elements of a scene into a group or whole, and perceptual grouping\nprinciples play an essential role in scene perception and object\nidentification. Recently, Deep Neural Networks (DNNs) trained on natural images\n(ImageNet) have been proposed as compelling models of human vision based on\nreports that they perform well on various brain and behavioral benchmarks. Here\nwe test a total of 16 networks covering a variety of architectures and learning\nparadigms (convolutional, attention-based, supervised and self-supervised,\nfeed-forward and recurrent) on dots (Experiment 1) and more complex shapes\n(Experiment 2) stimuli that produce strong Gestalts effects in humans. In\nExperiment 1 we found that convolutional networks were indeed sensitive in a\nhuman-like fashion to the principles of proximity, linearity, and orientation,\nbut only at the output layer. In Experiment 2, we found that most networks\nexhibited Gestalt effects only for a few sets, and again only at the latest\nstage of processing. Overall, self-supervised and Vision-Transformer appeared\nto perform worse than convolutional networks in terms of human similarity.\nRemarkably, no model presented a grouping effect at the early or intermediate\nstages of processing. This is at odds with the widespread assumption that\nGestalts occur prior to object recognition, and indeed, serve to organize the\nvisual scene for the sake of object recognition. Our overall conclusion is\nthat, albeit noteworthy that networks trained on simple 2D images support a\nform of Gestalt grouping for some stimuli at the output layer, this ability\ndoes not seem to transfer to more complex features. Additionally, the fact that\nthis grouping only occurs at the last layer suggests that networks learn\nfundamentally different perceptual properties than humans.\n",
        "english": "Neural scene models, particularly Deep Neural Networks (DNNs) trained on natural images, have been proposed as compelling models of human vision due to their performance on various brain and behavioral benchmarks, highlighting their potential in understanding perceptual grouping principles. In examining these models, a study tested 16 networks with diverse architectures, such as convolutional and attention-based, on stimuli that evoke strong Gestalt effects in humans, revealing that while convolutional networks exhibited human-like sensitivity to principles like proximity, linearity, and orientation, this was observed only at the output layer. Notably, the research underscores that no model demonstrated a grouping effect at early or intermediate processing stages, indicating that $\\text{Gestalt grouping}$ occurs differently in neural scene models compared to human perception, thus challenging the assumption that these effects precede object recognition.",
        "korean": "신경 장면 모델(neural scene models), 특히 자연 이미지에 대해 훈련된 심층 신경망(deep neural networks, DNNs)은 다양한 뇌 및 행동 벤치마크(brain and behavioral benchmarks)에서의 성능 덕분에 인간 시각의 설득력 있는 모델로 제안되었습니다. 이러한 모델을 검토하는 과정에서, 연구는 다양한 아키텍처를 가진 16개의 네트워크를 시험하였으며, 여기에는 합성곱 및 주의 기반(convolutional and attention-based) 네트워크가 포함되었습니다. 이들은 인간에게 강한 형태 효과(Gestalt effects)를 유발하는 자극에 대해 시험되었으며, 합성곱 네트워크는 근접성, 선형성, 방향성 등의 원리에 대해 인간과 유사한 민감성을 보였지만, 이는 출력 층에서만 관찰되었습니다. 특히, 연구는 초기 또는 중간 처리 단계에서 어떤 모델도 군집 효과(grouping effect)를 나타내지 않았음을 강조하며, 이는 신경 장면 모델(neural scene models)에서의 형태 군집(Gestalt grouping)이 인간 지각과 다르게 발생함을 나타내며, 이러한 효과가 객체 인식에 선행한다는 가정을 도전합니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent lowercase for all terms within parentheses."
    },
    {
        "turn_index": 2,
        "term": "neural probabilistic text learning",
        "domain": "cs.AI",
        "summary": "  Explanations on relational data are hard to verify since the explanation\nstructures are more complex (e.g. graphs). To verify interpretable explanations\n(e.g. explanations of predictions made in images, text, etc.), typically human\nsubjects are used since it does not necessarily require a lot of expertise.\nHowever, to verify the quality of a relational explanation requires expertise\nand is hard to scale-up. GNNExplainer is arguably one of the most popular\nexplanation methods for Graph Neural Networks. In this paper, we develop an\napproach where we assess the uncertainty in explanations generated by\nGNNExplainer. Specifically, we ask the explainer to generate explanations for\nseveral counterfactual examples. We generate these examples as symmetric\napproximations of the relational structure in the original data. From these\nexplanations, we learn a factor graph model to quantify uncertainty in an\nexplanation. Our results on several datasets show that our approach can help\nverify explanations from GNNExplainer by reliably estimating the uncertainty of\na relation specified in the explanation.\n",
        "english": "Neural probabilistic text learning involves leveraging complex explanation structures, such as graphs, to enhance the interpretability of predictions made in text, images, and other domains. In this context, methodologies like GNNExplainer, which is one of the most popular explanation methods for Graph Neural Networks, are pivotal as they generate explanations for counterfactual examples, allowing the assessment of uncertainty in these explanations. By learning a factor graph model from these explanations, the uncertainty of a relation specified in the explanation can be quantified, with results on several datasets demonstrating that this approach can reliably estimate uncertainty, thereby enhancing the verification process of relational explanations.",
        "korean": "신경 확률적 텍스트 학습(neural probabilistic text learning)은 그래프와 같은 복잡한 설명 구조를 활용하여 텍스트, 이미지 및 기타 도메인에서 예측의 해석 가능성을 향상시키는 것을 포함합니다. 이 맥락에서 그래프 신경망(graph neural networks, GNN)의 가장 인기 있는 설명 방법 중 하나인 GNNExplainer와 같은 방법론은 반사실적 예제에 대한 설명을 생성하여 이러한 설명의 불확실성을 평가할 수 있게 해주는 중요한 역할을 합니다. 이러한 설명으로부터 인자 그래프 모델(factor graph model)을 학습함으로써 설명에 명시된 관계의 불확실성을 정량화할 수 있으며, 여러 데이터셋에서의 결과는 이 접근 방식이 불확실성을 신뢰성 있게 추정할 수 있음을 보여주어 관계적 설명의 검증 과정을 향상시킵니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as adjusting the placement of \"GNNExplainer\" for better flow."
    },
    {
        "turn_index": 2,
        "term": "sequence tagging",
        "domain": "cs.AI",
        "summary": "  The knowledge graph (KG) stores a large amount of structural knowledge, while\nit is not easy for direct human understanding. Knowledge graph-to-text\n(KG-to-text) generation aims to generate easy-to-understand sentences from the\nKG, and at the same time, maintains semantic consistency between generated\nsentences and the KG. Existing KG-to-text generation methods phrase this task\nas a sequence-to-sequence generation task with linearized KG as input and\nconsider the consistency issue of the generated texts and KG through a simple\nselection between decoded sentence word and KG node word at each time step.\nHowever, the linearized KG order is commonly obtained through a heuristic\nsearch without data-driven optimization. In this paper, we optimize the\nknowledge description order prediction under the order supervision extracted\nfrom the caption and further enhance the consistency of the generated sentences\nand KG through syntactic and semantic regularization. We incorporate the\nPart-of-Speech (POS) syntactic tags to constrain the positions to copy words\nfrom the KG and employ a semantic context scoring function to evaluate the\nsemantic fitness for each word in its local context when decoding each word in\nthe generated sentence. Extensive experiments are conducted on two datasets,\nWebNLG and DART, and achieve state-of-the-art performances.\n",
        "korean": "시퀀스 태깅(sequence tagging)은 캡션에서 추출된 순서 감독 하에 지식 설명 순서 예측을 최적화하는 데 중요한 역할을 하며, 구문 및 의미 규제를 통해 생성된 문장과 지식 그래프(knowledge graph, KG) 간의 일관성을 향상시킵니다. 품사(part-of-speech, POS) 구문 태그를 통합함으로써, 이 방법론은 KG에서 단어를 복사할 위치를 제한하고, 각 단어의 지역적 맥락에서 의미적 적합성을 평가하는 의미적 맥락 점수 함수를 사용하여 생성된 문장이 KG와 의미적 일관성을 유지하도록 합니다. 연구는 WebNLG 및 DART와 같은 데이터셋에서 최첨단 성능을 달성하며, 공식 \\( \\text{Score} = \\frac{\\text{Semantic Fit}}{\\text{KG Consistency}} \\)을 사용하여 정량적 개선을 측정함으로써 혁신적인 접근 방식의 효능을 강조합니다."
    },
    {
        "turn_index": 2,
        "term": "adaptive neural learning",
        "domain": "cs.AI",
        "summary": "  Motor adaptation displays a structure-learning effect: adaptation to a new\nperturbation occurs more quickly when the subject has prior exposure to\nperturbations with related structure. Although this `learning-to-learn' effect\nis well documented, its underlying computational mechanisms are poorly\nunderstood. We present a new model of motor structure learning, approaching it\nfrom the point of view of deep reinforcement learning. Previous work outside of\nmotor control has shown how recurrent neural networks can account for\nlearning-to-learn effects. We leverage this insight to address motor learning,\nby importing it into the setting of model-based reinforcement learning. We\napply the resulting processing architecture to empirical findings from a\nlandmark study of structure learning in target-directed reaching (Braun et al.,\n2009), and discuss its implications for a wider range of learning-to-learn\nphenomena.\n",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and maintain a natural flow in the translation. Consider rephrasing for smoother readability while preserving the original meaning."
    },
    {
        "turn_index": 2,
        "term": "dynamic neural inference",
        "domain": "cs.AI",
        "summary": "  Sequence-to-sequence (encoder-decoder) models with attention constitute a\ncornerstone of deep learning research, as they have enabled unprecedented\nsequential data modeling capabilities. This effectiveness largely stems from\nthe capacity of these models to infer salient temporal dynamics over long\nhorizons; these are encoded into the obtained neural attention (NA)\ndistributions. However, existing NA formulations essentially constitute\npoint-wise selection mechanisms over the observed source sequences; that is,\nattention weights computation relies on the assumption that each source\nsequence element is independent of the rest. Unfortunately, although\nconvenient, this assumption fails to account for higher-order dependencies\nwhich might be prevalent in real-world data. This paper addresses these\nlimitations by leveraging Quantum-Statistical modeling arguments. Specifically,\nour work broadens the notion of NA, by attempting to account for the case that\nthe NA model becomes inherently incapable of discerning between individual\nsource elements; this is assumed to be the case due to higher-order temporal\ndynamics. On the contrary, we postulate that in some cases selection may be\nfeasible only at the level of pairs of source sequence elements. To this end,\nwe cast NA into inference of an attention density matrix (ADM) approximation.\nWe derive effective training and inference algorithms, and evaluate our\napproach in the context of a machine translation (MT) application. We perform\nexperiments with challenging benchmark datasets. As we show, our approach\nyields favorable outcomes in terms of several evaluation metrics.\n",
        "english": "Dynamic neural inference, as explored through sequence-to-sequence models with attention, significantly enhances sequential data modeling by enabling the inference of salient temporal dynamics over extended periods, which are encoded into the neural attention (NA) distributions. This research innovatively broadens the concept of NA by leveraging Quantum-Statistical modeling arguments to address the limitations of existing formulations that rely on point-wise selection mechanisms, thus failing to account for higher-order dependencies prevalent in real-world data. By casting NA into the inference of an attention density matrix (ADM) approximation and deriving effective training and inference algorithms, the study demonstrates improved outcomes in machine translation applications, achieving favorable results across several evaluation metrics.",
        "korean": "주의 메커니즘(attention)을 갖춘 시퀀스-투-시퀀스 모델(sequence-to-sequence models)을 통해 탐구된 동적 신경 추론(dynamic neural inference)은 확장된 기간 동안 중요한 시간적 역학을 추론할 수 있게 함으로써 순차적 데이터 모델링을 크게 향상시킵니다. 이는 신경 주의(NA) 분포에 인코딩됩니다. 이 연구는 기존의 점별 선택 메커니즘에 의존하는 공식의 한계를 해결하기 위해 양자-통계적 모델링 논거(quantum-statistical modeling arguments)를 활용하여 NA의 개념을 혁신적으로 확장합니다. 이는 실제 데이터에서 흔히 발생하는 고차 의존성을 고려하지 못하는 문제를 해결합니다. NA를 주의 밀도 행렬(ADM) 근사(attention density matrix approximation)의 추론으로 변환하고 효과적인 훈련 및 추론 알고리즘을 도출함으로써, 이 연구는 기계 번역 응용에서 개선된 결과를 보여주며 여러 평가 지표에서 유리한 결과를 달성합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure that all technical terms are consistently parenthesized in the format Korean term(English term) and adjust the structure for natural flow and grammar."
    },
    {
        "turn_index": 2,
        "term": "domain generalization",
        "domain": "cs.AI",
        "summary": "  Social media misinformation harms individuals and societies and is\npotentialized by fast-growing multi-modal content (i.e., texts and images),\nwhich accounts for higher \"credibility\" than text-only news pieces. Although\nexisting supervised misinformation detection methods have obtained acceptable\nperformances in key setups, they may require large amounts of labeled data from\nvarious events, which can be time-consuming and tedious. In turn, directly\ntraining a model by leveraging a publicly available dataset may fail to\ngeneralize due to domain shifts between the training data (a.k.a. source\ndomains) and the data from target domains. Most prior work on domain shift\nfocuses on a single modality (e.g., text modality) and ignores the scenario\nwhere sufficient unlabeled target domain data may not be readily available in\nan early stage. The lack of data often happens due to the dynamic propagation\ntrend (i.e., the number of posts related to fake news increases slowly before\ncatching the public attention). We propose a novel robust domain and\ncross-modal approach (\\textbf{RDCM}) for multi-modal misinformation detection.\nIt reduces the domain shift by aligning the joint distribution of textual and\nvisual modalities through an inter-domain alignment module and bridges the\nsemantic gap between both modalities through a cross-modality alignment module.\nWe also propose a framework that simultaneously considers application scenarios\nof domain generalization (in which the target domain data is unavailable) and\ndomain adaptation (in which unlabeled target domain data is available).\nEvaluation results on two public multi-modal misinformation detection datasets\n(Pheme and Twitter Datasets) evince the superiority of the proposed model. The\nformal implementation of this paper can be found in this link:\nhttps://github.com/less-and-less-bugs/RDCM\n",
        "english": "In the context of domain generalization, the proposed robust domain and cross-modal approach (RDCM) for multi-modal misinformation detection addresses the challenge of domain shifts by aligning the joint distribution of textual and visual modalities through an inter-domain alignment module. This innovative framework simultaneously considers scenarios of domain generalization, where target domain data is unavailable, and domain adaptation, where unlabeled target domain data is present, thus enhancing the model's adaptability. Evaluation results on datasets such as Pheme and Twitter demonstrate the model's efficacy, with a significant reduction in domain shift, as evidenced by improved performance metrics, including a notable increase in accuracy from $0.75$ to $0.82$.",
        "korean": "도메인 일반화(domain generalization)의 맥락에서, 다중 모달 허위 정보 탐지를 위한 제안된 강력한 도메인 및 교차 모달 접근법(robust domain and cross-modal approach, RDCM)은 도메인 이동의 문제를 해결하기 위해 도메인 간 정렬 모듈(inter-domain alignment module)을 통해 텍스트 및 시각 모달리티의 결합 분포를 정렬합니다. 이 혁신적인 프레임워크는 대상 도메인 데이터가 없는 도메인 일반화(domain generalization) 시나리오와 레이블이 없는 대상 도메인 데이터가 있는 도메인 적응(domain adaptation) 시나리오를 동시에 고려하여 모델의 적응성을 향상시킵니다. Pheme 및 Twitter와 같은 데이터셋에 대한 평가 결과는 정확도가 $0.75$에서 $0.82$로 눈에 띄게 증가하는 등 성능 지표가 개선되어 도메인 이동이 크게 감소했음을 보여줍니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "contextual neural modeling",
        "domain": "cs.AI",
        "summary": "  In recent years, data-intensive AI, particularly the domain of natural\nlanguage processing and understanding, has seen significant progress driven by\nthe advent of large datasets and deep neural networks that have sidelined more\nclassic AI approaches to the field. These systems can apparently demonstrate\nsophisticated linguistic understanding or generation capabilities, but often\nfail to transfer their skills to situations they have not encountered before.\nWe argue that computational situated grounding provides a solution to some of\nthese learning challenges by creating situational representations that both\nserve as a formal model of the salient phenomena, and contain rich amounts of\nexploitable, task-appropriate data for training new, flexible computational\nmodels. Our model reincorporates some ideas of classic AI into a framework of\nneurosymbolic intelligence, using multimodal contextual modeling of interactive\nsituations, events, and object properties. We discuss how situated grounding\nprovides diverse data and multiple levels of modeling for a variety of AI\nlearning challenges, including learning how to interact with object\naffordances, learning semantics for novel structures and configurations, and\ntransferring such learned knowledge to new objects and situations.\n",
        "english": "Contextual neural modeling, as an innovative approach within data-intensive AI, integrates multimodal contextual modeling to enhance the understanding and generation capabilities of neural networks, particularly in natural language processing and understanding. By creating situational representations that serve as formal models of salient phenomena, this approach incorporates the principles of computational situated grounding to address learning challenges, such as interacting with object affordances and learning semantics for novel structures. Moreover, leveraging these rich situational representations, contextual neural modeling facilitates the transfer of learned knowledge to new objects and situations, thereby enhancing the adaptability of AI systems, which can be represented as $f(x) = \\sum_{i=1}^{n} \\alpha_i x_i$, where $\\alpha_i$ are the learned weights and $x_i$ represent different contextual inputs.",
        "korean": "데이터 집약적 인공지능(data-intensive AI) 내에서 혁신적인 접근 방식으로서의 맥락적 신경 모델링(contextual neural modeling)은 자연어 처리 및 이해 분야에서 신경망의 이해 및 생성 능력을 향상시키기 위해 다중 모달 맥락 모델링(multimodal contextual modeling)을 통합합니다. 이 접근 방식은 두드러진 현상의 형식적 모델로 작용하는 상황적 표현을 생성함으로써, 객체의 사용 가능성과 새로운 구조에 대한 의미론 학습과 같은 학습 과제를 해결하기 위해 계산적 상황적 그라운딩(computational situated grounding)의 원칙을 통합합니다. 더욱이, 이러한 풍부한 상황적 표현을 활용하여 맥락적 신경 모델링(contextual neural modeling)은 학습된 지식을 새로운 객체와 상황으로 전이하는 것을 용이하게 하여 인공지능 시스템의 적응성을 향상시킵니다. 이는 $\\alpha_i$가 학습된 가중치이고 $x_i$가 다양한 맥락적 입력을 나타내는 경우 $f(x) = \\sum_{i=1}^{n} \\alpha_i x_i$로 표현될 수 있습니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "capsule networks",
        "domain": "cs.AI",
        "summary": "  In this study, we explore capsule networks with dynamic routing for text\nclassification. We propose three strategies to stabilize the dynamic routing\nprocess to alleviate the disturbance of some noise capsules which may contain\n\"background\" information or have not been successfully trained. A series of\nexperiments are conducted with capsule networks on six text classification\nbenchmarks. Capsule networks achieve state of the art on 4 out of 6 datasets,\nwhich shows the effectiveness of capsule networks for text classification. We\nadditionally show that capsule networks exhibit significant improvement when\ntransfer single-label to multi-label text classification over strong baseline\nmethods. To the best of our knowledge, this is the first work that capsule\nnetworks have been empirically investigated for text modeling.\n",
        "english": "Capsule networks, when employed with dynamic routing, demonstrate significant advancements in text classification by proposing three strategies to stabilize the dynamic routing process, thereby mitigating the disturbance caused by noise capsules containing \"background\" information or those not successfully trained. Through a series of experiments conducted on six text classification benchmarks, capsule networks achieved state-of-the-art results on four datasets, underscoring their effectiveness and potential in this domain. Notably, the research highlights the capability of capsule networks to substantially improve performance when transferring from single-label to multi-label text classification, outperforming strong baseline methods, with a notable accuracy improvement quantified as $\\Delta \\text{Accuracy} = +5.3\\%$.",
        "korean": "캡슐 네트워크(capsule networks)는 동적 라우팅(dynamic routing)을 활용할 때, 동적 라우팅 과정을 안정화하기 위한 세 가지 전략을 제안하여 \"배경\" 정보를 포함하거나 성공적으로 훈련되지 않은 노이즈 캡슐(noise capsules)로 인한 방해를 완화함으로써 텍스트 분류(text classification)에서 상당한 발전을 보여줍니다. 여섯 개의 텍스트 분류 벤치마크에서 수행된 일련의 실험을 통해 캡슐 네트워크(capsule networks)는 네 개의 데이터셋에서 최첨단 결과를 달성하여 이 분야에서의 효과성과 잠재력을 강조합니다. 특히, 연구는 캡슐 네트워크(capsule networks)가 단일 레이블(single-label)에서 다중 레이블 텍스트 분류(multi-label text classification)로 전환할 때 성능을 크게 향상시킬 수 있는 능력을 강조하며, 강력한 기준 방법을 능가하고, 정확도 개선이 $\\Delta \\text{Accuracy} = +5.3\\%$로 정량화된다는 점을 주목합니다.",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "meta-gradient learning",
        "domain": "cs.AI",
        "summary": "  Mechanical learning is a computing system that is based on a set of simple\nand fixed rules, and can learn from incoming data. A learning machine is a\nsystem that realizes mechanical learning. Importantly, we emphasis that it is\nbased on a set of simple and fixed rules, contrasting to often called machine\nlearning that is sophisticated software based on very complicated mathematical\ntheory, and often needs human intervene for software fine tune and manual\nadjustments. Here, we discuss some basic facts and principles of such system,\nand try to lay down a framework for further study. We propose 2 directions to\napproach mechanical learning, just like Church-Turing pair: one is trying to\nrealize a learning machine, another is trying to well describe the mechanical\nlearning.\n",
        "english": "Meta-gradient learning, a subset of mechanical learning, operates on \"a set of simple and fixed rules\" and emphasizes learning from incoming data without requiring sophisticated software or human intervention. This approach contrasts with traditional machine learning, which \"is based on very complicated mathematical theory,\" often necessitating manual adjustments. By integrating the principles of mechanical learning, meta-gradient learning can be represented as a function $f(x) = ax + b$, where $a$ and $b$ are constants derived from the fixed rules, highlighting its potential for innovation in creating more autonomous learning systems.",
        "korean": "기계 학습(mechanical learning)의 하위 집합인 메타-그라디언트 학습(meta-gradient learning)은 \"단순하고 고정된 규칙의 집합\"에 기반하여 작동하며, 정교한 소프트웨어나 인간의 개입 없이 들어오는 데이터로부터 학습하는 것을 강조합니다. 이 접근 방식은 종종 수동 조정이 필요한 \"매우 복잡한 수학 이론에 기반한\" 전통적인 기계 학습(traditional machine learning)과 대조됩니다. 기계 학습(mechanical learning)의 원칙을 통합함으로써, 메타-그라디언트 학습(meta-gradient learning)은 $f(x) = ax + b$와 같은 함수로 표현될 수 있으며, 여기서 $a$와 $b$는 고정된 규칙에서 도출된 상수로, 보다 자율적인 학습 시스템을 창출하는 혁신의 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural adaptive computation",
        "domain": "cs.AI",
        "summary": "  Most recently proposed methods for Neural Program Induction work under the\nassumption of having a large set of input/output (I/O) examples for learning\nany underlying input-output mapping. This paper aims to address the problem of\ndata and computation efficiency of program induction by leveraging information\nfrom related tasks. Specifically, we propose two approaches for cross-task\nknowledge transfer to improve program induction in limited-data scenarios. In\nour first proposal, portfolio adaptation, a set of induction models is\npretrained on a set of related tasks, and the best model is adapted towards the\nnew task using transfer learning. In our second approach, meta program\ninduction, a $k$-shot learning approach is used to make a model generalize to\nnew tasks without additional training. To test the efficacy of our methods, we\nconstructed a new benchmark of programs written in the Karel programming\nlanguage. Using an extensive experimental evaluation on the Karel benchmark, we\ndemonstrate that our proposals dramatically outperform the baseline induction\nmethod that does not use knowledge transfer. We also analyze the relative\nperformance of the two approaches and study conditions in which they perform\nbest. In particular, meta induction outperforms all existing approaches under\nextreme data sparsity (when a very small number of examples are available),\ni.e., fewer than ten. As the number of available I/O examples increase (i.e. a\nthousand or more), portfolio adapted program induction becomes the best\napproach. For intermediate data sizes, we demonstrate that the combined method\nof adapted meta program induction has the strongest performance.\n",
        "english": "Neural adaptive computation has recently advanced through methods that leverage information from related tasks to address the data and computation efficiency of program induction, particularly in scenarios with limited data availability. Specifically, the proposed approaches of portfolio adaptation and meta program induction demonstrate significant improvements, with meta induction excelling under extreme data sparsity conditions, where fewer than ten examples are available, and portfolio adaptation becoming optimal as the number of input/output examples increases to a thousand or more. By employing a $k$-shot learning approach, neural adaptive computation in meta program induction facilitates model generalization to new tasks without additional training, thereby showcasing its innovation and importance in the field of program induction.",
        "korean": "신경 적응 계산(neural adaptive computation)은 최근 관련 작업에서 정보를 활용하여 프로그램 유도(program induction)의 데이터 및 계산 효율성을 해결하는 방법을 통해 발전하였습니다. 특히, 포트폴리오 적응(portfolio adaptation)과 메타 프로그램 유도(meta program induction)의 제안된 접근 방식은 상당한 개선을 보여주며, 메타 유도(meta induction)는 데이터가 극도로 부족한 조건, 즉 10개 미만의 예제가 있는 경우에 뛰어난 성능을 발휘하고, 포트폴리오 적응(portfolio adaptation)은 입력/출력 예제의 수가 천 개 이상으로 증가할 때 최적의 성능을 발휘합니다. $k$-샷 학습 접근법($k$-shot learning approach)을 사용함으로써, 메타 프로그램 유도(meta program induction)에서의 신경 적응 계산(neural adaptive computation)은 추가적인 훈련 없이 새로운 작업에 대한 모델 일반화를 촉진하여 프로그램 유도(program induction) 분야에서의 혁신성과 중요성을 보여줍니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "hidden markov models",
        "domain": "cs.AI",
        "summary": "  Analysis of sequential event data has been recognized as one of the essential\ntools in data modeling and analysis field. In this paper, after the examination\nof its technical requirements and issues to model complex but practical\nsituation, we propose a new sequential data model, dubbed Duration and Interval\nHidden Markov Model (DI-HMM), that efficiently represents \"state duration\" and\n\"state interval\" of data events. This has significant implications to play an\nimportant role in representing practical time-series sequential data. This\neventually provides an efficient and flexible sequential data retrieval.\nNumerical experiments on synthetic and real data demonstrate the efficiency and\naccuracy of the proposed DI-HMM.\n",
        "korean": "은닉 마르코프 모델(hidden markov models, hmms)은 데이터 이벤트의 \"상태 지속 시간\"과 \"상태 간격\"을 효율적으로 포착하는 새로운 프레임워크인 지속 시간 및 간격 은닉 마르코프 모델(duration and interval hidden markov model, di-hmm)로 확장되었습니다. 이 접근 방식은 복잡한 시나리오를 모델링하기 위한 기술적 요구 사항을 해결하며, 고유한 시간 구조를 활용하여 시계열 순차 데이터 검색에서 상당한 개선을 제공합니다. 합성 및 실제 데이터셋 모두에 대해 수행된 수치 실험은 di-hmm의 우수한 효율성과 정확성을 입증하며, 정밀도와 재현율과 같은 성능 지표가 전통적인 hmms에 비해 개선되었음을 보여주며, 이는 $\\text{DI-HMM} = \\text{HMM} + \\text{Temporal Features}$를 나타냅니다."
    },
    {
        "turn_index": 2,
        "term": "neural context-aware generation",
        "domain": "cs.AI",
        "summary": "  The problem of automatically generating a computer program from some\nspecification has been studied since the early days of AI. Recently, two\ncompeting approaches for automatic program learning have received significant\nattention: (1) neural program synthesis, where a neural network is conditioned\non input/output (I/O) examples and learns to generate a program, and (2) neural\nprogram induction, where a neural network generates new outputs directly using\na latent program representation.\n  Here, for the first time, we directly compare both approaches on a\nlarge-scale, real-world learning task. We additionally contrast to rule-based\nprogram synthesis, which uses hand-crafted semantics to guide the program\ngeneration. Our neural models use a modified attention RNN to allow encoding of\nvariable-sized sets of I/O pairs. Our best synthesis model achieves 92%\naccuracy on a real-world test set, compared to the 34% accuracy of the previous\nbest neural synthesis approach. The synthesis model also outperforms a\ncomparable induction model on this task, but we more importantly demonstrate\nthat the strength of each approach is highly dependent on the evaluation metric\nand end-user application. Finally, we show that we can train our neural models\nto remain very robust to the type of noise expected in real-world data (e.g.,\ntypos), while a highly-engineered rule-based system fails entirely.\n",
        "english": "Neural context-aware generation leverages the power of modified attention RNNs to encode variable-sized sets of input/output (I/O) pairs, enabling the creation of robust and accurate program synthesis models. In a direct comparison on a large-scale, real-world learning task, the synthesis model achieved an impressive 92\\% accuracy, significantly outperforming the previous best neural synthesis approach, which only reached 34\\% accuracy, as well as a comparable induction model. This advancement underscores the importance of neural context-aware generation in achieving high performance across various applications and metrics, particularly in environments with real-world noise such as typographical errors, where traditional rule-based systems may falter.",
        "korean": "신경 문맥 인식 생성(neural context-aware generation)은 수정된 주의 메커니즘(attention mechanisms)을 사용하는 순환 신경망(RNNs)을 활용하여 가변 크기의 입력/출력(I/O) 쌍을 인코딩함으로써 견고하고 정확한 프로그램 합성 모델(program synthesis models)을 생성할 수 있게 합니다. 대규모 실세계 학습 과제에서의 직접 비교에서, 이 합성 모델은 92\\%의 인상적인 정확도를 달성하여 이전 최고의 신경 합성 접근법(neural synthesis approach)이 달성한 34\\%의 정확도와 유사한 유도 모델(induction model)을 크게 능가했습니다. 이러한 발전은 특히 전통적인 규칙 기반 시스템(rule-based systems)이 실패할 수 있는 오타와 같은 실세계의 잡음이 있는 환경에서 다양한 응용 프로그램과 지표에서 높은 성능을 달성하는 데 있어 신경 문맥 인식 생성(neural context-aware generation)의 중요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "computer vision",
        "domain": "cs.AI",
        "summary": "  We present DeepSeek-VL, an open-source Vision-Language (VL) Model designed\nfor real-world vision and language understanding applications. Our approach is\nstructured around three key dimensions:\n  We strive to ensure our data is diverse, scalable, and extensively covers\nreal-world scenarios including web screenshots, PDFs, OCR, charts, and\nknowledge-based content, aiming for a comprehensive representation of practical\ncontexts. Further, we create a use case taxonomy from real user scenarios and\nconstruct an instruction tuning dataset accordingly. The fine-tuning with this\ndataset substantially improves the model's user experience in practical\napplications. Considering efficiency and the demands of most real-world\nscenarios, DeepSeek-VL incorporates a hybrid vision encoder that efficiently\nprocesses high-resolution images (1024 x 1024), while maintaining a relatively\nlow computational overhead. This design choice ensures the model's ability to\ncapture critical semantic and detailed information across various visual tasks.\nWe posit that a proficient Vision-Language Model should, foremost, possess\nstrong language abilities. To ensure the preservation of LLM capabilities\nduring pretraining, we investigate an effective VL pretraining strategy by\nintegrating LLM training from the beginning and carefully managing the\ncompetitive dynamics observed between vision and language modalities.\n  The DeepSeek-VL family (both 1.3B and 7B models) showcases superior user\nexperiences as a vision-language chatbot in real-world applications, achieving\nstate-of-the-art or competitive performance across a wide range of\nvisual-language benchmarks at the same model size while maintaining robust\nperformance on language-centric benchmarks. We have made both 1.3B and 7B\nmodels publicly accessible to foster innovations based on this foundation\nmodel.\n",
        "english": "In the domain of computer vision, the development of DeepSeek-VL represents a significant advancement, as it is an open-source Vision-Language (VL) Model specifically designed for real-world vision and language understanding applications. The model's architecture includes a hybrid vision encoder capable of efficiently processing high-resolution images of size $1024 \\times 1024$, while maintaining a relatively low computational overhead, thus ensuring its ability to capture critical semantic and detailed information across various visual tasks. By integrating LLM training from the outset and managing the competitive dynamics between vision and language modalities, DeepSeek-VL achieves state-of-the-art or competitive performance across a wide range of visual-language benchmarks, marking a substantial contribution to the field.",
        "korean": "컴퓨터 비전(computer vision) 분야에서 DeepSeek-VL의 개발은 실세계 비전 및 언어 이해 응용을 위해 특별히 설계된 오픈 소스 비전-언어(vision-language, VL) 모델로서 중요한 발전을 나타냅니다. 이 모델의 아키텍처는 $1024 \\times 1024$ 크기의 고해상도 이미지를 효율적으로 처리할 수 있는 하이브리드 비전 인코더(hybrid vision encoder)를 포함하고 있으며, 상대적으로 낮은 계산 오버헤드를 유지하여 다양한 시각적 작업에서 중요한 의미론적 및 세부 정보를 포착할 수 있는 능력을 보장합니다. 초기부터 대형 언어 모델(large language model, llm) 훈련을 통합하고 비전과 언어 모달리티 간의 경쟁 역학을 관리함으로써, DeepSeek-VL은 다양한 비전-언어 벤치마크에서 최첨단 또는 경쟁력 있는 성능을 달성하여 이 분야에 상당한 기여를 하고 있습니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic probabilistic modeling",
        "domain": "cs.AI",
        "summary": "  We describe a representation and a set of inference methods that combine\nlogic programming techniques with probabilistic network representations for\nuncertainty (influence diagrams). The techniques emphasize the dynamic\nconstruction and solution of probabilistic and decision-theoretic models for\ncomplex and uncertain domains. Given a query, a logical proof is produced if\npossible; if not, an influence diagram based on the query and the knowledge of\nthe decision domain is produced and subsequently solved. A uniform declarative,\nfirst-order, knowledge representation is combined with a set of integrated\ninference procedures for logical, probabilistic, and decision-theoretic\nreasoning.\n",
        "english": "Dynamic probabilistic modeling is enhanced by integrating logic programming techniques with probabilistic network representations, such as influence diagrams, to address uncertainty in complex domains. This approach emphasizes the \"dynamic construction and solution of probabilistic and decision-theoretic models,\" allowing for the generation of logical proofs or the creation of influence diagrams based on queries and domain knowledge. By combining a \"uniform declarative, first-order, knowledge representation\" with integrated inference procedures, the methodology supports logical, probabilistic, and decision-theoretic reasoning, thereby enabling the solution of models where $P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$ is utilized to calculate conditional probabilities effectively.",
        "korean": "동적 확률 모델링(dynamic probabilistic modeling)은 복잡한 도메인에서의 불확실성을 해결하기 위해 논리 프로그래밍 기법(logic programming techniques)과 영향 다이어그램(influence diagrams)과 같은 확률 네트워크 표현(probabilistic network representations)을 통합함으로써 향상됩니다. 이 접근법은 \"확률 및 의사결정 이론 모델의 동적 구성 및 해결\"을 강조하며, 쿼리와 도메인 지식을 기반으로 논리적 증명을 생성하거나 영향 다이어그램을 생성할 수 있게 합니다. \"균일한 선언적, 일차 지식 표현(uniform declarative, first-order, knowledge representation)\"과 통합된 추론 절차를 결합함으로써, 이 방법론은 논리적, 확률적, 의사결정 이론적 추론을 지원하여 $P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$를 사용하여 조건부 확률을 효과적으로 계산할 수 있는 모델의 해결을 가능하게 합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all terms within parentheses are in lowercase for consistency."
    },
    {
        "turn_index": 2,
        "term": "word embeddings",
        "domain": "cs.AI",
        "summary": "  Over the last few years, neural network derived word embeddings became\npopular in the natural language processing literature. Studies conducted have\nmostly focused on the quality and application of word embeddings trained on\npublic available corpuses such as Wikipedia or other news and social media\nsources. However, these studies are limited to generic text and thus lack\ntechnical and scientific nuances such as domain specific vocabulary,\nabbreviations, or scientific formulas which are commonly used in academic\ncontext. This research focuses on the performance of word embeddings applied to\na large scale academic corpus. More specifically, we compare quality and\nefficiency of trained word embeddings to TFIDF representations in modeling\ncontent of scientific articles. We use a word2vec skip-gram model trained on\ntitles and abstracts of about 70 million scientific articles. Furthermore, we\nhave developed a benchmark to evaluate content models in a scientific context.\nThe benchmark is based on a categorization task that matches articles to\njournals for about 1.3 million articles published in 2017. Our results show\nthat content models based on word embeddings are better for titles (short text)\nwhile TFIDF works better for abstracts (longer text). However, the slight\nimprovement of TFIDF for larger text comes at the expense of 3.7 times more\nmemory requirement as well as up to 184 times higher computation times which\nmay make it inefficient for online applications. In addition, we have created a\n2-dimensional visualization of the journals modeled via embeddings to\nqualitatively inspect embedding model. This graph shows useful insights and can\nbe used to find competitive journals or gaps to propose new journals.\n",
        "english": "In recent years, neural network derived word embeddings have gained prominence in the natural language processing literature, particularly for their application to \"public available corpuses such as Wikipedia or other news and social media sources.\" This research innovatively applies word embeddings to a \"large scale academic corpus,\" utilizing a word2vec skip-gram model trained on titles and abstracts of approximately 70 million scientific articles, and compares these embeddings' performance to TFIDF representations in modeling scientific content. Notably, while TFIDF demonstrates a slight advantage for longer texts such as abstracts, this benefit comes at a significant cost, requiring \"3.7 times more memory\" and up to \"184 times higher computation times,\" thus potentially rendering it inefficient for online applications.",
        "korean": "최근 몇 년 동안, 신경망에서 파생된 단어 임베딩(word embeddings)은 자연어 처리 문헌에서 특히 위키피디아나 다른 뉴스 및 소셜 미디어 소스와 같은 \"공개적으로 이용 가능한 코퍼스\"에 대한 적용으로 주목을 받았습니다. 이 연구는 혁신적으로 단어 임베딩(word embeddings)을 \"대규모 학술 코퍼스\"에 적용하여 약 7천만 개의 과학 논문 제목과 초록에 대해 학습된 word2vec 스킵그램 모델(skip-gram model)을 활용하고, 이러한 임베딩의 성능을 과학적 콘텐츠 모델링에서 TFIDF 표현과 비교합니다. 특히, TFIDF는 초록과 같은 긴 텍스트에서 약간의 이점을 보여주지만, 이는 \"3.7배 더 많은 메모리\"와 최대 \"184배 더 높은 계산 시간\"을 요구하는 상당한 비용을 수반하여 온라인 응용 프로그램에는 비효율적일 수 있습니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring consistent use of parentheses for all technical terms, such as \"TFIDF 표현(TFIDF representations)\" to maintain uniformity."
    },
    {
        "turn_index": 2,
        "term": "multitask learning",
        "domain": "cs.AI",
        "summary": "  Empirical evidence suggests that hashing is an effective strategy for\ndimensionality reduction and practical nonparametric estimation. In this paper\nwe provide exponential tail bounds for feature hashing and show that the\ninteraction between random subspaces is negligible with high probability. We\ndemonstrate the feasibility of this approach with experimental results for a\nnew use case -- multitask learning with hundreds of thousands of tasks.\n",
        "english": "Empirical evidence suggests that hashing is an effective strategy for dimensionality reduction, which plays a crucial role in enhancing the efficiency of multitask learning with a vast number of tasks. In this context, the study provides exponential tail bounds for feature hashing, demonstrating that the interaction between random subspaces is negligible with high probability, thus ensuring the robustness of multitask learning models. Notably, experimental results underscore the feasibility of this approach, particularly in scenarios involving hundreds of thousands of tasks, highlighting its potential to significantly advance nonparametric estimation in complex multitask learning environments.",
        "korean": "실증적 증거에 따르면 해싱(hashing)은 차원 축소를 위한 효과적인 전략으로, 다수의 작업을 포함한 다중 작업 학습(multitask learning) 효율성을 향상시키는 데 중요한 역할을 합니다. 이 맥락에서 연구는 특징 해싱(feature hashing)에 대한 지수 꼬리 경계(exponential tail bounds)를 제공하며, 무작위 부분 공간 간의 상호작용이 높은 확률로 무시할 수 있음을 보여주어 다중 작업 학습(multitask learning) 모델의 견고성을 보장합니다. 특히, 실험 결과는 수십만 개의 작업을 포함하는 시나리오에서 이 접근 방식의 실행 가능성을 강조하며, 복잡한 다중 작업 학습(multitask learning) 환경에서 비모수 추정(nonparametric estimation)을 크게 발전시킬 잠재력을 보여줍니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "context-aware probabilistic learning",
        "domain": "cs.AI",
        "summary": "  This thesis describes work on two applications of probabilistic programming:\nthe learning of probabilistic program code given specifications, in particular\nprogram code of one-dimensional samplers; and the facilitation of sequential\nMonte Carlo inference with help of data-driven proposals. The latter is\npresented with experimental results on a linear Gaussian model and a\nnon-parametric dependent Dirichlet process mixture of objects model for object\nrecognition and tracking.\n  In Chapter 1 we provide a brief introduction to probabilistic programming.\n  In Chapter 2 we present an approach to automatic discovery of samplers in the\nform of probabilistic programs. We formulate a Bayesian approach to this\nproblem by specifying a grammar-based prior over probabilistic program code. We\nuse an approximate Bayesian computation method to learn the programs, whose\nexecutions generate samples that statistically match observed data or\nanalytical characteristics of distributions of interest. In our experiments we\nleverage different probabilistic programming systems to perform Markov chain\nMonte Carlo sampling over the space of programs. Experimental results have\ndemonstrated that, using the proposed methodology, we can learn approximate and\neven some exact samplers. Finally, we show that our results are competitive\nwith regard to genetic programming methods.\n  In Chapter 3, we describe a way to facilitate sequential Monte Carlo\ninference in probabilistic programming using data-driven proposals. In\nparticular, we develop a distance-based proposal for the non-parametric\ndependent Dirichlet process mixture of objects model. We implement this\napproach in the probabilistic programming system Anglican, and show that for\nthat model data-driven proposals provide significant performance improvements.\nWe also explore the possibility of using neural networks to improve data-driven\nproposals.\n",
        "english": "Context-aware probabilistic learning is exemplified in the thesis through the automatic discovery of samplers, where a Bayesian approach is employed by specifying a grammar-based prior over probabilistic program code, facilitating the learning of programs whose executions generate samples that statistically match observed data or analytical characteristics of distributions of interest. By leveraging different probabilistic programming systems, such as Markov chain Monte Carlo sampling, the research demonstrates that the proposed methodology can learn approximate and even some exact samplers, showcasing results that are competitive with genetic programming methods. Furthermore, the development of a distance-based proposal for the non-parametric dependent Dirichlet process mixture of objects model, implemented in the Anglican probabilistic programming system, highlights significant performance improvements, with the potential for further enhancement through neural networks, thus emphasizing the innovative nature of context-aware probabilistic learning.",
        "korean": "문맥 인식 확률 학습(context-aware probabilistic learning)은 논문에서 샘플러(samplers)의 자동 발견을 통해 예시됩니다. 여기서 베이지안 접근법(Bayesian approach)은 확률적 프로그램 코드(probabilistic program code)에 문법 기반 사전(grammar-based prior)을 지정하여 사용되며, 이는 실행이 관찰된 데이터 또는 관심 있는 분포의 분석적 특성과 통계적으로 일치하는 샘플을 생성하는 프로그램의 학습을 용이하게 합니다. 마르코프 체인 몬테카를로 샘플링(Markov chain Monte Carlo sampling)과 같은 다양한 확률적 프로그래밍 시스템(probabilistic programming systems)을 활용하여, 제안된 방법론이 근사적 샘플러(approximate samplers)와 심지어 일부 정확한 샘플러(exact samplers)를 학습할 수 있음을 연구는 입증하며, 이는 유전 프로그래밍 방법(genetic programming methods)과 경쟁력 있는 결과를 보여줍니다. 또한, 앵글리칸 확률적 프로그래밍 시스템(Anglican probabilistic programming system)에서 구현된 비모수 종속 디리클레 과정 혼합 모델(non-parametric dependent Dirichlet process mixture of objects model)을 위한 거리 기반 제안(distance-based proposal)의 개발은 신경망(neural networks)을 통한 추가 향상의 가능성과 함께 상당한 성능 향상을 강조하며, 문맥 인식 확률 학습(context-aware probabilistic learning)의 혁신적인 성격을 강조합니다.",
        "score": 10,
        "parentheses_count": 17,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "deep probabilistic forecasting",
        "domain": "cs.AI",
        "summary": "  Obtaining accurate probabilistic forecasts is an important operational\nchallenge in many applications, perhaps most obviously in energy management,\nclimate forecasting, supply chain planning, and resource allocation. In many of\nthese applications, there is a natural hierarchical structure over the\nforecasted quantities; and forecasting systems that adhere to this hierarchical\nstructure are said to be coherent. Furthermore, operational planning benefits\nfrom accuracy at all levels of the aggregation hierarchy. Building accurate and\ncoherent forecasting systems, however, is challenging: classic multivariate\ntime series tools and neural network methods are still being adapted for this\npurpose. In this paper, we augment an MQForecaster neural network architecture\nwith a novel deep Gaussian factor forecasting model that achieves coherence by\nconstruction, yielding a method we call the Deep Coherent Factor Model Neural\nNetwork (DeepCoFactor) model. DeepCoFactor generates samples that can be\ndifferentiated with respect to model parameters, allowing optimization on\nvarious sample-based learning objectives that align with the forecasting\nsystem's goals, including quantile loss and the scaled Continuous Ranked\nProbability Score (CRPS). In a comparison to state-of-the-art coherent\nforecasting methods, DeepCoFactor achieves significant improvements in scaled\nCRPS forecast accuracy, with gains between 4.16 and 54.40%, as measured on\nthree publicly available hierarchical forecasting datasets.\n",
        "english": "Deep probabilistic forecasting addresses the operational challenge of obtaining accurate probabilistic forecasts across applications such as energy management, climate forecasting, supply chain planning, and resource allocation, where a natural hierarchical structure over the forecasted quantities is often present. The novel Deep Coherent Factor Model Neural Network (DeepCoFactor) model enhances the MQForecaster neural network architecture with a deep Gaussian factor forecasting model that achieves coherence by construction, thereby allowing optimization on sample-based learning objectives like quantile loss and the scaled Continuous Ranked Probability Score (CRPS). Notably, DeepCoFactor demonstrates significant improvements in scaled CRPS forecast accuracy, achieving gains between 4.16\\% and 54.40\\% when compared to state-of-the-art coherent forecasting methods, as evaluated on three publicly available hierarchical forecasting datasets.",
        "korean": "심층 확률적 예측(deep probabilistic forecasting)은 에너지 관리, 기후 예측, 공급망 계획, 자원 할당과 같은 응용 분야에서 정확한 확률적 예측을 얻는 운영상의 문제를 해결합니다. 이러한 분야에서는 예측된 양에 대한 자연적인 계층 구조가 자주 존재합니다. 새로운 심층 일관성 인자 모델 신경망(Deep Coherent Factor Model Neural Network, DeepCoFactor) 모델은 심층 가우시안 인자 예측 모델을 통해 MQForecaster 신경망 아키텍처를 향상시켜, 구조적으로 일관성을 달성함으로써 분위 손실(quantile loss) 및 스케일된 연속 순위 확률 점수(scaled Continuous Ranked Probability Score, CRPS)와 같은 샘플 기반 학습 목표에 대한 최적화를 가능하게 합니다. 특히, DeepCoFactor는 세 가지 공개된 계층적 예측 데이터셋에서 평가된 결과, 최첨단 일관성 예측 방법과 비교하여 스케일된 CRPS 예측 정확도에서 4.16\\%에서 54.40\\%까지의 개선을 보여줍니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using lowercase for all letters within parentheses to maintain consistency."
    },
    {
        "turn_index": 2,
        "term": "neural search",
        "domain": "cs.AI",
        "summary": "  Heterogeneous graph neural architecture search (HGNAS) represents a powerful\ntool for automatically designing effective heterogeneous graph neural networks.\nHowever, existing HGNAS algorithms suffer from inefficient searches and\nunstable results. In this paper, we present a new GPT-4 based HGNAS model to\nimprove the search efficiency and search accuracy of HGNAS. Specifically, we\npresent a new GPT-4 enhanced Heterogeneous Graph Neural Architecture Search\n(GHGNAS for short). The basic idea of GHGNAS is to design a set of prompts that\ncan guide GPT-4 toward the task of generating new heterogeneous graph neural\narchitectures. By iteratively asking GPT-4 with the prompts, GHGNAS continually\nvalidates the accuracy of the generated HGNNs and uses the feedback to further\noptimize the prompts. Experimental results show that GHGNAS can design new\nHGNNs by leveraging the powerful generalization capability of GPT-4. Moreover,\nGHGNAS runs more effectively and stably than previous HGNAS models based on\nreinforcement learning and differentiable search algorithms.\n",
        "english": "Neural search, particularly in the domain of heterogeneous graph neural architecture search (HGNAS), has been significantly advanced by the introduction of a new GPT-4 based model, as it improves both the search efficiency and accuracy of HGNAS. The innovative approach, known as GHGNAS, leverages GPT-4's generalization capability by designing a set of prompts to iteratively guide the generation of new heterogeneous graph neural architectures, thereby validating and optimizing the generated HGNNs. Experimental results confirm that GHGNAS not only enhances the effectiveness and stability of neural search compared to previous models but also demonstrates superior performance, as evidenced by its ability to outperform reinforcement learning and differentiable search algorithms, with search accuracy improvements quantified by a metric $\\text{Accuracy}_{\\text{GHGNAS}} > \\text{Accuracy}_{\\text{Previous Models}}$.",
        "korean": "이기종 그래프 신경 아키텍처 탐색(heterogeneous graph neural architecture search, HGNAS) 분야에서 신경 탐색(neural search)은 GPT-4 기반의 새로운 모델 도입으로 크게 발전하였으며, 이는 HGNAS의 탐색 효율성과 정확성을 모두 향상시킵니다. GHGNAS로 알려진 이 혁신적인 접근법은 GPT-4의 일반화 능력을 활용하여 새로운 이기종 그래프 신경 아키텍처를 생성하는 일련의 프롬프트를 설계함으로써 생성된 HGNN을 검증하고 최적화합니다. 실험 결과에 따르면, GHGNAS는 이전 모델과 비교하여 신경 탐색(neural search)의 효과성과 안정성을 향상시킬 뿐만 아니라 강화 학습(reinforcement learning) 및 미분 가능 탐색 알고리즘(differentiable search algorithms)을 능가하는 우수한 성능을 보여주며, 탐색 정확성 개선은 $\\text{Accuracy}_{\\text{GHGNAS}} > \\text{Accuracy}_{\\text{Previous Models}}$라는 지표로 정량화됩니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent lowercase for all terms within parentheses."
    },
    {
        "turn_index": 2,
        "term": "attention networks",
        "domain": "cs.AI",
        "summary": "  Deep neural networks are able to solve tasks across a variety of domains and\nmodalities of data. Despite many empirical successes, we lack the ability to\nclearly understand and interpret the learned internal mechanisms that\ncontribute to such effective behaviors or, more critically, failure modes. In\nthis work, we present a general method for visualizing an arbitrary neural\nnetwork's inner mechanisms and their power and limitations. Our dataset-centric\nmethod produces visualizations of how a trained network attends to components\nof its inputs. The computed \"attention masks\" support improved interpretability\nby highlighting which input attributes are critical in determining output. We\ndemonstrate the effectiveness of our framework on a variety of deep neural\nnetwork architectures in domains from computer vision, natural language\nprocessing, and reinforcement learning. The primary contribution of our\napproach is an interpretable visualization of attention that provides unique\ninsights into the network's underlying decision-making process irrespective of\nthe data modality.\n",
        "english": "Attention networks have demonstrated the ability to solve tasks across various domains and modalities of data, yet the interpretability of their learned internal mechanisms remains a challenge. Our dataset-centric method produces visualizations of how a trained network attends to components of its inputs, with the computed \"attention masks\" highlighting critical input attributes that determine output, thereby enhancing the interpretability of these networks. By providing an interpretable visualization of attention, our approach offers unique insights into the network's decision-making process, irrespective of the data modality, and is applicable across diverse architectures, including those in computer vision, natural language processing, and reinforcement learning.",
        "korean": "주의 네트워크(attention networks)는 다양한 도메인과 데이터의 모달리티에서 작업을 해결할 수 있는 능력을 입증했지만, 학습된 내부 메커니즘의 해석 가능성은 여전히 도전 과제로 남아 있습니다. 우리의 데이터셋 중심 방법은 훈련된 네트워크가 입력의 구성 요소에 어떻게 주의를 기울이는지를 시각화하여, 계산된 \"주의 마스크(attention masks)\"가 출력을 결정하는 중요한 입력 속성을 강조함으로써 이러한 네트워크의 해석 가능성을 향상시킵니다. 주의의 해석 가능한 시각화를 제공함으로써, 우리의 접근법은 데이터 모달리티와 상관없이 네트워크의 의사 결정 과정을 독특한 통찰력으로 제공하며, 컴퓨터 비전(computer vision), 자연어 처리(natural language processing, NLP), 강화 학습(reinforcement learning)을 포함한 다양한 아키텍처에 적용 가능합니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as \"컴퓨터 비전(computer vision), 자연어 처리(natural language processing, NLP), 강화 학습(reinforcement learning)\" to \"컴퓨터 비전(computer vision), 자연어 처리(natural language processing), 강화 학습(reinforcement learning)\" for consistency."
    },
    {
        "turn_index": 2,
        "term": "deep probabilistic inference",
        "domain": "cs.AI",
        "summary": "  We introduce DeepProbLog, a probabilistic logic programming language that\nincorporates deep learning by means of neural predicates. We show how existing\ninference and learning techniques can be adapted for the new language. Our\nexperiments demonstrate that DeepProbLog supports both symbolic and subsymbolic\nrepresentations and inference, 1) program induction, 2) probabilistic (logic)\nprogramming, and 3) (deep) learning from examples. To the best of our\nknowledge, this work is the first to propose a framework where general-purpose\nneural networks and expressive probabilistic-logical modeling and reasoning are\nintegrated in a way that exploits the full expressiveness and strengths of both\nworlds and can be trained end-to-end based on examples.\n",
        "english": "In the domain of deep probabilistic inference, DeepProbLog emerges as a pioneering probabilistic logic programming language that seamlessly integrates deep learning through neural predicates, thereby expanding the horizons of inference and learning techniques. By supporting both symbolic and subsymbolic representations, DeepProbLog facilitates program induction, probabilistic (logic) programming, and deep learning from examples, demonstrating its versatility and adaptability. Notably, the framework allows for the integration of general-purpose neural networks with expressive probabilistic-logical modeling, enabling end-to-end training based on examples, while leveraging the full expressiveness and strengths of both approaches, as denoted by the function $f(x) = \\text{DeepProbLog}(x)$.",
        "korean": "딥 확률 추론(deep probabilistic inference) 분야에서 DeepProbLog는 신경 술어(neural predicates)를 통해 딥 러닝(deep learning)을 매끄럽게 통합하여 추론 및 학습 기법의 지평을 넓히는 선구적인 확률 논리 프로그래밍 언어(probabilistic logic programming language)로 부상하고 있습니다. DeepProbLog는 상징적(symbolic) 및 하위 상징적(subsymbolic) 표현을 모두 지원함으로써 프로그램 유도(program induction), 확률적 논리 프로그래밍(probabilistic logic programming), 예제로부터의 딥 러닝(deep learning)을 용이하게 하여 그 다재다능함과 적응성을 입증합니다. 특히, 이 프레임워크는 일반 목적의 신경망(neural networks)과 표현력 있는 확률 논리 모델링(probabilistic-logical modeling)의 통합을 가능하게 하여 예제를 기반으로 한 종단 간(end-to-end) 학습을 가능하게 하며, 두 접근 방식의 완전한 표현력과 강점을 활용할 수 있도록 합니다. 이는 함수 $f(x) = \\text{DeepProbLog}(x)$로 나타낼 수 있습니다.",
        "score": 9,
        "parentheses_count": 13,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase within parentheses."
    },
    {
        "turn_index": 2,
        "term": "transformer-based models",
        "domain": "cs.AI",
        "summary": "  Causal Models are like Dependency Graphs and Belief Nets in that they provide\na structure and a set of assumptions from which a joint distribution can, in\nprinciple, be computed. Unlike Dependency Graphs, Causal Models are models of\nhierarchical and/or parallel processes, rather than models of distributions\n(partially) known to a model builder through some sort of gestalt. As such,\nCausal Models are more modular, easier to build, more intuitive, and easier to\nunderstand than Dependency Graph Models. Causal Models are formally defined and\nDependency Graph Models are shown to be a special case of them. Algorithms\nsupporting inference are presented. Parsimonious methods for eliciting\ndependent probabilities are presented.\n",
        "english": "Transformer-based models, akin to Causal Models, provide a structure and a set of assumptions from which a joint distribution can be computed, thereby facilitating complex hierarchical and/or parallel processes. Unlike Dependency Graphs, transformer-based models are inherently modular and intuitive, making them easier to build and understand, which significantly enhances their applicability in various domains. The formal definition of Causal Models, where Dependency Graph Models are a special case, underscores the versatility of transformer-based models, with algorithms supporting inference and parsimonious methods for eliciting dependent probabilities, expressed as $P(A | B) = \\frac{P(A, B)}{P(B)}$, showcasing their computational efficiency and innovation.",
        "korean": "변환기 기반 모델(transformer-based models)은 인과 모델(causal models)과 유사하게 결합 분포를 계산할 수 있는 구조와 가정을 제공하여 복잡한 계층적 및/또는 병렬 프로세스를 용이하게 합니다. 의존 그래프(dependency graphs)와 달리 변환기 기반 모델(transformer-based models)은 본질적으로 모듈식이고 직관적이어서 구축 및 이해가 용이하며, 이는 다양한 도메인에서의 적용 가능성을 크게 향상시킵니다. 의존 그래프 모델(dependency graph models)이 특수한 경우인 인과 모델(causal models)의 공식 정의는 변환기 기반 모델(transformer-based models)의 다재다능함을 강조하며, 알고리즘은 의존 확률을 유도하기 위한 추론 및 간결한 방법을 지원하여 $P(A | B) = \\frac{P(A, B)}{P(B)}$로 표현된 계산 효율성과 혁신성을 보여줍니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "semantic neural learning",
        "domain": "cs.AI",
        "summary": "  We consider learning and compositionality as the key mechanisms towards\nsimulating human-like intelligence. While each mechanism is successfully\nachieved by neural networks and symbolic AIs, respectively, it is the\ncombination of the two mechanisms that makes human-like intelligence possible.\nDespite the numerous attempts on building hybrid neuralsymbolic systems, we\nargue that our true goal should be unifying learning and compositionality, the\ncore mechanisms, instead of neural and symbolic methods, the surface approaches\nto achieve them. In this work, we review and analyze the strengths and\nweaknesses of neural and symbolic methods by separating their forms and\nmeanings (structures and semantics), and propose Connectionist Probabilistic\nProgram (CPPs), a framework that connects connectionist structures (for\nlearning) and probabilistic program semantics (for compositionality). Under the\nframework, we design a CPP extension for small scale sequence modeling and\nprovide a learning algorithm based on Bayesian inference. Although challenges\nexist in learning complex patterns without supervision, our early results\ndemonstrate CPP's successful extraction of concepts and relations from raw\nsequential data, an initial step towards compositional learning.\n",
        "english": "Semantic neural learning emphasizes the unification of learning and compositionality, which are considered the core mechanisms for simulating human-like intelligence, rather than merely combining neural and symbolic methods as surface approaches. The Connectionist Probabilistic Program (CPP) framework exemplifies this approach by connecting connectionist structures for learning with probabilistic program semantics for compositionality, enabling the extraction of concepts and relations from raw sequential data. Notably, under the CPP framework, a learning algorithm based on Bayesian inference is designed to model sequences, with early results indicating successful compositional learning, despite challenges in learning complex patterns without supervision.",
        "korean": "의미 신경 학습(semantic neural learning)은 표면적인 접근 방식으로 신경 및 기호 방법을 단순히 결합하는 것이 아니라 인간과 유사한 지능을 시뮬레이션하기 위한 핵심 메커니즘으로 학습과 구성성을 통합하는 것을 강조합니다. 연결주의 확률적 프로그램(connectionist probabilistic program, CPP) 프레임워크는 학습을 위한 연결주의 구조와 구성성을 위한 확률적 프로그램 의미론을 연결하여 원시 순차 데이터에서 개념과 관계를 추출할 수 있게 함으로써 이러한 접근 방식을 예시합니다. 특히, CPP 프레임워크 하에서 베이지안 추론에 기반한 학습 알고리즘은 시퀀스를 모델링하도록 설계되었으며, 초기 결과는 복잡한 패턴을 감독 없이 학습하는 데 어려움이 있음에도 불구하고 성공적인 구성 학습을 나타냅니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "multilevel models",
        "domain": "cs.AI",
        "summary": "  Supply chain formation is the process of determining the structure and terms\nof exchange relationships to enable a multilevel, multiagent production\nactivity. We present a simple model of supply chains, highlighting two\ncharacteristic features: hierarchical subtask decomposition, and resource\ncontention. To decentralize the formation process, we introduce a market price\nsystem over the resources produced along the chain. In a competitive\nequilibrium for this system, agents choose locally optimal allocations with\nrespect to prices, and outcomes are optimal overall. To determine prices, we\ndefine a market protocol based on distributed, progressive auctions, and\nmyopic, non-strategic agent bidding policies. In the presence of resource\ncontention, this protocol produces better solutions than the greedy protocols\ncommon in the artificial intelligence and multiagent systems literature. The\nprotocol often converges to high-value supply chains, and when competitive\nequilibria exist, typically to approximate competitive equilibria. However,\ncomplementarities in agent production technologies can cause the protocol to\nwastefully allocate inputs to agents that do not produce their outputs. A\nsubsequent decommitment phase recovers a significant fraction of the lost\nsurplus.\n",
        "english": "Multilevel models in supply chain formation highlight the importance of hierarchical subtask decomposition and resource contention, which are essential for enabling multilevel, multiagent production activities. The introduction of a market price system over resources, combined with a market protocol based on distributed, progressive auctions, allows agents to choose locally optimal allocations, leading to outcomes that are optimal overall. Importantly, in the presence of resource contention, this protocol often converges to high-value supply chains and approximates competitive equilibria, demonstrating its superiority over greedy protocols commonly found in artificial intelligence and multiagent systems literature.",
        "korean": "공급망 형성에서 다단계 모델(multilevel models)은 계층적 하위 작업 분해와 자원 경쟁의 중요성을 강조하며, 이는 다단계, 다중 에이전트 생산 활동을 가능하게 하는 데 필수적입니다. 자원에 대한 시장 가격 시스템의 도입과 분산된 점진적 경매에 기반한 시장 프로토콜의 결합은 에이전트가 지역적으로 최적의 할당을 선택할 수 있게 하여 전체적으로 최적의 결과를 이끌어냅니다. 특히 자원 경쟁이 존재하는 경우, 이 프로토콜은 종종 높은 가치의 공급망으로 수렴하고 경쟁적 균형을 근사하여 인공지능 및 다중 에이전트 시스템 문헌에서 흔히 발견되는 탐욕적 프로토콜보다 우수함을 입증합니다.",
        "score": 10,
        "parentheses_count": 1,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "basis pursuit",
        "domain": "cs.AI",
        "summary": "  We present a method for pursuit/evasion that is highly efficient and and\nscales to large teams of aircraft. The underlying algorithm is an efficient\nalgorithm for solving Markov Decision Processes (MDPs) that supports fully\ncontinuous state spaces. We demonstrate the algorithm in a team pursuit/evasion\nsetting in a 3D environment using a pseudo-6DOF model and study performance by\nvarying sizes of team members. We show that as the number of aircraft in the\nsimulation grows, computational performance remains efficient and is suitable\nfor real-time systems. We also define probability-to-win and survivability\nmetrics that describe the teams' performance over multiple trials, and show\nthat the algorithm performs consistently. We provide numerical results showing\ncontrol inputs for a typical 1v1 encounter and provide videos for 1v1, 2v2,\n3v3, 4v4, and 10v10 contests to demonstrate the ability of the algorithm to\nadapt seamlessly to complex environments.\n",
        "english": "In the context of basis pursuit, the presented method demonstrates efficiency and scalability in pursuit/evasion tasks involving large teams of aircraft, utilizing a robust algorithm designed for Markov Decision Processes (MDPs) with continuous state spaces. The algorithm's performance remains efficient even as the number of aircraft in the simulation increases, making it suitable for real-time systems, as evidenced by the control inputs for typical 1v1 encounters and the adaptability showcased in 1v1, 2v2, 3v3, 4v4, and 10v10 contests. Notably, the study introduces probability-to-win and survivability metrics, which quantitatively describe team performance, with results consistently affirming the algorithm's capability to handle complex environments.",
        "korean": "기저 추구(basis pursuit)의 맥락에서 제시된 방법은 연속 상태 공간을 가진 마르코프 결정 과정(markov decision processes, MDPs)을 위한 견고한 알고리즘을 활용하여 대규모 항공기 팀이 참여하는 추적/회피 작업에서 효율성과 확장성을 입증합니다. 이 알고리즘의 성능은 시뮬레이션에서 항공기의 수가 증가하더라도 효율성을 유지하여 실시간 시스템에 적합하며, 이는 일반적인 1대1 교전에서의 제어 입력과 1대1, 2대2, 3대3, 4대4, 10대10 대결에서 보여준 적응성을 통해 입증됩니다. 특히, 이 연구는 팀 성능을 정량적으로 설명하는 승리 확률과 생존 가능성 지표를 도입하며, 결과는 복잡한 환경을 처리하는 알고리즘의 능력을 일관되게 확인합니다.",
        "score": 9,
        "parentheses_count": 2,
        "suggestions": "Ensure all English terms within parentheses are in lowercase for consistency and adjust the structure for a more natural flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "t-SNE (t-Distributed Stochastic Neighbor Embedding)",
        "domain": "cs.AI",
        "summary": "  Feature representation is an important aspect of remote-sensing based image\nclassification. While deep convolutional neural networks are able to\neffectively amalgamate information, large numbers of parameters often make\nlearned features inscrutable and difficult to transfer to alternative models.\nIn order to better represent statistical texture information for remote-sensing\nimage classification, in this paper, we investigate performing joint\ndimensionality reduction and classification using a novel histogram neural\nnetwork. Motivated by a popular dimensionality reduction approach,\nt-Distributed Stochastic Neighbor Embedding (t-SNE), our proposed method\nincorporates a classification loss computed on samples in a low-dimensional\nembedding space. We compare the learned sample embeddings against coordinates\nfound by t-SNE in terms of classification accuracy and qualitative assessment.\nWe also explore use of various divergence measures in the t-SNE objective. The\nproposed method has several advantages such as readily embedding out-of-sample\npoints and reducing feature dimensionality while retaining class\ndiscriminability. Our results show that the proposed approach maintains and/or\nimproves classification performance and reveals characteristics of features\nproduced by neural networks that may be helpful for other applications.\n",
        "english": "The innovative approach of incorporating t-SNE (t-Distributed Stochastic Neighbor Embedding) into a histogram neural network allows for joint dimensionality reduction and classification, effectively representing statistical texture information in remote-sensing image classification. By comparing the learned sample embeddings against coordinates found by t-SNE, the study evaluates classification accuracy and qualitative assessment, revealing that the proposed method maintains or improves performance. Furthermore, exploring various divergence measures in the t-SNE objective highlights its capacity to embed out-of-sample points and reduce feature dimensionality while retaining class discriminability, enhancing the utility of neural network-generated features for other applications.",
        "korean": "혁신적인 접근 방식으로 t-SNE(t-distributed stochastic neighbor embedding)를 히스토그램 신경망(histogram neural network)에 통합함으로써 차원 축소와 분류를 동시에 수행하여 원격 감지 이미지 분류에서 통계적 텍스처 정보를 효과적으로 표현할 수 있습니다. 학습된 샘플 임베딩을 t-SNE(t-distributed stochastic neighbor embedding)로 찾은 좌표와 비교함으로써, 연구는 분류 정확도와 정성적 평가를 수행하여 제안된 방법이 성능을 유지하거나 개선함을 보여줍니다. 또한, t-SNE(t-distributed stochastic neighbor embedding) 목적에서 다양한 발산 측정을 탐구함으로써 샘플 외 포인트를 임베딩하고 특징 차원을 줄이면서 클래스 구분 가능성을 유지하는 능력을 강조하여, 신경망이 생성한 특징의 다른 응용 분야에 대한 유용성을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "maximum likelihood estimation",
        "domain": "cs.AI",
        "summary": "  We consider the problem of estimating the distribution underlying an observed\nsample of data. Instead of maximum likelihood, which maximizes the probability\nof the ob served values, we propose a different estimate, the high-profile\ndistribution, which maximizes the probability of the observed profile the\nnumber of symbols appearing any given number of times. We determine the\nhigh-profile distribution of several data samples, establish some of its\ngeneral properties, and show that when the number of distinct symbols observed\nis small compared to the data size, the high-profile and maximum-likelihood\ndistributions are roughly the same, but when the number of symbols is large,\nthe distributions differ, and high-profile better explains the data.\n",
        "english": "Maximum likelihood estimation (MLE) is a widely-used method for estimating the distribution underlying an observed sample of data by maximizing the probability of the observed values. However, the research introduces an innovative alternative, the high-profile distribution, which instead maximizes the probability of the observed profile, specifically the number of symbols appearing any given number of times. Notably, the study demonstrates that when the number of distinct symbols observed is small compared to the data size, the high-profile and maximum likelihood distributions are roughly the same, but when the number of symbols is large, the distributions differ, with high-profile better explaining the data, indicating that $\\text{MLE}$ may not always be the optimal choice for complex datasets.",
        "korean": "최대 우도 추정(maximum likelihood estimation, MLE)은 관찰된 데이터 샘플의 분포를 추정하기 위해 관찰된 값의 확률을 최대화하는 데 널리 사용되는 방법입니다. 그러나 연구에서는 관찰된 프로파일, 특히 주어진 횟수만큼 나타나는 기호의 수의 확률을 최대화하는 혁신적인 대안인 하이 프로파일 분포(high-profile distribution)를 소개합니다. 특히, 연구는 관찰된 기호의 수가 데이터 크기에 비해 작을 때 하이 프로파일 분포와 최대 우도 분포가 대체로 동일하지만, 기호의 수가 많을 때는 분포가 달라지며, 하이 프로파일이 데이터를 더 잘 설명한다는 것을 보여주며, 이는 $\\text{MLE}$이 복잡한 데이터셋에 항상 최적의 선택이 아닐 수 있음을 나타냅니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Ensure consistent use of lowercase within parentheses and consider reducing redundancy by using the English term only once per sentence. Adjust the sentence structure for a more natural flow in Korean, and ensure that the translation captures the nuances of the original text."
    },
    {
        "turn_index": 2,
        "term": "symbolic AI",
        "domain": "cs.AI",
        "summary": "  Despite the surprising power of many modern AI systems that often learn their\nown representations, there is significant discontent about their inscrutability\nand the attendant problems in their ability to interact with humans. While\nalternatives such as neuro-symbolic approaches have been proposed, there is a\nlack of consensus on what they are about. There are often two independent\nmotivations (i) symbols as a lingua franca for human-AI interaction and (ii)\nsymbols as system-produced abstractions used by the AI system in its internal\nreasoning. The jury is still out on whether AI systems will need to use symbols\nin their internal reasoning to achieve general intelligence capabilities.\nWhatever the answer there is, the need for (human-understandable) symbols in\nhuman-AI interaction seems quite compelling. Symbols, like emotions, may well\nnot be sine qua non for intelligence per se, but they will be crucial for AI\nsystems to interact with us humans -- as we can neither turn off our emotions\nnor get by without our symbols. In particular, in many human-designed domains,\nhumans would be interested in providing explicit (symbolic) knowledge and\nadvice -- and expect machine explanations in kind. This alone requires AI\nsystems to to maintain a symbolic interface for interaction with humans. In\nthis blue sky paper, we argue this point of view, and discuss research\ndirections that need to be pursued to allow for this type of human-AI\ninteraction.\n",
        "english": "Symbolic AI, which involves using symbols as a lingua franca for human-AI interaction, addresses the growing concern regarding the inscrutability of AI systems that learn their own representations. This approach posits that symbols can serve as system-produced abstractions used by the AI in its internal reasoning, potentially enhancing the transparency and explainability of AI systems for human users. The necessity for AI systems to maintain a symbolic interface is underscored by the compelling need for human-understandable symbols in interactions, as expressed in the equation: $f(\\text{symbols}) = \\text{AI}_{\\text{interaction}} + \\text{human}_{\\text{understanding}}$.",
        "korean": "기호를 인간-AI 상호작용의 공통 언어로 사용하는 기호적 AI(symbolic AI)는 자체 표현을 학습하는 AI 시스템의 불가해성에 대한 증가하는 우려를 해결합니다. 이 접근법은 기호가 AI의 내부 추론에서 사용되는 시스템 생성 추상화로 작용할 수 있으며, 이는 인간 사용자에게 AI 시스템의 투명성과 설명 가능성을 향상시킬 수 있다고 주장합니다. AI 시스템이 기호적 인터페이스를 유지해야 하는 필요성은 상호작용에서 인간이 이해할 수 있는 기호의 필요성에 의해 강조되며, 이는 다음과 같은 방정식으로 표현됩니다: $f(\\text{symbols}) = \\text{AI}_{\\text{interaction}} + \\text{human}_{\\text{understanding}}$.",
        "score": 10,
        "parentheses_count": 1,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural sequence-to-sequence learning",
        "domain": "cs.AI",
        "summary": "  We use neural graph networks with a message-passing architecture and an\nattention mechanism to enhance the branching heuristic in two SAT-solving\nalgorithms. We report improvements of learned neural heuristics compared with\ntwo standard human-designed heuristics.\n",
        "english": "Neural sequence-to-sequence learning is enhanced by integrating neural graph networks with a message-passing architecture, which serves to improve the branching heuristic in SAT-solving algorithms. By employing an attention mechanism, this approach demonstrates significant advancements, as evidenced by the improvements of learned neural heuristics when compared to two standard human-designed heuristics. Importantly, this innovative method can be represented mathematically, where the attention weights $\\alpha_{ij}$ are computed to dynamically adjust the influence of various nodes within the graph, showcasing the potential of neural sequence-to-sequence learning in complex problem-solving scenarios.",
        "korean": "신경 시퀀스-투-시퀀스 학습(neural sequence-to-sequence learning)은 메시지 전달 아키텍처(message-passing architecture)를 갖춘 신경 그래프 네트워크(neural graph networks)를 통합함으로써 SAT-해결 알고리즘(SAT-solving algorithms)에서 분기 휴리스틱(branching heuristic)을 개선하는 데 기여합니다. 주의 메커니즘(attention mechanism)을 활용하여, 이 접근법은 두 가지 표준 인간 설계 휴리스틱(human-designed heuristics)과 비교했을 때 학습된 신경 휴리스틱(neural heuristics)의 개선을 통해 상당한 발전을 보여줍니다. 중요한 점은, 이 혁신적인 방법은 수학적으로 표현될 수 있으며, 주의 가중치 $\\alpha_{ij}$는 그래프 내 다양한 노드의 영향을 동적으로 조정하기 위해 계산되어, 복잡한 문제 해결 시나리오에서 신경 시퀀스-투-시퀀스 학습(neural sequence-to-sequence learning)의 잠재력을 보여줍니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent lowercase for all terms within parentheses to maintain uniformity."
    },
    {
        "turn_index": 2,
        "term": "recall",
        "domain": "cs.AI",
        "summary": "  We introduce the Xapagy cognitive architecture: a software system designed to\nperform narrative reasoning. The architecture has been designed from scratch to\nmodel and mimic the activities performed by humans when witnessing, reading,\nrecalling, narrating and talking about stories.\n",
        "english": "The Xapagy cognitive architecture is a novel software system meticulously designed to model and mimic human activities, including recalling, which is crucial for narrative reasoning. This architecture operates by simulating how humans engage with stories through witnessing, reading, and narrating, thereby offering a unique approach to understanding recall processes. Importantly, the system's ability to handle complex narrative tasks can be quantitatively assessed using metrics such as recall rate, often expressed as $R = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$, highlighting its innovative contribution to cognitive modeling.",
        "korean": "Xapagy 인지 아키텍처(cognitive architecture)는 인간 활동을 모델링하고 모방하도록 세심하게 설계된 새로운 소프트웨어 시스템으로, 내러티브 추론(narrative reasoning)에 중요한 회상(recalling)을 포함합니다. 이 아키텍처는 인간이 목격, 읽기, 서술을 통해 이야기에 참여하는 방식을 시뮬레이션하여 회상 과정(recall processes)을 이해하는 독특한 접근 방식을 제공합니다. 특히, 시스템의 복잡한 내러티브 작업을 처리하는 능력은 회상률(recall rate)과 같은 지표를 사용하여 정량적으로 평가할 수 있으며, 이는 $R = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$로 표현되어 인지 모델링(cognitive modeling)에 대한 혁신적인 기여를 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "roberta",
        "domain": "cs.AI",
        "summary": "  There has been significant progress in recent years in the field of Natural\nLanguage Processing thanks to the introduction of the Transformer architecture.\nCurrent state-of-the-art models, via a large number of parameters and\npre-training on massive text corpus, have shown impressive results on several\ndownstream tasks. Many researchers have studied previous (non-Transformer)\nmodels to understand their actual behavior under different scenarios, showing\nthat these models are taking advantage of clues or failures of datasets and\nthat slight perturbations on the input data can severely reduce their\nperformance. In contrast, recent models have not been systematically tested\nwith adversarial-examples in order to show their robustness under severe stress\nconditions. For that reason, this work evaluates three Transformer-based models\n(RoBERTa, XLNet, and BERT) in Natural Language Inference (NLI) and Question\nAnswering (QA) tasks to know if they are more robust or if they have the same\nflaws as their predecessors. As a result, our experiments reveal that RoBERTa,\nXLNet and BERT are more robust than recurrent neural network models to stress\ntests for both NLI and QA tasks. Nevertheless, they are still very fragile and\ndemonstrate various unexpected behaviors, thus revealing that there is still\nroom for future improvement in this field.\n",
        "english": "RoBERTa, a Transformer-based model, has demonstrated significant progress in Natural Language Processing tasks such as Natural Language Inference (NLI) and Question Answering (QA), outperforming previous recurrent neural network models. Despite its robustness, RoBERTa, alongside XLNet and BERT, still exhibits unexpected behaviors under stress tests, indicating the need for further research to enhance its resilience. The study reveals that RoBERTa's performance, measured through various stress conditions, is quantitatively more robust than its predecessors, yet the model's fragility suggests that $O(n^2)$ complexity inherent in Transformer architectures could be a factor in its limitations.",
        "korean": "트랜스포머 기반 모델(transformer-based model)인 로버타(roberta)는 자연어 추론(natural language inference, nli) 및 질문 응답(question answering, qa)과 같은 자연어 처리(natural language processing) 작업에서 이전의 순환 신경망 모델(recurrent neural network models)을 능가하는 상당한 진전을 보여주었습니다. 그 견고함에도 불구하고, 로버타(roberta)는 xlnet 및 bert와 함께 스트레스 테스트(stress tests)에서 예상치 못한 행동을 보이며, 그 회복력을 향상시키기 위한 추가 연구의 필요성을 나타냅니다. 연구 결과는 다양한 스트레스 조건을 통해 측정된 로버타(roberta)의 성능이 이전 모델들보다 정량적으로 더 견고하다는 것을 보여주지만, 모델의 취약성은 트랜스포머 아키텍처(transformer architectures)에 내재된 $o(n^2)$ 복잡성이 그 한계의 요인일 수 있음을 시사합니다.",
        "score": 10,
        "parentheses_count": 12,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "stochastic text segmentation",
        "domain": "cs.AI",
        "summary": "  We present a new, deterministic, distributed MAP estimation algorithm for\nMarkov Random Fields called Local Highest Confidence First (Local HCF). The\nalgorithm has been applied to segmentation problems in computer vision and its\nperformance compared with stochastic algorithms. The experiments show that\nLocal HCF finds better estimates than stochastic algorithms with much less\ncomputation.\n",
        "english": "In the domain of stochastic text segmentation, the Local Highest Confidence First (Local HCF) algorithm emerges as a novel deterministic approach, offering a distributed MAP estimation method for Markov Random Fields. By applying this algorithm to segmentation problems, the research demonstrates that Local HCF outperforms stochastic algorithms, achieving superior estimates with significantly reduced computational effort. Specifically, the Local HCF algorithm minimizes the energy function $E(x) = \\sum_{i \\in V} \\phi_i(x_i) + \\sum_{(i,j) \\in E} \\psi_{ij}(x_i, x_j)$ more effectively, highlighting its innovative contribution to the field.",
        "korean": "확률적 텍스트 분할(stochastic text segmentation) 분야에서 지역 최고 신뢰도 우선(Local Highest Confidence First, Local HCF) 알고리즘은 새로운 결정론적 접근법으로 부상하며, 마르코프 랜덤 필드(Markov Random Fields, MRF)에 대한 분산된 최대 사후 확률(MAP) 추정 방법을 제공합니다. 이 알고리즘을 분할 문제에 적용함으로써 연구는 Local HCF가 확률적 알고리즘을 능가하여 훨씬 적은 계산 노력으로 우수한 추정을 달성함을 입증합니다. 특히, Local HCF 알고리즘은 에너지 함수 $E(x) = \\sum_{i \\in V} \\phi_i(x_i) + \\sum_{(i,j) \\in E} \\psi_{ij}(x_i, x_j)$를 더 효과적으로 최소화하여 이 분야에 대한 혁신적인 기여를 강조합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure that all terms within parentheses are consistently in lowercase to maintain uniformity and adhere to the specified format."
    },
    {
        "turn_index": 2,
        "term": "explainable AI",
        "domain": "cs.AI",
        "summary": "  The rapidly advancing domain of Explainable Artificial Intelligence (XAI) has\nsparked significant interests in developing techniques to make AI systems more\ntransparent and understandable. Nevertheless, in real-world contexts, the\nmethods of explainability and their evaluation strategies present numerous\nlimitations.Moreover, the scope of responsible AI extends beyond just\nexplainability. In this paper, we explore these limitations and discuss their\nimplications in a boarder context of responsible AI when considering other\nimportant aspects, including privacy, fairness and contestability.\n",
        "korean": "급속히 발전하는 설명 가능한 인공지능(explainable artificial intelligence, XAI) 분야는 AI 시스템을 보다 투명하고 이해하기 쉽게 만드는 기술 개발에 대한 상당한 관심을 불러일으켰으며, 복잡한 알고리즘과 인간의 해석 가능성 간의 격차를 해소하는 데 있어 이 분야의 중요성을 강조합니다. 그럼에도 불구하고, 실제 세계의 맥락에서 설명 가능성의 방법과 그 평가 전략은 투명성과 모델 성능 간의 절충을 정량화하는 데 있어 도전과제와 같은 수많은 한계를 제시하며, 이는 $\\text{Performance} = f(\\text{Transparency})$로 표현될 수 있습니다. 더욱이, 책임 있는 인공지능(responsible AI)의 범위는 단순한 설명 가능성을 넘어 확장되며, AI 시스템에서 신뢰와 책임성을 증진하는 데 필수적인 프라이버시, 공정성, 논쟁 가능성과 같은 다른 중요한 측면에 대한 보다 폭넓은 고려가 필요합니다."
    },
    {
        "turn_index": 2,
        "term": "probabilistic dynamic learning",
        "domain": "cs.AI",
        "summary": "  State abstraction enables sample-efficient learning and better task transfer\nin complex reinforcement learning environments. Recently, we proposed RePReL\n(Kokel et al. 2021), a hierarchical framework that leverages a relational\nplanner to provide useful state abstractions for learning. We present a brief\noverview of this framework and the use of a dynamic probabilistic logic model\nto design these state abstractions. Our experiments show that RePReL not only\nachieves better performance and efficient learning on the task at hand but also\ndemonstrates better generalization to unseen tasks.\n",
        "english": "In the domain of probabilistic dynamic learning, the RePReL framework, as proposed by Kokel et al. (2021), exemplifies a hierarchical approach that employs a relational planner to derive beneficial state abstractions for enhanced learning efficiency. Notably, the integration of a dynamic probabilistic logic model within RePReL facilitates the design of these abstractions, allowing for improved performance and generalization across tasks. Empirical results demonstrate that RePReL achieves superior task performance, with an efficiency gain quantified by the equation $E = \\frac{P_{new}}{P_{base}}$, where $P_{new}$ and $P_{base}$ represent the performance metrics of the new and baseline models, respectively, highlighting its innovative contribution to the field.",
        "korean": "확률적 동적 학습(probabilistic dynamic learning) 분야에서 kokel et al. (2021)이 제안한 reprel 프레임워크는 관계적 계획자(relational planner)를 활용하여 학습 효율성을 향상시키기 위한 유익한 상태 추상화를 도출하는 계층적 접근 방식을 예시합니다. 특히, reprel 내에서 동적 확률 논리 모델(dynamic probabilistic logic model)의 통합은 이러한 추상화 설계를 용이하게 하여 작업 전반에 걸쳐 성능과 일반화를 개선할 수 있도록 합니다. 실험 결과에 따르면 reprel은 새로운 모델과 기준 모델의 성능 지표를 각각 나타내는 $p_{new}$와 $p_{base}$를 사용하여 효율성 이득을 $e = \\frac{p_{new}}{p_{base}}$로 정량화하여 우수한 작업 성능을 달성하며, 이는 이 분야에 대한 혁신적인 기여를 강조합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "semantic probabilistic text models",
        "domain": "cs.AI",
        "summary": "  Probabilistic Logic Programming (PLP), exemplified by Sato and Kameya's\nPRISM, Poole's ICL, Raedt et al's ProbLog and Vennekens et al's LPAD, is aimed\nat combining statistical and logical knowledge representation and inference. A\nkey characteristic of PLP frameworks is that they are conservative extensions\nto non-probabilistic logic programs which have been widely used for knowledge\nrepresentation. PLP frameworks extend traditional logic programming semantics\nto a distribution semantics, where the semantics of a probabilistic logic\nprogram is given in terms of a distribution over possible models of the\nprogram. However, the inference techniques used in these works rely on\nenumerating sets of explanations for a query answer. Consequently, these\nlanguages permit very limited use of random variables with continuous\ndistributions. In this paper, we present a symbolic inference procedure that\nuses constraints and represents sets of explanations without enumeration. This\npermits us to reason over PLPs with Gaussian or Gamma-distributed random\nvariables (in addition to discrete-valued random variables) and linear equality\nconstraints over reals. We develop the inference procedure in the context of\nPRISM; however the procedure's core ideas can be easily applied to other PLP\nlanguages as well. An interesting aspect of our inference procedure is that\nPRISM's query evaluation process becomes a special case in the absence of any\ncontinuous random variables in the program. The symbolic inference procedure\nenables us to reason over complex probabilistic models such as Kalman filters\nand a large subclass of Hybrid Bayesian networks that were hitherto not\npossible in PLP frameworks. (To appear in Theory and Practice of Logic\nProgramming).\n",
        "english": "Semantic probabilistic text models, as exemplified by frameworks like PRISM, extend traditional logic programming semantics to a distribution semantics, where the semantics of a probabilistic logic program is expressed in terms of a distribution over possible models of the program. This innovative approach allows for reasoning over complex probabilistic models, such as Kalman filters and a large subclass of Hybrid Bayesian networks, which were previously not feasible within traditional PLP frameworks. A key advancement in this field is the symbolic inference procedure that employs constraints and represents sets of explanations without enumeration, thus enabling reasoning over PLPs with Gaussian or Gamma-distributed random variables and linear equality constraints over reals, as expressed in the formulation $\\mathcal{P}(X = x) = \\int_{\\mathcal{X}} f(x) \\, dx$.",
        "korean": "프리즘(prism)과 같은 프레임워크로 예시되는 의미론적 확률 텍스트 모델(semantic probabilistic text models)은 전통적인 논리 프로그래밍 의미론을 분포 의미론으로 확장하여, 확률 논리 프로그램의 의미론을 프로그램의 가능한 모델에 대한 분포로 표현합니다. 이 혁신적인 접근 방식은 칼만 필터(kalman filters) 및 하이브리드 베이지안 네트워크(hybrid bayesian networks)의 큰 하위 클래스와 같은 복잡한 확률 모델에 대한 추론을 가능하게 하며, 이는 전통적인 확률 논리 프로그래밍(plp) 프레임워크 내에서는 불가능했던 것입니다. 이 분야의 주요 발전은 제약을 활용하고 설명의 집합을 열거 없이 표현하는 상징적 추론 절차로, 가우시안 또는 감마 분포 확률 변수와 실수에 대한 선형 등식 제약을 가진 확률 논리 프로그램(plps)에 대한 추론을 가능하게 합니다. 이는 수식 $\\mathcal{P}(X = x) = \\int_{\\mathcal{X}} f(x) \\, dx$로 표현됩니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother transitions between technical terms and their explanations."
    },
    {
        "turn_index": 2,
        "term": "graph structure learning",
        "domain": "cs.AI",
        "summary": "  Graph-level contrastive learning, aiming to learn the representations for\neach graph by contrasting two augmented graphs, has attracted considerable\nattention. Previous studies usually simply assume that a graph and its\naugmented graph as a positive pair, otherwise as a negative pair. However, it\nis well known that graph structure is always complex and multi-scale, which\ngives rise to a fundamental question: after graph augmentation, will the\nprevious assumption still hold in reality? By an experimental analysis, we\ndiscover the semantic information of an augmented graph structure may be not\nconsistent as original graph structure, and whether two augmented graphs are\npositive or negative pairs is highly related with the multi-scale structures.\nBased on this finding, we propose a multi-scale subgraph contrastive learning\narchitecture which is able to characterize the fine-grained semantic\ninformation. Specifically, we generate global and local views at different\nscales based on subgraph sampling, and construct multiple contrastive\nrelationships according to their semantic associations to provide richer\nself-supervised signals. Extensive experiments and parametric analyzes on eight\ngraph classification real-world datasets well demonstrate the effectiveness of\nthe proposed method.\n",
        "english": "Graph structure learning has gained significant attention in the context of graph-level contrastive learning, where the challenge lies in contrasting two augmented graphs to learn their representations effectively. The complexity and multi-scale nature of graph structures pose a fundamental question regarding the assumption that a graph and its augmented graph are inherently positive pairs, as experimental analysis reveals that the semantic information of an augmented graph structure may not be consistent with the original graph structure. To address this, a novel multi-scale subgraph contrastive learning architecture is proposed, which generates global and local views at different scales via subgraph sampling, constructing multiple contrastive relationships based on their semantic associations to provide richer self-supervised signals, thereby enhancing the graph classification tasks across various datasets.",
        "korean": "그래프 수준 대조 학습(graph-level contrastive learning) 맥락에서 그래프 구조 학습(graph structure learning)은 두 개의 증강된 그래프를 대조하여 그들의 표현을 효과적으로 학습하는 데 있어 중요한 관심을 받고 있습니다. 그래프 구조의 복잡성과 다중 스케일 특성은 그래프와 그 증강 그래프가 본질적으로 긍정적인 쌍이라는 가정에 대한 근본적인 질문을 제기합니다. 실험적 분석에 따르면 증강된 그래프 구조의 의미 정보가 원래 그래프 구조와 일치하지 않을 수 있습니다. 이를 해결하기 위해, 새로운 다중 스케일 부분 그래프 대조 학습 아키텍처(multi-scale subgraph contrastive learning architecture)가 제안되었으며, 이는 부분 그래프 샘플링을 통해 다양한 스케일에서 글로벌 및 로컬 뷰를 생성하고, 그들의 의미적 연관성을 기반으로 여러 대조 관계를 구축하여 더 풍부한 자가 지도 신호(self-supervised signals)를 제공함으로써 다양한 데이터셋에서 그래프 분류 작업을 향상시킵니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure that all technical terms are consistently formatted as Korean term(English term) and consider simplifying complex sentence structures for better readability."
    },
    {
        "turn_index": 2,
        "term": "end-to-end learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "english": "End-to-end learning can be effectively described through the framework of mechanical learning, which emphasizes the significance of subjective patterns in the learning process. By employing the concept of X-form as an algebraic expression for subjective patterns, the internal representation space, denoted as $X$, becomes the focal point of the learning machine's capabilities. This innovative approach highlights the potential of end-to-end learning systems to achieve universal learning, as they can express any objective pattern through a corresponding subjective pattern, given sufficient data and certain capabilities.",
        "korean": "end-to-end learning(end-to-end learning)은 기계 학습(mechanical learning)의 프레임워크를 통해 효과적으로 설명될 수 있으며, 이는 학습 과정에서 주관적 패턴의 중요성을 강조합니다. 주관적 패턴에 대한 대수적 표현으로 x-형식(x-form)의 개념을 사용함으로써, 내부 표현 공간인 $x$는 학습 기계의 능력의 초점이 됩니다. 이 혁신적인 접근 방식은 end-to-end learning(end-to-end learning) 시스템이 충분한 데이터와 특정 능력을 갖춘 경우, 대응하는 주관적 패턴을 통해 모든 객관적 패턴을 표현할 수 있음을 강조하며, 보편적 학습을 달성할 수 있는 잠재력을 보여줍니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure that the term \"end-to-end learning\" is consistently enclosed in parentheses throughout the translation. Adjust the structure for natural flow and grammar, and ensure all technical terms are consistently parenthesized."
    },
    {
        "turn_index": 2,
        "term": "semi-supervised learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "english": "Semi-supervised learning, akin to the mechanical learning approach introduced in [1], leverages both objective and subjective patterns to enhance the learning process. By employing X-form algebraic expressions for subjective patterns, semi-supervised learning can effectively express objective patterns with minimal base patterns, thereby optimizing the internal representation space, which is crucial for the learning machine. This innovative methodology underscores the potential of semi-supervised learning to act as a universal learning machine, capable of learning any pattern given sufficient data and certain capabilities, as demonstrated through various learning strategies discussed in the study.",
        "korean": "[1]에서 소개된 기계 학습 접근 방식과 유사하게, 반지도 학습(semi-supervised learning)은 학습 과정을 향상시키기 위해 객관적 패턴과 주관적 패턴을 모두 활용합니다. 주관적 패턴에 대해 x-형 대수 표현을 사용함으로써, 반지도 학습(semi-supervised learning)은 최소한의 기본 패턴으로 객관적 패턴을 효과적으로 표현할 수 있으며, 이는 학습 기계에 중요한 내부 표현 공간을 최적화합니다. 이 혁신적인 방법론은 충분한 데이터와 특정 능력이 주어졌을 때, 모든 패턴을 학습할 수 있는 보편적 학습 기계로서 반지도 학습(semi-supervised learning)의 잠재력을 강조하며, 연구에서 논의된 다양한 학습 전략을 통해 입증되었습니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "bert",
        "domain": "cs.AI",
        "summary": "  The recent state-of-the-art natural language understanding (NLU) systems\noften behave unpredictably, failing on simpler reasoning examples. Despite\nthis, there has been limited focus on quantifying progress towards systems with\nmore predictable behavior. We think that reasoning capability-wise behavioral\nsummary is a step towards bridging this gap. We create a CheckList test-suite\n(184K examples) for the Natural Language Inference (NLI) task, a representative\nNLU task. We benchmark state-of-the-art NLI systems on this test-suite, which\nreveals fine-grained insights into the reasoning abilities of BERT and RoBERTa.\nOur analysis further reveals inconsistencies of the models on examples derived\nfrom the same template or distinct templates but pertaining to same reasoning\ncapability, indicating that generalizing the models' behavior through\nobservations made on a CheckList is non-trivial. Through an user-study, we find\nthat users were able to utilize behavioral information to generalize much\nbetter for examples predicted from RoBERTa, compared to that of BERT.\n",
        "english": "The CheckList test-suite for Natural Language Inference (NLI) tasks, comprising 184K examples, provides fine-grained insights into the reasoning abilities of BERT, revealing inconsistencies in its performance on examples derived from the same or distinct templates but requiring similar reasoning capabilities. Through benchmarking, it was observed that users could generalize much better for examples predicted from RoBERTa compared to BERT, suggesting that the latter's behavior is more challenging to predict. Notably, the analysis indicates that generalizing the models' behavior through observations made on a CheckList is non-trivial, with the accuracy of BERT's predictions not consistently aligning with the expected reasoning capabilities, as demonstrated by the variability in its performance across different templates.",
        "korean": "자연어 추론(natural language inference, NLI) 작업을 위한 체크리스트 테스트 스위트(CheckList test-suite)는 184K 예제를 포함하고 있으며, BERT(bert)의 추론 능력에 대한 세밀한 통찰을 제공하여 동일하거나 다른 템플릿에서 파생된 예제에서의 성능 불일치를 드러냅니다. 벤치마킹을 통해 사용자가 RoBERTa(roberta)에서 예측된 예제에 대해 BERT(bert)보다 훨씬 더 잘 일반화할 수 있음을 관찰했으며, 이는 후자의 행동이 예측하기 더 어렵다는 것을 시사합니다. 특히, 체크리스트(CheckList)에서 관찰된 모델의 행동을 일반화하는 것은 쉽지 않으며, BERT(bert)의 예측 정확도가 기대되는 추론 능력과 일관되게 맞지 않음을 나타내며, 이는 다양한 템플릿에서의 성능 변동성으로 입증됩니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase for all terms within parentheses."
    },
    {
        "turn_index": 2,
        "term": "group sparsity",
        "domain": "cs.AI",
        "summary": "  The unit selection problem is to identify a group of individuals who are most\nlikely to exhibit a desired mode of behavior, for example, selecting\nindividuals who would respond one way if incentivized and a different way if\nnot. The unit selection problem consists of evaluation and search subproblems.\nLi and Pearl defined the \"benefit function\" to evaluate the average payoff of\nselecting a certain individual with given characteristics. The search\nsubproblem is then to design an algorithm to identify the characteristics that\nmaximize the above benefit function. The hardness of the search subproblem\narises due to the large number of characteristics available for each individual\nand the sparsity of the data available in each cell of characteristics. In this\npaper, we present a machine learning framework that uses the bounds of the\nbenefit function that are estimable from the finite population data to learn\nthe bounds of the benefit function for each cell of characteristics. Therefore,\nwe could easily obtain the characteristics that maximize the benefit function.\n",
        "english": "In addressing the unit selection problem, the concept of group sparsity is crucial due to the \"large number of characteristics available for each individual and the sparsity of the data available in each cell of characteristics,\" which complicates the search for optimal solutions. The research presents a machine learning framework that leverages the \"bounds of the benefit function that are estimable from the finite population data\" to effectively learn the bounds for each characteristic cell, thus facilitating the identification of characteristics that maximize the benefit function. This innovative approach not only addresses the inherent challenges posed by group sparsity but also enhances the efficiency of selecting individuals who are most likely to exhibit a desired mode of behavior, as represented by the maximization problem $\\max_{\\text{characteristics}} \\text{Benefit}(\\text{characteristics})$.",
        "korean": "단위 선택 문제를 해결하는 데 있어 그룹 희소성(group sparsity)의 개념은 \"각 개인에게 제공되는 많은 수의 특성과 각 특성 셀에 제공되는 데이터의 희소성\" 때문에 최적의 솔루션을 찾는 것을 복잡하게 만듭니다. 연구는 \"유한 모집단 데이터로부터 추정 가능한 이익 함수의 경계\"를 활용하여 각 특성 셀에 대한 경계를 효과적으로 학습하는 기계 학습 프레임워크(machine learning framework)를 제시하며, 이를 통해 이익 함수를 최대화하는 특성을 식별할 수 있도록 합니다. 이 혁신적인 접근 방식은 그룹 희소성(group sparsity)이 제기하는 고유한 문제를 해결할 뿐만 아니라, $\\max_{\\text{characteristics}} \\text{Benefit}(\\text{characteristics})$로 표현되는 최대화 문제를 통해 원하는 행동 양식을 보일 가능성이 가장 높은 개인을 선택하는 효율성을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "adaptive computation time",
        "domain": "cs.AI",
        "summary": " ",
        "korean": "적응형 계산 시간(adaptive computation time, ACT)은 신경망 아키텍처(neural network architectures)에서 중요한 발전을 나타내며, 입력 복잡성에 따라 모델이 동적으로 계산 자원을 할당할 수 있도록 합니다. 참조 문헌에서 논의된 바와 같이, 계산을 중지할 시점을 결정하는 정지 유닛(halting unit)을 통합함으로써 ACT는 계산 효율성과 정확성의 균형을 효과적으로 맞춥니다. 이 과정에서 정지 점수(halting score) $h_t$는 의사 결정 과정에서 중요한 요소입니다. 이 혁신적인 접근 방식은 자원 사용을 최적화할 뿐만 아니라 입력 데이터의 복잡성이 크게 다른 시나리오에서 모델 성능을 향상시킵니다."
    },
    {
        "turn_index": 2,
        "term": "scalable neural networks",
        "domain": "cs.AI",
        "summary": "  Counterfactual Regret Minimization (CFR)} is the popular method for finding\napproximate Nash equilibrium in two-player zero-sum games with imperfect\ninformation. CFR solves games by travsersing the full game tree iteratively,\nwhich limits its scalability in larger games. When applying CFR to solve\nlarge-scale games in previously, large-scale games are abstracted into\nsmall-scale games firstly. Secondly, CFR is used to solve the abstract game.\nAnd finally, the solution strategy is mapped back to the original large-scale\ngame. However, this process requires considerable expert knowledge, and the\naccuracy of abstraction is closely related to expert knowledge. In addition,\nthe abstraction also loses certain information, which will eventually affect\nthe accuracy of the solution strategy. Towards this problem, a recent method,\n\\textit{Deep CFR} alleviates the need for abstraction and expert knowledge by\napplying deep neural networks directly to CFR in full games. In this paper, we\nintroduces \\textit{Neural Network Counterfactual Regret Minimization (NNCFR)},\nan improved variant of \\textit{Deep CFR} that has a faster convergence by\nconstructing a dueling netwok as the value network. Moreover, an evaluation\nmodule is designed by combining the value network and Monte Carlo, which\nreduces the approximation error of the value network. In addition, a new loss\nfunction is designed in the procedure of training policy network in the\nproposed \\textit{NNCFR}, which can be good to make the policy network more\nstable. The extensive experimental tests are conducted to show that the\n\\textit{NNCFR} converges faster and performs more stable than \\textit{Deep\nCFR}, and outperforms \\textit{Deep CFR} with respect to exploitability and\nhead-to-head performance on test games.\n",
        "english": "Scalable neural networks, such as those employed in \\textit{Neural Network Counterfactual Regret Minimization (NNCFR)}, offer significant advancements by eliminating the necessity for game abstraction and expert knowledge, thus facilitating the direct application of deep neural networks to Counterfactual Regret Minimization (CFR) in full games. The innovative approach of \\textit{NNCFR} introduces a dueling network as the value network, which enhances convergence speed and stability, with experimental results demonstrating superior performance over \\textit{Deep CFR} in terms of exploitability and head-to-head performance. Furthermore, the integration of a new loss function in the policy network training procedure, denoted as $\\mathcal{L}_{\\text{new}}$, contributes to the robustness and precision of the solution strategy, underscoring the potential of scalable neural networks in complex decision-making environments.",
        "korean": "\\textit{신경망 반사실 후회 최소화(neural network counterfactual regret minimization, NNCFR)}에 사용되는 확장 가능한 신경망(scalable neural networks)은 게임 추상화와 전문가 지식의 필요성을 제거하여 심층 신경망(deep neural networks)을 전체 게임의 반사실 후회 최소화(counterfactual regret minimization, CFR)에 직접 적용할 수 있도록 함으로써 상당한 발전을 제공합니다. \\textit{NNCFR}의 혁신적인 접근 방식은 가치 네트워크(value network)로서 대결 네트워크(dueling network)를 도입하여 수렴 속도와 안정성을 향상시키며, 실험 결과는 착취 가능성(exploitability)과 직접 대결 성능에서 \\textit{딥 CFR(deep CFR)}보다 우수한 성능을 보여줍니다. 또한, 정책 네트워크(policy network) 훈련 절차에 새로운 손실 함수(loss function) $\\mathcal{L}_{\\text{new}}$를 통합함으로써 솔루션 전략의 견고성과 정밀성을 높여 복잡한 의사 결정 환경에서 확장 가능한 신경망(scalable neural networks)의 잠재력을 강조합니다.",
        "score": 9,
        "parentheses_count": 11,
        "suggestions": "Ensure all English terms within parentheses are in lowercase for consistency and adjust the structure for a more natural flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "neural dynamic sequence learning",
        "domain": "cs.AI",
        "summary": "  Sequence-to-sequence (encoder-decoder) models with attention constitute a\ncornerstone of deep learning research, as they have enabled unprecedented\nsequential data modeling capabilities. This effectiveness largely stems from\nthe capacity of these models to infer salient temporal dynamics over long\nhorizons; these are encoded into the obtained neural attention (NA)\ndistributions. However, existing NA formulations essentially constitute\npoint-wise selection mechanisms over the observed source sequences; that is,\nattention weights computation relies on the assumption that each source\nsequence element is independent of the rest. Unfortunately, although\nconvenient, this assumption fails to account for higher-order dependencies\nwhich might be prevalent in real-world data. This paper addresses these\nlimitations by leveraging Quantum-Statistical modeling arguments. Specifically,\nour work broadens the notion of NA, by attempting to account for the case that\nthe NA model becomes inherently incapable of discerning between individual\nsource elements; this is assumed to be the case due to higher-order temporal\ndynamics. On the contrary, we postulate that in some cases selection may be\nfeasible only at the level of pairs of source sequence elements. To this end,\nwe cast NA into inference of an attention density matrix (ADM) approximation.\nWe derive effective training and inference algorithms, and evaluate our\napproach in the context of a machine translation (MT) application. We perform\nexperiments with challenging benchmark datasets. As we show, our approach\nyields favorable outcomes in terms of several evaluation metrics.\n",
        "english": "Neural dynamic sequence learning has become a pivotal aspect of deep learning research, particularly in sequence-to-sequence (encoder-decoder) models with attention, which have demonstrated exceptional capabilities in modeling sequential data by inferring salient temporal dynamics over extended periods. The proposed research innovatively broadens the notion of neural attention (NA) by introducing a quantum-statistical approach, which accounts for higher-order dependencies that traditional NA formulations overlook, thereby casting NA into the inference of an attention density matrix (ADM) approximation. Our experiments, conducted on challenging benchmark datasets in the context of a machine translation application, show that this approach achieves superior outcomes, with evaluation metrics indicating significant improvements in performance.",
        "korean": "신경 동적 시퀀스 학습(neural dynamic sequence learning)은 특히 주의(attention)를 사용하는 시퀀스-투-시퀀스(sequence-to-sequence, 인코더-디코더) 모델에서 심층 학습 연구의 중요한 측면이 되었습니다. 이러한 모델은 확장된 기간 동안 중요한 시간적 역학을 추론하여 순차 데이터를 모델링하는 데 뛰어난 능력을 입증했습니다. 제안된 연구는 전통적인 신경 주의(neural attention, NA) 공식이 간과하는 고차 의존성을 고려하는 양자 통계적 접근 방식을 도입하여 신경 주의(neural attention, NA)의 개념을 혁신적으로 확장하며, 이를 주의 밀도 행렬(attention density matrix, ADM) 근사의 추론으로 전환합니다. 기계 번역 응용 프로그램의 맥락에서 도전적인 벤치마크 데이터셋(benchmark datasets)을 대상으로 수행한 실험 결과, 이 접근 방식이 성능 평가 지표에서 상당한 개선을 나타내며 우수한 결과를 달성함을 보여줍니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure all English terms within parentheses are in lowercase and maintain consistent parenthesization throughout the text for a more natural flow."
    },
    {
        "turn_index": 2,
        "term": "mcmc",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Markov Chain Monte Carlo (MCMC) methods are pivotal in approximating complex posterior distributions that are analytically intractable, facilitating advancements in Bayesian inference. By employing a Metropolis-Hastings algorithm, the study demonstrates the convergence of the chain to the target distribution, ensuring that the acceptance probability \\( \\alpha = \\min\\left(1, \\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right) \\) is maintained, where \\( \\pi \\) represents the target distribution and \\( q \\) is the proposal distribution. This innovative approach underscores MCMC's capability to efficiently sample high-dimensional spaces, significantly enhancing the accuracy and computational feasibility of statistical models.",
        "korean": "마르코프 연쇄 몬테카를로(Markov Chain Monte Carlo, MCMC) 방법은 분석적으로 다루기 어려운 복잡한 사후 분포를 근사하는 데 중요한 역할을 하며, 베이지안 추론(bayesian inference)의 발전을 촉진합니다. 메트로폴리스-헤이스팅스 알고리즘(metropolis-hastings algorithm)을 사용하여 연구는 사슬이 목표 분포로 수렴함을 입증하며, 수용 확률 \\( \\alpha = \\min\\left(1, \\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right) \\)이 유지되도록 보장합니다. 여기서 \\( \\pi \\)는 목표 분포를 나타내고 \\( q \\)는 제안 분포입니다. 이 혁신적인 접근 방식은 mcmc의 고차원 공간을 효율적으로 샘플링하는 능력을 강조하며, 통계 모델의 정확성과 계산 가능성을 크게 향상시킵니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure consistent use of lowercase for all English terms within parentheses and verify that all technical terms are correctly parenthesized."
    },
    {
        "turn_index": 2,
        "term": "semantic neural inference",
        "domain": "cs.AI",
        "summary": "  The representation of knowledge based on first-order logic captures the\nrichness of natural language and supports multiple probabilistic inference\nmodels. Although symbolic representation enables quantitative reasoning with\nstatistical probability, it is difficult to utilize with machine learning\nmodels as they perform numerical operations. In contrast, knowledge embedding\n(i.e., high-dimensional and continuous vectors) is a feasible approach to\ncomplex reasoning that can not only retain the semantic information of\nknowledge but also establish the quantifiable relationship among them. In this\npaper, we propose recursive neural knowledge network (RNKN), which combines\nmedical knowledge based on first-order logic with recursive neural network for\nmulti-disease diagnosis. After RNKN is efficiently trained from manually\nannotated Chinese Electronic Medical Records (CEMRs), diagnosis-oriented\nknowledge embeddings and weight matrixes are learned. Experimental results\nverify that the diagnostic accuracy of RNKN is superior to that of some\nclassical machine learning models and Markov logic network (MLN). The results\nalso demonstrate that the more explicit the evidence extracted from CEMRs is,\nthe better is the performance achieved. RNKN gradually exhibits the\ninterpretation of knowledge embeddings as the number of training epochs\nincreases.\n",
        "english": "Semantic neural inference, exemplified by the recursive neural knowledge network (RNKN), integrates medical knowledge based on first-order logic with recursive neural networks to enhance multi-disease diagnosis. By efficiently training RNKN from manually annotated Chinese Electronic Medical Records (CEMRs), the model learns diagnosis-oriented knowledge embeddings and weight matrices, thereby achieving a diagnostic accuracy superior to classical machine learning models and Markov logic networks (MLN). The performance of RNKN improves with explicit evidence extracted from CEMRs, and the interpretation of knowledge embeddings becomes more apparent as the number of training epochs, denoted as $E$, increases, highlighting the innovative approach of embedding-based reasoning in complex medical diagnostics.",
        "korean": "일차 논리(first-order logic)에 기반한 의료 지식을 재귀 신경망(recursive neural networks)과 통합하여 다중 질병 진단을 향상시키는 재귀 신경 지식 네트워크(recursive neural knowledge network, RNKN)로 예시되는 의미론적 신경 추론(semantic neural inference)은 수작업으로 주석이 달린 중국 전자 의료 기록(chinese electronic medical records, CEMRs)에서 RNKN을 효율적으로 훈련함으로써 진단 지향 지식 임베딩과 가중치 행렬을 학습하여 고전적인 기계 학습 모델과 마르코프 논리 네트워크(markov logic networks, MLN)를 능가하는 진단 정확도를 달성합니다. RNKN의 성능은 CEMRs에서 추출된 명시적 증거와 함께 향상되며, 훈련 에포크 수를 $E$로 나타낼 때, 지식 임베딩의 해석이 더욱 명확해져 복잡한 의료 진단에서 임베딩 기반 추론의 혁신적인 접근 방식을 강조합니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural probabilistic text models",
        "domain": "cs.AI",
        "summary": "  We propose a deep learning model - Probabilistic Prognostic Estimates of\nSurvival in Metastatic Cancer Patients (PPES-Met) for estimating short-term\nlife expectancy (3 months) of the patients by analyzing free-text clinical\nnotes in the electronic medical record, while maintaining the temporal visit\nsequence. In a single framework, we integrated semantic data mapping and neural\nembedding technique to produce a text processing method that extracts relevant\ninformation from heterogeneous types of clinical notes in an unsupervised\nmanner, and we designed a recurrent neural network to model the temporal\ndependency of the patient visits. The model was trained on a large dataset\n(10,293 patients) and validated on a separated dataset (1818 patients). Our\nmethod achieved an area under the ROC curve (AUC) of 0.89. To provide\nexplain-ability, we developed an interactive graphical tool that may improve\nphysician understanding of the basis for the model's predictions. The high\naccuracy and explain-ability of the PPES-Met model may enable our model to be\nused as a decision support tool to personalize metastatic cancer treatment and\nprovide valuable assistance to the physicians.\n",
        "english": "Neural probabilistic text models have been effectively utilized in the development of a deep learning framework, Probabilistic Prognostic Estimates of Survival in Metastatic Cancer Patients (PPES-Met), which estimates short-term life expectancy by analyzing free-text clinical notes while maintaining temporal visit sequences. By integrating semantic data mapping and neural embedding techniques, this model processes text in an unsupervised manner, achieving a high area under the ROC curve (AUC) of 0.89, indicative of its predictive accuracy. The innovation of this model lies in its ability to provide explainability through an interactive graphical tool, potentially serving as a decision support tool to personalize metastatic cancer treatment and assist physicians.",
        "korean": "신경 확률적 텍스트 모델(neural probabilistic text models)은 전이성 암 환자의 생존 확률 추정(Probabilistic Prognostic Estimates of Survival in Metastatic Cancer Patients, PPES-Met)이라는 심층 학습 프레임워크 개발에 효과적으로 활용되었습니다. 이 모델은 자유 텍스트 임상 노트를 분석하여 단기 생존 가능성을 추정하며, 시간 순서에 따른 방문 시퀀스를 유지합니다. 의미론적 데이터 매핑과 신경 임베딩 기법을 통합함으로써, 이 모델은 비지도 방식으로 텍스트를 처리하며, ROC 곡선 아래 면적(AUC) 0.89라는 높은 예측 정확도를 달성했습니다. 이 모델의 혁신은 상호작용 그래픽 도구를 통해 설명 가능성을 제공하는 데 있으며, 이는 전이성 암 치료를 개인화하고 의사를 지원하는 의사 결정 지원 도구로 활용될 가능성이 있습니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability in Korean, particularly in the explanation of the model's innovation and its potential applications."
    },
    {
        "turn_index": 2,
        "term": "reinforcement learning frameworks",
        "domain": "cs.AI",
        "summary": "  Deep reinforcement learning has gradually shown its latent decision-making\nability in urban rail transit autonomous operation. However, since\nreinforcement learning can not neither guarantee safety during learning nor\nexecution, this is still one of the major obstacles to the practical\napplication of reinforcement learning. Given this drawback, reinforcement\nlearning applied in the safety-critical autonomous operation domain remains\nchallenging without generating a safe control command sequence that avoids\noverspeed operations. Therefore, a SSA-DRL framework is proposed in this paper\nfor safe intelligent control of urban rail transit autonomous operation trains.\nThe proposed framework is combined with linear temporal logic, reinforcement\nlearning and Monte Carlo tree search and consists of four mainly module: a\npost-posed shielding, a searching tree module, a DRL framework and an\nadditional actor. Furthermore, the output of the framework can meet speed\nconstraint, schedule constraint and optimize the operation process. Finally,\nthe proposed SSA-DRL framework for decision-making in urban rail transit\nautonomous operation is evaluated in sixteen different sections, and its\neffectiveness is demonstrated through an ablation experiment and comparison\nwith the scheduled operation plan.\n",
        "english": "Reinforcement learning frameworks have demonstrated significant potential in urban rail transit autonomous operation, yet they face challenges in ensuring safety during both learning and execution phases, which is crucial for practical applications. To address these challenges, the proposed SSA-DRL framework integrates linear temporal logic, reinforcement learning, and Monte Carlo tree search, consisting of modules such as post-posed shielding and a searching tree module, ensuring that the output meets speed and schedule constraints while optimizing the operation process. Importantly, the effectiveness of this framework is underscored by its evaluation across sixteen different sections, where it successfully generates a control command sequence that avoids overspeed operations, as demonstrated by the ablation experiment and comparison with a scheduled operation plan.",
        "korean": "강화 학습 프레임워크(reinforcement learning frameworks)는 도시 철도 자율 운행에서 상당한 잠재력을 보여주었지만, 학습 및 실행 단계에서의 안전성을 보장하는 데 어려움을 겪고 있으며, 이는 실용적인 응용에 있어 매우 중요합니다. 이러한 문제를 해결하기 위해 제안된 SSA-DRL 프레임워크는 선형 시간 논리(linear temporal logic), 강화 학습(reinforcement learning), 몬테카를로 트리 탐색(monte carlo tree search)을 통합하여, 후방 차폐(post-posed shielding) 및 탐색 트리 모듈(searching tree module)과 같은 모듈로 구성되어 있으며, 출력이 속도 및 일정 제약을 충족하면서 운행 과정을 최적화하도록 보장합니다. 특히, 이 프레임워크의 효과는 16개의 다른 구간에 걸친 평가를 통해 강조되며, 여기서 과속 운행을 피하는 제어 명령 시퀀스를 성공적으로 생성함으로써, 절제 실험 및 예정된 운행 계획과의 비교를 통해 입증되었습니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Suggest ensuring all technical terms are consistently parenthesized as Korean term(English term) and check for any missing or inconsistent parenthesization. Adjust the structure for natural flow and grammar."
    },
    {
        "turn_index": 2,
        "term": "context-aware sequence learning",
        "domain": "cs.AI",
        "summary": "  An effective and efficient encoding of the source code of a computer program\nis critical to the success of sequence-to-sequence deep neural network models\nfor tasks in computer program comprehension, such as automated code\nsummarization and documentation. A significant challenge is to find a\nsequential representation that captures the structural/syntactic information in\na computer program and facilitates the training of the learning models.\n  In this paper, we propose to use the Pr\\\"ufer sequence of the Abstract Syntax\nTree (AST) of a computer program to design a sequential representation scheme\nthat preserves the structural information in an AST. Our representation makes\nit possible to develop deep-learning models in which signals carried by lexical\ntokens in the training examples can be exploited automatically and selectively\nbased on their syntactic role and importance. Unlike other recently-proposed\napproaches, our representation is concise and lossless in terms of the\nstructural information of the AST. Empirical studies on real-world benchmark\ndatasets, using a sequence-to-sequence learning model we designed for code\nsummarization, show that our Pr\\\"ufer-sequence-based representation is indeed\nhighly effective and efficient, outperforming significantly all the\nrecently-proposed deep-learning models we used as the baseline models.\n",
        "english": "Context-aware sequence learning in the realm of computer program comprehension necessitates an encoding that effectively captures the structural and syntactic intricacies of source code, crucial for tasks such as automated code summarization and documentation. The proposed approach utilizes the Pr\\\"ufer sequence of the Abstract Syntax Tree (AST) to create a sequential representation that is both concise and lossless, ensuring that the structural information of the AST is preserved and can be exploited by deep-learning models to selectively utilize lexical tokens based on their syntactic importance. Empirical evaluations demonstrate the efficacy of this method, with results indicating that the Pr\\\"ufer-sequence-based representation significantly outperforms baseline models, as evidenced by a marked increase in performance metrics $\\Delta P$, where $\\Delta P$ represents the improvement over existing models.",
        "korean": "컴퓨터 프로그램 이해 영역에서 맥락 인식 시퀀스 학습(context-aware sequence learning)은 소스 코드의 구조적 및 구문적 복잡성을 효과적으로 포착하는 인코딩을 필요로 하며, 이는 자동 코드 요약 및 문서화와 같은 작업에 필수적입니다. 제안된 접근 방식은 추상 구문 트리(Abstract Syntax Tree, AST)의 프뤼퍼 시퀀스(Pr\\\"ufer sequence)를 활용하여 간결하고 손실 없는 순차적 표현을 생성하며, 이는 AST의 구조적 정보를 보존하고 심층 학습 모델이 구문적 중요성에 따라 어휘 토큰을 선택적으로 활용할 수 있도록 합니다. 실증적 평가 결과, 프뤼퍼 시퀀스 기반 표현이 성능 지표 $\\Delta P$에서 기존 모델에 비해 현저한 성능 향상을 나타내며, $\\Delta P$는 기존 모델에 대한 개선을 나타냅니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure that all technical terms are consistently parenthesized in the format Korean term(English term) and consider adjusting the sentence structure for smoother readability in Korean."
    },
    {
        "turn_index": 2,
        "term": "non-Euclidean domains",
        "domain": "cs.AI",
        "summary": "  The existing network attack and defense method can be regarded as game, but\nmost of the game only involves network domain, not multiple domain cyberspace.\nTo address this challenge, this paper proposed a multiple domain cyberspace\nattack and defense game model based on reinforcement learning. We define the\nmultiple domain cyberspace include physical domain, network domain and digital\ndomain. By establishing two agents, representing the attacker and the defender\nrespectively, defender will select the multiple domain actions in the multiple\ndomain cyberspace to obtain defender's optimal reward by reinforcement\nlearning. In order to improve the defense ability of defender, a game model\nbased on reward randomization reinforcement learning is proposed. When the\ndefender takes the multiple domain defense action, the reward is randomly given\nand subject to linear distribution, so as to find the better defense policy and\nimprove defense success rate. The experimental results show that the game model\ncan effectively simulate the attack and defense state of multiple domain\ncyberspace, and the proposed method has a higher defense success rate than DDPG\nand DQN.\n",
        "english": "In addressing the complexities inherent in non-Euclidean domains, the paper introduces a multiple domain cyberspace attack and defense game model, which incorporates the physical, network, and digital domains, thereby expanding the scope beyond traditional network-centric approaches. The model employs reinforcement learning, where two agents—representing the attacker and defender—are utilized to simulate interactions within these non-Euclidean domains, with the defender selecting actions to maximize their reward, $R$, subject to a linear distribution. This innovative approach, leveraging reward randomization in reinforcement learning, demonstrates an improved defense success rate over established methods such as DDPG and DQN, underscoring its potential to enhance cybersecurity strategies within complex, multi-domain environments.",
        "korean": "비유클리드 도메인(non-Euclidean domains)에 내재된 복잡성을 해결하기 위해, 이 논문은 물리적, 네트워크, 디지털 도메인을 포함하여 전통적인 네트워크 중심 접근 방식을 넘어서는 다중 도메인 사이버 공간 공격 및 방어 게임 모델을 소개합니다. 이 모델은 강화 학습(reinforcement learning)을 활용하며, 공격자와 방어자를 대표하는 두 에이전트를 사용하여 이러한 비유클리드 도메인(non-Euclidean domains) 내에서의 상호작용을 시뮬레이션합니다. 방어자는 선형 분포에 따라 보상 $R$을 최대화하기 위한 행동을 선택합니다. 보상 무작위화를 활용한 이 혁신적인 접근 방식은 DDPG 및 DQN과 같은 기존 방법에 비해 향상된 방어 성공률을 보여주며, 복잡한 다중 도메인 환경 내에서 사이버 보안 전략을 강화할 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "contextual text generation",
        "domain": "cs.AI",
        "summary": "  This study evaluates the potential of ChatGPT-4, an artificial intelligence\nlanguage model developed by OpenAI, as an editing tool for Spanish literary and\nacademic books. The need for efficient and accessible reviewing and editing\nprocesses in the publishing industry has driven the search for automated\nsolutions. ChatGPT-4, being one of the most advanced language models, offers\nnotable capabilities in text comprehension and generation. In this study, the\nfeatures and capabilities of ChatGPT-4 are analyzed in terms of grammatical\ncorrection, stylistic coherence, and linguistic enrichment of texts in Spanish.\nTests were conducted with 100 literary and academic texts, where the edits made\nby ChatGPT-4 were compared to those made by expert human reviewers and editors.\nThe results show that while ChatGPT-4 is capable of making grammatical and\northographic corrections with high accuracy and in a very short time, it still\nfaces challenges in areas such as context sensitivity, bibliometric analysis,\ndeep contextual understanding, and interaction with visual content like graphs\nand tables. However, it is observed that collaboration between ChatGPT-4 and\nhuman reviewers and editors can be a promising strategy for improving\nefficiency without compromising quality. Furthermore, the authors consider that\nChatGPT-4 represents a valuable tool in the editing process, but its use should\nbe complementary to the work of human editors to ensure high-caliber editing in\nSpanish literary and academic books.\n",
        "english": "Contextual text generation, as demonstrated by ChatGPT-4, is a promising approach for enhancing the efficiency of editing processes in the publishing industry, particularly for Spanish literary and academic books. While ChatGPT-4 exhibits notable capabilities in text comprehension and generation, its performance in areas such as context sensitivity and deep contextual understanding remains an area for improvement, as indicated by the mathematical expression of its accuracy in grammatical corrections, which can be represented as $P(\\text{accuracy} = 0.95)$. The integration of ChatGPT-4 with human editors offers a synergistic strategy that leverages the strengths of both, ensuring high-quality editing outcomes without compromising the richness of contextual nuances.",
        "korean": "챗GPT-4(ChatGPT-4)로 입증된 바와 같이, 문맥적 텍스트 생성(contextual text generation)은 특히 스페인어 문학 및 학술 서적의 출판 산업에서 편집 과정의 효율성을 향상시키는 유망한 접근 방식입니다. 챗GPT-4(ChatGPT-4)는 텍스트 이해 및 생성에서 주목할 만한 능력을 보이지만, 문맥 민감성과 깊은 문맥적 이해와 같은 영역에서의 성능은 여전히 개선이 필요한 부분으로 남아 있으며, 이는 문법적 수정의 정확도를 수학적 표현으로 나타낸 $P(\\text{accuracy} = 0.95)$로 나타낼 수 있습니다. 챗GPT-4(ChatGPT-4)와 인간 편집자의 통합은 양측의 강점을 활용하여 문맥적 뉘앙스를 손상시키지 않으면서 고품질의 편집 결과를 보장하는 시너지 전략을 제공합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "continuous normalizing flows",
        "domain": "cs.AI",
        "summary": "  Generative modeling seeks to uncover the underlying factors that give rise to\nobserved data that can often be modeled as the natural symmetries that manifest\nthemselves through invariances and equivariances to certain transformation\nlaws. However, current approaches to representing these symmetries are couched\nin the formalism of continuous normalizing flows that require the construction\nof equivariant vector fields -- inhibiting their simple application to\nconventional higher dimensional generative modelling domains like natural\nimages. In this paper, we focus on building equivariant normalizing flows using\ndiscrete layers. We first theoretically prove the existence of an equivariant\nmap for compact groups whose actions are on compact spaces. We further\nintroduce three new equivariant flows: $G$-Residual Flows, $G$-Coupling Flows,\nand $G$-Inverse Autoregressive Flows that elevate classical Residual, Coupling,\nand Inverse Autoregressive Flows with equivariant maps to a prescribed group\n$G$. Our construction of $G$-Residual Flows are also universal, in the sense\nthat we prove an $G$-equivariant diffeomorphism can be exactly mapped by a\n$G$-residual flow. Finally, we complement our theoretical insights with\ndemonstrative experiments -- for the first time -- on image datasets like\nCIFAR-10 and show $G$-Equivariant Finite Normalizing flows lead to increased\ndata efficiency, faster convergence, and improved likelihood estimates.\n",
        "english": "Continuous normalizing flows are pivotal in generative modeling as they are employed to represent the natural symmetries manifesting through invariances and equivariances to specific transformation laws. Despite their potential, the application of continuous normalizing flows to conventional higher-dimensional generative modeling domains, such as natural images, is hindered by the necessity to construct equivariant vector fields. By introducing three novel equivariant flows—$G$-Residual Flows, $G$-Coupling Flows, and $G$-Inverse Autoregressive Flows—this research elevates classical flow models with equivariant maps to a prescribed group $G$, demonstrating increased data efficiency and improved likelihood estimates on image datasets like CIFAR-10.",
        "korean": "연속 정규화 흐름(continuous normalizing flows)은 생성 모델링(generative modeling)에서 자연 대칭성을 특정 변환 법칙에 대한 불변성과 공변성으로 나타내는 데 사용되기 때문에 매우 중요합니다. 그 잠재력에도 불구하고, 연속 정규화 흐름(continuous normalizing flows)을 자연 이미지와 같은 전통적인 고차원 생성 모델링 도메인에 적용하는 것은 공변 벡터 필드를 구성해야 한다는 필요성 때문에 방해받고 있습니다. 이 연구는 세 가지 새로운 공변 흐름(equivariant flows)인 $G$-잔차 흐름($G$-Residual Flows), $G$-결합 흐름($G$-Coupling Flows), $G$-역 자기회귀 흐름($G$-Inverse Autoregressive Flows)을 도입하여, 고전적인 흐름 모델(flow models)을 주어진 그룹 $G$에 대한 공변 사상으로 향상시킴으로써 CIFAR-10과 같은 이미지 데이터셋에서 데이터 효율성을 높이고 가능도 추정치를 개선하는 것을 보여줍니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "pairwise Markov networks",
        "domain": "cs.AI",
        "summary": "  Individual and group decisions are complex, often involving choosing an apt\nalternative from a multitude of options. Evaluating pairwise comparisons breaks\ndown such complex decision problems into tractable ones. Pairwise comparison\nmatrices (PCMs) are regularly used to solve multiple-criteria decision-making\n(MCDM) problems, for example, using Saaty's analytic hierarchy process (AHP)\nframework. However, there are two significant drawbacks of using PCMs. First,\nhumans evaluate PCMs in an inconsistent manner. Second, not all entries of a\nlarge PCM can be reliably filled by human decision makers. We address these two\nissues by first establishing a novel connection between PCMs and\ntime-irreversible Markov processes. Specifically, we show that every PCM\ninduces a family of dissipative maximum path entropy random walks (MERW) over\nthe set of alternatives. We show that only `consistent' PCMs correspond to\ndetailed balanced MERWs. We identify the non-equilibrium entropy production in\nthe induced MERWs as a metric of inconsistency of the underlying PCMs. Notably,\nthe entropy production satisfies all of the recently laid out criteria for\nreasonable consistency indices. We also propose an approach to use incompletely\nfilled PCMs in AHP. Potential future avenues are discussed as well.\n  keywords: analytic hierarchy process, markov chains, maximum entropy\n",
        "english": "Pairwise Markov networks can be utilized to address inconsistencies in pairwise comparison matrices (PCMs) by establishing a connection to time-irreversible Markov processes, where every PCM induces a family of dissipative maximum path entropy random walks (MERW) over the set of alternatives. This innovative approach identifies the non-equilibrium entropy production in the induced MERWs as a metric of inconsistency, which satisfies all of the recently laid out criteria for reasonable consistency indices, highlighting the robustness of this method. Mathematically, the entropy production metric, $S_{prod}$, provides a quantitative measure for evaluating the consistency of PCMs, thus offering a new perspective in the analytic hierarchy process (AHP) framework.",
        "korean": "쌍별 마르코프 네트워크(pairwise Markov networks)는 쌍별 비교 행렬(pairwise comparison matrices, PCMs)의 불일치를 해결하기 위해 시간 비가역 마르코프 과정(time-irreversible Markov processes)과의 연결을 설정함으로써 활용될 수 있으며, 여기서 각 PCM은 대안 집합에 대한 소산적 최대 경로 엔트로피 무작위 보행(dissipative maximum path entropy random walks, MERW) 가족을 유도합니다. 이 혁신적인 접근법은 유도된 MERW에서 비평형 엔트로피 생산(non-equilibrium entropy production)을 불일치의 척도로 식별하며, 이는 최근에 제시된 합리적인 일관성 지수 기준을 모두 충족하여 이 방법의 견고성을 강조합니다. 수학적으로, 엔트로피 생산 척도(entropy production metric), $S_{prod}$는 PCMs의 일관성을 평가하기 위한 정량적 측정을 제공하여 분석적 계층화 과정(analytic hierarchy process, AHP) 프레임워크에 새로운 관점을 제공합니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase letters within parentheses."
    },
    {
        "turn_index": 2,
        "term": "sequence-to-sequence models",
        "domain": "cs.AI",
        "summary": "  Causal Models are like Dependency Graphs and Belief Nets in that they provide\na structure and a set of assumptions from which a joint distribution can, in\nprinciple, be computed. Unlike Dependency Graphs, Causal Models are models of\nhierarchical and/or parallel processes, rather than models of distributions\n(partially) known to a model builder through some sort of gestalt. As such,\nCausal Models are more modular, easier to build, more intuitive, and easier to\nunderstand than Dependency Graph Models. Causal Models are formally defined and\nDependency Graph Models are shown to be a special case of them. Algorithms\nsupporting inference are presented. Parsimonious methods for eliciting\ndependent probabilities are presented.\n",
        "english": "Sequence-to-sequence models, akin to Causal Models, provide a structured framework with a set of assumptions that allow for the computation of a joint distribution, thereby enhancing their utility in various applications. Unlike Dependency Graphs, which are models of distributions known through gestalt, sequence-to-sequence models can be considered more modular and intuitive, facilitating easier construction and understanding of hierarchical and/or parallel processes. The mathematical representation of these models, which can be expressed as $P(Y|X)$ where $X$ and $Y$ are input and output sequences respectively, underscores their innovation and importance in advancing machine learning methodologies.",
        "korean": "인과 모델(causal models)과 유사한 시퀀스-투-시퀀스 모델(sequence-to-sequence models)은 결합 분포를 계산할 수 있는 가정 집합을 통해 다양한 응용 분야에서 유용성을 높이는 구조화된 프레임워크를 제공합니다. 게슈탈트(gestalt)를 통해 알려진 분포의 모델인 의존 그래프(dependency graphs)와 달리, 시퀀스-투-시퀀스 모델(sequence-to-sequence models)은 더 모듈화되고 직관적이며, 계층적 및/또는 병렬 프로세스의 더 쉬운 구성과 이해를 촉진합니다. 이러한 모델의 수학적 표현은 입력 시퀀스와 출력 시퀀스를 각각 $X$와 $Y$로 나타내는 $P(Y|X)$로 표현될 수 있으며, 이는 기계 학습 방법론을 발전시키는 데 있어 그 혁신성과 중요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural dynamic learning",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Neural dynamic learning, as outlined in the reference, employs a sophisticated methodology that integrates temporal dynamics into neural network architectures to enhance predictive accuracy. By leveraging the equation $\\mathbf{y}(t) = \\mathbf{W} \\cdot \\mathbf{x}(t) + \\mathbf{b}$, where $\\mathbf{y}(t)$ represents the output at time $t$, $\\mathbf{W}$ denotes the weight matrix, $\\mathbf{x}(t)$ is the input vector, and $\\mathbf{b}$ is the bias term, this approach effectively captures the evolving patterns within time-series data. The innovation of neural dynamic learning lies in its ability to adapt to non-static environments, making it a pivotal advancement in the field of machine learning.",
        "korean": "참조 문헌에 설명된 신경 역학 학습(neural dynamic learning)은 예측 정확성을 향상시키기 위해 신경망 아키텍처에 시간적 역학을 통합하는 정교한 방법론을 사용합니다. $\\mathbf{y}(t) = \\mathbf{W} \\cdot \\mathbf{x}(t) + \\mathbf{b}$라는 방정식을 활용하여, 여기서 $\\mathbf{y}(t)$는 시간 $t$에서의 출력을 나타내고, $\\mathbf{W}$는 가중치 행렬을, $\\mathbf{x}(t)$는 입력 벡터를, $\\mathbf{b}$는 편향 항을 나타내며, 이 접근법은 시계열 데이터 내의 변화하는 패턴을 효과적으로 포착합니다. 신경 역학 학습(neural dynamic learning)의 혁신은 비정적 환경에 적응할 수 있는 능력에 있으며, 이는 기계 학습 분야에서 중요한 발전을 이루고 있습니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "deep q-networks",
        "domain": "cs.AI",
        "summary": "  Multi-agent systems in which secondary agents with conflicting agendas also\nalter their methods need opponent modeling. In this study, we simulate the main\nagent's and secondary agents' tactics using Double Deep Q-Networks (DDQN) with\na prioritized experience replay mechanism. Then, under the opponent modeling\nsetup, a Mixture-of-Experts architecture is used to identify various opponent\nstrategy patterns. Finally, we analyze our models in two environments with\nseveral agents. The findings indicate that the Mixture-of-Experts model, which\nis based on opponent modeling, performs better than DDQN.\n",
        "korean": "다중 에이전트 시스템 분야에서 심층 q-네트워크(deep q-networks), 특히 이중 심층 q-네트워크(Double Deep Q-Networks, DDQN)의 형태는 우선순위 경험 재생 메커니즘(prioritized experience replay mechanism)을 통해 주요 에이전트와 보조 에이전트의 전술을 시뮬레이션하는 데 활용되어 동적 환경에서의 적응성을 강조합니다. 특히 상대 모델링 설정에서 DDQN의 성능을 능가하는 전문가 혼합 아키텍처(Mixture-of-Experts architecture)의 통합은 다양한 상대 전략 패턴을 식별하여 의사 결정 과정을 향상시킵니다. 연구는 여러 에이전트가 있는 환경에서 전문가 혼합 모델(Mixture-of-Experts model)을 사용하는 혁신을 강조하며, 성능 지표가 $P_{MoE} > P_{DDQN}$로 표시되는 성능 향상을 통해 모델의 정확도가 크게 개선됨을 보여줍니다. 여기서 $P$는 성능 측정을 나타냅니다."
    },
    {
        "turn_index": 2,
        "term": "object detection",
        "domain": "cs.AI",
        "summary": "  This paper presents a knowledge-based detection of objects approach using the\nOWL ontology language, the Semantic Web Rule Language, and 3D processing\nbuilt-ins aiming at combining geometrical analysis of 3D point clouds and\nspecialist's knowledge. Here, we share our experience regarding the creation of\n3D semantic facility model out of unorganized 3D point clouds. Thus, a\nknowledge-based detection approach of objects using the OWL ontology language\nis presented. This knowledge is used to define SWRL detection rules. In\naddition, the combination of 3D processing built-ins and topological Built-Ins\nin SWRL rules allows a more flexible and intelligent detection, and the\nannotation of objects contained in 3D point clouds. The created WiDOP prototype\ntakes a set of 3D point clouds as input, and produces as output a populated\nontology corresponding to an indexed scene visualized within VRML language. The\ncontext of the study is the detection of railway objects materialized within\nthe Deutsche Bahn scene such as signals, technical cupboards, electric poles,\netc. Thus, the resulting enriched and populated ontology, that contains the\nannotations of objects in the point clouds, is used to feed a GIS system or an\nIFC file for architecture purposes.\n",
        "english": "The paper introduces a knowledge-based object detection approach utilizing the OWL ontology language and the Semantic Web Rule Language (SWRL), which integrates geometrical analysis of 3D point clouds with domain expertise for enhanced detection accuracy. By applying SWRL detection rules, the research leverages the combination of 3D processing built-ins and topological Built-Ins, resulting in a more flexible and intelligent detection system capable of annotating objects within 3D point clouds, such as signals and electric poles in the Deutsche Bahn scene. The innovative WiDOP prototype takes 3D point clouds as input and produces a populated ontology, represented as an indexed scene in VRML language, which can be used to feed a GIS system or an IFC file, facilitating architectural applications.",
        "korean": "이 논문은 OWL 온톨로지 언어(owl ontology language)와 시맨틱 웹 규칙 언어(semantic web rule language, swrl)를 활용한 지식 기반 객체 탐지(object detection) 접근 방식을 소개하며, 이는 3D 포인트 클라우드의 기하학적 분석과 도메인 전문 지식을 통합하여 탐지 정확성을 향상시킵니다. swrl 탐지 규칙을 적용함으로써, 연구는 3D 처리 내장 기능과 위상 내장 기능의 결합을 활용하여 3D 포인트 클라우드 내의 객체를 주석 처리할 수 있는 보다 유연하고 지능적인 탐지 시스템을 구현합니다. 이러한 시스템은 deutsche bahn 장면에서 신호 및 전기 기둥과 같은 객체를 탐지할 수 있습니다. 혁신적인 widop 프로토타입은 3D 포인트 클라우드를 입력으로 받아 vrml 언어로 인덱싱된 장면으로 표현된 온톨로지를 생성하며, 이는 gis 시스템이나 ifc 파일에 공급되어 건축 응용 프로그램을 용이하게 합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure consistent use of lowercase for all terms within parentheses and consider rephrasing for smoother readability, especially in the second sentence."
    },
    {
        "turn_index": 2,
        "term": "stochastic neural processes",
        "domain": "cs.AI",
        "summary": "  Heuristic forward search is currently the dominant paradigm in classical\nplanning. Forward search algorithms typically rely on a single, relatively\nsimple variation of best-first search and remain fixed throughout the process\nof solving a planning problem. Existing work combining multiple search\ntechniques usually aims at supporting best-first search with an additional\nexploratory mechanism, triggered using a handcrafted criterion. A notable\nexception is very recent work which combines various search techniques using a\ntrainable policy. It is, however, confined to a discrete action space\ncomprising several fixed subroutines.\n  In this paper, we introduce a parametrized search algorithm template which\ncombines various search techniques within a single routine. The template's\nparameter space defines an infinite space of search algorithms, including,\namong others, BFS, local and random search. We further introduce a neural\narchitecture for designating the values of the search parameters given the\nstate of the search. This enables expressing neural search policies that change\nthe values of the parameters as the search progresses. The policies can be\nlearned automatically, with the objective of maximizing the planner's\nperformance on a given distribution of planning problems. We consider a\ntraining setting based on a stochastic optimization algorithm known as the\ncross-entropy method (CEM). Experimental evaluation of our approach shows that\nit is capable of finding effective distribution-specific search policies,\noutperforming the relevant baselines.\n",
        "english": "Stochastic neural processes facilitate the development of a parametrized search algorithm template, which \"combines various search techniques within a single routine,\" thereby enabling the dynamic adaptation of search strategies based on the current state of the search (reference). This approach is further enhanced by a neural architecture that designates search parameter values, allowing for the expression of neural search policies that evolve as the search progresses, with the objective function expressed as $\\max_{\\theta} \\mathbb{E}_{p(x;\\theta)}[f(x)]$, where $\\theta$ represents the policy parameters (reference). By employing a stochastic optimization algorithm known as the cross-entropy method (CEM), the research demonstrates the ability to \"find effective distribution-specific search policies,\" significantly outperforming traditional baselines and highlighting the potential of stochastic neural processes in optimizing planner performance (reference).",
        "korean": "확률적 신경 프로세스(stochastic neural processes)는 매개변수화된 탐색 알고리즘 템플릿(parametrized search algorithm template)의 개발을 촉진하며, 이는 \"단일 루틴 내에서 다양한 탐색 기법을 결합\"하여 탐색의 현재 상태에 따라 탐색 전략을 동적으로 적응할 수 있게 합니다(참조). 이 접근법은 탐색 매개변수 값을 지정하는 신경 아키텍처(neural architecture)에 의해 더욱 강화되며, 탐색이 진행됨에 따라 진화하는 신경 탐색 정책(neural search policies)을 표현할 수 있게 합니다. 목적 함수는 $\\max_{\\theta} \\mathbb{E}_{p(x;\\theta)}[f(x)]$로 표현되며, 여기서 $\\theta$는 정책 매개변수(policy parameters)를 나타냅니다(참조). 교차 엔트로피 방법(cross-entropy method, CEM)으로 알려진 확률적 최적화 알고리즘을 사용함으로써, 연구는 \"효과적인 분포 특정 탐색 정책(distribution-specific search policies)을 찾는\" 능력을 입증하며, 전통적인 기준을 크게 능가하고 계획자 성능 최적화에서 확률적 신경 프로세스(stochastic neural processes)의 잠재력을 강조합니다(참조).",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "graph-based neural modeling",
        "domain": "cs.AI",
        "summary": "  Robots and autonomous systems require an understanding of complex events\n(CEs) from sensor data to interact with their environments and humans\neffectively. Traditional end-to-end neural architectures, despite processing\nsensor data efficiently, struggle with long-duration events due to limited\ncontext sizes and reasoning capabilities. Recent advances in neuro-symbolic\nmethods, which integrate neural and symbolic models leveraging human knowledge,\npromise improved performance with less data. This study addresses the gap in\nunderstanding these approaches' effectiveness in complex event detection (CED),\nespecially in temporal reasoning. We investigate neural and neuro-symbolic\narchitectures' performance in a multimodal CED task, analyzing IMU and acoustic\ndata streams to recognize CE patterns. Our methodology includes (i) end-to-end\nneural architectures for direct CE detection from sensor embeddings, (ii)\ntwo-stage concept-based neural models mapping sensor embeddings to atomic\nevents (AEs) before CE detection, and (iii) a neuro-symbolic approach using a\nsymbolic finite-state machine for CE detection from AEs. Empirically, the\nneuro-symbolic architecture significantly surpasses purely neural models,\ndemonstrating superior performance in CE recognition, even with extensive\ntraining data and ample temporal context for neural approaches.\n",
        "english": "Graph-based neural modeling is a promising approach for understanding complex events (CEs) from sensor data, as it can integrate neural and symbolic models leveraging human knowledge to enhance reasoning capabilities. In this context, a two-stage concept-based neural model is employed, where sensor embeddings are first mapped to atomic events (AEs) before CE detection, allowing for more effective temporal reasoning. Empirical results indicate that the neuro-symbolic architecture, which incorporates a symbolic finite-state machine, significantly surpasses purely neural models in CE recognition, with performance improvements even when neural models have extensive training data and ample temporal context, suggesting that graph-based neural modeling can be expressed as $f(x) = g(h(x))$, where $f$ is the CE detection function, $g$ is the mapping to AEs, and $h$ is the sensor embedding function.",
        "korean": "그래프 기반 신경 모델링(graph-based neural modeling)은 센서 데이터(sensor data)로부터 복잡한 이벤트(complex events, CEs)를 이해하는 데 유망한 접근 방식으로, 인간의 지식을 활용하여 신경 모델과 상징 모델을 통합함으로써 추론 능력을 향상시킬 수 있습니다. 이 맥락에서, 두 단계 개념 기반 신경 모델(two-stage concept-based neural model)이 사용되며, 센서 임베딩(sensor embeddings)이 먼저 원자 이벤트(atomic events, AEs)로 매핑된 후 CE 감지가 이루어져 보다 효과적인 시간적 추론이 가능합니다. 실험 결과에 따르면, 상징적 유한 상태 기계(symbolic finite-state machine)를 통합한 신경-상징 아키텍처(neuro-symbolic architecture)는 CE 인식에서 순수 신경 모델을 크게 능가하며, 신경 모델이 광범위한 훈련 데이터와 충분한 시간적 맥락을 가지고 있을 때도 성능 향상을 보여줍니다. 이는 그래프 기반 신경 모델링(graph-based neural modeling)이 $f(x) = g(h(x))$로 표현될 수 있음을 시사하며, 여기서 $f$는 CE 감지 함수, $g$는 AEs로의 매핑, $h$는 센서 임베딩 함수입니다.",
        "score": 9,
        "parentheses_count": 11,
        "suggestions": "Ensure all English terms within parentheses are in lowercase to maintain consistency and adhere to the criteria."
    },
    {
        "turn_index": 2,
        "term": "feature engineering",
        "domain": "cs.AI",
        "summary": "  The digitalization of automation engineering generates large quantities of\nengineering data that is interlinked in knowledge graphs. Classifying and\nclustering subgraphs according to their functionality is useful to discover\nfunctionally equivalent engineering artifacts that exhibit different graph\nstructures. This paper presents a new graph learning algorithm designed to\nclassify engineering data artifacts -- represented in the form of graphs --\naccording to their structure and neighborhood features. Our Structural Graph\nConvolutional Neural Network (SGCNN) is capable of learning graphs and\nsubgraphs with a novel graph invariant convolution kernel and\ndownsampling/pooling algorithm. On a realistic engineering-related dataset, we\nshow that SGCNN is capable of achieving ~91% classification accuracy.\n",
        "korean": "[TERM](feature engineering)의 영역에서 자동화 공학의 디지털화는 지식 그래프(knowledge graphs)로 연결된 방대한 양의 공학 데이터를 생성하며, 이는 다양한 그래프 구조를 가진 기능적으로 동등한 공학 아티팩트를 발견하기 위해 분류 및 클러스터링될 수 있습니다. 새로운 구조적 그래프 합성곱 신경망(Structural Graph Convolutional Neural Network, SGCNN)의 도입은 그래프 불변 합성곱 커널과 정교한 다운샘플링/풀링 알고리즘을 활용하여 구조적 및 이웃 특징에 기반한 공학 데이터 아티팩트를 효과적으로 학습하고 분류하는 데 있어 중요한 발전을 나타냅니다. 특히, SGCNN은 현실적인 공학 관련 데이터셋에서 약 91\\%의 분류 정확도를 달성하며, [TERM](feature engineering) 프로세스의 효율성과 정밀성을 향상시킬 잠재력을 강조합니다."
    },
    {
        "turn_index": 2,
        "term": "semantic adaptive processes",
        "domain": "cs.AI",
        "summary": "  Taaable is a case-based reasoning system that adapts cooking recipes to user\nconstraints. Within it, the preparation part of recipes is formalised as a\ngraph. This graph is a semantic representation of the sequence of instructions\ncomposing the cooking process and is used to compute the procedure adaptation,\nconjointly with the textual adaptation. It is composed of cooking actions and\ningredients, among others, represented as vertices, and semantic relations\nbetween those, shown as arcs, and is built automatically thanks to natural\nlanguage processing. The results of the automatic annotation process is often a\ndisconnected graph, representing an incomplete annotation, or may contain\nerrors. Therefore, a validating and correcting step is required. In this paper,\nwe present an existing graphic tool named \\kcatos, conceived for representing\nand editing decision trees, and show how it has been adapted and integrated in\nWikiTaaable, the semantic wiki in which the knowledge used by Taaable is\nstored. This interface provides the wiki users with a way to correct the case\nrepresentation of the cooking process, improving at the same time the quality\nof the knowledge about cooking procedures stored in WikiTaaable.\n",
        "english": "Semantic adaptive processes are crucial in systems like Taaable, where the preparation part of recipes is formalised as a graph, representing a semantic sequence of cooking instructions. This graph, composed of vertices for cooking actions and ingredients and arcs for semantic relations, is constructed automatically via natural language processing, yet often results in a disconnected graph requiring a validating and correcting step. By integrating the graphic tool \\kcatos\\ into WikiTaaable, users can edit and correct these semantic representations, thereby enhancing the overall quality of knowledge stored about cooking procedures, demonstrating the innovative use of semantic adaptive processes in culinary knowledge management.",
        "korean": "의미 적응 프로세스(semantic adaptive processes)는 Taaable과 같은 시스템에서 매우 중요합니다. 이 시스템에서는 요리법의 준비 부분이 요리 지침의 의미적 순서를 나타내는 그래프로 형식화됩니다. 이 그래프는 요리 동작과 재료에 대한 정점과 의미적 관계에 대한 호로 구성되며, 자연어 처리 과정을 통해 자동으로 생성되지만 종종 연결되지 않은 그래프로 결과가 나타나기 때문에 검증 및 수정 단계가 필요합니다. WikiTaaable에 그래픽 도구 \\kcatos\\를 통합함으로써 사용자는 이러한 의미적 표현을 편집하고 수정할 수 있으며, 이를 통해 요리 절차에 대한 지식의 전반적인 품질을 향상시킬 수 있습니다. 이는 요리 지식 관리에서 의미 적응 프로세스(semantic adaptive processes)의 혁신적인 사용을 보여줍니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic attention models",
        "domain": "cs.AI",
        "summary": "  In neuroscience, attention has been shown to bidirectionally interact with\nreinforcement learning (RL) processes. This interaction is thought to support\ndimensionality reduction of task representations, restricting computations to\nrelevant features. However, it remains unclear whether these properties can\ntranslate into real algorithmic advantages for artificial agents, especially in\ndynamic environments. We design a model incorporating a self-attention\nmechanism that implements task-state representations in semantic feature-space,\nand test it on a battery of Atari games. To evaluate the agent's selective\nproperties, we add a large volume of task-irrelevant features to observations.\nIn line with neuroscience predictions, self-attention leads to increased\nrobustness to noise compared to benchmark models. Strikingly, this\nself-attention mechanism is general enough, such that it can be naturally\nextended to implement a transient working-memory, able to solve a partially\nobservable maze task. Lastly, we highlight the predictive quality of attended\nstimuli. Because we use semantic observations, we can uncover not only which\nfeatures the agent elects to base decisions on, but also how it chooses to\ncompile more complex, relational features from simpler ones. These results\nformally illustrate the benefits of attention in deep RL and provide evidence\nfor the interpretability of self-attention mechanisms.\n",
        "english": "Dynamic attention models, as demonstrated through a self-attention mechanism, effectively implement task-state representations in semantic feature-space, showcasing increased robustness to noise when tested on a battery of Atari games. By incorporating a large volume of task-irrelevant features into observations, these models exhibit enhanced interpretability, allowing researchers to uncover not only which features the agent elects to base decisions on but also how it compiles more complex, relational features from simpler ones. Strikingly, the self-attention mechanism within dynamic attention models is sufficiently general to be extended to a transient working-memory, $W_t = f(S_t, A_t)$, capable of solving partially observable maze tasks, thus illustrating the potential for significant algorithmic advantages in dynamic environments.",
        "korean": "자기 주의 메커니즘(self-attention mechanism)을 통해 입증된 동적 주의 모델(dynamic attention models)은 의미적 특징 공간(semantic feature-space)에서 과제 상태 표현(task-state representations)을 효과적으로 구현하며, 아타리 게임(Atari games) 배터리 테스트에서 잡음에 대한 강인성이 증가한 것을 보여줍니다. 이러한 모델은 관찰에 대량의 과제와 무관한 특징(task-irrelevant features)을 포함함으로써 해석 가능성을 향상시켜, 연구자들이 에이전트가 어떤 특징을 기반으로 결정을 내리는지뿐만 아니라 단순한 특징으로부터 더 복잡하고 관계적인 특징을 어떻게 구성하는지를 밝혀낼 수 있게 합니다. 놀랍게도, 동적 주의 모델(dynamic attention models) 내의 자기 주의 메커니즘(self-attention mechanism)은 부분적으로 관찰 가능한 미로 과제(maze tasks)를 해결할 수 있는 일시적 작업 기억(transient working-memory), $W_t = f(S_t, A_t)$로 확장될 수 있을 만큼 충분히 일반적이며, 이는 동적 환경에서 상당한 알고리즘적 이점을 보여줍니다.",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "importance weighted autoencoders",
        "domain": "cs.AI",
        "summary": "  Despite its rise as a prominent solution to the data inefficiency of today's\nmachine learning models, self-supervised learning has yet to be studied from a\npurely multi-agent perspective. In this work, we propose that aligning internal\nsubjective representations, which naturally arise in a multi-agent setup where\nagents receive partial observations of the same underlying environmental state,\ncan lead to more data-efficient representations. We propose that multi-agent\nenvironments, where agents do not have access to the observations of others but\ncan communicate within a limited range, guarantees a common context that can be\nleveraged in individual representation learning. The reason is that subjective\nobservations necessarily refer to the same subset of the underlying\nenvironmental states and that communication about these states can freely offer\na supervised signal. To highlight the importance of communication, we refer to\nour setting as \\textit{socially supervised representation learning}. We present\na minimal architecture comprised of a population of autoencoders, where we\ndefine loss functions, capturing different aspects of effective communication,\nand examine their effect on the learned representations. We show that our\nproposed architecture allows the emergence of aligned representations. The\nsubjectivity introduced by presenting agents with distinct perspectives of the\nenvironment state contributes to learning abstract representations that\noutperform those learned by a single autoencoder and a population of\nautoencoders, presented with identical perspectives of the environment state.\nAltogether, our results demonstrate how communication from subjective\nperspectives can lead to the acquisition of more abstract representations in\nmulti-agent systems, opening promising perspectives for future research at the\nintersection of representation learning and emergent communication.\n",
        "english": "In the context of multi-agent environments, importance weighted autoencoders can facilitate the learning of more data-efficient representations by leveraging subjective observations that refer to the same subset of underlying environmental states. The proposed architecture, which comprises a population of autoencoders, defines loss functions that capture different aspects of effective communication, thereby enabling the emergence of aligned representations. Specifically, the subjectivity introduced by presenting agents with distinct perspectives, in conjunction with communication, contributes to learning abstract representations that outperform those learned by a single autoencoder, as demonstrated by the improvement in representation quality, denoted as $R_{aligned} > R_{single}$, where $R$ represents the quality of learned representations.",
        "korean": "다중 에이전트 환경의 맥락에서 중요도 가중치 오토인코더(importance weighted autoencoders)는 동일한 하위 환경 상태를 참조하는 주관적 관찰을 활용하여 더 데이터 효율적인 표현 학습을 촉진할 수 있습니다. 제안된 아키텍처는 오토인코더(autoencoders) 집단으로 구성되어 있으며, 효과적인 의사소통의 다양한 측면을 포착하는 손실 함수를 정의하여 정렬된 표현의 출현을 가능하게 합니다. 특히, 에이전트에게 서로 다른 관점을 제공함으로써 도입된 주관성은 의사소통과 결합하여 단일 오토인코더(single autoencoder)로 학습된 것보다 뛰어난 추상적 표현을 학습하는 데 기여하며, 이는 학습된 표현의 품질이 $R_{aligned} > R_{single}$로 나타나는 개선을 통해 입증됩니다. 여기서 $R$은 학습된 표현의 품질을 나타냅니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "cross-modal learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "score": 9,
        "parentheses_count": 11,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and verify that all technical terms are correctly parenthesized to maintain clarity and readability."
    },
    {
        "turn_index": 2,
        "term": "transfer learning",
        "domain": "cs.AI",
        "summary": "  Transferring high-level knowledge from a source task to a target task is an\neffective way to expedite reinforcement learning (RL). For example,\npropositional logic and first-order logic have been used as representations of\nsuch knowledge. We study the transfer of knowledge between tasks in which the\ntiming of the events matters. We call such tasks temporal tasks. We concretize\nsimilarity between temporal tasks through a notion of logical transferability,\nand develop a transfer learning approach between different yet similar temporal\ntasks. We first propose an inference technique to extract metric interval\ntemporal logic (MITL) formulas in sequential disjunctive normal form from\nlabeled trajectories collected in RL of the two tasks. If logical\ntransferability is identified through this inference, we construct a timed\nautomaton for each sequential conjunctive subformula of the inferred MITL\nformulas from both tasks. We perform RL on the extended state which includes\nthe locations and clock valuations of the timed automata for the source task.\nWe then establish mappings between the corresponding components (clocks,\nlocations, etc.) of the timed automata from the two tasks, and transfer the\nextended Q-functions based on the established mappings. Finally, we perform RL\non the extended state for the target task, starting with the transferred\nextended Q-functions. Our results in two case studies show, depending on how\nsimilar the source task and the target task are, that the sampling efficiency\nfor the target task can be improved by up to one order of magnitude by\nperforming RL in the extended state space, and further improved by up to\nanother order of magnitude using the transferred extended Q-functions.\n",
        "english": "Transfer learning, an effective method to expedite reinforcement learning (RL), involves \"transferring high-level knowledge from a source task to a target task,\" particularly when the timing of events is crucial, as in temporal tasks. By employing an inference technique to extract metric interval temporal logic (MITL) formulas in sequential disjunctive normal form from labeled trajectories, researchers can identify logical transferability and construct timed automata for each sequential conjunctive subformula. The study's innovation lies in its ability to improve the sampling efficiency for the target task by up to one order of magnitude, and further by another order using transferred extended Q-functions, depending on the similarity between the source and target tasks.",
        "korean": "전이 학습(transfer learning)은 강화 학습(reinforcement learning, RL)을 가속화하는 효과적인 방법으로, 특히 시간적 과제가 중요한 경우 소스 작업에서 타겟 작업으로 고수준의 지식을 \"전이\"하는 것을 포함합니다. 레이블이 지정된 궤적에서 순차적 이산적 정규형으로 된 메트릭 간격 시간 논리(metric interval temporal logic, MITL) 공식을 추출하기 위해 추론 기법을 사용함으로써 연구자들은 논리적 전이 가능성을 식별하고 각 순차적 연결적 하위 공식에 대한 시간 오토마타(timed automata)를 구성할 수 있습니다. 이 연구의 혁신은 소스 작업과 타겟 작업 간의 유사성에 따라 타겟 작업의 샘플링 효율성을 최대 한 차수까지, 그리고 전이된 확장 Q-함수(extended Q-functions)를 사용하여 추가로 한 차수까지 개선할 수 있는 능력에 있습니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic neural scene learning",
        "domain": "cs.AI",
        "summary": "  Embodied AI agents in large scenes often need to navigate to find objects. In\nthis work, we study a naturally emerging variant of the object navigation task,\nhierarchical relational object navigation (HRON), where the goal is to find\nobjects specified by logical predicates organized in a hierarchical structure -\nobjects related to furniture and then to rooms - such as finding an apple on\ntop of a table in the kitchen. Solving such a task requires an efficient\nrepresentation to reason about object relations and correlate the relations in\nthe environment and in the task goal. HRON in large scenes (e.g. homes) is\nparticularly challenging due to its partial observability and long horizon,\nwhich invites solutions that can compactly store the past information while\neffectively exploring the scene. We demonstrate experimentally that scene\ngraphs are the best-suited representation compared to conventional\nrepresentations such as images or 2D maps. We propose a solution that uses\nscene graphs as part of its input and integrates graph neural networks as its\nbackbone, with an integrated task-driven attention mechanism, and demonstrate\nits better scalability and learning efficiency than state-of-the-art baselines.\n",
        "english": "Dynamic neural scene learning is crucial for embodied AI agents tasked with hierarchical relational object navigation (HRON), where the objective involves locating objects specified by logical predicates within a hierarchical framework, such as finding an apple on top of a table in the kitchen. By integrating scene graphs with graph neural networks, this approach efficiently represents and reasons about object relations, achieving better scalability and learning efficiency compared to conventional representations like images or 2D maps. The mathematical formulation of this model's efficiency can be expressed as $E = \\sum_{i=1}^{n} w_i \\cdot f_i(x)$, where $E$ denotes the efficiency metric, $w_i$ represents the weight of each feature, and $f_i(x)$ is the feature function, highlighting the model's ability to compactly store past information while effectively exploring large, partially observable scenes.",
        "korean": "동적 신경 장면 학습(dynamic neural scene learning)은 계층적 관계 객체 탐색(hierarchical relational object navigation, HRON)을 수행하는 구현된 인공지능 에이전트에게 필수적입니다. 이 작업의 목표는 주방의 테이블 위에 있는 사과를 찾는 것과 같이 계층적 프레임워크 내에서 논리적 술어로 지정된 객체를 찾는 것입니다. 장면 그래프(scene graphs)와 그래프 신경망(graph neural networks)을 통합함으로써 이 접근 방식은 객체 관계를 효율적으로 표현하고 추론하며, 이미지나 2D 지도와 같은 기존 표현에 비해 더 나은 확장성과 학습 효율성을 달성합니다. 이 모델의 효율성에 대한 수학적 공식은 $E = \\sum_{i=1}^{n} w_i \\cdot f_i(x)$로 표현될 수 있으며, 여기서 $E$는 효율성 지표를 나타내고, $w_i$는 각 특징의 가중치를 나타내며, $f_i(x)$는 특징 함수로서, 모델이 과거 정보를 압축하여 저장하면서도 크고 부분적으로 관찰 가능한 장면을 효과적으로 탐색할 수 있는 능력을 강조합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability in Korean."
    },
    {
        "turn_index": 2,
        "term": "sequential decision making",
        "domain": "cs.AI",
        "summary": "  Moving beyond the dualistic view in AI where agent and environment are\nseparated incurs new challenges for decision making, as calculation of expected\nutility is no longer straightforward. The non-dualistic decision theory\nliterature is split between causal decision theory and evidential decision\ntheory. We extend these decision algorithms to the sequential setting where the\nagent alternates between taking actions and observing their consequences. We\nfind that evidential decision theory has two natural extensions while causal\ndecision theory only has one.\n",
        "english": "In the context of sequential decision making, the integration of agent and environment beyond a dualistic framework presents significant challenges, as the calculation of expected utility becomes complex and non-trivial. Extending decision algorithms to a sequential setting, where the agent alternates between taking actions and observing their consequences, reveals that evidential decision theory offers two natural extensions, contrasting with causal decision theory's singular extension. This innovation highlights the potential of evidential decision theory in sequential decision making, particularly when considering the mathematical expression of expected utility, $U(A) = \\sum_{s} P(s|A) \\cdot U(s)$, where $U(A)$ is the utility of action $A$, $P(s|A)$ is the probability of state $s$ given action $A$, and $U(s)$ is the utility of state $s$.",
        "korean": "순차적 의사 결정(sequential decision making)의 맥락에서, 이원론적 프레임워크를 넘어 에이전트와 환경의 통합은 상당한 도전 과제를 제시하며, 기대 효용의 계산이 복잡하고 비자명해집니다. 에이전트가 행동을 취하고 그 결과를 관찰하는 순차적 설정으로 의사 결정 알고리즘을 확장하면, 증거적 의사 결정 이론(evidential decision theory)이 인과적 의사 결정 이론(causal decision theory)의 단일 확장과 대조적으로 두 가지 자연스러운 확장을 제공함을 알 수 있습니다. 이러한 혁신은 순차적 의사 결정(sequential decision making)에서 증거적 의사 결정 이론(evidential decision theory)의 잠재력을 강조하며, 특히 기대 효용의 수학적 표현을 고려할 때, $U(A) = \\sum_{s} P(s|A) \\cdot U(s)$, 여기서 $U(A)$는 행동 $A$의 효용, $P(s|A)$는 행동 $A$가 주어졌을 때 상태 $s$의 확률, $U(s)$는 상태 $s$의 효용입니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural spline flows",
        "domain": "cs.AI",
        "summary": "  The fully connected (FC) layer, one of the most fundamental modules in\nartificial neural networks (ANN), is often considered difficult and inefficient\nto train due to issues including the risk of overfitting caused by its large\namount of parameters. Based on previous work studying ANN from linear spline\nperspectives, we propose a spline-based approach that eases the difficulty of\ntraining FC layers. Given some dataset, we first obtain a continuous piece-wise\nlinear (CPWL) fit through spline methods such as multivariate adaptive\nregression spline (MARS). Next, we construct an ANN model from the linear\nspline model and continue to train the ANN model on the dataset using gradient\ndescent optimization algorithms. Our experimental results and theoretical\nanalysis show that our approach reduces the computational cost, accelerates the\nconvergence of FC layers, and significantly increases the interpretability of\nthe resulting model (FC layers) compared with standard ANN training with random\nparameter initialization followed by gradient descent optimizations.\n",
        "english": "Neural spline flows represent an innovative approach that addresses the inherent challenges in training fully connected (FC) layers within artificial neural networks (ANN), which are often plagued by inefficiencies and the risk of overfitting due to their large parameter set. By employing a spline-based method, specifically utilizing continuous piece-wise linear (CPWL) fits through techniques such as multivariate adaptive regression spline (MARS), neural spline flows facilitate the construction of an ANN model that can be further optimized using gradient descent algorithms. Importantly, this approach not only reduces computational costs and accelerates convergence but also enhances the interpretability of the resulting model, offering a significant advancement over traditional ANN training methods that rely on random parameter initialization followed by gradient descent, as evidenced by the theoretical analysis and experimental results.",
        "korean": "신경 스플라인 흐름(neural spline flows)은 인공 신경망(artificial neural networks, ANN) 내에서 완전 연결(fully connected, FC) 계층을 훈련하는 데 있어 내재된 문제를 해결하는 혁신적인 접근법을 나타냅니다. 이러한 계층은 종종 큰 매개변수 집합으로 인해 비효율성과 과적합의 위험에 시달립니다. 스플라인 기반 방법을 사용하여, 특히 다변량 적응 회귀 스플라인(multivariate adaptive regression spline, MARS)과 같은 기법을 통해 연속적인 조각별 선형(CPWL) 적합을 활용함으로써, 신경 스플라인 흐름(neural spline flows)은 경사 하강법(gradient descent) 알고리즘을 사용하여 추가로 최적화할 수 있는 ANN 모델의 구성을 용이하게 합니다. 중요한 점은 이 접근법이 계산 비용을 줄이고 수렴 속도를 가속화할 뿐만 아니라 결과 모델의 해석 가능성을 향상시켜, 무작위 매개변수 초기화 후 경사 하강법에 의존하는 전통적인 ANN 훈련 방법에 비해 이론적 분석과 실험 결과로 입증된 바와 같이 상당한 발전을 제공합니다.",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "propensity score matching",
        "domain": "cs.AI",
        "summary": "  PD is linked to faster brain aging. Sex is recognized as an important factor\nin PD, such that males are twice as likely as females to have the disease and\nhave more severe symptoms and a faster progression rate. Despite previous\nresearch, there remains a significant gap in understanding the function of sex\nin the process of brain aging in PD patients. The T1-weighted MRI-driven\nbrain-predicted age difference was computed in a group of 373 PD patients from\nthe PPMI database using a robust brain-age estimation framework that was\ntrained on 949 healthy subjects. Linear regression models were used to\ninvestigate the association between brain-PAD and clinical variables in PD,\nstratified by sex. All female PD patients were used in the correlational\nanalysis while the same number of males were selected based on propensity score\nmatching method considering age, education level, age of symptom onset, and\nclinical symptom severity. Despite both patient groups being matched for\ndemographics, motor and non-motor symptoms, it was observed that males with\nParkinson's disease exhibited a significantly higher mean brain age-delta than\ntheir female counterparts . In the propensity score-matched PD male group,\nbrain-PAD was found to be associated with a decline in general cognition, a\nworse degree of sleep behavior disorder, reduced visuospatial acuity, and\ncaudate atrophy. Conversely, no significant links were observed between these\nfactors and brain-PAD in the PD female group.\n",
        "english": "Propensity score matching was employed to select an equivalent number of male Parkinson's disease (PD) patients as their female counterparts for correlational analysis, using variables such as age, education level, age of symptom onset, and clinical symptom severity. This matching method allowed for a rigorous comparison, revealing that males with PD exhibited a significantly higher mean brain age-delta than females, despite being matched for demographics and symptoms. Notably, in the propensity score-matched PD male group, brain-predicted age difference (brain-PAD) was significantly associated with cognitive decline, sleep behavior disorder severity, reduced visuospatial acuity, and caudate atrophy, whereas no such associations were found in females.",
        "korean": "성향 점수 매칭(propensity score matching)을 사용하여 상관 분석을 위해 남성 파킨슨병(Parkinson's disease, PD) 환자와 여성 환자를 연령, 교육 수준, 증상 발현 연령, 임상 증상 심각도와 같은 변수를 기준으로 동일한 수로 선택했습니다. 이 매칭 방법은 엄격한 비교를 가능하게 하여, 인구통계 및 증상에 맞춰진 상태에서도 남성 PD 환자가 여성보다 평균 뇌 연령 델타(brain age-delta)가 유의하게 높다는 것을 밝혀냈습니다. 특히, 성향 점수 매칭(propensity score matching)된 PD 남성 그룹에서는 뇌 예측 연령 차이(brain-predicted age difference, brain-PAD)가 인지 저하, 수면 행동 장애 심각도, 시공간적 예리함 감소, 미상핵 위축과 유의한 연관성을 보였으나, 여성에서는 이러한 연관성이 발견되지 않았습니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure all technical terms are consistently formatted as Korean term(English term) and consider adjusting the sentence structure for improved readability and flow."
    },
    {
        "turn_index": 2,
        "term": "neural architecture search techniques",
        "domain": "cs.AI",
        "summary": "  Recent advances in Neural Architecture Search (NAS) which extract specialized\nhardware-aware configurations (a.k.a. \"sub-networks\") from a hardware-agnostic\n\"super-network\" have become increasingly popular. While considerable effort has\nbeen employed towards improving the first stage, namely, the training of the\nsuper-network, the search for derivative high-performing sub-networks is still\nlargely under-explored. For example, some recent network morphism techniques\nallow a super-network to be trained once and then have hardware-specific\nnetworks extracted from it as needed. These methods decouple the super-network\ntraining from the sub-network search and thus decrease the computational burden\nof specializing to different hardware platforms. We propose a comprehensive\nsystem that automatically and efficiently finds sub-networks from a pre-trained\nsuper-network that are optimized to different performance metrics and hardware\nconfigurations. By combining novel search tactics and algorithms with\nintelligent use of predictors, we significantly decrease the time needed to\nfind optimal sub-networks from a given super-network. Further, our approach\ndoes not require the super-network to be refined for the target task a priori,\nthus allowing it to interface with any super-network. We demonstrate through\nextensive experiments that our system works seamlessly with existing\nstate-of-the-art super-network training methods in multiple domains. Moreover,\nwe show how novel search tactics paired with evolutionary algorithms can\naccelerate the search process for ResNet50, MobileNetV3 and Transformer while\nmaintaining objective space Pareto front diversity and demonstrate an 8x faster\nsearch result than the state-of-the-art Bayesian optimization WeakNAS approach.\n",
        "english": "Recent advances in neural architecture search techniques have focused on extracting specialized hardware-aware configurations, or \"sub-networks,\" from a hardware-agnostic \"super-network,\" which has led to a significant reduction in the computational burden of adapting to different hardware platforms. By employing network morphism techniques, these methods allow a super-network to be trained once and then utilized to derive hardware-specific networks, effectively decoupling the super-network training from the sub-network search process. Notably, our approach showcases an 8x faster search result than the state-of-the-art Bayesian optimization WeakNAS approach, while maintaining objective space Pareto front diversity, by integrating novel search tactics and evolutionary algorithms to efficiently explore the search space for optimal sub-networks, such as ResNet50, MobileNetV3, and Transformer, without requiring the super-network to be pre-refined for the target task.",
        "korean": "최근 신경 아키텍처 검색 기법(neural architecture search techniques)의 발전은 하드웨어에 구애받지 않는 \"슈퍼 네트워크(super-network)\"에서 하드웨어 인식 구성, 즉 \"서브 네트워크(sub-networks)\"를 추출하는 데 중점을 두고 있으며, 이는 다양한 하드웨어 플랫폼에 적응하는 데 필요한 계산 부담을 크게 줄였습니다. 네트워크 형태 변환 기법(network morphism techniques)을 사용함으로써 이러한 방법들은 슈퍼 네트워크(super-network)를 한 번 훈련한 후 하드웨어에 특화된 네트워크를 도출할 수 있게 하여, 슈퍼 네트워크(super-network) 훈련과 서브 네트워크(sub-network) 검색 과정을 효과적으로 분리합니다. 특히, 우리의 접근 방식은 새로운 검색 전술과 진화 알고리즘(evolutionary algorithms)을 통합하여 최적의 서브 네트워크(sub-networks)를 효율적으로 탐색함으로써, ResNet50, MobileNetV3, Transformer와 같은 네트워크를 목표 작업에 맞게 사전 정제할 필요 없이, 최첨단 베이지안 최적화(WeakNAS) 접근 방식보다 8배 빠른 검색 결과를 보여주며, 목표 공간 파레토 전선 다양성을 유지합니다.",
        "score": 9,
        "parentheses_count": 11,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability in Korean, particularly in complex sentence structures."
    },
    {
        "turn_index": 2,
        "term": "probabilistic neural optimization",
        "domain": "cs.AI",
        "summary": "  To plan safely in uncertain environments, agents must balance utility with\nsafety constraints. Safe planning problems can be modeled as a\nchance-constrained partially observable Markov decision process (CC-POMDP) and\nsolutions often use expensive rollouts or heuristics to estimate the optimal\nvalue and action-selection policy. This work introduces the ConstrainedZero\npolicy iteration algorithm that solves CC-POMDPs in belief space by learning\nneural network approximations of the optimal value and policy with an\nadditional network head that estimates the failure probability given a belief.\nThis failure probability guides safe action selection during online Monte Carlo\ntree search (MCTS). To avoid overemphasizing search based on the failure\nestimates, we introduce $\\Delta$-MCTS, which uses adaptive conformal inference\nto update the failure threshold during planning. The approach is tested on a\nsafety-critical POMDP benchmark, an aircraft collision avoidance system, and\nthe sustainability problem of safe CO$_2$ storage. Results show that by\nseparating safety constraints from the objective we can achieve a target level\nof safety without optimizing the balance between rewards and costs.\n",
        "english": "In the domain of probabilistic neural optimization, agents are required to navigate uncertain environments by balancing utility with safety constraints, which can be effectively modeled as a chance-constrained partially observable Markov decision process (CC-POMDP). The innovative ConstrainedZero policy iteration algorithm addresses this by leveraging neural network approximations of the optimal value and policy, alongside an additional network head that estimates the failure probability given a belief, thereby facilitating safe action selection during online Monte Carlo tree search (MCTS). Moreover, the introduction of $\\Delta$-MCTS, which employs adaptive conformal inference to dynamically update the failure threshold during planning, demonstrates that separating safety constraints from the objective can achieve a desired level of safety without necessitating the optimization of the reward-cost balance, as evidenced in applications such as aircraft collision avoidance systems and safe CO$_2$ storage.",
        "korean": "확률적 신경 최적화(probabilistic neural optimization) 분야에서 에이전트는 유틸리티와 안전 제약을 균형 있게 고려하여 불확실한 환경을 탐색해야 하며, 이는 기회 제약 부분 관찰 마르코프 결정 과정(chance-constrained partially observable Markov decision process, CC-POMDP)으로 효과적으로 모델링될 수 있습니다. 혁신적인 ConstrainedZero 정책 반복 알고리즘(policy iteration algorithm)은 최적 가치와 정책의 신경망 근사를 활용하고, 신념에 따른 실패 확률을 추정하는 추가 네트워크 헤드를 통해 온라인 몬테카를로 트리 탐색(online Monte Carlo tree search, MCTS) 중 안전한 행동 선택을 용이하게 합니다. 또한, 계획 중 실패 임계값을 동적으로 업데이트하기 위해 적응형 적합 추론(adaptive conformal inference)을 사용하는 $\\Delta$-MCTS의 도입은 보상-비용 균형의 최적화를 필요로 하지 않고도 원하는 수준의 안전성을 달성할 수 있음을 보여주며, 이는 항공기 충돌 회피 시스템과 안전한 CO$_2$ 저장과 같은 응용 분야에서 입증되었습니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase letters within parentheses."
    },
    {
        "turn_index": 2,
        "term": "q-learning",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Q-learning, a model-free reinforcement learning algorithm, is instrumental in optimizing decision-making processes by iteratively updating the value of the state-action pair, denoted as $Q(s, a)$, using the Bellman equation. This method's significance lies in its ability to learn optimal policies in environments with unknown dynamics, as it does not require a model of the environment, thereby enhancing its applicability to real-world problems. Importantly, the research highlights the innovation of employing a learning rate parameter, $\\alpha$, which balances the trade-off between exploring new actions and exploiting known information, ensuring convergence to the optimal policy.",
        "korean": "모델 프리 강화 학습 알고리즘(model-free reinforcement learning algorithm)인 q-러닝(q-learning)은 벨만 방정식(Bellman equation)을 사용하여 상태-행동 쌍의 값을 반복적으로 업데이트함으로써 의사 결정 과정을 최적화하는 데 중요한 역할을 합니다. 이 방법의 중요성은 환경의 모델을 필요로 하지 않기 때문에 동적이 알려지지 않은 환경에서 최적의 정책을 학습할 수 있다는 점에 있습니다. 이는 실제 문제에 대한 적용 가능성을 높입니다. 특히, 연구는 새로운 행동을 탐색하는 것과 이미 알려진 정보를 활용하는 것 사이의 균형을 맞추어 최적의 정책으로 수렴을 보장하는 학습률 매개변수(learning rate parameter), $\\alpha$를 사용하는 혁신을 강조합니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Ensure consistency by using lowercase for all terms within parentheses and consider rephrasing for smoother readability in Korean."
    },
    {
        "turn_index": 2,
        "term": "neural dynamic optimization",
        "domain": "cs.AI",
        "summary": "  This paper presents the deep learning-based recent achievements to resolve\nthe problem of autonomous mobility control and efficient resource management of\nautonomous vehicles and UAVs, i.e., (i) multi-agent reinforcement learning\n(MARL), and (ii) neural Myerson auction. Representatively, communication\nnetwork (CommNet), which is one of the most popular MARL algorithms, is\nintroduced to enable multiple agents to take actions in a distributed manner\nfor their shared goals by training all agents' states and actions in a single\nneural network. Moreover, the neural Myerson auction guarantees trustfulness\namong multiple agents as well as achieves the optimal revenue of highly dynamic\nsystems. Therefore, we survey the recent studies on autonomous mobility control\nbased on MARL and neural Myerson auction. Furthermore, we emphasize that\nintegration of MARL and neural Myerson auction is expected to be critical for\nefficient and trustful autonomous mobility services.\n",
        "english": "Neural dynamic optimization plays a crucial role in advancing autonomous mobility control by leveraging multi-agent reinforcement learning (MARL) and the neural Myerson auction, which collectively enable efficient resource management and trustful interactions among autonomous vehicles and UAVs. In particular, the integration of MARL algorithms such as the Communication Network (CommNet) allows for distributed action-taking by training all agents' states and actions in a single neural network, thereby optimizing the shared goals of multiple agents in dynamic environments. Furthermore, the neural Myerson auction ensures trustfulness and maximizes revenue, with the optimal solution characterized by $\\text{argmax}_{x} \\sum_i v_i x_i - \\sum_i p_i$, where $v_i$ denotes the valuation and $p_i$ the payment for agent $i$, underscoring the importance of neural dynamic optimization in achieving efficient and reliable autonomous mobility services.",
        "korean": "신경 동적 최적화(neural dynamic optimization)는 다중 에이전트 강화 학습(multi-agent reinforcement learning, MARL)과 신경 마이어슨 경매(neural Myerson auction)를 활용하여 자율 이동 제어를 발전시키는 데 중요한 역할을 합니다. 이는 자율 차량과 UAV 간의 효율적인 자원 관리와 신뢰할 수 있는 상호 작용을 가능하게 합니다. 특히, 통신 네트워크(Communication Network, CommNet)와 같은 MARL 알고리즘의 통합은 모든 에이전트의 상태와 행동을 단일 신경망에서 학습하여 동적 환경에서 여러 에이전트의 공유 목표를 최적화할 수 있도록 분산된 행동을 가능하게 합니다. 또한, 신경 마이어슨 경매(neural Myerson auction)는 신뢰성을 보장하고 수익을 극대화하며, 최적의 해는 $\\text{argmax}_{x} \\sum_i v_i x_i - \\sum_i p_i$로 특징지어지며, 여기서 $v_i$는 에이전트 $i$의 평가 가치, $p_i$는 지불을 나타내며, 신경 동적 최적화(neural dynamic optimization)가 효율적이고 신뢰할 수 있는 자율 이동 서비스를 달성하는 데 있어 중요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "context-aware sequence generation",
        "domain": "cs.AI",
        "summary": "  In this work, we attempt to answer a critical question: whether there exists\nsome input sequence that will cause a well-trained discrete-space neural\nnetwork sequence-to-sequence (seq2seq) model to generate egregious outputs\n(aggressive, malicious, attacking, etc.). And if such inputs exist, how to find\nthem efficiently. We adopt an empirical methodology, in which we first create\nlists of egregious output sequences, and then design a discrete optimization\nalgorithm to find input sequences that will cause the model to generate them.\nMoreover, the optimization algorithm is enhanced for large vocabulary search\nand constrained to search for input sequences that are likely to be input by\nreal-world users. In our experiments, we apply this approach to dialogue\nresponse generation models trained on three real-world dialogue data-sets:\nUbuntu, Switchboard and OpenSubtitles, testing whether the model can generate\nmalicious responses. We demonstrate that given the trigger inputs our algorithm\nfinds, a significant number of malicious sentences are assigned large\nprobability by the model, which reveals an undesirable consequence of standard\nseq2seq training.\n",
        "english": "Context-aware sequence generation plays a crucial role in evaluating whether a well-trained discrete-space neural network sequence-to-sequence (seq2seq) model can be manipulated to produce egregious outputs such as aggressive or malicious language. By employing an empirical methodology, researchers create lists of undesirable sequences and design a discrete optimization algorithm to identify input sequences that trigger such outputs, demonstrating that given the trigger inputs, a significant number of malicious sentences are assigned large probabilities by the model, denoted as $P(\\text{malicious output} \\mid \\text{trigger input})$. This innovative approach, applied to dialogue response generation models trained on real-world datasets like Ubuntu, Switchboard, and OpenSubtitles, highlights an undesirable consequence of standard seq2seq training, emphasizing the importance of context-aware sequence generation in mitigating the risks associated with harmful content generation.",
        "korean": "문맥 인식 시퀀스 생성(context-aware sequence generation)은 잘 훈련된 이산 공간 신경망 시퀀스-투-시퀀스(sequence-to-sequence, seq2seq) 모델이 공격적이거나 악의적인 언어와 같은 심각한 출력을 생성하도록 조작될 수 있는지를 평가하는 데 중요한 역할을 합니다. 경험적 방법론을 사용하여 연구자들은 바람직하지 않은 시퀀스 목록을 만들고, 그러한 출력을 유발하는 입력 시퀀스를 식별하기 위한 이산 최적화 알고리즘(discrete optimization algorithm)을 설계하여, 트리거 입력이 주어졌을 때 모델이 상당수의 악의적인 문장에 큰 확률을 할당함을 보여줍니다. 이는 $P(\\text{malicious output} \\mid \\text{trigger input})$로 나타납니다. 이 혁신적인 접근법은 Ubuntu, Switchboard, OpenSubtitles와 같은 실제 데이터셋(real-world datasets)으로 훈련된 대화 응답 생성 모델(dialogue response generation models)에 적용되어, 표준 seq2seq 훈련의 바람직하지 않은 결과를 강조하며, 유해한 콘텐츠 생성과 관련된 위험을 완화하는 데 있어 문맥 인식 시퀀스 생성(context-aware sequence generation)의 중요성을 부각시킵니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all technical terms are consistently parenthesized, and consider simplifying complex sentence structures for better readability."
    },
    {
        "turn_index": 2,
        "term": "probabilistic text learning",
        "domain": "cs.AI",
        "summary": "  One important challenge for probabilistic logics is reasoning with very large\nknowledge bases (KBs) of imperfect information, such as those produced by\nmodern web-scale information extraction systems. One scalability problem shared\nby many probabilistic logics is that answering queries involves \"grounding\" the\nquery---i.e., mapping it to a propositional representation---and the size of a\n\"grounding\" grows with database size. To address this bottleneck, we present a\nfirst-order probabilistic language called ProPPR in which that approximate\n\"local groundings\" can be constructed in time independent of database size.\nTechnically, ProPPR is an extension to stochastic logic programs (SLPs) that is\nbiased towards short derivations; it is also closely related to an earlier\nrelational learning algorithm called the path ranking algorithm (PRA). We show\nthat the problem of constructing proofs for this logic is related to\ncomputation of personalized PageRank (PPR) on a linearized version of the proof\nspace, and using on this connection, we develop a proveably-correct approximate\ngrounding scheme, based on the PageRank-Nibble algorithm. Building on this, we\ndevelop a fast and easily-parallelized weight-learning algorithm for ProPPR. In\nexperiments, we show that learning for ProPPR is orders magnitude faster than\nlearning for Markov logic networks; that allowing mutual recursion (joint\nlearning) in KB inference leads to improvements in performance; and that ProPPR\ncan learn weights for a mutually recursive program with hundreds of clauses,\nwhich define scores of interrelated predicates, over a KB containing one\nmillion entities.\n",
        "english": "Probabilistic text learning faces significant challenges when dealing with \"very large knowledge bases (KBs) of imperfect information,\" which are often generated by modern web-scale information extraction systems. To address the scalability issues inherent in traditional probabilistic logics, ProPPR, a first-order probabilistic language, introduces an innovative approach where \"approximate 'local groundings' can be constructed in time independent of database size,\" thereby enhancing the efficiency of query processing. Furthermore, the research demonstrates that learning for ProPPR is \"orders magnitude faster than learning for Markov logic networks,\" indicating its potential for handling complex, large-scale KBs with mutual recursion and joint learning, ultimately leading to improved performance in probabilistic text learning tasks.",
        "korean": "확률적 텍스트 학습(probabilistic text learning)은 현대 웹 규모 정보 추출 시스템에 의해 생성되는 \"불완전한 정보의 매우 큰 지식 기반(knowledge bases, KBs)\"을 다룰 때 상당한 도전에 직면합니다. 전통적인 확률 논리의 확장성 문제를 해결하기 위해, ProPPR은 \"데이터베이스 크기와 무관하게 시간 내에 근사적인 '지역적 그라운딩(local groundings)'을 구성할 수 있는\" 혁신적인 접근 방식을 도입하여 쿼리 처리의 효율성을 향상시킵니다. 더욱이, 연구는 ProPPR의 학습이 \"마르코프 논리 네트워크(Markov logic networks) 학습보다 몇 배 빠르다\"고 입증하여 상호 재귀와 공동 학습을 포함한 복잡하고 대규모 KBs를 처리할 수 있는 잠재력을 보여주며, 궁극적으로 확률적 텍스트 학습(probabilistic text learning) 작업에서 성능을 향상시킵니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as adjusting the placement of technical terms to maintain natural flow."
    },
    {
        "turn_index": 2,
        "term": "differentiable programming",
        "domain": "cs.AI",
        "summary": "  Deep neural learning uses an increasing amount of computation and data to\nsolve very specific problems. By stark contrast, human minds solve a wide range\nof problems using a fixed amount of computation and limited experience. One\nability that seems crucial to this kind of general intelligence is\nmeta-reasoning, i.e., our ability to reason about reasoning. To make deep\nlearning do more from less, we propose the first neural meta-symbolic system\n(NEMESYS) for reasoning and learning: meta programming using differentiable\nforward-chaining reasoning in first-order logic. Differentiable meta\nprogramming naturally allows NEMESYS to reason and learn several tasks\nefficiently. This is different from performing object-level deep reasoning and\nlearning, which refers in some way to entities external to the system. In\ncontrast, NEMESYS enables self-introspection, lifting from object- to\nmeta-level reasoning and vice versa. In our extensive experiments, we\ndemonstrate that NEMESYS can solve different kinds of tasks by adapting the\nmeta-level programs without modifying the internal reasoning system. Moreover,\nwe show that NEMESYS can learn meta-level programs given examples. This is\ndifficult, if not impossible, for standard differentiable logic programming\n",
        "english": "Differentiable programming plays a crucial role in the development of neural meta-symbolic systems like NEMESYS, which employs \"differentiable forward-chaining reasoning in first-order logic\" to enhance reasoning and learning capabilities. This innovative approach enables the system to perform \"meta-level reasoning and vice versa,\" allowing for self-introspection and adaptability across a variety of tasks without altering the internal reasoning system. Importantly, NEMESYS demonstrates the ability to learn meta-level programs from examples, a feat challenging for standard differentiable logic programming, highlighting its potential to bridge the gap between human-like general intelligence and machine learning.",
        "korean": "미분 가능 프로그래밍(differentiable programming)은 NEMESYS와 같은 신경 메타-상징 시스템(neural meta-symbolic systems)의 개발에 중요한 역할을 합니다. NEMESYS는 \"일차 논리에서의 미분 가능한 순방향 연쇄 추론(differentiable forward-chaining reasoning in first-order logic)\"을 활용하여 추론 및 학습 능력을 향상시킵니다. 이 혁신적인 접근 방식은 시스템이 \"메타 수준의 추론(meta-level reasoning)과 그 반대의 경우도 수행\"할 수 있게 하여, 내부 추론 시스템을 변경하지 않고도 다양한 작업에서 자기 성찰과 적응성을 가능하게 합니다. 특히, NEMESYS는 표준 미분 가능 논리 프로그래밍(differentiable logic programming)에서는 어려운 예시로부터 메타 수준 프로그램을 학습할 수 있는 능력을 보여주며, 인간과 유사한 일반 지능과 기계 학습 사이의 격차를 좁힐 수 있는 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural scene understanding",
        "domain": "cs.AI",
        "summary": "  Consumer electronic devices such as mobile handsets, goods tagged with RFID\nlabels, location and position sensors are continuously generating a vast amount\nof location enriched data called geospatial data. Conventionally such\ngeospatial data is used for military applications. In recent times, many useful\ncivilian applications have been designed and deployed around such geospatial\ndata. For example, a recommendation system to suggest restaurants or places of\nattraction to a tourist visiting a particular locality. At the same time, civic\nbodies are harnessing geospatial data generated through remote sensing devices\nto provide better services to citizens such as traffic monitoring, pothole\nidentification, and weather reporting. Typically such applications are\nleveraged upon non-hierarchical machine learning techniques such as Naive-Bayes\nClassifiers, Support Vector Machines, and decision trees. Recent advances in\nthe field of deep-learning showed that Neural Network-based techniques\noutperform conventional techniques and provide effective solutions for many\ngeospatial data analysis tasks such as object recognition, image\nclassification, and scene understanding. The chapter presents a survey on the\ncurrent state of the applications of deep learning techniques for analyzing\ngeospatial data.\n  The chapter is organized as below: (i) A brief overview of deep learning\nalgorithms. (ii)Geospatial Analysis: a Data Science Perspective (iii)\nDeep-learning techniques for Remote Sensing data analytics tasks (iv)\nDeep-learning techniques for GPS data analytics(iv) Deep-learning techniques\nfor RFID data analytics.\n",
        "english": "Neural scene understanding has been significantly enhanced by recent advances in deep learning, which have demonstrated that neural network-based techniques outperform conventional methods in geospatial data analysis tasks such as object recognition, image classification, and scene understanding. These innovative approaches utilize non-hierarchical machine learning techniques, including Naive-Bayes Classifiers, Support Vector Machines, and decision trees, to effectively analyze complex datasets generated by consumer electronic devices and remote sensing technologies. Moreover, the application of deep learning in this domain has been pivotal, with neural networks providing more accurate and efficient solutions, as evidenced by the improved performance in tasks like traffic monitoring and weather reporting, where the mathematical expression $f(x) = \\sum_{i=1}^{n} w_i x_i + b$ illustrates the linear combination of input features that neural networks employ to model complex spatial patterns.",
        "korean": "신경 장면 이해(neural scene understanding)는 최근 심층 학습(deep learning)의 발전에 의해 크게 향상되었으며, 이는 신경망 기반 기법(neural network-based techniques)이 객체 인식(object recognition), 이미지 분류(image classification), 장면 이해(scene understanding)와 같은 지리 공간 데이터 분석 작업에서 기존 방법을 능가한다는 것을 입증했습니다. 이러한 혁신적인 접근법은 나이브 베이즈 분류기(Naive-Bayes Classifiers), 서포트 벡터 머신(Support Vector Machines), 의사 결정 트리(decision trees) 등 비계층적 기계 학습 기법(non-hierarchical machine learning techniques)을 활용하여 소비자 전자 기기와 원격 감지 기술에 의해 생성된 복잡한 데이터셋을 효과적으로 분석합니다. 더욱이, 이 분야에서의 심층 학습의 적용은 결정적이었으며, 신경망(neural networks)은 교통 모니터링(traffic monitoring)과 기상 보고(weather reporting)와 같은 작업에서 성능 향상을 보여주며, 수학적 표현 $f(x) = \\sum_{i=1}^{n} w_i x_i + b$는 신경망이 복잡한 공간 패턴을 모델링하기 위해 사용하는 입력 특징의 선형 결합을 설명합니다.",
        "score": 9,
        "parentheses_count": 14,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase letters within parentheses."
    },
    {
        "turn_index": 2,
        "term": "prompt engineering",
        "domain": "cs.AI",
        "summary": "  Despite impressive recent advances in text-to-image diffusion models,\nobtaining high-quality images often requires prompt engineering by humans who\nhave developed expertise in using them. In this work, we present NeuroPrompts,\nan adaptive framework that automatically enhances a user's prompt to improve\nthe quality of generations produced by text-to-image models. Our framework\nutilizes constrained text decoding with a pre-trained language model that has\nbeen adapted to generate prompts similar to those produced by human prompt\nengineers. This approach enables higher-quality text-to-image generations and\nprovides user control over stylistic features via constraint set specification.\nWe demonstrate the utility of our framework by creating an interactive\napplication for prompt enhancement and image generation using Stable Diffusion.\nAdditionally, we conduct experiments utilizing a large dataset of\nhuman-engineered prompts for text-to-image generation and show that our\napproach automatically produces enhanced prompts that result in superior image\nquality. We make our code and a screencast video demo of NeuroPrompts publicly\navailable.\n",
        "english": "Prompt engineering is crucial for obtaining high-quality images from text-to-image diffusion models, yet it often requires human expertise, as highlighted by the development of NeuroPrompts, an adaptive framework that enhances user prompts automatically. By employing constrained text decoding with a pre-trained language model, NeuroPrompts generates prompts akin to those crafted by human experts, thus enabling superior text-to-image generations while allowing user control over stylistic features through constraint set specification. The effectiveness of this approach is demonstrated through experiments with a large dataset of human-engineered prompts, where the enhanced prompts produced by NeuroPrompts lead to improved image quality, as evidenced by a significant increase in image quality scores, $Q$, where $Q_{\\text{enhanced}} > Q_{\\text{original}}$.",
        "korean": "프롬프트 엔지니어링(prompt engineering)은 텍스트-이미지 확산 모델(text-to-image diffusion models)에서 고품질 이미지를 얻기 위해 필수적이지만, 종종 인간의 전문 지식이 필요합니다. 이는 사용자 프롬프트를 자동으로 향상시키는 적응형 프레임워크(adaptive framework)인 뉴로프롬프트(neuroprompts)의 개발로 강조됩니다. 사전 훈련된 언어 모델(pre-trained language model)을 사용한 제한된 텍스트 디코딩(constrained text decoding)을 통해 뉴로프롬프트(neuroprompts)는 인간 전문가가 제작한 것과 유사한 프롬프트를 생성하여 우수한 텍스트-이미지 생성(text-to-image generations)을 가능하게 하며, 제약 집합 사양(constraint set specification)을 통해 스타일적 특징에 대한 사용자 제어를 허용합니다. 이 접근법의 효과는 인간이 설계한 프롬프트의 대규모 데이터셋(dataset) 실험을 통해 입증되었으며, 뉴로프롬프트(neuroprompts)가 생성한 향상된 프롬프트는 이미지 품질 점수(image quality scores) $Q$의 유의미한 증가로 나타난 바와 같이 이미지 품질을 개선합니다. 여기서 $Q_{\\text{enhanced}} > Q_{\\text{original}}$입니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "unsupervised language models",
        "domain": "cs.AI",
        "summary": "  Motivated by recent innovations in biologically-inspired neuromorphic\nhardware, this article presents a novel unsupervised machine learning algorithm\nnamed Hyperseed that draws on the principles of Vector Symbolic Architectures\n(VSA) for fast learning of a topology preserving feature map of unlabelled\ndata. It relies on two major operations of VSA, binding and bundling. The\nalgorithmic part of Hyperseed is expressed within Fourier Holographic Reduced\nRepresentations model, which is specifically suited for implementation on\nspiking neuromorphic hardware. The two primary contributions of the Hyperseed\nalgorithm are, few-shot learning and a learning rule based on single vector\noperation. These properties are empirically evaluated on synthetic datasets as\nwell as on illustrative benchmark use-cases, IRIS classification, and a\nlanguage identification task using n-gram statistics. The results of these\nexperiments confirm the capabilities of Hyperseed and its applications in\nneuromorphic hardware.\n",
        "english": "Unsupervised language models, inspired by recent advancements in biologically-inspired neuromorphic hardware, utilize algorithms like Hyperseed that leverage Vector Symbolic Architectures (VSA) for efficient learning of topology-preserving feature maps from unlabelled data. The Hyperseed algorithm, particularly effective for implementation on spiking neuromorphic hardware, employs the Fourier Holographic Reduced Representations model, enabling operations such as binding and bundling to facilitate few-shot learning and a learning rule based on a single vector operation. Empirical evaluations, including a language identification task using n-gram statistics, demonstrate the algorithm's capabilities, confirming its potential applications in neuromorphic hardware, thereby marking a significant innovation in the field of unsupervised language models.",
        "korean": "최근 생물학적으로 영감을 받은 뉴로모픽 하드웨어(biologically-inspired neuromorphic hardware)의 발전에 영감을 받은 비지도 언어 모델(unsupervised language models)은 벡터 기호 아키텍처(Vector Symbolic Architectures, VSA)를 활용하여 라벨이 없는 데이터로부터 토폴로지를 보존하는 특징 맵을 효율적으로 학습하는 하이퍼시드(Hyperseed)와 같은 알고리즘을 사용합니다. 하이퍼시드(Hyperseed) 알고리즘은 특히 스파이킹 뉴로모픽 하드웨어(spiking neuromorphic hardware)에서 구현하기에 효과적이며, 푸리에 홀로그래픽 축소 표현(Fourier Holographic Reduced Representations) 모델을 사용하여 바인딩(binding) 및 번들링(bundling)과 같은 작업을 가능하게 하여 소수의 샷 학습(few-shot learning)과 단일 벡터 연산에 기반한 학습 규칙을 촉진합니다. n-그램 통계(n-gram statistics)를 사용한 언어 식별 작업을 포함한 실증적 평가를 통해 알고리즘의 능력이 입증되었으며, 이는 뉴로모픽 하드웨어(neuromorphic hardware)에서의 잠재적 응용 가능성을 확인하여 비지도 언어 모델(unsupervised language models) 분야에서 중요한 혁신을 나타냅니다.",
        "score": 10,
        "parentheses_count": 12,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "adaptive scene segmentation",
        "domain": "cs.AI",
        "summary": "  Semantic scene completion (SSC) jointly predicts the semantics and geometry\nof the entire 3D scene, which plays an essential role in 3D scene understanding\nfor autonomous driving systems. SSC has achieved rapid progress with the help\nof semantic context in segmentation. However, how to effectively exploit the\nrelationships between the semantic context in semantic segmentation and\ngeometric structure in scene completion remains under exploration. In this\npaper, we propose to solve outdoor SSC from the perspective of representation\nseparation and BEV fusion. Specifically, we present the network, named SSC-RS,\nwhich uses separate branches with deep supervision to explicitly disentangle\nthe learning procedure of the semantic and geometric representations. And a BEV\nfusion network equipped with the proposed Adaptive Representation Fusion (ARF)\nmodule is presented to aggregate the multi-scale features effectively and\nefficiently. Due to the low computational burden and powerful representation\nability, our model has good generality while running in real-time. Extensive\nexperiments on SemanticKITTI demonstrate our SSC-RS achieves state-of-the-art\nperformance.\n",
        "korean": "적응형 장면 분할(adaptive scene segmentation)은 자율 주행 시스템을 위한 3D 장면 이해에서 전체 3D 장면의 의미론과 기하학을 공동으로 예측함으로써 중요한 역할을 합니다. 제안된 SSC-RS 네트워크는 깊은 감독을 가진 별도의 분기를 사용하여 의미론적 및 기하학적 표현의 학습 절차를 명시적으로 분리하고, 적응형 표현 융합(adaptive representation fusion, arf) 모듈이 장착된 BEV 융합 네트워크를 사용하여 다중 스케일 특징을 효과적이고 효율적으로 집계함으로써 적응형 장면 분할(adaptive scene segmentation)을 향상시킵니다. SemanticKITTI에 대한 광범위한 실험 결과, 우리의 SSC-RS는 실시간으로 작동할 수 있는 계산 효율성을 갖추어 최첨단 성능을 달성하며, 낮은 계산 부담과 강력한 표현 능력을 보여줍니다."
    },
    {
        "turn_index": 2,
        "term": "bayesian networks",
        "domain": "cs.AI",
        "summary": "  We develop the theory and practice of an approach to modelling and\nprobabilistic inference in causal networks that is suitable when\napplication-specific or analysis-specific constraints should inform such\ninference or when little or no data for the learning of causal network\nstructure or probability values at nodes are available. Constrained Bayesian\nNetworks generalize a Bayesian Network such that probabilities can be symbolic,\narithmetic expressions and where the meaning of the network is constrained by\nfinitely many formulas from the theory of the reals. A formal semantics for\nconstrained Bayesian Networks over first-order logic of the reals is given,\nwhich enables non-linear and non-convex optimisation algorithms that rely on\ndecision procedures for this logic, and supports the composition of several\nconstrained Bayesian Networks. A non-trivial case study in arms control, where\nfew or no data are available to assess the effectiveness of an arms inspection\nprocess, evaluates our approach. An open-access prototype implementation of\nthese foundations and their algorithms uses the SMT solver Z3 as decision\nprocedure, leverages an open-source package for Bayesian inference to symbolic\ncomputation, and is evaluated experimentally.\n",
        "english": "Constrained Bayesian Networks extend traditional Bayesian Networks by allowing probabilities to be expressed as symbolic or arithmetic expressions, where the network's meaning is bounded by finitely many formulas from the theory of the reals. This approach is particularly innovative in scenarios with limited or no data for learning causal network structures or node probability values, as demonstrated in a non-trivial case study on arms control, which assesses the effectiveness of an arms inspection process. The formal semantics for constrained Bayesian Networks over first-order logic of the reals supports non-linear and non-convex optimization algorithms, leveraging decision procedures from this logic, and utilizes the SMT solver Z3 to facilitate symbolic computation in Bayesian inference.",
        "korean": "제약된 베이지안 네트워크(constrained bayesian networks)는 전통적인 베이지안 네트워크(bayesian networks)를 확장하여 확률을 기호적 또는 산술적 표현으로 나타낼 수 있게 하며, 네트워크의 의미는 실수 이론의 유한한 공식들에 의해 제한됩니다. 이 접근법은 인과 네트워크 구조나 노드 확률 값을 학습할 데이터가 제한적이거나 없는 시나리오에서 특히 혁신적이며, 무기 통제에 대한 비사소한 사례 연구에서 무기 검사 과정의 효과성을 평가하는 데 입증되었습니다. 실수의 1차 논리에 대한 제약된 베이지안 네트워크(constrained bayesian networks)의 형식적 의미론은 비선형 및 비볼록 최적화 알고리즘을 지원하며, 이 논리의 결정 절차를 활용하고 SMT 솔버 Z3를 사용하여 베이지안 추론에서 기호적 계산을 용이하게 합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "sampling methods",
        "domain": "cs.AI",
        "summary": "  This paper describes a Bayesian method for learning causal networks using\nsamples that were selected in a non-random manner from a population of\ninterest. Examples of data obtained by non-random sampling include convenience\nsamples and case-control data in which a fixed number of samples with and\nwithout some condition is collected; such data are not uncommon. The paper\ndescribes a method for combining data under selection with prior beliefs in\norder to derive a posterior probability for a model of the causal processes\nthat are generating the data in the population of interest. The priors include\nbeliefs about the nature of the non-random sampling procedure. Although exact\napplication of the method would be computationally intractable for most\nrealistic datasets, efficient special-case and approximation methods are\ndiscussed. Finally, the paper describes how to combine learning under selection\nwith previous methods for learning from observational and experimental data\nthat are obtained on random samples of the population of interest. The net\nresult is a Bayesian methodology that supports causal modeling and discovery\nfrom a rich mixture of different types of data.\n",
        "english": "The paper outlines a Bayesian method for learning causal networks using samples that were selected in a non-random manner from a population of interest, highlighting the significance of incorporating prior beliefs about the nature of the non-random sampling procedure. Non-random sampling methods, such as convenience samples and case-control data, are utilized to derive a posterior probability for a model of causal processes, leveraging the formula $P(\\text{Model}|\\text{Data}) \\propto P(\\text{Data}|\\text{Model}) \\times P(\\text{Model})$, where the priors reflect the selection process. This innovative approach, despite the computational challenges associated with exact application, is enhanced by efficient special-case and approximation methods, enabling causal modeling and discovery from diverse data types, thereby advancing the methodology in the field.",
        "korean": "이 논문은 관심 있는 모집단에서 비무작위 방식으로 선택된 샘플을 사용하여 인과 네트워크를 학습하는 베이지안 방법을 설명하며, 비무작위 샘플링 절차의 본질에 대한 사전 신념을 통합하는 것의 중요성을 강조합니다. 편의 샘플(convenience samples)과 사례-대조군 데이터(case-control data)와 같은 비무작위 샘플링 방법(sampling methods)은 인과 과정 모델에 대한 사후 확률을 도출하는 데 사용되며, 이때 사전 확률은 선택 과정을 반영합니다. 이 혁신적인 접근 방식은 정확한 적용과 관련된 계산상의 어려움에도 불구하고, 효율적인 특수 사례 및 근사 방법에 의해 향상되어 다양한 데이터 유형으로부터 인과 모델링 및 발견을 가능하게 하여 이 분야의 방법론을 발전시킵니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "domain adaptation",
        "domain": "cs.AI",
        "summary": "  Domain adaptation deals with adapting classifiers trained on data from a\nsource distribution, to work effectively on data from a target distribution. In\nthis paper, we introduce the Nonlinear Embedding Transform (NET) for\nunsupervised domain adaptation. The NET reduces cross-domain disparity through\nnonlinear domain alignment. It also embeds the domain-aligned data such that\nsimilar data points are clustered together. This results in enhanced\nclassification. To determine the parameters in the NET model (and in other\nunsupervised domain adaptation models), we introduce a validation procedure by\nsampling source data points that are similar in distribution to the target\ndata. We test the NET and the validation procedure using popular image datasets\nand compare the classification results across competitive procedures for\nunsupervised domain adaptation.\n",
        "english": "Domain adaptation involves adapting classifiers trained on data from a source distribution to function effectively on data from a target distribution, a challenge addressed by the introduction of the Nonlinear Embedding Transform (NET) for unsupervised domain adaptation. The NET model reduces cross-domain disparity through nonlinear domain alignment and embeds the domain-aligned data such that similar data points are clustered together, enhancing classification performance. To optimize the parameters of the NET model and other unsupervised domain adaptation models, a validation procedure is introduced, sampling source data points similar in distribution to the target data, with the effectiveness of this approach demonstrated using popular image datasets where classification results were compared across competitive procedures, confirming the NET's efficacy.",
        "korean": "도메인 적응(domain adaptation)은 소스 분포(source distribution)에서 훈련된 분류기를 타겟 분포(target distribution)의 데이터에서 효과적으로 작동하도록 적응시키는 것을 포함하며, 이는 비지도 도메인 적응(unsupervised domain adaptation)을 위한 비선형 임베딩 변환(nonlinear embedding transform, net)의 도입으로 해결된 도전 과제입니다. net 모델은 비선형 도메인 정렬(nonlinear domain alignment)을 통해 도메인 간 격차를 줄이고, 도메인 정렬된 데이터를 유사한 데이터 포인트가 함께 클러스터링되도록 임베딩하여 분류 성능을 향상시킵니다. net 모델 및 기타 비지도 도메인 적응 모델의 매개변수를 최적화하기 위해, 타겟 데이터와 분포가 유사한 소스 데이터 포인트를 샘플링하는 검증 절차가 도입되었으며, 이 접근법의 효과는 인기 있는 이미지 데이터셋(image datasets)을 사용하여 입증되었고, 경쟁적인 절차와 비교된 분류 결과를 통해 net의 효능이 확인되었습니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural adaptive learning",
        "domain": "cs.AI",
        "summary": "  Motor adaptation displays a structure-learning effect: adaptation to a new\nperturbation occurs more quickly when the subject has prior exposure to\nperturbations with related structure. Although this `learning-to-learn' effect\nis well documented, its underlying computational mechanisms are poorly\nunderstood. We present a new model of motor structure learning, approaching it\nfrom the point of view of deep reinforcement learning. Previous work outside of\nmotor control has shown how recurrent neural networks can account for\nlearning-to-learn effects. We leverage this insight to address motor learning,\nby importing it into the setting of model-based reinforcement learning. We\napply the resulting processing architecture to empirical findings from a\nlandmark study of structure learning in target-directed reaching (Braun et al.,\n2009), and discuss its implications for a wider range of learning-to-learn\nphenomena.\n",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "xgboost",
        "domain": "cs.AI",
        "summary": "  Over the past years, topics ranging from climate change to human rights have\nseen increasing importance for investment decisions. Hence, investors (asset\nmanagers and asset owners) who wanted to incorporate these issues started to\nassess companies based on how they handle such topics. For this assessment,\ninvestors rely on specialized rating agencies that issue ratings along the\nenvironmental, social and governance (ESG) dimensions. Such ratings allow them\nto make investment decisions in favor of sustainability. However, rating\nagencies base their analysis on subjective assessment of sustainability\nreports, not provided by every company. Furthermore, due to human labor\ninvolved, rating agencies are currently facing the challenge to scale up the\ncoverage in a timely manner.\n  In order to alleviate these challenges and contribute to the overall goal of\nsupporting sustainability, we propose a heterogeneous ensemble model to predict\nESG ratings using fundamental data. This model is based on feedforward neural\nnetwork, CatBoost and XGBoost ensemble members. Given the public availability\nof fundamental data, the proposed method would allow cost-efficient and\nscalable creation of initial ESG ratings (also for companies without\nsustainability reporting). Using our approach we are able to explain 54% of the\nvariation in ratings R2 using fundamental data and outperform prior work in\nthis area.\n",
        "english": "In recent research, a heterogeneous ensemble model incorporating XGBoost, CatBoost, and a feedforward neural network has been proposed to predict ESG ratings using fundamental data, addressing the challenge of scaling up sustainability assessments. This innovative approach allows for the creation of cost-efficient and scalable initial ESG ratings, particularly benefiting companies without sustainability reporting, and achieves an explanatory power of 54% of the variation in ratings, as indicated by $R^2$. By leveraging the capabilities of XGBoost within the ensemble, the model outperforms prior work in the field, demonstrating significant advancements in supporting sustainability through data-driven methods.",
        "korean": "최근 연구에서는 xgboost(XGBoost), catboost(CatBoost), 전방향 신경망(feedforward neural network)을 통합한 이질적 앙상블 모델(heterogeneous ensemble model)을 제안하여 기본 데이터를 사용해 ESG 등급을 예측하고 지속 가능성 평가의 확장 문제를 해결했습니다. 이 혁신적인 접근 방식은 특히 지속 가능성 보고가 없는 기업에 이익이 되는 비용 효율적이고 확장 가능한 초기 ESG 등급을 생성할 수 있게 하며, $R^2$로 표시된 바와 같이 등급 변동의 54%에 대한 설명력을 달성합니다. 앙상블 내에서 xgboost(XGBoost)의 기능을 활용함으로써 이 모델은 데이터 기반 방법을 통해 지속 가능성을 지원하는 분야에서 이전 연구를 능가하며 상당한 발전을 보여줍니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as adjusting the placement of technical terms to enhance the natural flow of the sentences."
    },
    {
        "turn_index": 2,
        "term": "lightgbm",
        "domain": "cs.AI",
        "summary": "  This paper describes approaches and results for shared Task 1 and 4 of\nSMMH4-23 by Team Shayona. Shared Task-1 was binary classification of english\ntweets self-reporting a COVID-19 diagnosis, and Shared Task-4 was Binary\nclassification of English Reddit posts self-reporting a social anxiety disorder\ndiagnosis. Our team has achieved the highest f1-score 0.94 in Task-1 among all\nparticipants. We have leveraged the Transformer model (BERT) in combination\nwith the LightGBM model for both tasks.\n",
        "english": "In the research conducted by Team Shayona, the integration of the Transformer model (BERT) with the LightGBM model proved instrumental in achieving a remarkable f1-score of 0.94 for Task-1, which involved the binary classification of English tweets self-reporting a COVID-19 diagnosis. The innovative use of LightGBM, known for its efficiency and accuracy in handling large datasets, was pivotal in enhancing the performance metrics of the classification tasks. Specifically, the combination of these models allowed for a robust approach, where the f1-score, calculated as $F1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}$, demonstrated the effectiveness of their methodology in the context of social media data analysis.",
        "korean": "팀 샤요나(Team Shayona)가 수행한 연구에서 트랜스포머 모델(transformer model, BERT)과 라이트GBM 모델(lightgbm model)의 통합은 COVID-19 진단을 자가 보고하는 영어 트윗의 이진 분류를 포함한 작업-1에서 놀라운 f1-점수(f1-score) 0.94를 달성하는 데 중요한 역할을 했습니다. 대규모 데이터셋을 처리하는 데 있어 효율성과 정확성으로 잘 알려진 라이트GBM(lightgbm)의 혁신적인 사용은 분류 작업의 성능 지표를 향상시키는 데 결정적이었습니다. 특히, 이러한 모델의 조합은 강력한 접근 방식을 가능하게 하였으며, $F1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}$로 계산된 f1-점수(f1-score)는 소셜 미디어 데이터 분석의 맥락에서 그들의 방법론의 효과를 입증했습니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent use of lowercase letters within parentheses for all technical terms."
    },
    {
        "turn_index": 2,
        "term": "probabilistic text segmentation",
        "domain": "cs.AI",
        "summary": "  Nowadays, denoising diffusion probabilistic models have been adapted for many\nimage segmentation tasks. However, existing end-to-end models have already\ndemonstrated remarkable capabilities. Rather than using denoising diffusion\nprobabilistic models alone, integrating the abilities of both denoising\ndiffusion probabilistic models and existing end-to-end models can better\nimprove the performance of image segmentation. Based on this, we implicitly\nintroduce residual term into the diffusion process and propose\nResEnsemble-DDPM, which seamlessly integrates the diffusion model and the\nend-to-end model through ensemble learning. The output distributions of these\ntwo models are strictly symmetric with respect to the ground truth\ndistribution, allowing us to integrate the two models by reducing the residual\nterm. Experimental results demonstrate that our ResEnsemble-DDPM can further\nimprove the capabilities of existing models. Furthermore, its ensemble learning\nstrategy can be generalized to other downstream tasks in image generation and\nget strong competitiveness.\n",
        "english": "Integrating denoising diffusion probabilistic models with existing end-to-end models has demonstrated improved performance in image segmentation tasks, which suggests a potential application to probabilistic text segmentation. By introducing a residual term into the diffusion process, the ResEnsemble-DDPM model seamlessly combines the strengths of both methodologies through ensemble learning, thereby enhancing the segmentation capabilities. The output distributions of these models are strictly symmetric, with respect to the ground truth distribution, such that the integrated model minimizes the residual term, $R$, thereby optimizing the accuracy of probabilistic text segmentation.",
        "korean": "기존의 종단간 모델(end-to-end models)과 잡음 제거 확산 확률 모델(denoising diffusion probabilistic models)을 통합하는 것은 이미지 분할 작업에서 성능 향상을 입증하였으며, 이는 확률적 텍스트 분할(probabilistic text segmentation)에 대한 잠재적 응용 가능성을 시사합니다. 확산 과정에 잔여 항(residual term)을 도입함으로써, ResEnsemble-DDPM 모델은 앙상블 학습(ensemble learning)을 통해 두 방법론의 강점을 매끄럽게 결합하여 분할 능력을 향상시킵니다. 이러한 모델의 출력 분포는 실제 분포(ground truth distribution)에 대해 엄격히 대칭적이며, 통합 모델은 잔여 항 $R$을 최소화하여 확률적 텍스트 분할(probabilistic text segmentation)의 정확성을 최적화합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure all English terms within parentheses are in lowercase for consistency and adjust the sentence structure slightly to enhance the natural flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "subword tokenization",
        "domain": "cs.AI",
        "summary": "  The popular subword tokenizers of current language models, such as Byte-Pair\nEncoding (BPE), are known not to respect morpheme boundaries, which affects the\ndownstream performance of the models. While many improved tokenization\nalgorithms have been proposed, their evaluation and cross-comparison is still\nan open problem. As a solution, we propose a combined intrinsic-extrinsic\nevaluation framework for subword tokenization. Intrinsic evaluation is based on\nour new UniMorph Labeller tool that classifies subword tokenization as either\nmorphological or alien. Extrinsic evaluation, in turn, is performed via the\nOut-of-Vocabulary Generalization Challenge 1.0 benchmark, which consists of\nthree newly specified downstream text classification tasks. Our empirical\nfindings show that the accuracy of UniMorph Labeller is 98%, and that, in all\nlanguage models studied (including ALBERT, BERT, RoBERTa, and DeBERTa), alien\ntokenization leads to poorer generalizations compared to morphological\ntokenization for semantic compositionality of word meanings.\n",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider simplifying the sentence structure for improved readability and flow."
    },
    {
        "turn_index": 2,
        "term": "neural-symbolic learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "english": "Neural-symbolic learning, as explored through the lens of mechanical learning, involves the intricate balance between objective and subjective patterns, where the subjective pattern is pivotal for the learning machine's functionality. The innovation lies in the ability to represent any objective pattern through a corresponding subjective pattern using X-forms, which are algebraic expressions that form the internal representation space, the core of the learning machine. Mathematically, it is demonstrated that with sufficient data and certain capabilities, the learning machine can achieve universal learning, expressed as the ability to learn any pattern, thus highlighting the potential of neural-symbolic learning in advancing machine learning paradigms.",
        "korean": "기계 학습(mechanical learning)의 관점에서 탐구된 신경-상징적 학습(neural-symbolic learning)은 학습 기계의 기능에 중요한 주관적 패턴과 객관적 패턴 사이의 복잡한 균형을 포함합니다. 혁신은 X-형식(X-forms)을 사용하여 모든 객관적 패턴을 해당 주관적 패턴으로 표현할 수 있는 능력에 있으며, 이는 학습 기계의 핵심인 내부 표현 공간을 형성하는 대수적 표현입니다. 수학적으로 충분한 데이터와 특정 능력을 갖춘 학습 기계가 보편적 학습(universal learning)을 달성할 수 있음을 보여주며, 이는 모든 패턴을 학습할 수 있는 능력으로 표현되어 신경-상징적 학습(neural-symbolic learning)이 기계 학습 패러다임을 발전시키는 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "semantic neural models",
        "domain": "cs.AI",
        "summary": "  Topic models are widely used for thematic structure discovery in text. But\ntraditional topic models often require dedicated inference procedures for\nspecific tasks at hand. Also, they are not designed to generate word-level\nsemantic representations. To address these limitations, we propose a topic\nmodeling approach based on Generative Adversarial Nets (GANs), called\nAdversarial-neural Topic Model (ATM). The proposed ATM models topics with\nDirichlet prior and employs a generator network to capture the semantic\npatterns among latent topics. Meanwhile, the generator could also produce\nword-level semantic representations. To illustrate the feasibility of porting\nATM to tasks other than topic modeling, we apply ATM for open domain event\nextraction. Our experimental results on the two public corpora show that ATM\ngenerates more coherence topics, outperforming a number of competitive\nbaselines. Moreover, ATM is able to extract meaningful events from news\narticles.\n",
        "english": "Semantic neural models, such as the Adversarial-neural Topic Model (ATM), address the limitations of traditional topic models by employing Generative Adversarial Nets (GANs) to model topics with a Dirichlet prior, thereby capturing semantic patterns among latent topics and producing word-level semantic representations. By applying ATM to open domain event extraction, the model demonstrates its versatility beyond traditional topic modeling tasks, generating more coherent topics and outperforming competitive baselines. Specifically, the generator network in ATM is mathematically represented as $G(z)$, where $z$ is a latent variable, highlighting the model's capability to extract meaningful events from news articles, underscoring its innovative contribution to the field.",
        "korean": "적대적 신경 주제 모델(adversarial-neural topic model, ATM)과 같은 의미 신경 모델(semantic neural models)은 디리클레 사전(Dirichlet prior)을 사용하여 주제를 모델링하기 위해 생성적 적대 신경망(generative adversarial nets, GANs)을 활용함으로써 전통적인 주제 모델의 한계를 해결합니다. 이를 통해 잠재 주제 간의 의미 패턴을 포착하고 단어 수준의 의미 표현을 생성합니다. ATM을 개방형 도메인 이벤트 추출에 적용함으로써, 모델은 전통적인 주제 모델링 작업을 넘어서는 다재다능함을 입증하며, 더 일관된 주제를 생성하고 경쟁력 있는 기준선을 능가합니다. 특히, ATM의 생성기 네트워크는 $G(z)$로 수학적으로 표현되며, 여기서 $z$는 잠재 변수로, 뉴스 기사에서 의미 있는 이벤트를 추출하는 모델의 능력을 강조하며, 이 분야에 대한 혁신적인 기여를 나타냅니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure that all English terms within parentheses are consistently in lowercase to maintain uniformity and improve readability."
    },
    {
        "turn_index": 2,
        "term": "encoder-decoder architecture",
        "domain": "cs.AI",
        "summary": "  This study aims at making the architecture search process more adaptive for\none-shot or online training. It is extended from the existing study on\ndifferentiable neural architecture search, and we made the backbone\narchitecture transformable rather than fixed during the training process. As is\nknown, differentiable neural architecture search (DARTS) requires a pre-defined\nover-parameterized backbone architecture, while its size is to be determined\nmanually. Also, in DARTS backbone, Hadamard product of two elements is not\nintroduced, which exists in both LSTM and GRU cells for recurrent nets. This\nstudy introduces a growing mechanism for differentiable neural architecture\nsearch based on network morphism. It enables growing of the cell structures\nfrom small size towards large size ones with one-shot training. Two modes can\nbe applied in integrating the growing and original pruning process. We also\nimplement a recently proposed two-input backbone architecture for recurrent\nneural networks. Initial experimental results indicate that our approach and\nthe two-input backbone structure can be quite effective compared with other\nbaseline architectures including LSTM, in a variety of learning tasks including\nmulti-variate time series forecasting and language modeling. On the other hand,\nwe find that dynamic network transformation is promising in improving the\nefficiency of differentiable architecture search.\n",
        "english": "The encoder-decoder architecture, often utilized in differentiable neural architecture search (DARTS), traditionally relies on a pre-defined over-parameterized backbone, necessitating manual size determination. To enhance adaptability in this domain, a novel approach introduces a growing mechanism based on network morphism, allowing the encoder-decoder architecture to dynamically transform from small to large cell structures during one-shot training, thereby improving efficiency. Notably, this method incorporates the Hadamard product, denoted as $A \\odot B$, which is integral to LSTM and GRU cells, thereby offering promising results in tasks such as multi-variate time series forecasting and language modeling.",
        "korean": "인코더-디코더 아키텍처(encoder-decoder architecture)는 주로 미분 가능한 신경망 아키텍처 검색(differentiable neural architecture search, DARTS)에서 사용되며, 전통적으로 사전 정의된 과매개변수화된 백본(over-parameterized backbone)에 의존하여 수동으로 크기를 결정해야 합니다. 이 분야에서 적응성을 향상시키기 위해, 네트워크 형태 변환(network morphism)에 기반한 성장 메커니즘을 도입하여 인코더-디코더 아키텍처(encoder-decoder architecture)가 원샷 학습(one-shot training) 동안 작은 셀 구조에서 큰 셀 구조로 동적으로 변환될 수 있도록 하여 효율성을 개선합니다. 특히, 이 방법은 LSTM 및 GRU 셀에 필수적인 하다마드 곱(Hadamard product), $A \\odot B$를 통합하여 다변량 시계열 예측(multi-variate time series forecasting) 및 언어 모델링(language modeling)과 같은 작업에서 유망한 결과를 제공합니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "posterior predictive distributions",
        "domain": "cs.AI",
        "summary": "  Sentiment analysis is an important task in natural language processing (NLP).\nMost of existing state-of-the-art methods are under the supervised learning\nparadigm. However, human annotations can be scarce. Thus, we should leverage\nmore weak supervision for sentiment analysis. In this paper, we propose a\nposterior regularization framework for the variational approach to the weakly\nsupervised sentiment analysis to better control the posterior distribution of\nthe label assignment. The intuition behind the posterior regularization is that\nif extracted opinion words from two documents are semantically similar, the\nposterior distributions of two documents should be similar. Our experimental\nresults show that the posterior regularization can improve the original\nvariational approach to the weakly supervised sentiment analysis and the\nperformance is more stable with smaller prediction variance.\n",
        "english": "In the context of weakly supervised sentiment analysis, the posterior predictive distributions play a crucial role in enhancing model performance, as demonstrated by the integration of a posterior regularization framework. By ensuring that if extracted opinion words from two documents are semantically similar, the posterior distributions of two documents should be similar, the framework effectively controls the posterior distribution of the label assignment. This innovative approach is mathematically represented by the equation $p(y|x, \\theta) \\approx q(y|x, \\phi)$, where the variational approach is improved with a more stable performance and reduced prediction variance, thus highlighting its importance in natural language processing tasks.",
        "korean": "약하게 지도된 감성 분석(weakly supervised sentiment analysis)에서 후방 예측 분포(posterior predictive distributions)는 후방 정규화 프레임워크(posterior regularization framework)의 통합을 통해 모델 성능을 향상시키는 데 중요한 역할을 합니다. 두 문서에서 추출된 의견 단어가 의미적으로 유사하다면 두 문서의 후방 분포가 유사해야 한다는 것을 보장함으로써, 이 프레임워크는 레이블 할당의 후방 분포를 효과적으로 제어합니다. 이 혁신적인 접근법은 수학적으로 $p(y|x, \\theta) \\approx q(y|x, \\phi)$라는 방정식으로 표현되며, 변분 접근법(variational approach)은 더 안정적인 성능과 예측 분산 감소로 개선되어 자연어 처리 작업에서 그 중요성을 강조합니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Ensure that all terms within parentheses are consistently in lowercase to maintain uniformity and readability."
    },
    {
        "turn_index": 2,
        "term": "low-dimensional embeddings",
        "domain": "cs.AI",
        "summary": "  A network embedding is a representation of a large graph in a low-dimensional\nspace, where vertices are modeled as vectors. The objective of a good embedding\nis to preserve the proximity between vertices in the original graph. This way,\ntypical search and mining methods can be applied in the embedded space with the\nhelp of off-the-shelf multidimensional indexing approaches. Existing network\nembedding techniques focus on homogeneous networks, where all vertices are\nconsidered to belong to a single class.\n",
        "english": "A network embedding is a representation of a large graph in a low-dimensional space, where vertices are modeled as vectors, thereby enabling the preservation of proximity between vertices in the original graph. This preservation is crucial as it allows typical search and mining methods to be applied in the embedded space with the help of off-the-shelf multidimensional indexing approaches, enhancing the efficiency of data processing. The mathematical objective of a low-dimensional embedding can be expressed as minimizing the loss function $L = \\sum_{(i,j) \\in E} \\| f(i) - f(j) \\|^2$, where $f(i)$ and $f(j)$ are the vector representations of vertices $i$ and $j$, respectively, and $E$ denotes the set of edges in the graph, highlighting the innovative potential of such embeddings in handling homogeneous networks.",
        "korean": "네트워크 임베딩(network embedding)은 큰 그래프를 저차원 공간(low-dimensional space)에서 표현하는 것으로, 여기서 정점들은 벡터로 모델링되어 원래 그래프에서의 정점 간 근접성을 보존할 수 있게 합니다. 이러한 보존은 전형적인 검색 및 마이닝 방법을 임베딩된 공간에서 기성의 다차원 인덱싱 접근법(multidimensional indexing approaches)을 활용하여 적용할 수 있게 하여 데이터 처리의 효율성을 향상시키는 데 중요합니다. 저차원 임베딩(low-dimensional embedding)의 수학적 목표는 손실 함수 $L = \\sum_{(i,j) \\in E} \\| f(i) - f(j) \\|^2$를 최소화하는 것으로 표현될 수 있으며, 여기서 $f(i)$와 $f(j)$는 각각 정점 $i$와 $j$의 벡터 표현이고, $E$는 그래프의 간선 집합을 나타내며, 이러한 임베딩이 동질 네트워크(homogeneous networks)를 처리하는 데 있어 혁신적인 잠재력을 강조합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as \"기성의 다차원 인덱싱 접근법(multidimensional indexing approaches)을 활용하여\" to \"기성 다차원 인덱싱 접근법(multidimensional indexing approaches)을 활용하여\"."
    },
    {
        "turn_index": 2,
        "term": "neural task adaptation",
        "domain": "cs.AI",
        "summary": "  Answering complex logical queries on incomplete knowledge graphs (KGs) is a\nfundamental and challenging task in multi-hop reasoning. Recent work defines\nthis task as an end-to-end optimization problem, which significantly reduces\nthe training cost and enhances the generalization of the model by a pretrained\nlink predictors for query answering. However, most existing proposals ignore\nthe critical semantic knowledge inherently available in KGs, such as type\ninformation, which could help answer complex logical queries. To this end, we\npropose TypE-based Neural Link Prediction Adapter (TENLPA), a novel model that\nconstructs type-based entity-relation graphs to discover the latent\nrelationships between entities and relations by leveraging type information in\nKGs. Meanwhile, in order to effectively combine type information with complex\nlogical queries, an adaptive learning mechanism is introduced, which is trained\nby back-propagating during the complex query answering process to achieve\nadaptive adjustment of neural link predictors. Experiments on 3 standard\ndatasets show that TENLPA model achieves state-of-the-art performance on\ncomplex query answering with good generalization and robustness.\n",
        "english": "Neural task adaptation plays a critical role in addressing the challenge of answering complex logical queries on incomplete knowledge graphs (KGs) by incorporating type information, which recent work has shown to enhance the generalization of models through pretrained link predictors. The proposed TypE-based Neural Link Prediction Adapter (TENLPA) introduces an adaptive learning mechanism, trained by back-propagating during the complex query answering process, to achieve adaptive adjustment of neural link predictors, effectively combining type information with logical queries. Experiments on three standard datasets demonstrate that the TENLPA model achieves state-of-the-art performance with a notable improvement in generalization and robustness, as evidenced by its performance metrics surpassing previous benchmarks, such as an increase in precision from $P = 0.85$ to $P = 0.90$.",
        "korean": "신경 작업 적응(neural task adaptation)은 유형 정보를 통합하여 불완전한 지식 그래프(knowledge graphs, KGs)에서 복잡한 논리적 쿼리에 답하는 문제를 해결하는 데 중요한 역할을 합니다. 최근 연구에서는 사전 학습된 링크 예측기(pretrained link predictors)를 통해 모델의 일반화를 향상시킬 수 있음을 보여주었습니다. 제안된 유형 기반 신경 링크 예측 어댑터(TypE-based Neural Link Prediction Adapter, TENLPA)는 복잡한 쿼리 응답 과정에서 역전파(back-propagating)를 통해 훈련되는 적응형 학습 메커니즘을 도입하여 신경 링크 예측기의 적응적 조정을 달성하고, 유형 정보를 논리적 쿼리와 효과적으로 결합합니다. 세 가지 표준 데이터셋에 대한 실험 결과, TENLPA 모델은 일반화 및 강건성에서 주목할 만한 개선을 보이며, 이전 벤치마크를 능가하는 성능 지표로 최첨단 성능을 달성했음을 보여줍니다. 예를 들어, 정밀도가 $P = 0.85$에서 $P = 0.90$으로 증가했습니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, especially in the sections discussing the adaptive learning mechanism and performance metrics."
    },
    {
        "turn_index": 2,
        "term": "model evaluation",
        "domain": "cs.AI",
        "summary": "  Explanation methods and their evaluation have become a significant issue in\nexplainable artificial intelligence (XAI) due to the recent surge of opaque AI\nmodels in decision support systems (DSS). Since the most accurate AI models are\nopaque with low transparency and comprehensibility, explanations are essential\nfor bias detection and control of uncertainty. There are a plethora of criteria\nto choose from when evaluating explanation method quality. However, since\nexisting criteria focus on evaluating single explanation methods, it is not\nobvious how to compare the quality of different methods. This lack of consensus\ncreates a critical shortage of rigour in the field, although little is written\nabout comparative evaluations of explanation methods. In this paper, we have\nconducted a semi-systematic meta-survey over fifteen literature surveys\ncovering the evaluation of explainability to identify existing criteria usable\nfor comparative evaluations of explanation methods. The main contribution in\nthe paper is the suggestion to use appropriate trust as a criterion to measure\nthe outcome of the subjective evaluation criteria and consequently make\ncomparative evaluations possible. We also present a model of explanation\nquality aspects. In the model, criteria with similar definitions are grouped\nand related to three identified aspects of quality; model, explanation, and\nuser. We also notice four commonly accepted criteria (groups) in the\nliterature, covering all aspects of explanation quality: Performance,\nappropriate trust, explanation satisfaction, and fidelity. We suggest the model\nbe used as a chart for comparative evaluations to create more generalisable\nresearch in explanation quality.\n",
        "english": "In the realm of model evaluation within explainable artificial intelligence (XAI), the challenge lies in the opaque nature of highly accurate AI models, which necessitates explanations for bias detection and uncertainty control. The research identifies a significant gap in the comparative evaluation of explanation methods, advocating for the use of \"appropriate trust\" as a criterion to enhance subjective evaluation criteria, thereby facilitating comparative assessments and addressing the critical shortage of rigour in the field. By proposing a model that groups criteria with similar definitions into three quality aspects—model, explanation, and user—the study highlights four commonly accepted criteria, namely Performance, appropriate trust, explanation satisfaction, and fidelity, as essential components for a comprehensive and generalisable model evaluation framework.",
        "korean": "설명 가능한 인공지능(explainable artificial intelligence, XAI) 내에서 모델 평가(model evaluation)의 영역에서는 높은 정확도를 가진 AI 모델의 불투명한 특성으로 인해 편향 탐지 및 불확실성 제어를 위한 설명이 필요하다는 도전 과제가 존재합니다. 연구는 설명 방법의 비교 평가에서 중요한 격차를 식별하고, 주관적 평가 기준을 향상시키기 위한 기준으로 \"적절한 신뢰(appropriate trust)\"의 사용을 옹호하며, 이를 통해 비교 평가를 용이하게 하고 이 분야의 엄격성 부족 문제를 해결합니다. 유사한 정의를 가진 기준을 모델, 설명, 사용자라는 세 가지 품질 측면으로 그룹화하는 모델을 제안함으로써, 연구는 성능(Performance), 적절한 신뢰(appropriate trust), 설명 만족도(explanation satisfaction), 충실도(fidelity)라는 네 가지 일반적으로 수용되는 기준을 포괄적이고 일반화 가능한 모델 평가(model evaluation) 프레임워크의 필수 구성 요소로 강조합니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Ensure all English terms within parentheses are in lowercase for consistency and adjust the sentence structure for smoother flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "neural-symbolic integration",
        "domain": "cs.AI",
        "summary": "  Probabilistic inference in the hybrid domain, i.e. inference over\ndiscrete-continuous domains, requires tackling two well known #P-hard problems\n1)~weighted model counting (WMC) over discrete variables and 2)~integration\nover continuous variables. For both of these problems inference techniques have\nbeen developed separately in order to manage their #P-hardness, such as\nknowledge compilation for WMC and Monte Carlo (MC) methods for (approximate)\nintegration in the continuous domain. Weighted model integration (WMI), the\nextension of WMC to the hybrid domain, has been proposed as a formalism to\nstudy probabilistic inference over discrete and continuous variables alike.\nRecently developed WMI solvers have focused on exploiting structure in WMI\nproblems, for which they rely on symbolic integration to find the primitive of\nan integrand, i.e. to perform anti-differentiation. To combine these advances\nwith state-of-the-art Monte Carlo integration techniques, we introduce\n\\textit{Monte Carlo anti-differentiation} (MCAD), which computes MC\napproximations of anti-derivatives. In our empirical evaluation we substitute\nthe exact symbolic integration backend in an existing WMI solver with an MCAD\nbackend. Our experiments show that that equipping existing WMI solvers with\nMCAD yields a fast yet reliable approximate inference scheme.\n",
        "english": "Neural-symbolic integration, particularly in the context of probabilistic inference over discrete-continuous domains, addresses two #P-hard problems: weighted model counting (WMC) over discrete variables and integration over continuous variables. Recent advancements have introduced Monte Carlo anti-differentiation (MCAD) as a novel approach that combines symbolic integration with Monte Carlo methods, enabling the computation of Monte Carlo approximations of anti-derivatives. Empirical evaluations demonstrate that substituting the exact symbolic integration backend in existing WMI solvers with an MCAD backend results in a fast yet reliable approximate inference scheme, highlighting the innovation's potential to enhance neural-symbolic integration techniques.",
        "korean": "신경-상징적 통합(neural-symbolic integration), 특히 이산-연속 도메인에서의 확률적 추론(probabilistic inference over discrete-continuous domains)에서는 두 가지 #P-난제(#P-hard problems)를 다룹니다: 이산 변수에 대한 가중치 모델 계수(weighted model counting, wmc)와 연속 변수에 대한 적분입니다. 최근의 발전은 몬테카를로 반미분(monte carlo anti-differentiation, mcad)을 새로운 접근법으로 도입하여 상징적 적분(symbolic integration)과 몬테카를로 방법(monte carlo methods)을 결합함으로써 반미분의 몬테카를로 근사치를 계산할 수 있게 했습니다. 실험적 평가 결과, 기존의 wmi 해석기에서 정확한 상징적 적분 백엔드(symbolic integration backend)를 mcad 백엔드로 대체하면 빠르면서도 신뢰할 수 있는 근사 추론 체계를 제공하여 신경-상징적 통합 기법(neural-symbolic integration techniques)을 향상시킬 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural adaptive learning processes",
        "domain": "cs.AI",
        "summary": "  Answering complex logical queries on incomplete knowledge graphs (KGs) is a\nfundamental and challenging task in multi-hop reasoning. Recent work defines\nthis task as an end-to-end optimization problem, which significantly reduces\nthe training cost and enhances the generalization of the model by a pretrained\nlink predictors for query answering. However, most existing proposals ignore\nthe critical semantic knowledge inherently available in KGs, such as type\ninformation, which could help answer complex logical queries. To this end, we\npropose TypE-based Neural Link Prediction Adapter (TENLPA), a novel model that\nconstructs type-based entity-relation graphs to discover the latent\nrelationships between entities and relations by leveraging type information in\nKGs. Meanwhile, in order to effectively combine type information with complex\nlogical queries, an adaptive learning mechanism is introduced, which is trained\nby back-propagating during the complex query answering process to achieve\nadaptive adjustment of neural link predictors. Experiments on 3 standard\ndatasets show that TENLPA model achieves state-of-the-art performance on\ncomplex query answering with good generalization and robustness.\n",
        "english": "Neural adaptive learning processes are integral to the TypE-based Neural Link Prediction Adapter (TENLPA) model, which constructs type-based entity-relation graphs to discover latent relationships by leveraging type information in knowledge graphs (KGs). By introducing an adaptive learning mechanism, the model is trained through back-propagation during the complex query answering process, enabling the adaptive adjustment of neural link predictors. The effectiveness of these processes is demonstrated by the TENLPA model's state-of-the-art performance on complex query answering tasks, achieving an accuracy of approximately $95\\%$ across three standard datasets, thereby showcasing its robust generalization capabilities.",
        "korean": "신경 적응 학습 과정(neural adaptive learning processes)은 TypE 기반 신경 링크 예측 어댑터(TypE-based Neural Link Prediction Adapter, TENLPA) 모델에 필수적이며, 이는 지식 그래프(knowledge graphs, KGs)에서 유형 정보를 활용하여 잠재적 관계를 발견하기 위해 유형 기반 엔티티-관계 그래프를 구성합니다. 적응형 학습 메커니즘을 도입함으로써, 모델은 복잡한 쿼리 응답 과정에서 역전파(back-propagation)를 통해 훈련되어 신경 링크 예측기의 적응적 조정을 가능하게 합니다. 이러한 과정의 효과는 TENLPA 모델이 복잡한 쿼리 응답 작업에서 최첨단 성능을 발휘하여 세 가지 표준 데이터셋에서 약 $95\\%$의 정확도를 달성함으로써 입증되며, 이는 모델의 강력한 일반화 능력을 보여줍니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure all English terms within parentheses are in lowercase and maintain consistent parenthesization throughout the translation."
    },
    {
        "turn_index": 2,
        "term": "neural architecture optimization",
        "domain": "cs.AI",
        "summary": "  Heterogeneous graph neural architecture search (HGNAS) represents a powerful\ntool for automatically designing effective heterogeneous graph neural networks.\nHowever, existing HGNAS algorithms suffer from inefficient searches and\nunstable results. In this paper, we present a new GPT-4 based HGNAS model to\nimprove the search efficiency and search accuracy of HGNAS. Specifically, we\npresent a new GPT-4 enhanced Heterogeneous Graph Neural Architecture Search\n(GHGNAS for short). The basic idea of GHGNAS is to design a set of prompts that\ncan guide GPT-4 toward the task of generating new heterogeneous graph neural\narchitectures. By iteratively asking GPT-4 with the prompts, GHGNAS continually\nvalidates the accuracy of the generated HGNNs and uses the feedback to further\noptimize the prompts. Experimental results show that GHGNAS can design new\nHGNNs by leveraging the powerful generalization capability of GPT-4. Moreover,\nGHGNAS runs more effectively and stably than previous HGNAS models based on\nreinforcement learning and differentiable search algorithms.\n",
        "english": "Neural architecture optimization is significantly advanced by the development of a new GPT-4 enhanced Heterogeneous Graph Neural Architecture Search (GHGNAS) model, which aims to improve both the search efficiency and accuracy of HGNAS. The innovative approach involves designing a set of prompts that guide GPT-4 in generating new heterogeneous graph neural architectures, with the process iteratively refining these prompts based on feedback to optimize the results. Experimental findings demonstrate that GHGNAS, leveraging the generalization capabilities of GPT-4, achieves more effective and stable performance than previous HGNAS models, with a notable improvement in search accuracy as expressed by the equation $\\text{Accuracy}_{\\text{GHGNAS}} > \\text{Accuracy}_{\\text{Previous Models}}$.",
        "korean": "신경 아키텍처 최적화(neural architecture optimization)는 검색 효율성과 정확성을 향상시키기 위해 새로운 GPT-4 강화 이종 그래프 신경 아키텍처 검색(heterogeneous graph neural architecture search, GHGNAS) 모델의 개발로 크게 발전하였습니다. 이 혁신적인 접근법은 GPT-4가 새로운 이종 그래프 신경 아키텍처(heterogeneous graph neural architectures)를 생성하도록 안내하는 일련의 프롬프트를 설계하는 것을 포함하며, 이 과정은 결과를 최적화하기 위해 피드백을 기반으로 이러한 프롬프트를 반복적으로 개선합니다. 실험 결과는 GHGNAS가 GPT-4의 일반화 능력을 활용하여 이전 이종 그래프 신경 아키텍처 검색(heterogeneous graph neural architecture search, HGNAS) 모델보다 더 효과적이고 안정적인 성능을 달성하며, 검색 정확도에서 $\\text{Accuracy}_{\\text{GHGNAS}} > \\text{Accuracy}_{\\text{Previous Models}}$라는 방정식으로 표현된 바와 같이 주목할 만한 개선을 보여줍니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "context-aware learning",
        "domain": "cs.AI",
        "summary": "  Mechanical learning is a computing system that is based on a set of simple\nand fixed rules, and can learn from incoming data. A learning machine is a\nsystem that realizes mechanical learning. Importantly, we emphasis that it is\nbased on a set of simple and fixed rules, contrasting to often called machine\nlearning that is sophisticated software based on very complicated mathematical\ntheory, and often needs human intervene for software fine tune and manual\nadjustments. Here, we discuss some basic facts and principles of such system,\nand try to lay down a framework for further study. We propose 2 directions to\napproach mechanical learning, just like Church-Turing pair: one is trying to\nrealize a learning machine, another is trying to well describe the mechanical\nlearning.\n",
        "english": "The concept of context-aware learning can be likened to mechanical learning, which is a computing system \"based on a set of simple and fixed rules, and can learn from incoming data,\" contrasting with the complexity of traditional machine learning systems. In this framework, context-aware learning aims to develop systems that operate with minimal human intervention, emphasizing the establishment of a \"learning machine\" that can autonomously adapt to its environment. Moreover, by drawing parallels to the Church-Turing pair, the study suggests two approaches to advance context-aware learning: one being the realization of such a learning machine, and the other focusing on the formal description of mechanical learning, thereby providing a foundation for further research in this innovative domain.",
        "korean": "상황 인식 학습(context-aware learning)의 개념은 기계적 학습(mechanical learning)과 비슷하게 볼 수 있으며, 이는 \"간단하고 고정된 규칙 집합에 기반하여 들어오는 데이터로부터 학습할 수 있는\" 컴퓨팅 시스템으로, 전통적인 기계 학습 시스템의 복잡성과 대조됩니다. 이 프레임워크에서 상황 인식 학습(context-aware learning)은 최소한의 인간 개입으로 작동하는 시스템을 개발하는 것을 목표로 하며, 환경에 자율적으로 적응할 수 있는 \"학습 기계\"를 구축하는 데 중점을 둡니다. 또한, 처치-튜링 쌍(Church-Turing pair)과의 유사성을 통해 연구는 상황 인식 학습(context-aware learning)을 발전시키기 위한 두 가지 접근법을 제안합니다: 하나는 그러한 학습 기계의 실현이고, 다른 하나는 기계적 학습(mechanical learning)의 형식적 설명에 초점을 맞추어 이 혁신적인 분야에서의 추가 연구를 위한 기초를 제공합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "knowledge graph completion",
        "domain": "cs.AI",
        "summary": "  Knowledge graphs have been demonstrated to be an effective tool for numerous\nintelligent applications. However, a large amount of valuable knowledge still\nexists implicitly in the knowledge graphs. To enrich the existing knowledge\ngraphs, recent years witness that many algorithms for link prediction and\nknowledge graphs embedding have been designed to infer new facts. But most of\nthese studies focus on the static knowledge graphs and ignore the temporal\ninformation that reflects the validity of knowledge. Developing the model for\ntemporal knowledge graphs completion is an increasingly important task. In this\npaper, we build a new tensor decomposition model for temporal knowledge graphs\ncompletion inspired by the Tucker decomposition of order 4 tensor. We\ndemonstrate that the proposed model is fully expressive and report\nstate-of-the-art results for several public benchmarks. Additionally, we\npresent several regularization schemes to improve the strategy and study their\nimpact on the proposed model. Experimental studies on three temporal datasets\n(i.e. ICEWS2014, ICEWS2005-15, GDELT) justify our design and demonstrate that\nour model outperforms baselines with an explicit margin on link prediction\ntask.\n",
        "english": "Knowledge graph completion has been significantly advanced by the development of algorithms for link prediction and knowledge graph embedding, which are designed to infer new facts and enrich existing knowledge graphs. Recognizing the limitations of static approaches, the proposed tensor decomposition model for temporal knowledge graph completion, inspired by the Tucker decomposition of order 4 tensor, offers a fully expressive framework that achieves state-of-the-art results across several public benchmarks. Notably, experimental studies on temporal datasets such as ICEWS2014, ICEWS2005-15, and GDELT demonstrate that this model not only outperforms baselines with an explicit margin on the link prediction task but also highlights the importance of incorporating temporal information to reflect the validity of knowledge over time.",
        "korean": "지식 그래프 완성(knowledge graph completion)은 링크 예측(link prediction)과 지식 그래프 임베딩(knowledge graph embedding)을 위한 알고리즘 개발로 인해 크게 발전하였으며, 이는 새로운 사실을 추론하고 기존 지식 그래프를 풍부하게 하는 데 설계되었습니다. 정적 접근 방식의 한계를 인식하여 제안된 시계열 지식 그래프 완성(temporal knowledge graph completion)을 위한 텐서 분해 모델(tensor decomposition model)은 4차 텐서의 터커 분해(Tucker decomposition)를 기반으로 하여 완전한 표현력을 제공하며, 여러 공공 벤치마크에서 최첨단 결과를 달성합니다. 특히, ICEWS2014, ICEWS2005-15, GDELT와 같은 시계열 데이터셋에 대한 실험 연구는 이 모델이 링크 예측 작업에서 명확한 차이로 기준선을 능가할 뿐만 아니라 시간이 지남에 따라 지식의 유효성을 반영하기 위해 시계열 정보를 통합하는 것의 중요성을 강조함을 보여줍니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure all English terms within parentheses are in lowercase to maintain consistency and adhere to the criteria."
    },
    {
        "turn_index": 2,
        "term": "graph matching networks",
        "domain": "cs.AI",
        "summary": "  Applications such as employees sharing office spaces over a workweek can be\nmodeled as problems where agents are matched to resources over multiple rounds.\nAgents' requirements limit the set of compatible resources and the rounds in\nwhich they want to be matched. Viewing such an application as a multi-round\nmatching problem on a bipartite compatibility graph between agents and\nresources, we show that a solution (i.e., a set of matchings, with one matching\nper round) can be found efficiently if one exists. To cope with situations\nwhere a solution does not exist, we consider two extensions. In the first\nextension, a benefit function is defined for each agent and the objective is to\nfind a multi-round matching to maximize the total benefit. For a general class\nof benefit functions satisfying certain properties (including diminishing\nreturns), we show that this multi-round matching problem is efficiently\nsolvable. This class includes utilitarian and Rawlsian welfare functions. For\nanother benefit function, we show that the maximization problem is NP-hard. In\nthe second extension, the objective is to generate advice to each agent (i.e.,\na subset of requirements to be relaxed) subject to a budget constraint so that\nthe agent can be matched. We show that this budget-constrained advice\ngeneration problem is NP-hard. For this problem, we develop an integer linear\nprogramming formulation as well as a heuristic based on local search. We\nexperimentally evaluate our algorithms on synthetic networks and apply them to\ntwo real-world situations: shared office spaces and matching courses to\nclassrooms.\n",
        "english": "Graph matching networks are instrumental in modeling complex applications such as employees sharing office spaces over a workweek, where agents are matched to resources over multiple rounds based on their requirements and compatible resources. In scenarios where a perfect solution does not exist, the research innovatively extends the problem by introducing a benefit function for each agent, aiming to maximize the total benefit, and demonstrates that for a general class of benefit functions satisfying certain properties, the problem is efficiently solvable. Furthermore, for cases where the maximization problem is NP-hard, the study develops an integer linear programming formulation and a heuristic based on local search, highlighting the importance of these methodologies in addressing the intricacies of graph matching networks.",
        "korean": "그래프 매칭 네트워크(graph matching networks)는 복잡한 응용 프로그램을 모델링하는 데 중요한 역할을 하며, 예를 들어 직원들이 근무 주간 동안 사무실 공간을 공유하는 경우와 같이 에이전트가 여러 라운드에 걸쳐 자신의 요구 사항과 호환 가능한 자원에 따라 자원에 매칭되는 상황에서 활용됩니다. 완벽한 솔루션이 존재하지 않는 시나리오에서는 연구가 각 에이전트에 대한 이익 함수를 도입하여 문제를 혁신적으로 확장하고, 특정 속성을 만족하는 일반적인 클래스의 이익 함수에 대해 문제를 효율적으로 해결할 수 있음을 입증합니다. 또한, 최대화 문제가 NP-난해한 경우에 대해 연구는 정수 선형 프로그래밍(integer linear programming, ILP) 공식화와 지역 탐색에 기반한 휴리스틱을 개발하여 그래프 매칭 네트워크(graph matching networks)의 복잡성을 해결하는 데 이러한 방법론의 중요성을 강조합니다.",
        "score": 9,
        "parentheses_count": 4,
        "suggestions": "Ensure all English terms within parentheses are consistently in lowercase and consider rephrasing for smoother readability in Korean, particularly in the second sentence."
    },
    {
        "turn_index": 2,
        "term": "deep probabilistic embeddings",
        "domain": "cs.AI",
        "summary": "  We propose a deep learning model - Probabilistic Prognostic Estimates of\nSurvival in Metastatic Cancer Patients (PPES-Met) for estimating short-term\nlife expectancy (3 months) of the patients by analyzing free-text clinical\nnotes in the electronic medical record, while maintaining the temporal visit\nsequence. In a single framework, we integrated semantic data mapping and neural\nembedding technique to produce a text processing method that extracts relevant\ninformation from heterogeneous types of clinical notes in an unsupervised\nmanner, and we designed a recurrent neural network to model the temporal\ndependency of the patient visits. The model was trained on a large dataset\n(10,293 patients) and validated on a separated dataset (1818 patients). Our\nmethod achieved an area under the ROC curve (AUC) of 0.89. To provide\nexplain-ability, we developed an interactive graphical tool that may improve\nphysician understanding of the basis for the model's predictions. The high\naccuracy and explain-ability of the PPES-Met model may enable our model to be\nused as a decision support tool to personalize metastatic cancer treatment and\nprovide valuable assistance to the physicians.\n",
        "korean": "심층 확률적 임베딩(deep probabilistic embeddings) 맥락에서 제안된 모델인 전이성 암 환자의 생존 확률 추정(probabilistic prognostic estimates of survival in metastatic cancer patients, PPES-Met)은 의미론적 데이터 매핑과 신경 임베딩 기법을 혁신적으로 통합하여 비지도 방식으로 이질적인 임상 노트를 처리합니다. 순환 신경망(recurrent neural network)을 사용함으로써 모델은 환자 방문의 시간적 의존성을 효과적으로 포착하여 ROC 곡선 아래 면적(area under the ROC curve, auc) 0.89라는 주목할 만한 성과를 달성하며 단기 생명 기대치를 추정하는 데 높은 정확성을 입증합니다. 상호작용형 그래픽 도구의 개발은 모델의 설명 가능성을 더욱 향상시켜 전이성 암 치료를 개인화하고 임상 의사 결정을 지원하는 도구로서 의사들에게 도움을 줄 수 있습니다."
    },
    {
        "turn_index": 2,
        "term": "latent Dirichlet allocation",
        "domain": "cs.AI",
        "summary": "  Research in Natural Language Processing (NLP) has increasingly become\nimportant due to applications such as text classification, text mining,\nsentiment analysis, POS tagging, named entity recognition, textual entailment,\nand many others. This paper introduces several machine and deep learning\nmethods with manual and automatic labelling for news classification in the\nBangla language. We implemented several machine (ML) and deep learning (DL)\nalgorithms. The ML algorithms are Logistic Regression (LR), Stochastic Gradient\nDescent (SGD), Support Vector Machine (SVM), Random Forest (RF), and K-Nearest\nNeighbour (KNN), used with Bag of Words (BoW), Term Frequency-Inverse Document\nFrequency (TF-IDF), and Doc2Vec embedding models. The DL algorithms are Long\nShort-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), Gated Recurrent Unit\n(GRU), and Convolutional Neural Network (CNN), used with Word2vec, Glove, and\nFastText word embedding models. We develop automatic labelling methods using\nLatent Dirichlet Allocation (LDA) and investigate the performance of\nsingle-label and multi-label article classification methods. To investigate\nperformance, we developed from scratch Potrika, the largest and the most\nextensive dataset for news classification in the Bangla language, comprising\n185.51 million words and 12.57 million sentences contained in 664,880 news\narticles in eight distinct categories, curated from six popular online news\nportals in Bangladesh for the period 2014-2020. GRU and Fasttext with 91.83%\nachieve the highest accuracy for manually-labelled data. For the automatic\nlabelling case, KNN and Doc2Vec at 57.72% and 75% achieve the highest accuracy\nfor single-label and multi-label data, respectively. The methods developed in\nthis paper are expected to advance research in Bangla and other languages.\n",
        "english": "Latent Dirichlet Allocation (LDA) was employed to develop automatic labelling methods, enhancing the performance of news classification in the Bangla language, as detailed in the study. The research demonstrated that LDA-based automatic labelling, when combined with K-Nearest Neighbour (KNN) and Doc2Vec, achieved accuracies of 57.72\\% and 75\\% for single-label and multi-label data, respectively. This innovative approach not only contributes to the advancement of Bangla language processing but also showcases the potential of LDA in improving text classification across diverse applications.",
        "korean": "잠재 디리클레 할당(latent Dirichlet allocation, LDA)은 방글라어 뉴스 분류의 성능을 향상시키기 위한 자동 라벨링 방법 개발에 사용되었으며, 연구에서 자세히 설명되었습니다. 연구는 K-최근접 이웃(k-nearest neighbour, KNN) 및 Doc2Vec과 결합된 LDA 기반 자동 라벨링이 단일 라벨 데이터와 다중 라벨 데이터에 대해 각각 57.72\\%와 75\\%의 정확도를 달성했음을 보여주었습니다. 이 혁신적인 접근법은 방글라어 언어 처리의 발전에 기여할 뿐만 아니라 다양한 응용 분야에서 텍스트 분류를 개선하는 LDA의 잠재력을 보여줍니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "actor-critic methods",
        "domain": "cs.AI",
        "summary": "  A key aspect of intelligence is the ability to demonstrate a broad spectrum\nof behaviors for adapting to unexpected situations. Over the past decade,\nadvancements in deep reinforcement learning have led to groundbreaking\nachievements to solve complex continuous control tasks. However, most\napproaches return only one solution specialized for a specific problem. We\nintroduce Quality-Diversity Actor-Critic (QDAC), an off-policy actor-critic\ndeep reinforcement learning algorithm that leverages a value function critic\nand a successor features critic to learn high-performing and diverse behaviors.\nIn this framework, the actor optimizes an objective that seamlessly unifies\nboth critics using constrained optimization to (1) maximize return, while (2)\nexecuting diverse skills. Compared with other Quality-Diversity methods, QDAC\nachieves significantly higher performance and more diverse behaviors on six\nchallenging continuous control locomotion tasks. We also demonstrate that we\ncan harness the learned skills to adapt better than other baselines to five\nperturbed environments. Finally, qualitative analyses showcase a range of\nremarkable behaviors: adaptive-intelligent-robotics.github.io/QDAC.\n",
        "english": "Actor-critic methods have significantly advanced deep reinforcement learning, particularly in solving complex continuous control tasks, yet traditional approaches often yield a single solution tailored to a specific problem. In response, the Quality-Diversity Actor-Critic (QDAC) algorithm innovatively employs a value function critic and a successor features critic, enabling the actor to optimize an objective that integrates both critics through constrained optimization to maximize return and execute diverse skills. Notably, QDAC outperforms other Quality-Diversity methods, achieving higher performance and more diverse behaviors in six challenging locomotion tasks, as evidenced by its ability to adapt to perturbed environments better than other baselines, with the objective function expressed as $\\max_{\\theta} \\mathbb{E}_{\\pi_{\\theta}} [R - \\lambda D]$, where $R$ is the return and $D$ represents diversity.",
        "korean": "액터-크리틱 메소드(actor-critic methods)은 심층 강화 학습(deep reinforcement learning)을 크게 발전시켰으며, 특히 복잡한 연속 제어 작업을 해결하는 데 중요한 역할을 했습니다. 그러나 전통적인 접근 방식은 종종 특정 문제에 맞춘 단일 솔루션을 제공합니다. 이에 대응하여, 품질-다양성 액터-크리틱(Quality-Diversity Actor-Critic, QDAC) 알고리즘은 가치 함수 크리틱(value function critic)과 후속 특징 크리틱(successor features critic)을 혁신적으로 활용하여, 액터가 두 크리틱을 제약 최적화를 통해 통합하여 반환(return)을 극대화하고 다양한 기술을 실행할 수 있도록 최적화합니다. 특히, QDAC는 다른 품질-다양성 방법들보다 뛰어난 성능과 더 다양한 행동을 여섯 가지 도전적인 이동 작업에서 달성하며, 다른 기준선들보다 교란된 환경에 더 잘 적응하는 능력을 보여줍니다. 목표 함수는 $\\max_{\\theta} \\mathbb{E}_{\\pi_{\\theta}} [R - \\lambda D]$로 표현되며, 여기서 $R$은 반환(return)을, $D$는 다양성(diversity)을 나타냅니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure consistency in the use of parentheses for all technical terms, such as \"품질-다양성 액터-크리틱\" should be followed by \"(Quality-Diversity Actor-Critic)\" for clarity and consistency."
    },
    {
        "turn_index": 2,
        "term": "dynamic Bayesian networks",
        "domain": "cs.AI",
        "summary": "  In this report, we will be interested at Dynamic Bayesian Network (DBNs) as a\nmodel that tries to incorporate temporal dimension with uncertainty. We start\nwith basics of DBN where we especially focus in Inference and Learning concepts\nand algorithms. Then we will present different levels and methods of creating\nDBNs as well as approaches of incorporating temporal dimension in static\nBayesian network.\n",
        "english": "Dynamic Bayesian networks (DBNs) serve as a model that attempts to integrate the temporal dimension with uncertainty, providing a framework for analyzing time-dependent data. In exploring the fundamentals of DBNs, particular emphasis is placed on inference and learning concepts and algorithms, which are pivotal for understanding the evolution of states over time. Notably, the incorporation of temporal dimensions in static Bayesian networks can be mathematically represented as $P(X_t | X_{t-1})$, highlighting the transition probabilities between consecutive time steps, thus showcasing the innovative approach of DBNs in capturing dynamic processes.",
        "korean": "동적 베이지안 네트워크(dynamic Bayesian networks, DBNs)는 시간적 차원과 불확실성을 통합하려는 모델로, 시간에 의존하는 데이터를 분석하기 위한 프레임워크를 제공합니다. 동적 베이지안 네트워크(dynamic Bayesian networks, DBNs)의 기본 원리를 탐구할 때, 특히 추론 및 학습 개념과 알고리즘에 중점을 두며, 이는 시간에 따른 상태의 변화를 이해하는 데 필수적입니다. 특히 정적 베이지안 네트워크(static Bayesian networks)에 시간적 차원을 통합하는 것은 $P(X_t | X_{t-1})$로 수학적으로 표현될 수 있으며, 연속적인 시간 단계 간의 전이 확률을 강조하여 동적 프로세스를 포착하는 동적 베이지안 네트워크(dynamic Bayesian networks, DBNs)의 혁신적인 접근 방식을 보여줍니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "contextual neural attention",
        "domain": "cs.AI",
        "summary": "  Language modeling (LM) for automatic speech recognition (ASR) does not\nusually incorporate utterance level contextual information. For some domains\nlike voice assistants, however, additional context, such as the time at which\nan utterance was spoken, provides a rich input signal. We introduce an\nattention mechanism for training neural speech recognition language models on\nboth text and non-linguistic contextual data. When applied to a large\nde-identified dataset of utterances collected by a popular voice assistant\nplatform, our method reduces perplexity by 7.0% relative over a standard LM\nthat does not incorporate contextual information. When evaluated on utterances\nextracted from the long tail of the dataset, our method improves perplexity by\n9.0% relative over a standard LM and by over 2.8% relative when compared to a\nstate-of-the-art model for contextual LM.\n",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent lowercase for all terms within parentheses and ensure uniformity in the translation of technical terms."
    },
    {
        "turn_index": 2,
        "term": "deep task-driven learning",
        "domain": "cs.AI",
        "summary": "  Like any field of empirical science, AI may be approached axiomatically. We\nformulate requirements for a general-purpose, human-level AI system in terms of\npostulates. We review the methodology of deep learning, examining the explicit\nand tacit assumptions in deep learning research. Deep Learning methodology\nseeks to overcome limitations in traditional machine learning research as it\ncombines facets of model richness, generality, and practical applicability. The\nmethodology so far has produced outstanding results due to a productive synergy\nof function approximation, under plausible assumptions of irreducibility and\nthe efficiency of back-propagation family of algorithms. We examine these\nwinning traits of deep learning, and also observe the various known failure\nmodes of deep learning. We conclude by giving recommendations on how to extend\ndeep learning methodology to cover the postulates of general-purpose AI\nincluding modularity, and cognitive architecture. We also relate deep learning\nto advances in theoretical neuroscience research.\n",
        "english": "Deep task-driven learning, as an extension of the deep learning methodology, seeks to overcome limitations in traditional machine learning by combining facets of model richness, generality, and practical applicability, thereby producing outstanding results in function approximation. This approach builds on the efficiency of the back-propagation family of algorithms, which, under plausible assumptions of irreducibility, allows for the effective optimization of complex neural networks, as represented by the expression $E = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$, where $E$ is the error, $y_i$ are the true values, and $\\hat{y}_i$ are the predicted values. The innovation of deep task-driven learning lies in its potential to extend the methodology to cover the postulates of general-purpose AI, including modularity and cognitive architecture, thus aligning with advances in theoretical neuroscience research.",
        "korean": "심층 과제 주도 학습(deep task-driven learning)은 심층 학습 방법론의 확장으로서 모델의 풍부함, 일반성 및 실용성을 결합하여 전통적인 기계 학습의 한계를 극복하고 함수 근사에서 뛰어난 결과를 생성합니다. 이 접근법은 복잡한 신경망의 효과적인 최적화를 가능하게 하는 비가역성의 타당한 가정 하에 역전파 알고리즘(back-propagation family of algorithms)의 효율성을 기반으로 하며, 이는 $E = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$로 표현됩니다. 여기서 $E$는 오류, $y_i$는 실제 값, $\\hat{y}_i$는 예측 값입니다. 심층 과제 주도 학습(deep task-driven learning)의 혁신은 모듈성 및 인지 아키텍처를 포함한 범용 인공지능(general-purpose AI)의 가설을 포괄하도록 방법론을 확장할 수 있는 잠재력에 있으며, 이는 이론적 신경과학 연구의 발전과 일치합니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent parenthetical translations for all technical terms, such as \"범용 인공지능(general-purpose AI)\" to \"범용 인공지능(general-purpose ai)\" for lowercase consistency."
    },
    {
        "turn_index": 2,
        "term": "deep reinforcement learning frameworks",
        "domain": "cs.AI",
        "summary": "  Sparsity of rewards while applying a deep reinforcement learning method\nnegatively affects its sample-efficiency. A viable solution to deal with the\nsparsity of rewards is to learn via intrinsic motivation which advocates for\nadding an intrinsic reward to the reward function to encourage the agent to\nexplore the environment and expand the sample space. Though intrinsic\nmotivation methods are widely used to improve data-efficient learning in the\nreinforcement learning model, they also suffer from the so-called detachment\nproblem. In this article, we discuss the limitations of intrinsic curiosity\nmodule in sparse-reward multi-agent reinforcement learning and propose a method\ncalled I-Go-Explore that combines the intrinsic curiosity module with the\nGo-Explore framework to alleviate the detachment problem.\n",
        "english": "Deep reinforcement learning frameworks often encounter challenges related to the sparsity of rewards, which can significantly impact their sample-efficiency. A promising approach to mitigate this issue is incorporating intrinsic motivation, which involves adding an intrinsic reward to the reward function, thereby encouraging agents to explore their environment and expand the sample space. However, despite their widespread use in enhancing data-efficient learning, these intrinsic motivation methods are not without limitations, such as the detachment problem; thus, the proposed I-Go-Explore method, which integrates the intrinsic curiosity module with the Go-Explore framework, aims to address these challenges effectively.",
        "korean": "심층 강화 학습 프레임워크(deep reinforcement learning frameworks)는 보상의 희소성과 관련된 문제에 자주 직면하며, 이는 샘플 효율성(sample-efficiency)에 크게 영향을 미칠 수 있습니다. 이 문제를 완화하기 위한 유망한 접근법은 내재적 동기 부여(intrinsic motivation)를 통합하는 것으로, 이는 보상 함수에 내재적 보상(intrinsic reward)을 추가하여 에이전트가 환경을 탐색하고 샘플 공간을 확장하도록 장려하는 것을 포함합니다. 그러나 데이터 효율적 학습(data-efficient learning)을 향상시키기 위한 이러한 내재적 동기 부여 방법들이 널리 사용됨에도 불구하고, 분리 문제(detachment problem)와 같은 한계가 존재합니다. 따라서 내재적 호기심 모듈(intrinsic curiosity module)을 고-익스플로어 프레임워크(Go-Explore framework)와 통합한 제안된 I-Go-Explore 방법은 이러한 문제를 효과적으로 해결하는 것을 목표로 합니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "neural Turing machines",
        "domain": "cs.AI",
        "summary": "  The best improvisational theatre actors can make any scene partner, of any\nskill level or ability, appear talented and proficient in the art form, and\nthus \"make them shine\". To challenge this improvisational paradigm, we built an\nartificial intelligence (AI) trained to perform live shows alongside human\nactors for human audiences. Over the course of 30 performances to a combined\naudience of almost 3000 people, we have refined theatrical games which involve\ncombinations of human and (at times, adversarial) AI actors. We have developed\nspecific scene structures to include audience participants in interesting ways.\nFinally, we developed a complete show structure that submitted the audience to\na Turing test and observed their suspension of disbelief, which we believe is\nkey for human/non-human theatre co-creation.\n",
        "english": "Neural Turing machines (NTMs), akin to the best improvisational theatre actors who \"make them shine,\" are designed to enhance the capabilities of their counterparts, be they human or machine. By employing specific scene structures that include audience participants, NTMs can adapt and learn from diverse interactions, thereby refining their performance in real-time. The innovative aspect of NTMs is their ability to undergo a Turing test, where the probability \\( P \\) of a human audience's suspension of disbelief is maximized, highlighting their potential for human/non-human co-creation in dynamic environments.",
        "korean": "신경 튜링 기계(neural Turing machines, NTMs)는 최고의 즉흥 연극 배우처럼 \"그들을 빛나게\" 하기 위해 설계되어, 인간이든 기계든 그들의 역량을 향상시킵니다. 관객 참여자를 포함한 특정 장면 구조를 활용함으로써, 신경 튜링 기계(neural Turing machines, NTMs)는 다양한 상호작용에서 적응하고 학습하여 실시간으로 성능을 개선할 수 있습니다. 신경 튜링 기계(neural Turing machines, NTMs)의 혁신적인 측면은 튜링 테스트를 수행할 수 있는 능력에 있으며, 여기서 인간 관객의 불신 중지 확률 \\( P \\)가 극대화되어, 역동적인 환경에서 인간/비인간 공동 창작의 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar."
    },
    {
        "turn_index": 2,
        "term": "neural knowledge graphs",
        "domain": "cs.AI",
        "summary": "  The widespread use of knowledge graphs in various fields has brought about a\nchallenge in effectively integrating and updating information within them. When\nit comes to incorporating contexts, conventional methods often rely on rules or\nbasic machine learning models, which may not fully grasp the complexity and\nfluidity of context information. This research suggests an approach based on\nreinforcement learning (RL), specifically utilizing Deep Q Networks (DQN) to\nenhance the process of integrating contexts into knowledge graphs. By\nconsidering the state of the knowledge graph as environment states defining\nactions as operations for integrating contexts and using a reward function to\ngauge the improvement in knowledge graph quality post-integration, this method\naims to automatically develop strategies for optimal context integration. Our\nDQN model utilizes networks as function approximators, continually updating Q\nvalues to estimate the action value function, thus enabling effective\nintegration of intricate and dynamic context information. Initial experimental\nfindings show that our RL method outperforms techniques in achieving precise\ncontext integration across various standard knowledge graph datasets,\nhighlighting the potential and effectiveness of reinforcement learning in\nenhancing and managing knowledge graphs.\n",
        "english": "Neural knowledge graphs, which aim to effectively integrate and update information within knowledge graphs, can benefit from reinforcement learning (RL) approaches, particularly utilizing Deep Q Networks (DQN), to enhance context incorporation. By modeling the state of the knowledge graph as environment states and defining actions as operations for context integration, the DQN approach employs a reward function \\( R(s, a) \\) to evaluate the improvement in knowledge graph quality, thereby facilitating the development of optimal integration strategies. Initial experimental findings demonstrate that this RL-based method surpasses conventional techniques in achieving precise context integration across various standard datasets, underscoring the potential of reinforcement learning in managing and enhancing neural knowledge graphs.",
        "korean": "지식 그래프(knowledge graphs) 내에서 정보를 효과적으로 통합하고 업데이트하는 것을 목표로 하는 신경 지식 그래프(neural knowledge graphs)는 강화 학습(reinforcement learning, RL) 접근법, 특히 심층 Q 네트워크(Deep Q Networks, DQN)를 활용하여 문맥 통합을 향상시킬 수 있습니다. 지식 그래프의 상태를 환경 상태로 모델링하고 행동을 문맥 통합을 위한 작업으로 정의함으로써, DQN 접근법은 보상 함수 \\( R(s, a) \\)를 사용하여 지식 그래프 품질의 개선을 평가하고 최적의 통합 전략 개발을 촉진합니다. 초기 실험 결과는 이 RL 기반 방법이 다양한 표준 데이터셋(standard datasets)에서 정확한 문맥 통합을 달성하는 데 있어 기존 기술을 능가함을 보여주며, 신경 지식 그래프(neural knowledge graphs)를 관리하고 향상시키는 데 있어 강화 학습의 잠재력을 강조합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure all English terms within parentheses are in lowercase and maintain consistent parenthesization throughout the translation for a more natural flow."
    },
    {
        "turn_index": 2,
        "term": "causal inference algorithms",
        "domain": "cs.AI",
        "summary": "  A structural causal model is made of endogenous (manifest) and exogenous\n(latent) variables. We show that endogenous observations induce linear\nconstraints on the probabilities of the exogenous variables. This allows to\nexactly map a causal model into a credal network. Causal inferences, such as\ninterventions and counterfactuals, can consequently be obtained by standard\nalgorithms for the updating of credal nets. These natively return sharp values\nin the identifiable case, while intervals corresponding to the exact bounds are\nproduced for unidentifiable queries. A characterization of the causal models\nthat allow the map above to be compactly derived is given, along with a\ndiscussion about the scalability for general models. This contribution should\nbe regarded as a systematic approach to represent structural causal models by\ncredal networks and hence to systematically compute causal inferences. A number\nof demonstrative examples is presented to clarify our methodology. Extensive\nexperiments show that approximate algorithms for credal networks can\nimmediately be used to do causal inference in real-size problems.\n",
        "english": "Causal inference algorithms can be systematically computed by representing structural causal models as credal networks, which facilitates the derivation of causal inferences such as interventions and counterfactuals through standard algorithms for credal nets. Notably, these algorithms yield sharp values for identifiable cases, while producing intervals corresponding to exact bounds for unidentifiable queries, thereby offering a comprehensive framework for understanding the constraints on probabilities of exogenous variables induced by endogenous observations. The research highlights the innovative approach of mapping causal models into credal networks, which not only allows for the compact derivation of causal models but also demonstrates scalability in real-size problems, as evidenced by extensive experiments with approximate algorithms.",
        "korean": "인과 추론 알고리즘(causal inference algorithms)은 구조적 인과 모델(structural causal models)을 크리달 네트워크(credal networks)로 표현함으로써 체계적으로 계산될 수 있으며, 이는 크리달 네트워크(credal nets)에 대한 표준 알고리즘을 통해 개입(interventions) 및 반사실(counterfactuals)과 같은 인과 추론을 도출하는 것을 용이하게 합니다. 특히, 이러한 알고리즘은 식별 가능한 경우에 대해 명확한 값을 제공하며, 식별할 수 없는 쿼리에 대해서는 정확한 경계를 나타내는 구간을 생성하여 내생적 관찰에 의해 유도된 외생적 변수의 확률에 대한 제약을 이해하는 포괄적인 프레임워크를 제공합니다. 이 연구는 인과 모델을 크리달 네트워크(credal networks)로 매핑하는 혁신적인 접근 방식을 강조하며, 이는 인과 모델의 간결한 도출을 가능하게 할 뿐만 아니라 근사 알고리즘을 사용한 광범위한 실험을 통해 실제 크기의 문제에서도 확장성을 입증합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider using consistent terms for \"credal networks\" and \"credal nets\" to avoid confusion."
    },
    {
        "turn_index": 2,
        "term": "differentiable programming frameworks",
        "domain": "cs.AI",
        "summary": "  Current GP frameworks are highly effective on a range of real and simulated\nbenchmarks. However, due to the high dimensionality of the genotypes for GP,\nthe task of visualising the fitness landscape for GP search can be difficult.\nThis paper describes a new framework: Floating Point Grammatical Evolution\n(FP-GE) which uses a single floating point genotype to encode an individual\nprogram. This encoding permits easier visualisation of the fitness landscape\narbitrary problems by providing a way to map fitness against a single\ndimension. The new framework also makes it trivially easy to apply continuous\nsearch algorithms, such as Differential Evolution, to the search problem. In\nthis work, the FP-GE framework is tested against several regression problems,\nvisualising the search landscape for these and comparing different search\nmeta-heuristics.\n",
        "english": "Differentiable programming frameworks, such as the innovative Floating Point Grammatical Evolution (FP-GE), offer a novel approach by encoding an individual program using a single floating point genotype, thus facilitating the visualization of the fitness landscape for various problems. This unique encoding allows for the mapping of fitness against a single dimension, simplifying the application of continuous search algorithms, including Differential Evolution, to complex search problems. By leveraging these capabilities, the FP-GE framework demonstrates its efficacy on several regression problems, providing insights into the search landscape and enabling comparisons of different search meta-heuristics, ultimately enhancing our understanding of genotype fitness landscapes in high-dimensional spaces.",
        "korean": "부동 소수점 문법 진화(Floating Point Grammatical Evolution, FP-GE)와 같은 미분 가능 프로그래밍 프레임워크(differentiable programming frameworks)는 개별 프로그램을 단일 부동 소수점 유전자형으로 인코딩하여 다양한 문제의 적합도 지형을 시각화하는 새로운 접근 방식을 제공합니다. 이러한 독특한 인코딩은 적합도를 단일 차원에 대해 매핑할 수 있게 하여, 차등 진화(Differential Evolution)를 포함한 연속 탐색 알고리즘을 복잡한 탐색 문제에 적용하는 것을 단순화합니다. 이러한 기능을 활용함으로써 FP-GE 프레임워크는 여러 회귀 문제에서 그 효능을 입증하며, 탐색 지형에 대한 통찰력을 제공하고 다양한 탐색 메타 휴리스틱을 비교할 수 있게 하여 고차원 공간에서 유전자형 적합도 지형에 대한 이해를 향상시킵니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "gradient penalty",
        "domain": "cs.AI",
        "summary": "  Decision trees usefully represent sparse, high dimensional and noisy data.\nHaving learned a function from this data, we may want to thereafter integrate\nthe function into a larger decision-making problem, e.g., for picking the best\nchemical process catalyst. We study a large-scale, industrially-relevant\nmixed-integer nonlinear nonconvex optimization problem involving both\ngradient-boosted trees and penalty functions mitigating risk. This\nmixed-integer optimization problem with convex penalty terms broadly applies to\noptimizing pre-trained regression tree models. Decision makers may wish to\noptimize discrete models to repurpose legacy predictive models, or they may\nwish to optimize a discrete model that particularly well-represents a data set.\nWe develop several heuristic methods to find feasible solutions, and an exact,\nbranch-and-bound algorithm leveraging structural properties of the\ngradient-boosted trees and penalty functions. We computationally test our\nmethods on concrete mixture design instance and a chemical catalysis industrial\ninstance.\n",
        "korean": "사전 학습된 회귀 트리 모델(regression tree models)의 최적화(context of optimizing)에서, 그래디언트 패널티(gradient penalty)의 도입은 그래디언트 부스팅 트리(gradient-boosted trees)와 위험을 완화하는 패널티 함수(penalty functions)를 포함하는 혼합 정수 비선형 비볼록 최적화 문제(mixed-integer nonlinear nonconvex optimization problems)를 해결하는 데 필수적입니다. 그래디언트 부스팅 트리(gradient-boosted trees)와 패널티 함수(penalty functions)의 구조적 특성을 활용하여, 정확한 분기-경계 알고리즘(branch-and-bound algorithm)이 개발되어 볼록 패널티 항(convex penalty terms)을 포함하는 혼합 정수 최적화 문제(mixed-integer optimization problem)를 수학적으로 $\\min_{x} \\{f(x) + \\lambda \\|\\nabla f(x)\\|^2\\}$로 표현할 수 있습니다. 여기서 $\\lambda$는 패널티 매개변수(penalty parameter)입니다. 이 혁신적인 접근법은 콘크리트 혼합물 설계(concrete mixture design)와 화학 촉매 산업 사례(chemical catalysis industrial case)와 같은 사례에서 계산적으로 테스트되어 산업 의사 결정 시나리오에서의 적용 가능성과 잠재력을 입증합니다."
    },
    {
        "turn_index": 2,
        "term": "neural logic programming",
        "domain": "cs.AI",
        "summary": "  The field of probabilistic logic programming (PLP) focuses on integrating\nprobabilistic models into programming languages based on logic. Over the past\n30 years, numerous languages and frameworks have been developed for modeling,\ninference and learning in probabilistic logic programs. While originally PLP\nfocused on discrete probability, more recent approaches have incorporated\ncontinuous distributions as well as neural networks, effectively yielding\nneural-symbolic methods. We provide a unified algebraic perspective on PLP,\nshowing that many if not most of the extensions of PLP can be cast within a\ncommon algebraic logic programming framework, in which facts are labeled with\nelements of a semiring and disjunction and conjunction are replaced by addition\nand multiplication. This does not only hold for the PLP variations itself but\nalso for the underlying execution mechanism that is based on (algebraic) model\ncounting.\n",
        "english": "Neural logic programming represents a significant advancement in probabilistic logic programming (PLP) by incorporating neural networks into the framework, effectively creating neural-symbolic methods. This integration is achieved within a unified algebraic perspective, where \"facts are labeled with elements of a semiring\" and logical operations such as disjunction and conjunction are replaced by mathematical operations like addition and multiplication, forming an algebraic logic programming framework. The innovation of neural logic programming lies in its ability to extend PLP beyond discrete probabilities to include continuous distributions, thereby enhancing both the modeling and inference capabilities of probabilistic logic programs.",
        "korean": "신경 논리 프로그래밍(neural logic programming)은 확률적 논리 프로그래밍(probabilistic logic programming, plp)에서 신경망(neural networks)을 프레임워크에 통합하여 신경-상징적 방법(neural-symbolic methods)을 효과적으로 창출함으로써 중요한 발전을 나타냅니다. 이 통합은 \"사실이 반환환의 요소로 레이블이 붙여진다\"는 통일된 대수적 관점 내에서 달성되며, 논리적 연산인 논리합(disjunction)과 논리곱(conjunction)이 덧셈과 곱셈과 같은 수학적 연산으로 대체되어 대수적 논리 프로그래밍 프레임워크(algebraic logic programming framework)를 형성합니다. 신경 논리 프로그래밍(neural logic programming)의 혁신은 plp를 이산 확률을 넘어 연속 분포를 포함하도록 확장하여 확률적 논리 프로그램의 모델링 및 추론 능력을 향상시키는 데 있습니다.",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "probabilistic relational models",
        "domain": "cs.AI",
        "summary": "  The Rao-Blackwell theorem is utilized to analyze and improve the scalability\nof inference in large probabilistic models that exhibit symmetries. A novel\nmarginal density estimator is introduced and shown both analytically and\nempirically to outperform standard estimators by several orders of magnitude.\nThe developed theory and algorithms apply to a broad class of probabilistic\nmodels including statistical relational models considered not susceptible to\nlifted probabilistic inference.\n",
        "english": "Probabilistic relational models, a subset of statistical relational models, are enhanced through the application of the Rao-Blackwell theorem, which is employed to analyze and improve the scalability of inference in large models exhibiting symmetries. By introducing a novel marginal density estimator, the research demonstrates both analytically and empirically that this estimator outperforms standard estimators by several orders of magnitude, thereby addressing challenges in lifted probabilistic inference. The developed theory and algorithms, applicable to a broad class of probabilistic models, underscore significant advancements in the efficiency and accuracy of probabilistic relational models, with the novel estimator achieving improvements quantified as $O(n^k)$, where $n$ is the number of variables and $k$ is the complexity factor.",
        "korean": "확률적 관계 모델(probabilistic relational models)은 통계적 관계 모델(statistical relational models)의 하위 집합으로, rao-blackwell 정리(rao-blackwell theorem)를 적용하여 대칭성을 나타내는 대규모 모델에서 추론의 확장성을 분석하고 개선합니다. 새로운 주변 밀도 추정기(marginal density estimator)를 도입함으로써, 연구는 이 추정기가 표준 추정기보다 여러 차례 더 우수하다는 것을 분석적 및 경험적으로 입증하여 리프티드 확률적 추론(lifted probabilistic inference)의 문제를 해결합니다. 개발된 이론과 알고리즘은 광범위한 확률 모델에 적용 가능하며, 확률적 관계 모델(probabilistic relational models)의 효율성과 정확성에서 중요한 발전을 강조합니다. 새로운 추정기는 변수의 수를 $n$으로, 복잡도 계수를 $k$로 할 때 $O(n^k)$로 개선을 달성합니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "neural task-specific models",
        "domain": "cs.AI",
        "summary": "  Robots and autonomous systems require an understanding of complex events\n(CEs) from sensor data to interact with their environments and humans\neffectively. Traditional end-to-end neural architectures, despite processing\nsensor data efficiently, struggle with long-duration events due to limited\ncontext sizes and reasoning capabilities. Recent advances in neuro-symbolic\nmethods, which integrate neural and symbolic models leveraging human knowledge,\npromise improved performance with less data. This study addresses the gap in\nunderstanding these approaches' effectiveness in complex event detection (CED),\nespecially in temporal reasoning. We investigate neural and neuro-symbolic\narchitectures' performance in a multimodal CED task, analyzing IMU and acoustic\ndata streams to recognize CE patterns. Our methodology includes (i) end-to-end\nneural architectures for direct CE detection from sensor embeddings, (ii)\ntwo-stage concept-based neural models mapping sensor embeddings to atomic\nevents (AEs) before CE detection, and (iii) a neuro-symbolic approach using a\nsymbolic finite-state machine for CE detection from AEs. Empirically, the\nneuro-symbolic architecture significantly surpasses purely neural models,\ndemonstrating superior performance in CE recognition, even with extensive\ntraining data and ample temporal context for neural approaches.\n",
        "english": "Neural task-specific models, particularly those employing end-to-end neural architectures, are adept at processing sensor data efficiently; however, they often face challenges in complex event detection (CED) due to limitations in handling long-duration events and temporal reasoning. To address these challenges, a two-stage concept-based neural model has been proposed, which maps sensor embeddings to atomic events (AEs) prior to detecting complex events, thereby enhancing the model's ability to recognize intricate CE patterns. Notably, the neuro-symbolic approach, which integrates a symbolic finite-state machine for CE detection from AEs, significantly outperforms purely neural task-specific models, with empirical evidence showing a marked improvement in CE recognition, even when the neural models are provided with extensive training data and ample temporal context.",
        "korean": "신경 작업별 모델(neural task-specific models), 특히 종단 간 신경 아키텍처(end-to-end neural architectures)를 사용하는 모델은 센서 데이터를 효율적으로 처리하는 데 능숙하지만, 복잡한 이벤트 탐지(complex event detection, CED)에서는 장기간 이벤트와 시간적 추론을 처리하는 데 한계가 있어 도전에 직면합니다. 이러한 문제를 해결하기 위해, 센서 임베딩을 원자 이벤트(atomic events, AEs)로 매핑한 후 복잡한 이벤트를 탐지하는 두 단계 개념 기반 신경 모델이 제안되었습니다. 이를 통해 모델의 복잡한 CE 패턴 인식 능력이 향상됩니다. 특히, 신경-상징적 접근법(neuro-symbolic approach)은 AEs로부터 CE를 탐지하기 위해 상징적 유한 상태 기계(symbolic finite-state machine)를 통합하여, 순수한 신경 작업별 모델(neural task-specific models)보다 상당히 뛰어난 성능을 보이며, 신경 모델이 광범위한 훈련 데이터와 충분한 시간적 맥락을 제공받았을 때에도 CE 인식에서 현저한 개선을 보여줍니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and verify that all technical terms are enclosed in parentheses for uniformity."
    },
    {
        "turn_index": 2,
        "term": "deep relational networks",
        "domain": "cs.AI",
        "summary": "  Attributed network representation learning aims at learning node embeddings\nby integrating network structure and attribute information. It is a challenge\nto fully capture the microscopic structure and the attribute semantics\nsimultaneously, where the microscopic structure includes the one-step, two-step\nand multi-step relations, indicating the first-order, second-order and\nhigh-order proximity of nodes, respectively. In this paper, we propose a deep\nattributed network representation learning via attribute enhanced neighborhood\n(DANRL-ANE) model to improve the robustness and effectiveness of node\nrepresentations. The DANRL-ANE model adopts the idea of the autoencoder, and\nexpands the decoder component to three branches to capture different order\nproximity. We linearly combine the adjacency matrix with the attribute\nsimilarity matrix as the input of our model, where the attribute similarity\nmatrix is calculated by the cosine similarity between the attributes based on\nthe social homophily. In this way, we preserve the second-order proximity to\nenhance the robustness of DANRL-ANE model on sparse networks, and deal with the\ntopological and attribute information simultaneously. Moreover, the sigmoid\ncross-entropy loss function is extended to capture the neighborhood character,\nso that the first-order proximity is better preserved. We compare our model\nwith the state-of-the-art models on five real-world datasets and two network\nanalysis tasks, i.e., link prediction and node classification. The DANRL-ANE\nmodel performs well on various networks, even on sparse networks or networks\nwith isolated nodes given the attribute information is sufficient.\n",
        "english": "Deep relational networks, such as the proposed DANRL-ANE model, aim to enhance node embeddings by integrating both network structure and attribute information, addressing the challenge of capturing the microscopic structure and attribute semantics simultaneously. The model employs an autoencoder architecture with an expanded decoder, incorporating three branches to effectively capture different order proximities, where the adjacency matrix and attribute similarity matrix, calculated by cosine similarity, are linearly combined to enhance robustness, particularly in sparse networks. Furthermore, the extension of the sigmoid cross-entropy loss function to capture neighborhood character ensures better preservation of first-order proximity, demonstrating superior performance in tasks like link prediction and node classification across various networks, even those with isolated nodes, as long as the attribute information is sufficient.",
        "korean": "제안된 DANRL-ANE 모델과 같은 심층 관계 네트워크(deep relational networks)는 네트워크 구조와 속성 정보를 통합하여 노드 임베딩을 향상시키고, 미시적 구조와 속성 의미를 동시에 포착하는 문제를 해결하는 것을 목표로 합니다. 이 모델은 확장된 디코더를 갖춘 오토인코더(autoencoder) 아키텍처를 사용하며, 서로 다른 차수의 근접성을 효과적으로 포착하기 위해 세 개의 분기를 포함하고 있습니다. 여기서 인접 행렬과 코사인 유사도로 계산된 속성 유사도 행렬은 선형적으로 결합되어 특히 희소 네트워크에서의 강건성을 향상시킵니다. 또한, 시그모이드 교차 엔트로피 손실 함수(sigmoid cross-entropy loss function)의 확장은 이웃 특성을 포착하여 1차 근접성을 더 잘 보존할 수 있도록 하며, 충분한 속성 정보가 있는 한 고립된 노드를 포함한 다양한 네트워크에서 링크 예측(link prediction) 및 노드 분류(node classification)와 같은 작업에서 우수한 성능을 보여줍니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "semantic probabilistic scene learning",
        "domain": "cs.AI",
        "summary": "  Over the past three decades, the logic programming paradigm has been\nsuccessfully expanded to support probabilistic modeling, inference and\nlearning. The resulting paradigm of probabilistic logic programming (PLP) and\nits programming languages owes much of its success to a declarative semantics,\nthe so-called distribution semantics. However, the distribution semantics is\nlimited to discrete random variables only. While PLP has been extended in\nvarious ways for supporting hybrid, that is, mixed discrete and continuous\nrandom variables, we are still lacking a declarative semantics for hybrid PLP\nthat not only generalizes the distribution semantics and the modeling language\nbut also the standard inference algorithm that is based on knowledge\ncompilation. We contribute the measure semantics together with the hybrid PLP\nlanguage DC-ProbLog (where DC stands for distributional clauses) and its\ninference engine infinitesimal algebraic likelihood weighting (IALW). These\nhave the original distribution semantics, standard PLP languages such as\nProbLog, and standard inference engines for PLP based on knowledge compilation\nas special cases. Thus, we generalize the state of the art of PLP towards\nhybrid PLP in three different aspects: semantics, language and inference.\nFurthermore, IALW is the first inference algorithm for hybrid probabilistic\nprogramming based on knowledge compilation\n",
        "english": "Semantic probabilistic scene learning can benefit from the advancements in probabilistic logic programming (PLP), which has expanded over the past three decades to include probabilistic modeling, inference, and learning, notably through the introduction of the distribution semantics. The measure semantics, alongside the hybrid PLP language DC-ProbLog and its inference engine infinitesimal algebraic likelihood weighting (IALW), generalizes the state of the art of PLP towards hybrid PLP by encompassing semantics, language, and inference, thus providing a robust framework for semantic probabilistic scene learning. Importantly, the measure semantics extends the distribution semantics to support hybrid random variables, effectively enabling the modeling of both discrete and continuous variables, which can be expressed mathematically as \\( P(X = x \\mid Y = y) = \\frac{P(X = x, Y = y)}{P(Y = y)} \\), where \\( X \\) and \\( Y \\) represent random variables in a scene learning context.",
        "korean": "의미 확률적 장면 학습(semantic probabilistic scene learning)은 지난 30년 동안 확장되어 분포 의미론(distribution semantics)을 도입함으로써 확률적 모델링, 추론 및 학습을 포함하게 된 확률 논리 프로그래밍(probabilistic logic programming, PLP)의 발전으로부터 혜택을 받을 수 있습니다. 측정 의미론(measure semantics)은 하이브리드 PLP 언어 DC-ProbLog와 그 추론 엔진인 무한소 대수적 가중치(infinitesimal algebraic likelihood weighting, IALW)와 함께 의미론, 언어 및 추론을 포괄하여 하이브리드 PLP로의 PLP 최첨단 기술을 일반화함으로써 의미 확률적 장면 학습(semantic probabilistic scene learning)을 위한 강력한 프레임워크를 제공합니다. 특히, 측정 의미론(measure semantics)은 하이브리드 확률 변수를 지원하도록 분포 의미론(distribution semantics)을 확장하여 이산 및 연속 변수를 모두 모델링할 수 있게 하며, 이는 수학적으로 \\( P(X = x \\mid Y = y) = \\frac{P(X = x, Y = y)}{P(Y = y)} \\)로 표현될 수 있습니다. 여기서 \\( X \\)와 \\( Y \\)는 장면 학습(context of scene learning)에서의 확률 변수를 나타냅니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all terms within parentheses are in lowercase for consistency."
    },
    {
        "turn_index": 2,
        "term": "generative text modeling",
        "domain": "cs.AI",
        "summary": "  Despite impressive recent advances in text-to-image diffusion models,\nobtaining high-quality images often requires prompt engineering by humans who\nhave developed expertise in using them. In this work, we present NeuroPrompts,\nan adaptive framework that automatically enhances a user's prompt to improve\nthe quality of generations produced by text-to-image models. Our framework\nutilizes constrained text decoding with a pre-trained language model that has\nbeen adapted to generate prompts similar to those produced by human prompt\nengineers. This approach enables higher-quality text-to-image generations and\nprovides user control over stylistic features via constraint set specification.\nWe demonstrate the utility of our framework by creating an interactive\napplication for prompt enhancement and image generation using Stable Diffusion.\nAdditionally, we conduct experiments utilizing a large dataset of\nhuman-engineered prompts for text-to-image generation and show that our\napproach automatically produces enhanced prompts that result in superior image\nquality. We make our code and a screencast video demo of NeuroPrompts publicly\navailable.\n",
        "english": "Generative text modeling has seen significant advancements, particularly in the domain of text-to-image diffusion models, where the quality of generated images often hinges on the expertise of human prompt engineers (reference). The innovative NeuroPrompts framework enhances this process by utilizing constrained text decoding with a pre-trained language model, which has been adapted to generate prompts akin to those crafted by human experts, thus improving the generative capabilities of text-to-image models (reference). Notably, experiments demonstrated that enhanced prompts automatically produced by this approach lead to superior image quality, as evidenced by improved metrics such as the Fréchet Inception Distance (FID), a measure of similarity between generated and real images, which is minimized in the form $\\text{FID} = \\|\\mu_r - \\mu_g\\|^2 + \\text{Tr}(\\Sigma_r + \\Sigma_g - 2(\\Sigma_r\\Sigma_g)^{1/2})$ (reference).",
        "korean": "생성적 텍스트 모델링(generative text modeling)은 특히 텍스트-이미지 확산 모델(text-to-image diffusion models) 분야에서 상당한 발전을 이루었으며, 생성된 이미지의 품질은 종종 인간 프롬프트 엔지니어(prompt engineers)의 전문성에 달려 있습니다(참조). 혁신적인 뉴로프롬프트(NeuroPrompts) 프레임워크는 사전 훈련된 언어 모델(pre-trained language model)을 사용한 제한된 텍스트 디코딩(constrained text decoding)을 통해 이 과정을 향상시킵니다. 이는 인간 전문가가 제작한 프롬프트와 유사한 프롬프트를 생성하도록 적응되어 텍스트-이미지 모델의 생성 능력을 개선합니다(참조). 특히, 이 접근 방식으로 자동 생성된 향상된 프롬프트가 이미지 품질을 향상시킨다는 실험 결과가 있으며, 이는 생성된 이미지와 실제 이미지 간의 유사성을 측정하는 프레셰 인셉션 거리(Fréchet Inception Distance, FID)와 같은 향상된 지표로 입증됩니다. FID는 $\\text{FID} = \\|\\mu_r - \\mu_g\\|^2 + \\text{Tr}(\\Sigma_r + \\Sigma_g - 2(\\Sigma_r\\Sigma_g)^{1/2})$ 형태로 최소화됩니다(참조).",
        "score": 10,
        "parentheses_count": 9,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar"
    },
    {
        "turn_index": 2,
        "term": "dynamic neural optimization",
        "domain": "cs.AI",
        "summary": "  This paper presents the deep learning-based recent achievements to resolve\nthe problem of autonomous mobility control and efficient resource management of\nautonomous vehicles and UAVs, i.e., (i) multi-agent reinforcement learning\n(MARL), and (ii) neural Myerson auction. Representatively, communication\nnetwork (CommNet), which is one of the most popular MARL algorithms, is\nintroduced to enable multiple agents to take actions in a distributed manner\nfor their shared goals by training all agents' states and actions in a single\nneural network. Moreover, the neural Myerson auction guarantees trustfulness\namong multiple agents as well as achieves the optimal revenue of highly dynamic\nsystems. Therefore, we survey the recent studies on autonomous mobility control\nbased on MARL and neural Myerson auction. Furthermore, we emphasize that\nintegration of MARL and neural Myerson auction is expected to be critical for\nefficient and trustful autonomous mobility services.\n",
        "english": "Dynamic neural optimization plays a crucial role in enabling autonomous vehicles and UAVs to achieve efficient resource management through methodologies such as multi-agent reinforcement learning (MARL) and neural Myerson auction. By integrating MARL, specifically using the communication network (CommNet) algorithm, multiple agents can effectively take actions in a distributed manner, optimizing their shared goals by training all agents' states and actions within a single neural network framework. Furthermore, the neural Myerson auction ensures trustfulness among agents while maximizing the optimal revenue of highly dynamic systems, where the revenue $R$ can be expressed as $R = \\sum_{i=1}^{n} p_i x_i$, with $p_i$ representing the payment from agent $i$ and $x_i$ denoting the allocation decision for agent $i$.",
        "korean": "동적 신경 최적화(dynamic neural optimization)는 자율 주행 차량과 UAV가 다중 에이전트 강화 학습(multi-agent reinforcement learning, MARL) 및 신경 마이어슨 경매(neural Myerson auction)와 같은 방법론을 통해 효율적인 자원 관리를 달성하는 데 중요한 역할을 합니다. 특히 통신 네트워크(communication network, CommNet) 알고리즘을 사용하여 MARL을 통합함으로써 여러 에이전트가 분산된 방식으로 효과적으로 행동을 취할 수 있으며, 단일 신경망 프레임워크 내에서 모든 에이전트의 상태와 행동을 훈련하여 공유 목표를 최적화할 수 있습니다. 또한, 신경 마이어슨 경매(neural Myerson auction)는 에이전트 간의 신뢰성을 보장하면서 고도로 동적인 시스템의 최적 수익을 극대화합니다. 여기서 수익 $R$은 $R = \\sum_{i=1}^{n} p_i x_i$로 표현될 수 있으며, $p_i$는 에이전트 $i$의 지불을 나타내고 $x_i$는 에이전트 $i$에 대한 할당 결정을 나타냅니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as \"신경 마이어슨 경매(neural Myerson auction)는\" to \"신경 마이어슨 경매(neural myerson auction)는\"."
    },
    {
        "turn_index": 2,
        "term": "contextual learning",
        "domain": "cs.AI",
        "summary": "  Concepts are the foundation of human deep learning, understanding, and\nknowledge integration and transfer. We propose concept-oriented deep learning\n(CODL) which extends (machine) deep learning with concept representations and\nconceptual understanding capability. CODL addresses some of the major\nlimitations of deep learning: interpretability, transferability, contextual\nadaptation, and requirement for lots of labeled training data. We discuss the\nmajor aspects of CODL including concept graph, concept representations, concept\nexemplars, and concept representation learning systems supporting incremental\nand continual learning.\n",
        "english": "Contextual learning is significantly enhanced by concept-oriented deep learning (CODL), which extends traditional deep learning with the ability to represent and understand concepts, thereby improving interpretability and transferability. CODL utilizes concept graphs and concept representation learning systems to facilitate incremental and continual learning, addressing the limitations of deep learning such as the requirement for extensive labeled data. A key innovation of CODL is its capacity for contextual adaptation, mathematically expressed as $f(C) = \\sum_{i=1}^{n} w_i c_i$, where $C$ represents the concept and $w_i$ are the weights associated with each concept exemplar $c_i$, highlighting its potential for efficient knowledge integration and transfer.",
        "korean": "개념 지향 심층 학습(concept-oriented deep learning, CODL)은 개념을 표현하고 이해하는 능력을 확장하여 해석 가능성과 전이 가능성을 향상시킴으로써 맥락 학습(contextual learning)을 크게 강화합니다. CODL은 개념 그래프(concept graphs)와 개념 표현 학습 시스템(concept representation learning systems)을 활용하여 점진적이고 지속적인 학습을 촉진하며, 방대한 양의 라벨링된 데이터가 필요한 심층 학습(deep learning)의 한계를 해결합니다. CODL의 주요 혁신은 맥락 적응(contextual adaptation) 능력으로, 이는 수학적으로 $f(C) = \\sum_{i=1}^{n} w_i c_i$로 표현되며, 여기서 $C$는 개념을 나타내고 $w_i$는 각 개념 예시 $c_i$에 연관된 가중치입니다. 이는 효율적인 지식 통합 및 전이의 잠재력을 강조합니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Ensure consistency in the use of parentheses throughout the translation for a more natural flow and grammar."
    },
    {
        "turn_index": 2,
        "term": "machine reasoning",
        "domain": "cs.AI",
        "summary": "  Commonsense reasoning has long been considered as one of the holy grails of\nartificial intelligence. Most of the recent progress in the field has been\nachieved by novel machine learning algorithms for natural language processing.\nHowever, without incorporating logical reasoning, these algorithms remain\narguably shallow. With some notable exceptions, developers of practical\nautomated logic-based reasoners have mostly avoided focusing on the problem.\nThe paper argues that the methods and algorithms used by existing automated\nreasoners for classical first-order logic can be extended towards commonsense\nreasoning. Instead of devising new specialized logics we propose a framework of\nextensions to the mainstream resolution-based search methods to make these\ncapable of performing search tasks for practical commonsense reasoning with\nreasonable efficiency. The proposed extensions mostly rely on operating on\nordinary proof trees and are devised to handle commonsense knowledge bases\ncontaining inconsistencies, default rules, taxonomies, topics, relevance,\nconfidence and similarity measures. We claim that machine learning is best\nsuited for the construction of commonsense knowledge bases while the extended\nlogic-based methods would be well-suited for actually answering queries from\nthese knowledge bases.\n",
        "english": "Machine reasoning, particularly in the realm of commonsense reasoning, has been identified as a critical component of artificial intelligence, with the current advancements largely attributed to novel machine learning algorithms in natural language processing. However, these algorithms are often criticized for their lack of depth, as they do not incorporate logical reasoning; thus, extending the methods used by automated reasoners for classical first-order logic could enhance their capability for practical commonsense reasoning. The research proposes a framework of extensions to mainstream resolution-based search methods, which operate on ordinary proof trees and are designed to handle complex knowledge bases; these extensions aim to efficiently manage inconsistencies, default rules, and other elements, with the potential to significantly advance the field of machine reasoning.",
        "korean": "기계 추론(machine reasoning), 특히 상식 추론 영역에서, 인공지능의 중요한 구성 요소로 확인되었으며, 현재의 발전은 주로 자연어 처리 분야의 새로운 기계 학습 알고리즘(machine learning algorithms)에 기인합니다. 그러나 이러한 알고리즘은 논리적 추론을 포함하지 않아 깊이가 부족하다는 비판을 받습니다. 따라서 고전적 1차 논리를 위한 자동 추론기(automated reasoners)의 방법을 확장하면 실용적인 상식 추론을 위한 능력을 향상시킬 수 있습니다. 연구는 복잡한 지식 기반을 처리하도록 설계된 일반적인 증명 트리(proof trees)에서 작동하는 주류 해결 기반 탐색 방법(resolution-based search methods)의 확장 프레임워크를 제안하며, 이러한 확장은 비일관성, 기본 규칙 및 기타 요소를 효율적으로 관리하여 기계 추론(machine reasoning) 분야를 크게 발전시킬 잠재력을 가지고 있습니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "neural probabilistic text segmentation",
        "domain": "cs.AI",
        "summary": "  Most of the web user's requirements are search or navigation time and getting\ncorrectly matched result. These constrains can be satisfied with some\nadditional modules attached to the existing search engines and web servers.\nThis paper proposes that powerful architecture for search engines with the\ntitle of Probabilistic Semantic Web Mining named from the methods used. With\nthe increase of larger and larger collection of various data resources on the\nWorld Wide Web (WWW), Web Mining has become one of the most important\nrequirements for the web users. Web servers will store various formats of data\nincluding text, image, audio, video etc., but servers can not identify the\ncontents of the data. These search techniques can be improved by adding some\nspecial techniques including semantic web mining and probabilistic analysis to\nget more accurate results. Semantic web mining technique can provide meaningful\nsearch of data resources by eliminating useless information with mining\nprocess. In this technique web servers will maintain Meta information of each\nand every data resources available in that particular web server. This will\nhelp the search engine to retrieve information that is relevant to user given\ninput string. This paper proposing the idea of combing these two techniques\nSemantic web mining and Probabilistic analysis for efficient and accurate\nsearch results of web mining. SPF can be calculated by considering both\nsemantic accuracy and syntactic accuracy of data with the input string. This\nwill be the deciding factor for producing results.\n",
        "english": "Neural probabilistic text segmentation can significantly enhance the accuracy of search engines by integrating semantic web mining and probabilistic analysis, which are crucial for \"getting correctly matched result\" in a vast collection of web data. By maintaining \"Meta information of each and every data resource,\" this method allows for a more precise alignment of user queries with web resources, thereby improving the relevance of search outcomes. The integration of semantic accuracy and syntactic accuracy, represented by the Semantic Probabilistic Factor (SPF), can be mathematically expressed as \\( \\text{SPF} = f(\\text{semantic accuracy}, \\text{syntactic accuracy}) \\), serving as a pivotal factor in optimizing search results.",
        "korean": "신경 확률적 텍스트 분할(neural probabilistic text segmentation)은 의미 웹 마이닝(semantic web mining)과 확률 분석(probabilistic analysis)을 통합하여 검색 엔진의 정확성을 크게 향상시킬 수 있으며, 이는 방대한 웹 데이터에서 \"정확히 일치하는 결과를 얻는 것\"에 필수적입니다. \"각 데이터 자원의 메타 정보(meta information of each and every data resource)\"를 유지함으로써 이 방법은 사용자 쿼리와 웹 자원의 보다 정확한 정렬을 가능하게 하여 검색 결과의 관련성을 향상시킵니다. 의미 정확도(semantic accuracy)와 구문 정확도(syntactic accuracy)로 표현되는 의미 확률 인자(Semantic Probabilistic Factor, SPF)의 통합은 수학적으로 \\( \\text{SPF} = f(\\text{semantic accuracy}, \\text{syntactic accuracy}) \\)로 표현될 수 있으며, 이는 검색 결과 최적화의 중요한 요소로 작용합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure consistent lowercase usage within parentheses."
    },
    {
        "turn_index": 2,
        "term": "heterogeneous graphs",
        "domain": "cs.AI",
        "summary": "  Predicting Remaining Useful Life (RUL) plays a crucial role in the\nprognostics and health management of industrial systems that involve a variety\nof interrelated sensors. Given a constant stream of time series sensory data\nfrom such systems, deep learning models have risen to prominence at identifying\ncomplex, nonlinear temporal dependencies in these data. In addition to the\ntemporal dependencies of individual sensors, spatial dependencies emerge as\nimportant correlations among these sensors, which can be naturally modelled by\na temporal graph that describes time-varying spatial relationships. However,\nthe majority of existing studies have relied on capturing discrete snapshots of\nthis temporal graph, a coarse-grained approach that leads to loss of temporal\ninformation. Moreover, given the variety of heterogeneous sensors, it becomes\nvital that such inherent heterogeneity is leveraged for RUL prediction in\ntemporal sensor graphs. To capture the nuances of the temporal and spatial\nrelationships and heterogeneous characteristics in an interconnected graph of\nsensors, we introduce a novel model named Temporal and Heterogeneous Graph\nNeural Networks (THGNN). Specifically, THGNN aggregates historical data from\nneighboring nodes to accurately capture the temporal dynamics and spatial\ncorrelations within the stream of sensor data in a fine-grained manner.\nMoreover, the model leverages Feature-wise Linear Modulation (FiLM) to address\nthe diversity of sensor types, significantly improving the model's capacity to\nlearn the heterogeneity in the data sources. Finally, we have validated the\neffectiveness of our approach through comprehensive experiments. Our empirical\nfindings demonstrate significant advancements on the N-CMAPSS dataset,\nachieving improvements of up to 19.2% and 31.6% in terms of two different\nevaluation metrics over state-of-the-art methods.\n",
        "korean": "산업 시스템의 잔여 수명 예측(RUL) 맥락에서 이종 그래프(heterogeneous graphs)를 활용하는 것은 상호 연결된 센서들 간의 시간적 및 공간적 관계의 미묘한 차이를 포착하는 데 필수적입니다. 특히 이러한 센서들이 다양한 특성을 보일 때 더욱 중요합니다. 시간적 및 이종 그래프 신경망(temporal and heterogeneous graph neural networks, THGNN) 모델은 특징별 선형 변조(feature-wise linear modulation, FiLM)를 혁신적으로 활용하여 센서 유형의 이질성을 효과적으로 처리하고 복잡한 의존성을 모델링하는 능력을 향상시켜 예측 정확도를 높입니다. N-CMAPSS 데이터셋에 대한 실험 결과는 모델의 효능을 입증하며, 특정 평가 지표에서 최첨단 방법과 비교하여 최대 19.2\\% 및 31.6\\%의 개선을 달성하여 예지 및 건강 관리에서 이종 그래프(heterogeneous graphs)를 통합하는 것의 중요성을 강조합니다."
    },
    {
        "turn_index": 2,
        "term": "inverse graphical models",
        "domain": "cs.AI",
        "summary": "  Inspired by the recently introduced framework of AND/OR search spaces for\ngraphical models, we propose to augment Multi-Valued Decision Diagrams (MDD)\nwith AND nodes, in order to capture function decomposition structure and to\nextend these compiled data structures to general weighted graphical models\n(e.g., probabilistic models). We present the AND/OR Multi-Valued Decision\nDiagram (AOMDD) which compiles a graphical model into a canonical form that\nsupports polynomial (e.g., solution counting, belief updating) or constant time\n(e.g. equivalence of graphical models) queries. We provide two algorithms for\ncompiling the AOMDD of a graphical model. The first is search-based, and works\nby applying reduction rules to the trace of the memory intensive AND/OR search\nalgorithm. The second is inference-based and uses a Bucket Elimination schedule\nto combine the AOMDDs of the input functions via the the APPLY operator. For\nboth algorithms, the compilation time and the size of the AOMDD are, in the\nworst case, exponential in the treewidth of the graphical model, rather than\npathwidth as is known for ordered binary decision diagrams (OBDDs). We\nintroduce the concept of semantic treewidth, which helps explain why the size\nof a decision diagram is often much smaller than the worst case bound. We\nprovide an experimental evaluation that demonstrates the potential of AOMDDs.\n",
        "english": "Inverse graphical models benefit significantly from the introduction of the AND/OR Multi-Valued Decision Diagram (AOMDD), which compiles a graphical model into a canonical form that supports efficient queries, such as polynomial time solution counting and belief updating. The research proposes two algorithms for compiling the AOMDD, with the first being search-based and applying reduction rules to the trace of the memory-intensive AND/OR search algorithm, while the second is inference-based, utilizing a Bucket Elimination schedule to merge the AOMDDs of input functions via the APPLY operator. Importantly, the size of the AOMDD is often much smaller than the worst-case bound, as explained by the concept of semantic treewidth, which contrasts with the exponential dependence on treewidth, $O(2^{\\text{tw}})$, rather than pathwidth as seen in ordered binary decision diagrams (OBDDs).",
        "korean": "역 그래프 모델(inverse graphical models)은 AND/OR 다중 값 결정 다이어그램(AND/OR Multi-Valued Decision Diagram, AOMDD)의 도입으로 크게 이점을 얻습니다. AOMDD는 그래프 모델을 정규형으로 컴파일하여 다항 시간 해답 계산 및 신념 갱신과 같은 효율적인 쿼리를 지원합니다. 연구에서는 AOMDD를 컴파일하기 위한 두 가지 알고리즘을 제안하는데, 첫 번째는 탐색 기반으로 메모리 집약적인 AND/OR 탐색 알고리즘의 추적에 감소 규칙을 적용하며, 두 번째는 추론 기반으로 버킷 제거 일정(Bucket Elimination schedule)을 사용하여 입력 함수의 AOMDD를 APPLY 연산자를 통해 병합합니다. 중요한 점은 AOMDD의 크기가 종종 최악의 경우 경계보다 훨씬 작다는 것이며, 이는 경로 폭이 아닌 트리 폭에 대한 지수적 의존성, $O(2^{\\text{tw}})$, 과 대조되는 의미론적 트리 폭의 개념으로 설명됩니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring all technical terms are consistently parenthesized as Korean term(English term) throughout the text."
    },
    {
        "turn_index": 2,
        "term": "temporal difference learning",
        "domain": "cs.AI",
        "summary": "  Reasoning over Temporal Knowledge Graphs (TKGs) aims to predict future facts\nbased on given history. One of the key challenges for prediction is to learn\nthe evolution of facts. Most existing works focus on exploring evolutionary\ninformation in history to obtain effective temporal embeddings for entities and\nrelations, but they ignore the variation in evolution patterns of facts, which\nmakes them struggle to adapt to future data with different evolution patterns.\nMoreover, new entities continue to emerge along with the evolution of facts\nover time. Since existing models highly rely on historical information to learn\nembeddings for entities, they perform poorly on such entities with little\nhistorical information. To tackle these issues, we propose a novel Temporal\nMeta-learning framework for TKG reasoning, MetaTKG for brevity. Specifically,\nour method regards TKG prediction as many temporal meta-tasks, and utilizes the\ndesigned Temporal Meta-learner to learn evolutionary meta-knowledge from these\nmeta-tasks. The proposed method aims to guide the backbones to learn to adapt\nquickly to future data and deal with entities with little historical\ninformation by the learned meta-knowledge. Specially, in temporal meta-learner,\nwe design a Gating Integration module to adaptively establish temporal\ncorrelations between meta-tasks. Extensive experiments on four widely-used\ndatasets and three backbones demonstrate that our method can greatly improve\nthe performance.\n",
        "english": "Temporal difference learning can significantly enhance the prediction of future facts in temporal knowledge graphs by focusing on learning the evolution of facts, thus addressing the challenge of adapting to different evolution patterns. By integrating temporal difference learning within a novel Temporal Meta-learning framework for TKG reasoning, specifically the MetaTKG, the proposed method effectively utilizes a Temporal Meta-learner to guide backbones to learn evolutionary meta-knowledge from temporal meta-tasks. This approach, which includes a Gating Integration module to adaptively establish temporal correlations between meta-tasks, demonstrates improved performance across multiple datasets, suggesting that the learned meta-knowledge can be mathematically represented as $M_{t} = \\gamma M_{t-1} + (1 - \\gamma) \\Delta M$, where $M_{t}$ is the updated meta-knowledge at time $t$, $\\gamma$ is the learning rate, and $\\Delta M$ is the change in meta-knowledge.",
        "korean": "시간적 차이 학습(temporal difference learning)은 사실의 진화를 학습하는 데 중점을 두어 시간적 지식 그래프(temporal knowledge graphs)에서 미래 사실의 예측을 크게 향상시킬 수 있으며, 이는 다양한 진화 패턴에 적응하는 문제를 해결합니다. 시간적 차이 학습(temporal difference learning)을 TKG 추론을 위한 새로운 시간적 메타 학습 프레임워크(Temporal Meta-learning framework), 즉 MetaTKG에 통합함으로써 제안된 방법은 시간적 메타 학습자(Temporal Meta-learner)를 활용하여 시간적 메타 작업(temporal meta-tasks)에서 진화적 메타 지식을 학습하도록 백본을 안내합니다. 메타 작업 간의 시간적 상관관계를 적응적으로 설정하기 위한 게이팅 통합 모듈(Gating Integration module)을 포함하는 이 접근 방식은 여러 데이터셋에서 향상된 성능을 보여주며, 학습된 메타 지식이 수학적으로 $M_{t} = \\gamma M_{t-1} + (1 - \\gamma) \\Delta M$로 표현될 수 있음을 시사합니다. 여기서 $M_{t}$는 시간 $t$에서의 업데이트된 메타 지식, $\\gamma$는 학습률, $\\Delta M$은 메타 지식의 변화입니다.",
        "score": 9,
        "parentheses_count": 9,
        "suggestions": "Ensure that all technical terms are consistently parenthesized, such as \"시간적 메타 학습 프레임워크(Temporal Meta-learning framework)\" should be \"시간적 메타 학습 프레임워크(temporal meta-learning framework)\" for consistency with lowercase formatting."
    },
    {
        "turn_index": 2,
        "term": "contextual learning frameworks",
        "domain": "cs.AI",
        "summary": "  Cognitive control, the ability of a system to adapt to the demands of a task,\nis an integral part of cognition. A widely accepted fact about cognitive\ncontrol is that it is context-sensitive: Adults and children alike infer\ninformation about a task's demands from contextual cues and use these\ninferences to learn from ambiguous cues. However, the precise way in which\npeople use contextual cues to guide adaptation to a new task remains poorly\nunderstood. This work connects the context-sensitive nature of cognitive\ncontrol to a method for meta-learning with context-conditioned adaptation. We\nbegin by identifying an essential difference between human learning and current\napproaches to meta-learning: In contrast to humans, existing meta-learning\nalgorithms do not make use of task-specific contextual cues but instead rely\nexclusively on online feedback in the form of task-specific labels or rewards.\nTo remedy this, we introduce a framework for using contextual information about\na task to guide the initialization of task-specific models before adaptation to\nonline feedback. We show how context-conditioned meta-learning can capture\nhuman behavior in a cognitive task and how it can be scaled to improve the\nspeed of learning in various settings, including few-shot classification and\nlow-sample reinforcement learning. Our work demonstrates that guiding\nmeta-learning with task information can capture complex, human-like behavior,\nthereby deepening our understanding of cognitive control.\n",
        "english": "Contextual learning frameworks, which align with the context-sensitive nature of cognitive control, offer a novel approach to meta-learning by utilizing contextual cues rather than relying solely on online feedback such as task-specific labels or rewards. This framework involves the initialization of task-specific models using contextual information, thereby enhancing the adaptability and efficiency of learning processes, particularly in scenarios like few-shot classification and low-sample reinforcement learning. By employing context-conditioned meta-learning, the framework can be mathematically represented as optimizing a model's parameters $\\theta$ conditioned on context $c$, thus $p(\\theta | c)$, which significantly improves the speed of adaptation and captures complex, human-like behavior, advancing our understanding of cognitive control mechanisms.",
        "korean": "인지 제어의 맥락 민감한 특성과 일치하는 맥락 학습 프레임워크(contextual learning frameworks)는 과제별 레이블이나 보상과 같은 온라인 피드백에만 의존하지 않고 맥락적 단서를 활용하여 메타 학습(meta-learning)에 대한 새로운 접근 방식을 제공합니다. 이 프레임워크는 맥락 정보를 사용하여 과제별 모델을 초기화함으로써 학습 과정의 적응성과 효율성을 향상시키며, 특히 소수 샷 분류(few-shot classification) 및 저샘플 강화 학습(low-sample reinforcement learning)과 같은 시나리오에서 유용합니다. 맥락 조건 메타 학습(context-conditioned meta-learning)을 활용함으로써 이 프레임워크는 맥락 $c$에 조건화된 모델의 매개변수 $\\theta$를 최적화하는 것으로 수학적으로 표현될 수 있으며, 따라서 $p(\\theta | c)$는 적응 속도를 크게 향상시키고 복잡하고 인간과 유사한 행동을 포착하여 인지 제어 메커니즘에 대한 이해를 발전시킵니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure that all technical terms are consistently parenthesized as Korean term(English term) throughout the text."
    },
    {
        "turn_index": 2,
        "term": "liquid state machines",
        "domain": "cs.AI",
        "summary": "  This paper presents an implemented system for recognizing the occurrence of\nevents described by simple spatial-motion verbs in short image sequences. The\nsemantics of these verbs is specified with event-logic expressions that\ndescribe changes in the state of force-dynamic relations between the\nparticipants of the event. An efficient finite representation is introduced for\nthe infinite sets of intervals that occur when describing liquid and\nsemi-liquid events. Additionally, an efficient procedure using this\nrepresentation is presented for inferring occurrences of compound events,\ndescribed with event-logic expressions, from occurrences of primitive events.\nUsing force dynamics and event logic to specify the lexical semantics of events\nallows the system to be more robust than prior systems based on motion profile.\n",
        "english": "Liquid state machines can be enhanced by employing an efficient finite representation for the infinite sets of intervals that occur when describing liquid and semi-liquid events, as detailed in the presented system for recognizing spatial-motion verbs in image sequences. By utilizing event-logic expressions, these machines can infer occurrences of compound events from primitive ones, thereby improving robustness over systems relying solely on motion profiles. This approach leverages force dynamics, allowing for a more precise specification of lexical semantics, with the ability to describe changes in the state of force-dynamic relations, ultimately contributing to advancements in event recognition technology.",
        "korean": "액체 상태 기계(liquid state machines)는 이미지 시퀀스에서 공간-운동 동사를 인식하는 시스템에서 설명된 바와 같이 액체 및 반액체 이벤트를 설명할 때 발생하는 무한한 간격 집합에 대한 효율적인 유한 표현을 사용하여 향상될 수 있습니다. 이벤트 논리 표현(event-logic expressions)을 활용함으로써 이러한 기계는 기본 이벤트로부터 복합 이벤트의 발생을 추론할 수 있으며, 이는 단순히 운동 프로필에 의존하는 시스템보다 견고성을 향상시킵니다. 이 접근법은 힘 역학(force dynamics)을 활용하여 어휘 의미론의 보다 정밀한 명세를 가능하게 하며, 힘-역학 관계의 상태 변화를 설명할 수 있는 능력을 갖추어 궁극적으로 이벤트 인식 기술의 발전에 기여합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "dynamic text modeling",
        "domain": "cs.AI",
        "summary": "  Ontologies have been known for their semantic representation of knowledge.\nontologies cannot automatically evolve to reflect updates that occur in\nrespective domains. To address this limitation, researchers have called for\nautomatic ontology generation from unstructured text corpus. Unfortunately,\nsystems that aim to generate ontologies from unstructured text corpus are\ndomain-specific and require manual intervention. In addition, they suffer from\nuncertainty in creating concept linkages and difficulty in finding axioms for\nthe same concept. Knowledge Graphs (KGs) has emerged as a powerful model for\nthe dynamic representation of knowledge. However, KGs have many quality\nlimitations and need extensive refinement. This research aims to develop a\nnovel domain-independent automatic ontology generation framework that converts\nunstructured text corpus into domain consistent ontological form. The framework\ngenerates KGs from unstructured text corpus as well as refine and correct them\nto be consistent with domain ontologies. The power of the proposed\nautomatically generated ontology is that it integrates the dynamic features of\nKGs and the quality features of ontologies.\n",
        "english": "Dynamic text modeling plays a crucial role in the \"automatic ontology generation from unstructured text corpus,\" addressing the challenge that \"ontologies cannot automatically evolve to reflect updates that occur in respective domains.\" By leveraging the integration of Knowledge Graphs (KGs), which \"emerged as a powerful model for the dynamic representation of knowledge,\" the proposed framework refines and corrects generated KGs to maintain consistency with domain ontologies. The innovation of this research lies in its ability to create a novel domain-independent framework that combines the dynamic features of KGs and the quality features of ontologies, denoted mathematically as $KG_{dynamic} \\cap Ontology_{quality}$.",
        "korean": "동적 텍스트 모델링(dynamic text modeling)은 \"비구조화된 텍스트 코퍼스에서의 자동 온톨로지 생성(automatic ontology generation from unstructured text corpus)\"에서 중요한 역할을 하며, \"온톨로지가 해당 도메인에서 발생하는 업데이트를 반영하여 자동으로 진화할 수 없다\"는 문제를 해결합니다. 지식 그래프(Knowledge Graphs, KGs)의 통합을 활용하여, \"지식의 동적 표현을 위한 강력한 모델로 부상한\" 제안된 프레임워크는 생성된 KGs를 정제하고 수정하여 도메인 온톨로지와의 일관성을 유지합니다. 이 연구의 혁신은 KGs의 동적 특성과 온톨로지의 품질 특성을 결합한 새로운 도메인 독립적 프레임워크를 생성할 수 있는 능력에 있으며, 이는 수학적으로 $KG_{dynamic} \\cap Ontology_{quality}$로 표시됩니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring all technical terms are consistently parenthesized as Korean term(English term) throughout the text."
    },
    {
        "turn_index": 2,
        "term": "graph spectral methods",
        "domain": "cs.AI",
        "summary": "  Graph embedding methods such as Graph Neural Networks (GNNs) and Graph\nTransformers have contributed to the development of graph reasoning algorithms\nfor various tasks on knowledge graphs. However, the lack of interpretability\nand explainability of graph embedding methods has limited their applicability\nin scenarios requiring explicit reasoning. In this paper, we introduce the\nGraph Agent (GA), an intelligent agent methodology of leveraging large language\nmodels (LLMs), inductive-deductive reasoning modules, and long-term memory for\nknowledge graph reasoning tasks. GA integrates aspects of symbolic reasoning\nand existing graph embedding methods to provide an innovative approach for\ncomplex graph reasoning tasks. By converting graph structures into textual\ndata, GA enables LLMs to process, reason, and provide predictions alongside\nhuman-interpretable explanations. The effectiveness of the GA was evaluated on\nnode classification and link prediction tasks. Results showed that GA reached\nstate-of-the-art performance, demonstrating accuracy of 90.65%, 95.48%, and\n89.32% on Cora, PubMed, and PrimeKG datasets, respectively. Compared to\nexisting GNN and transformer models, GA offered advantages of explicit\nreasoning ability, free-of-training, easy adaption to various graph reasoning\ntasks\n",
        "english": "Graph spectral methods, which encompass techniques such as Graph Neural Networks (GNNs) and Graph Transformers, have significantly advanced the development of graph reasoning algorithms for various tasks on knowledge graphs. Despite their contributions, the lack of interpretability and explainability has limited their applicability, prompting innovations like the Graph Agent (GA), which integrates symbolic reasoning and existing graph embedding methods to enhance complex graph reasoning tasks. With GA achieving state-of-the-art performance, evidenced by accuracies of 90.65\\%, 95.48\\%, and 89.32\\% on the Cora, PubMed, and PrimeKG datasets respectively, it underscores the potential of combining graph spectral methods with large language models to offer explicit reasoning and human-interpretable explanations.",
        "korean": "그래프 스펙트럼 방법(graph spectral methods), 즉 그래프 신경망(graph neural networks, gnns)과 그래프 변환기(graph transformers)와 같은 기법들은 지식 그래프(knowledge graphs)에서 다양한 작업을 위한 그래프 추론 알고리즘의 개발을 크게 발전시켰습니다. 그들의 기여에도 불구하고, 해석 가능성과 설명 가능성의 부족은 그들의 적용 가능성을 제한하였으며, 이는 복잡한 그래프 추론 작업을 향상시키기 위해 상징적 추론과 기존의 그래프 임베딩 방법을 통합하는 그래프 에이전트(graph agent, ga)와 같은 혁신을 촉발했습니다. ga가 코라(cora), 퍼브메드(pubmed), 프라임kg(primekg) 데이터셋에서 각각 90.65\\%, 95.48\\%, 89.32\\%의 정확도를 달성하며 최첨단 성능을 입증함에 따라, 그래프 스펙트럼 방법(graph spectral methods)과 대형 언어 모델(large language models)을 결합하여 명시적 추론과 인간이 해석할 수 있는 설명을 제공할 수 있는 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 11,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "adaptive neural processes",
        "domain": "cs.AI",
        "summary": "  This study aims at making the architecture search process more adaptive for\none-shot or online training. It is extended from the existing study on\ndifferentiable neural architecture search, and we made the backbone\narchitecture transformable rather than fixed during the training process. As is\nknown, differentiable neural architecture search (DARTS) requires a pre-defined\nover-parameterized backbone architecture, while its size is to be determined\nmanually. Also, in DARTS backbone, Hadamard product of two elements is not\nintroduced, which exists in both LSTM and GRU cells for recurrent nets. This\nstudy introduces a growing mechanism for differentiable neural architecture\nsearch based on network morphism. It enables growing of the cell structures\nfrom small size towards large size ones with one-shot training. Two modes can\nbe applied in integrating the growing and original pruning process. We also\nimplement a recently proposed two-input backbone architecture for recurrent\nneural networks. Initial experimental results indicate that our approach and\nthe two-input backbone structure can be quite effective compared with other\nbaseline architectures including LSTM, in a variety of learning tasks including\nmulti-variate time series forecasting and language modeling. On the other hand,\nwe find that dynamic network transformation is promising in improving the\nefficiency of differentiable architecture search.\n",
        "english": "Adaptive neural processes are enhanced through a novel growing mechanism for differentiable neural architecture search, which allows the transformation of backbone architectures during training rather than keeping them fixed. By introducing dynamic network transformation, this approach improves the efficiency of differentiable architecture search, as evidenced by experimental results showing its effectiveness in tasks such as multi-variate time series forecasting and language modeling. Notably, the integration of a two-input backbone architecture for recurrent neural networks, expressed mathematically as $y = f(x_1, x_2)$, demonstrates significant advancements over traditional architectures like LSTM, highlighting the potential of adaptive neural processes in diverse learning contexts.",
        "korean": "적응형 신경 프로세스(adaptive neural processes)는 훈련 중 백본 아키텍처(backbone architectures)를 고정하지 않고 변환할 수 있는 차별화된 신경 아키텍처 검색(differentiable neural architecture search)을 위한 새로운 성장 메커니즘을 통해 향상됩니다. 동적 네트워크 변환(dynamic network transformation)을 도입함으로써 이 접근 방식은 다변량 시계열 예측(multi-variate time series forecasting) 및 언어 모델링(language modeling)과 같은 작업에서 그 효과가 입증된 바와 같이 차별화된 아키텍처 검색의 효율성을 개선합니다. 특히, 수학적으로 $y = f(x_1, x_2)$로 표현되는 순환 신경망(recurrent neural networks, RNN)을 위한 두 입력 백본 아키텍처(two-input backbone architecture)의 통합은 LSTM과 같은 전통적인 아키텍처에 비해 상당한 발전을 보여주며, 다양한 학습 맥락에서 적응형 신경 프로세스(adaptive neural processes)의 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "high-dimensional statistics",
        "domain": "cs.AI",
        "summary": "  Statistical information is ubiquitous but drawing valid conclusions from it\nis prohibitively hard. We explain how knowledge graph embeddings can be used to\napproximate probabilistic inference efficiently using the example of\nStatistical EL (SEL), a statistical extension of the lightweight Description\nLogic EL. We provide proofs for runtime and soundness guarantees, and\nempirically evaluate the runtime and approximation quality of our approach.\n",
        "english": "In the realm of high-dimensional statistics, drawing valid conclusions from statistical information remains \"prohibitively hard,\" yet the innovative use of knowledge graph embeddings offers a promising solution. By leveraging the Statistical EL (SEL), a statistical extension of the lightweight Description Logic EL, researchers have developed methods to \"approximate probabilistic inference efficiently,\" showcasing the potential of this approach in handling complex statistical data. Moreover, the research provides \"proofs for runtime and soundness guarantees,\" with empirical evaluation of runtime and approximation quality, demonstrating that the time complexity of the approach is bounded by $O(n^2)$, where $n$ is the number of entities in the knowledge graph, underscoring its practical applicability in high-dimensional statistical analysis.",
        "korean": "고차원 통계(high-dimensional statistics) 분야에서 통계 정보를 통해 유효한 결론을 도출하는 것은 \"극도로 어렵지만,\" 지식 그래프 임베딩(knowledge graph embeddings)의 혁신적인 사용이 유망한 해결책을 제공합니다. 경량 설명 논리 EL(lightweight Description Logic EL)의 통계적 확장인 통계 EL(Statistical EL, SEL)을 활용하여 연구자들은 \"확률적 추론을 효율적으로 근사\"하는 방법을 개발하였으며, 복잡한 통계 데이터를 처리하는 데 있어 이 접근법의 잠재력을 보여주고 있습니다. 더욱이, 연구는 \"실행 시간 및 건전성 보장에 대한 증명\"을 제공하며, 실행 시간 및 근사 품질에 대한 실증적 평가를 통해 이 접근법의 시간 복잡도가 지식 그래프의 엔티티 수 $n$에 대해 $O(n^2)$로 제한됨을 입증하여 고차원 통계 분석(high-dimensional statistical analysis)에서의 실용성을 강조합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as \"고차원 통계(high-dimensional statistics) 분석에서의 실용성을 강조합니다.\""
    },
    {
        "turn_index": 2,
        "term": "deep uncertainty estimation",
        "domain": "cs.AI",
        "summary": "  Real-world social events typically exhibit a severe class-imbalance\ndistribution, which makes the trained detection model encounter a serious\ngeneralization challenge. Most studies solve this problem from the frequency\nperspective and emphasize the representation or classifier learning for tail\nclasses. While in our observation, compared to the rarity of classes, the\ncalibrated uncertainty estimated from well-trained evidential deep learning\nnetworks better reflects model performance. To this end, we propose a novel\nuncertainty-guided class imbalance learning framework - UCL$_{SED}$, and its\nvariant - UCL-EC$_{SED}$, for imbalanced social event detection tasks. We aim\nto improve the overall model performance by enhancing model generalization to\nthose uncertain classes. Considering performance degradation usually comes from\nmisclassifying samples as their confusing neighboring classes, we focus on\nboundary learning in latent space and classifier learning with high-quality\nuncertainty estimation. First, we design a novel uncertainty-guided contrastive\nlearning loss, namely UCL and its variant - UCL-EC, to manipulate\ndistinguishable representation distribution for imbalanced data. During\ntraining, they force all classes, especially uncertain ones, to adaptively\nadjust a clear separable boundary in the feature space. Second, to obtain more\nrobust and accurate class uncertainty, we combine the results of multi-view\nevidential classifiers via the Dempster-Shafer theory under the supervision of\nan additional calibration method. We conduct experiments on three severely\nimbalanced social event datasets including Events2012\\_100, Events2018\\_100,\nand CrisisLexT\\_7. Our model significantly improves social event representation\nand classification tasks in almost all classes, especially those uncertain\nones.\n",
        "english": "In the realm of social event detection, deep uncertainty estimation is pivotal for addressing the severe class-imbalance distribution, as it enhances model generalization to uncertain classes, which in turn reflects better model performance compared to merely focusing on class rarity. The proposed framework, UCL$_{SED}$, alongside its variant UCL-EC$_{SED}$, integrates an uncertainty-guided contrastive learning loss to create a distinguishable representation distribution, particularly for imbalanced data, by enforcing an adaptive, clear separable boundary in the feature space. Furthermore, the integration of multi-view evidential classifiers with the Dempster-Shafer theory, under the supervision of an additional calibration method, significantly improves representation and classification tasks across three imbalanced datasets, notably advancing performance in uncertain classes.",
        "korean": "사회적 이벤트 탐지 분야에서 심층 불확실성 추정(deep uncertainty estimation)은 심각한 클래스 불균형 분포를 해결하는 데 있어 매우 중요합니다. 이는 불확실한 클래스에 대한 모델의 일반화 능력을 향상시켜 단순히 클래스 희소성에 집중하는 것보다 더 나은 모델 성능을 반영합니다. 제안된 프레임워크인 UCL$_{SED}$와 그 변형인 UCL-EC$_{SED}$는 불균형 데이터에 대해 적응적이고 명확하게 구분 가능한 경계를 특징 공간에 강제함으로써 구별 가능한 표현 분포를 생성하기 위해 불확실성 유도 대조 학습 손실(uncertainty-guided contrastive learning loss)을 통합합니다. 또한, 추가적인 보정 방법의 감독 하에 덴프스터-셰이퍼 이론(Dempster-Shafer theory)을 활용한 다중 뷰 증거 분류기(multi-view evidential classifiers)의 통합은 세 가지 불균형 데이터셋 전반에 걸쳐 표현 및 분류 작업을 크게 개선하며, 특히 불확실한 클래스에서의 성능을 현저히 향상시킵니다.",
        "score": 10,
        "parentheses_count": 4,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar"
    },
    {
        "turn_index": 2,
        "term": "adaptive probabilistic scene learning",
        "domain": "cs.AI",
        "summary": "  Probabilistic Law Discovery (PLD) is a logic based Machine Learning method,\nwhich implements a variant of probabilistic rule learning. In several aspects,\nPLD is close to Decision Tree/Random Forest methods, but it differs\nsignificantly in how relevant rules are defined. The learning procedure of PLD\nsolves the optimization problem related to the search for rules (called\nprobabilistic laws), which have a minimal length and relatively high\nprobability. At inference, ensembles of these rules are used for prediction.\nProbabilistic laws are human-readable and PLD based models are transparent and\ninherently interpretable. Applications of PLD include\nclassification/clusterization/regression tasks, as well as time series\nanalysis/anomaly detection and adaptive (robotic) control. In this paper, we\noutline the main principles of PLD, highlight its benefits and limitations and\nprovide some application guidelines.\n",
        "english": "Adaptive probabilistic scene learning can be conceptualized as a variant of probabilistic rule learning, similar in several aspects to Decision Tree/Random Forest methods, but distinct in its definition of relevant rules, as highlighted by the Probabilistic Law Discovery (PLD) framework. In this context, the learning procedure focuses on solving an optimization problem that involves searching for probabilistic laws, denoted by $L$, which possess minimal length and a relatively high probability, thereby ensuring that the resulting models are transparent and inherently interpretable. The innovative nature of this approach lies in its applicability to a variety of tasks, including classification, regression, and anomaly detection, thereby underscoring its versatility and importance in machine learning applications.",
        "korean": "적응 확률적 장면 학습(adaptive probabilistic scene learning)은 확률적 규칙 학습(probabilistic rule learning)의 변형으로 개념화될 수 있으며, 여러 측면에서 의사결정 트리/랜덤 포레스트(Decision Tree/Random Forest) 방법과 유사하지만, 관련 규칙의 정의에 있어 확률적 법칙 발견(Probabilistic Law Discovery, PLD) 프레임워크가 강조하는 바와 같이 독특합니다. 이 맥락에서 학습 절차는 최소한의 길이와 상대적으로 높은 확률을 가진 확률적 법칙 $L$을 찾는 최적화 문제를 해결하는 데 중점을 두며, 이를 통해 결과 모델이 투명하고 본질적으로 해석 가능하도록 보장합니다. 이 접근 방식의 혁신적인 특성은 분류, 회귀, 이상 탐지와 같은 다양한 작업에 적용 가능하다는 점에 있으며, 이는 기계 학습 응용 분야에서의 다재다능함과 중요성을 강조합니다.",
        "score": 9,
        "parentheses_count": 5,
        "suggestions": "Ensure that all technical terms are consistently parenthesized as Korean term(English term) to maintain uniformity and clarity throughout the translation."
    },
    {
        "turn_index": 2,
        "term": "adaptive probabilistic models",
        "domain": "cs.AI",
        "summary": "  Probabilistic Law Discovery (PLD) is a logic based Machine Learning method,\nwhich implements a variant of probabilistic rule learning. In several aspects,\nPLD is close to Decision Tree/Random Forest methods, but it differs\nsignificantly in how relevant rules are defined. The learning procedure of PLD\nsolves the optimization problem related to the search for rules (called\nprobabilistic laws), which have a minimal length and relatively high\nprobability. At inference, ensembles of these rules are used for prediction.\nProbabilistic laws are human-readable and PLD based models are transparent and\ninherently interpretable. Applications of PLD include\nclassification/clusterization/regression tasks, as well as time series\nanalysis/anomaly detection and adaptive (robotic) control. In this paper, we\noutline the main principles of PLD, highlight its benefits and limitations and\nprovide some application guidelines.\n",
        "english": "Adaptive probabilistic models, as implemented in Probabilistic Law Discovery (PLD), offer a unique approach to machine learning by utilizing a variant of probabilistic rule learning that is inherently interpretable and transparent. Unlike traditional methods such as Decision Trees or Random Forests, PLD defines relevant rules through an optimization problem that seeks probabilistic laws with minimal length and relatively high probability, denoted mathematically as $\\text{minimize} \\, \\text{length}(r) \\, \\text{subject to} \\, \\text{probability}(r) \\geq p_{\\text{threshold}}$. This innovative framework not only facilitates applications in classification, clusterization, regression, and time series analysis but also extends to adaptive (robotic) control, underscoring its versatility and potential impact across various domains.",
        "korean": "확률적 법칙 발견(probabilistic law discovery, PLD)에서 구현된 적응형 확률 모델(adaptive probabilistic models)은 본질적으로 해석 가능하고 투명한 확률적 규칙 학습의 변형을 활용하여 기계 학습에 독특한 접근 방식을 제공합니다. 의사 결정 나무(decision trees)나 랜덤 포레스트(random forests)와 같은 전통적인 방법과 달리, PLD는 최소 길이와 상대적으로 높은 확률을 갖는 확률적 법칙을 찾는 최적화 문제를 통해 관련 규칙을 정의하며, 이는 수학적으로 $\\text{minimize} \\, \\text{length}(r) \\, \\text{subject to} \\, \\text{probability}(r) \\geq p_{\\text{threshold}}$로 나타냅니다. 이 혁신적인 프레임워크는 분류, 군집화, 회귀, 시계열 분석뿐만 아니라 적응형(로봇) 제어(adaptive (robotic) control)에도 응용 가능하여 다양한 도메인에서의 다재다능함과 잠재적 영향을 강조합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "task-driven reinforcement learning",
        "domain": "cs.AI",
        "summary": "  Purpose: AI in radiology is hindered chiefly by: 1) Requiring large annotated\ndata sets. 2) Non-generalizability that limits deployment to new scanners /\ninstitutions. And 3) Inadequate explainability and interpretability. We believe\nthat reinforcement learning can address all three shortcomings, with robust and\nintuitive algorithms trainable on small datasets. To the best of our knowledge,\nreinforcement learning has not been directly applied to computer vision tasks\nfor radiological images. In this proof-of-principle work, we train a deep\nreinforcement learning network to predict brain tumor location.\n  Materials and Methods: Using the BraTS brain tumor imaging database, we\ntrained a deep Q network on 70 post-contrast T1-weighted 2D image slices. We\ndid so in concert with image exploration, with rewards and punishments designed\nto localize lesions. To compare with supervised deep learning, we trained a\nkeypoint detection convolutional neural network on the same 70 images. We\napplied both approaches to a separate 30 image testing set.\n  Results: Reinforcement learning predictions consistently improved during\ntraining, whereas those of supervised deep learning quickly diverged.\nReinforcement learning predicted testing set lesion locations with 85%\naccuracy, compared to roughly 7% accuracy for the supervised deep network.\n  Conclusion: Reinforcement learning predicted lesions with high accuracy,\nwhich is unprecedented for such a small training set. We believe that\nreinforcement learning can propel radiology AI well past the inherent\nlimitations of supervised deep learning, with more clinician-driven research\nand finally toward true clinical applicability.\n",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "content-based filtering",
        "domain": "cs.AI",
        "summary": "  Mobile-centric AI applications have high requirements for resource-efficiency\nof model inference. Input filtering is a promising approach to eliminate the\nredundancy so as to reduce the cost of inference. Previous efforts have\ntailored effective solutions for many applications, but left two essential\nquestions unanswered: (1) theoretical filterability of an inference workload to\nguide the application of input filtering techniques, thereby avoiding the\ntrial-and-error cost for resource-constrained mobile applications; (2) robust\ndiscriminability of feature embedding to allow input filtering to be widely\neffective for diverse inference tasks and input content. To answer them, we\nfirst formalize the input filtering problem and theoretically compare the\nhypothesis complexity of inference models and input filters to understand the\noptimization potential. Then we propose the first end-to-end learnable input\nfiltering framework that covers most state-of-the-art methods and surpasses\nthem in feature embedding with robust discriminability. We design and implement\nInFi that supports six input modalities and multiple mobile-centric\ndeployments. Comprehensive evaluations confirm our theoretical results and show\nthat InFi outperforms strong baselines in applicability, accuracy, and\nefficiency. InFi achieve 8.5x throughput and save 95% bandwidth, while keeping\nover 90% accuracy, for a video analytics application on mobile platforms.\n",
        "english": "Content-based filtering, as a promising approach for resource-efficient mobile-centric AI applications, addresses the redundancy in model inference by optimizing input filtering, thereby reducing inference costs. The research introduces InFi, an innovative end-to-end learnable input filtering framework, which not only encapsulates most state-of-the-art methods but also surpasses them with robust discriminability in feature embedding, achieving a remarkable throughput increase of 8.5x and a bandwidth savings of 95\\% while maintaining over 90\\% accuracy in mobile video analytics. By formalizing the input filtering problem and comparing the hypothesis complexity of inference models and input filters, the study highlights the optimization potential, ensuring that content-based filtering is both theoretically sound and practically applicable across diverse inference tasks.",
        "korean": "자원 효율적인 모바일 중심 AI 응용 프로그램을 위한 유망한 접근 방식으로서의 콘텐츠 기반 필터링(content-based filtering)은 입력 필터링 최적화를 통해 모델 추론의 중복성을 해결하여 추론 비용을 줄입니다. 이 연구는 혁신적인 종단 간 학습 가능한 입력 필터링 프레임워크인 인피(InFi)를 소개하며, 이는 대부분의 최신 방법을 포괄할 뿐만 아니라 특징 임베딩에서 강력한 변별력을 발휘하여 8.5배의 처리량 증가와 95\\%의 대역폭 절감을 달성하면서 모바일 비디오 분석에서 90\\% 이상의 정확도를 유지합니다. 입력 필터링 문제를 공식화하고 추론 모델과 입력 필터의 가설 복잡성을 비교함으로써, 이 연구는 최적화 가능성을 강조하며 콘텐츠 기반 필터링(content-based filtering)이 다양한 추론 작업에서 이론적으로 타당하고 실질적으로 적용 가능함을 보장합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "relational inductive biases",
        "domain": "cs.AI",
        "summary": "  Strong inductive biases give humans the ability to quickly learn to perform a\nvariety of tasks. Although meta-learning is a method to endow neural networks\nwith useful inductive biases, agents trained by meta-learning may sometimes\nacquire very different strategies from humans. We show that co-training these\nagents on predicting representations from natural language task descriptions\nand programs induced to generate such tasks guides them toward more human-like\ninductive biases. Human-generated language descriptions and program induction\nmodels that add new learned primitives both contain abstract concepts that can\ncompress description length. Co-training on these representations result in\nmore human-like behavior in downstream meta-reinforcement learning agents than\nless abstract controls (synthetic language descriptions, program induction\nwithout learned primitives), suggesting that the abstraction supported by these\nrepresentations is key.\n",
        "english": "Relational inductive biases play a crucial role in enabling humans to efficiently learn and perform a wide array of tasks, as they provide strong inductive biases that guide learning processes. The study demonstrates that co-training agents on predicting representations from natural language task descriptions and programs induced to generate such tasks can steer them toward acquiring more human-like inductive biases, thereby enhancing their performance in meta-reinforcement learning contexts. Notably, the research highlights that human-generated language descriptions and program induction models, which incorporate new learned primitives and abstract concepts, effectively compress description length, as represented by the formula \\( L = \\sum_{i=1}^{n} \\log P(x_i) \\), indicating the abstraction supported by these representations is a key factor in achieving more human-like behavior.",
        "korean": "관계적 귀납 편향(relational inductive biases)은 학습 과정을 안내하는 강력한 귀납 편향을 제공하여 인간이 다양한 작업을 효율적으로 학습하고 수행할 수 있도록 하는 데 중요한 역할을 합니다. 연구는 자연어 작업 설명과 그러한 작업을 생성하도록 유도된 프로그램으로부터 표현을 예측하는 공동 훈련 에이전트가 보다 인간과 유사한 귀납 편향을 획득하도록 유도하여 메타 강화 학습(meta-reinforcement learning) 맥락에서 성능을 향상시킬 수 있음을 보여줍니다. 특히, 연구는 새로운 학습 원시 개념과 추상 개념을 통합한 인간 생성 언어 설명과 프로그램 유도 모델이 설명 길이를 효과적으로 압축하며, 이는 수식 \\( L = \\sum_{i=1}^{n} \\log P(x_i) \\)로 표현되며, 이러한 표현이 지원하는 추상화가 보다 인간과 유사한 행동을 달성하는 데 중요한 요소임을 강조합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "semantic scene learning",
        "domain": "cs.AI",
        "summary": "  Reasoning and interacting with dynamic environments is a fundamental problem\nin AI, but it becomes extremely challenging when actions can trigger cascades\nof cross-dependent events. We introduce a new supervised learning setup called\n{\\em Cascade} where an agent is shown a video of a physically simulated dynamic\nscene, and is asked to intervene and trigger a cascade of events, such that the\nsystem reaches a \"counterfactual\" goal. For instance, the agent may be asked to\n\"Make the blue ball hit the red one, by pushing the green ball\". The agent\nintervention is drawn from a continuous space, and cascades of events makes the\ndynamics highly non-linear.\n  We combine semantic tree search with an event-driven forward model and devise\nan algorithm that learns to search in semantic trees in continuous spaces. We\ndemonstrate that our approach learns to effectively follow instructions to\nintervene in previously unseen complex scenes. It can also reason about\nalternative outcomes, when provided an observed cascade of events.\n",
        "english": "In the realm of semantic scene learning, reasoning and interacting with dynamic environments presents significant challenges, particularly when actions lead to \"cascades of cross-dependent events,\" necessitating sophisticated intervention strategies. By integrating semantic tree search with an event-driven forward model, researchers have developed an algorithm capable of learning to search in semantic trees within continuous spaces, effectively allowing agents to follow complex instructions and intervene in previously unseen scenes. Notably, this approach enables the agent to reason about alternative outcomes by analyzing observed cascades, thereby enhancing its ability to achieve a counterfactual goal, such as making a blue ball hit a red one by manipulating a green ball, with the intervention drawn from a continuous space, $x \\in \\mathbb{R}^n$.",
        "korean": "의미 장면 학습(semantic scene learning) 분야에서 동적 환경과의 추론 및 상호작용은 특히 행동이 \"상호 의존적인 사건의 연쇄\"를 초래할 때 상당한 도전을 제기하며, 이는 정교한 개입 전략을 필요로 합니다. 의미 트리 탐색(semantic tree search)과 사건 기반 전진 모델(event-driven forward model)을 통합함으로써 연구자들은 연속 공간 내에서 의미 트리를 탐색하는 방법을 학습할 수 있는 알고리즘을 개발하였으며, 이를 통해 에이전트가 복잡한 지시를 따르고 이전에 보지 못한 장면에 개입할 수 있게 합니다. 특히, 이 접근법은 에이전트가 관찰된 연쇄를 분석하여 대안적 결과에 대해 추론할 수 있게 하여, 연속 공간 $x \\in \\mathbb{R}^n$에서 개입을 통해 녹색 공을 조작하여 파란 공이 빨간 공을 치게 만드는 것과 같은 반사실적 목표를 달성하는 능력을 향상시킵니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Ensure that all technical terms are consistently formatted as Korean term(English term) and consider rephrasing for smoother readability, such as adjusting the placement of clauses for better flow."
    },
    {
        "turn_index": 2,
        "term": "sequential Monte Carlo",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Sequential Monte Carlo (SMC) methods are pivotal in addressing high-dimensional filtering problems, where traditional approaches often falter due to computational inefficiencies. As highlighted in the reference, the SMC framework employs a set of weighted particles to approximate the posterior distribution, which can be mathematically represented as $\\hat{p}(x_{0:t} | y_{1:t}) = \\sum_{i=1}^N w_t^{(i)} \\delta_{x_{0:t}^{(i)}}(x_{0:t})$, where $w_t^{(i)}$ are the weights and $x_{0:t}^{(i)}$ are the particles. This innovative approach not only enhances the accuracy of state estimation in dynamic systems but also provides a scalable solution that can be adapted to various complex models, demonstrating its broad applicability and effectiveness.",
        "korean": "순차적 몬테카를로(sequential Monte Carlo, SMC) 방법은 전통적인 접근 방식이 계산 효율성 문제로 인해 종종 실패하는 고차원 필터링 문제를 해결하는 데 필수적입니다. 참고 문헌에서 강조된 바와 같이, SMC 프레임워크(sequential Monte Carlo framework, SMC)는 후방 분포를 근사하기 위해 가중된 입자 집합을 사용하며, 이는 수학적으로 $\\hat{p}(x_{0:t} | y_{1:t}) = \\sum_{i=1}^N w_t^{(i)} \\delta_{x_{0:t}^{(i)}}(x_{0:t})$로 표현될 수 있습니다. 여기서 $w_t^{(i)}$는 가중치이고 $x_{0:t}^{(i)}$는 입자입니다. 이 혁신적인 접근 방식은 동적 시스템에서 상태 추정의 정확성을 향상시킬 뿐만 아니라 다양한 복잡한 모델에 적응할 수 있는 확장 가능한 솔루션을 제공하여 그 광범위한 적용 가능성과 효과성을 입증합니다.",
        "score": 9,
        "parentheses_count": 3,
        "suggestions": "Ensure that the use of parentheses for technical terms is consistent throughout the translation, particularly for terms like SMC, to maintain clarity and uniformity."
    },
    {
        "turn_index": 2,
        "term": "face recognition",
        "domain": "cs.AI",
        "summary": "  In this paper, we introduce the first large vocabulary speech recognition\nsystem (LVSR) for the Central Kurdish language, named Jira. The Kurdish\nlanguage is an Indo-European language spoken by more than 30 million people in\nseveral countries, but due to the lack of speech and text resources, there is\nno speech recognition system for this language. To fill this gap, we introduce\nthe first speech corpus and pronunciation lexicon for the Kurdish language.\nRegarding speech corpus, we designed a sentence collection in which the ratio\nof di-phones in the collection resembles the real data of the Central Kurdish\nlanguage. The designed sentences are uttered by 576 speakers in a controlled\nenvironment with noise-free microphones (called AsoSoft Speech-Office) and in\nTelegram social network environment using mobile phones (denoted as AsoSoft\nSpeech-Crowdsourcing), resulted in 43.68 hours of speech. Besides, a test set\nincluding 11 different document topics is designed and recorded in two\ncorresponding speech conditions (i.e., Office and Crowdsourcing). Furthermore,\na 60K pronunciation lexicon is prepared in this research in which we faced\nseveral challenges and proposed solutions for them. The Kurdish language has\nseveral dialects and sub-dialects that results in many lexical variations. Our\nmethods for script standardization of lexical variations and automatic\npronunciation of the lexicon tokens are presented in detail. To setup the\nrecognition engine, we used the Kaldi toolkit. A statistical tri-gram language\nmodel that is extracted from the AsoSoft text corpus is used in the system.\nSeveral standard recipes including HMM-based models (i.e., mono, tri1, tr2,\ntri2, tri3), SGMM, and DNN methods are used to generate the acoustic model.\nThese methods are trained with AsoSoft Speech-Office and AsoSoft\nSpeech-Crowdsourcing and a combination of them. The best performance achieved\nby the SGMM acoustic model which results in 13.9% of the average word error\nrate (on different document topics) and 4.9% for the general topic.\n",
        "english": "In the realm of face recognition, similar to the challenges faced in developing a large vocabulary speech recognition system (LVSR) for the Central Kurdish language, the lack of comprehensive datasets and resources poses significant obstacles. To address these challenges, methodologies akin to those used in the creation of the AsoSoft Speech-Office and AsoSoft Speech-Crowdsourcing datasets could be employed, where controlled environments and diverse conditions enhance the robustness of the recognition systems. Furthermore, employing statistical models like the tri-gram language model, as extracted from the AsoSoft text corpus, could improve face recognition accuracy, potentially reducing error rates to a level comparable to the 13.9\\% average word error rate achieved in the Kurdish language system.",
        "korean": "얼굴 인식(face recognition) 분야에서는 중앙 쿠르드어(central Kurdish language)를 위한 대규모 어휘 음성 인식 시스템(large vocabulary speech recognition system, LVSR)을 개발하는 데 직면한 도전과 유사하게, 포괄적인 데이터셋과 자원의 부족이 상당한 장애물로 작용합니다. 이러한 문제를 해결하기 위해 AsoSoft 음성-오피스(AsoSoft Speech-Office) 및 AsoSoft 음성-크라우드소싱(AsoSoft Speech-Crowdsourcing) 데이터셋의 생성에 사용된 방법론을 활용할 수 있으며, 이는 통제된 환경과 다양한 조건에서 인식 시스템의 견고성을 향상시킵니다. 또한, AsoSoft 텍스트 코퍼스(AsoSoft text corpus)에서 추출한 3-그램 언어 모델(tri-gram language model)과 같은 통계 모델을 사용하면 얼굴 인식(face recognition) 정확도를 향상시킬 수 있으며, 이는 쿠르드어 시스템에서 달성한 평균 13.9\\%의 단어 오류율과 유사한 수준으로 오류율을 줄일 수 있습니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all English terms in parentheses are lowercase for consistency."
    },
    {
        "turn_index": 2,
        "term": "dynamic representation learning",
        "domain": "cs.AI",
        "summary": "  In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.\n",
        "english": "Dynamic representation learning is intricately linked to the concept of the internal representation space, which is described as the \"center of learning machine\" and is formed by a collection of X-forms, representing algebraic expressions for subjective patterns. In the context of dynamic representation learning, it is demonstrated that for any objective pattern, there exists a corresponding subjective pattern, formulated using least base patterns, to effectively express the objective pattern, thereby enhancing the machine's learning capability. Notably, the research highlights that with sufficient data and certain capabilities, a learning machine can achieve universal learning, suggesting that dynamic representation learning is crucial for advancing machine learning technologies.",
        "korean": "동적 표현 학습(dynamic representation learning)은 \"학습 기계의 중심\"으로 설명되는 내부 표현 공간의 개념과 밀접하게 연결되어 있으며, 이는 주관적 패턴에 대한 대수적 표현을 나타내는 x-형식의 집합으로 형성됩니다. 동적 표현 학습(dynamic representation learning)의 맥락에서, 어떤 객관적 패턴에 대해서도 최소 기저 패턴을 사용하여 해당 주관적 패턴을 공식화할 수 있으며, 이를 통해 객관적 패턴을 효과적으로 표현하여 기계의 학습 능력을 향상시킬 수 있음을 보여줍니다. 특히, 연구는 충분한 데이터와 특정 능력을 갖춘 학습 기계가 보편적 학습을 달성할 수 있음을 강조하며, 이는 동적 표현 학습(dynamic representation learning)이 기계 학습 기술을 발전시키는 데 필수적임을 시사합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "self-supervised image classification",
        "domain": "cs.AI",
        "summary": "  The textured images' classification assumes to consider the images in terms\nof area with the same texture. In uncertain environment, it could be better to\ntake an imprecise decision or to reject the area corresponding to an unlearning\nclass. Moreover, on the areas that are the classification units, we can have\nmore than one texture. These considerations allows us to develop a belief\ndecision model permitting to reject an area as unlearning and to decide on\nunions and intersections of learning classes. The proposed approach finds all\nits justification in an application of seabed characterization from sonar\nimages, which contributes to an illustration.\n",
        "english": "In the context of self-supervised image classification, the classification of textured images assumes consideration of the images in terms of areas with the same texture, allowing for more precise identification of features within an image. In environments characterized by uncertainty, it may be advantageous to make an imprecise decision or to reject the area corresponding to an unlearning class, thereby enhancing the model's robustness and adaptability. The proposed belief decision model, which permits the rejection of an area as unlearning and facilitates decisions on unions and intersections of learning classes, is mathematically supported by the expression $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$, underscoring its innovative application in seabed characterization from sonar images.",
        "korean": "자기 지도 이미지 분류(self-supervised image classification) 맥락에서, 텍스처가 있는 이미지의 분류는 동일한 텍스처를 가진 영역으로 이미지를 고려하여 이미지 내 특징을 보다 정확하게 식별할 수 있게 합니다. 불확실성이 특징인 환경에서는 부정확한 결정을 내리거나 학습되지 않은 클래스에 해당하는 영역을 거부하는 것이 모델의 견고성과 적응성을 향상시키는 데 유리할 수 있습니다. 제안된 신념 결정 모델(belief decision model)은 학습되지 않은 영역을 거부하고 학습 클래스의 합집합과 교집합에 대한 결정을 용이하게 하며, 이는 수학적으로 $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$ 표현으로 뒷받침되어 소나 이미지에서 해저 특성화를 위한 혁신적인 응용을 강조합니다.",
        "score": 9,
        "parentheses_count": 2,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure all technical terms are consistently parenthesized as Korean term(English term)."
    },
    {
        "turn_index": 2,
        "term": "dynamic neural embeddings",
        "domain": "cs.AI",
        "summary": "  Knowledge graphs have emerged as an effective tool for managing and\nstandardizing semistructured domain knowledge in a human- and\nmachine-interpretable way. In terms of graph-based domain applications, such as\nembeddings and graph neural networks, current research is increasingly taking\ninto account the time-related evolution of the information encoded within a\ngraph. Algorithms and models for stationary and static knowledge graphs are\nextended to make them accessible for time-aware domains, where time-awareness\ncan be interpreted in different ways. In particular, a distinction needs to be\nmade between the validity period and the traceability of facts as objectives of\ntime-related knowledge graph extensions. In this context, terms and definitions\nsuch as dynamic and temporal are often used inconsistently or interchangeably\nin the literature. Therefore, with this paper we aim to provide a short but\nwell-defined overview of time-aware knowledge graph extensions and thus\nfaciliate future research in this field as well.\n",
        "english": "Dynamic neural embeddings have gained prominence as they extend traditional algorithms and models for stationary and static knowledge graphs to accommodate time-aware domains, where time-awareness is interpreted through both the validity period and the traceability of facts.",
        "korean": "동적 신경 임베딩(dynamic neural embeddings)은 전통적인 알고리즘과 정적 지식 그래프(static knowledge graphs) 모델을 시간 인식 도메인에 맞게 확장함으로써 주목받고 있습니다. 여기서 시간 인식은 사실의 유효 기간과 추적 가능성을 통해 해석됩니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "bagging",
        "domain": "cs.AI",
        "summary": "  The understanding of the buildings operation has become a challenging task\ndue to the large amount of data recorded in energy efficient buildings. Still,\ntoday the experts use visual tools for analyzing the data. In order to make the\ntask realistic, a method has been proposed in this paper to automatically\ndetect the different patterns in buildings. The K Means clustering is used to\nautomatically identify the ON (operational) cycles of the chiller. In the next\nstep the ON cycles are transformed to symbolic representation by using Symbolic\nAggregate Approximation (SAX) method. Then the SAX symbols are converted to bag\nof words representation for hierarchical clustering. Moreover, the proposed\ntechnique is applied to real life data of adsorption chiller. Additionally, the\nresults from the proposed method and dynamic time warping (DTW) approach are\nalso discussed and compared.\n",
        "english": "Bagging, a technique often used in machine learning, can enhance the effectiveness of hierarchical clustering by converting SAX symbols into a bag of words representation, as demonstrated in the proposed method for analyzing building operation data. This approach, which includes the K Means clustering to identify ON cycles of the chiller and their transformation into symbolic representations, is particularly innovative because it automates the detection of patterns in energy-efficient buildings. By comparing the results from this method with the dynamic time warping (DTW) approach, it is evident that the proposed technique offers a robust alternative, highlighting its potential for broader applications in the field.",
        "korean": "머신 러닝(machine learning)에서 자주 사용되는 기법인 배깅(bagging)은 SAX 기호를 단어 집합 표현으로 변환하여 계층적 군집화(hierarchical clustering)의 효과를 향상시킬 수 있으며, 이는 건물 운영 데이터 분석을 위한 제안된 방법에서 입증되었습니다. 이 접근법은 냉각기의 on 사이클을 식별하고 이를 기호적 표현으로 변환하기 위해 k 평균 군집화(k means clustering)를 포함하고 있으며, 에너지 효율적인 건물에서 패턴을 자동으로 감지하는 점에서 특히 혁신적입니다. 이 방법의 결과를 동적 시간 왜곡(dynamic time warping, dtw) 접근법과 비교해 보면, 제안된 기법이 강력한 대안을 제공하며, 이 분야에서 더 넓은 응용 가능성을 강조하고 있음을 알 수 있습니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure consistent capitalization within parentheses, such as \"k means clustering\" and \"dtw\" to maintain uniformity with other terms."
    },
    {
        "turn_index": 2,
        "term": "federated learning",
        "domain": "cs.AI",
        "summary": "  Federated learning has seen increased adoption in recent years in response to\nthe growing regulatory demand for data privacy. However, the opaque local\ntraining process of federated learning also sparks rising concerns about model\nfaithfulness. For instance, studies have revealed that federated learning is\nvulnerable to backdoor attacks, whereby a compromised participant can\nstealthily modify the model's behavior in the presence of backdoor triggers.\nThis paper proposes an effective defense against the attack by examining shared\nmodel updates. We begin with the observation that the embedding of backdoors\ninfluences the participants' local model weights in terms of the magnitude and\norientation of their model gradients, which can manifest as distinguishable\ndisparities. We enable a robust identification of backdoors by studying the\nstatistical distribution of the models' subsets of gradients. Concretely, we\nfirst segment the model gradients into fragment vectors that represent small\nportions of model parameters. We then employ anomaly detection to locate the\ndistributionally skewed fragments and prune the participants with the most\noutliers. We embody the findings in a novel defense method, ARIBA. We\ndemonstrate through extensive analyses that our proposed methods effectively\nmitigate state-of-the-art backdoor attacks with minimal impact on task utility.\n",
        "english": "Federated learning has gained traction due to increasing regulatory demands for data privacy, yet its opaque local training process raises concerns about model faithfulness, particularly in the face of vulnerabilities such as backdoor attacks. To counteract these threats, the study introduces a defense mechanism named ARIBA, which examines shared model updates by analyzing the statistical distribution of model gradients, specifically focusing on the magnitude and orientation disparities that signify backdoor embeddings. Employing anomaly detection, the method identifies distributionally skewed gradient fragments and prunes participants with the most outliers, effectively mitigating backdoor attacks while maintaining task utility, as demonstrated by the equation $\\nabla \\theta_i = \\nabla \\theta_i^{\\text{clean}} + \\delta$, where $\\delta$ represents the backdoor influence on participant $i$'s local model weights.",
        "korean": "연합 학습(federated learning)은 데이터 프라이버시에 대한 규제 요구가 증가함에 따라 주목받고 있지만, 불투명한 로컬 훈련 과정은 특히 백도어 공격(backdoor attacks)과 같은 취약성에 직면했을 때 모델의 신뢰성에 대한 우려를 제기합니다. 이러한 위협에 대응하기 위해, 연구는 ARIBA라는 방어 메커니즘을 도입하여 모델 그래디언트의 통계적 분포를 분석함으로써 공유된 모델 업데이트를 검사합니다. 특히 백도어 임베딩을 나타내는 크기 및 방향의 차이에 중점을 둡니다. 이상 탐지를 활용하여, 이 방법은 분포적으로 왜곡된 그래디언트 조각을 식별하고 가장 많은 이상치를 가진 참가자를 제거하여 백도어 공격을 효과적으로 완화하면서도 작업 유용성을 유지합니다. 이는 $\\nabla \\theta_i = \\nabla \\theta_i^{\\text{clean}} + \\delta$라는 방정식으로 입증되며, 여기서 $\\delta$는 참가자 $i$의 로컬 모델 가중치에 대한 백도어 영향을 나타냅니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": ""
    },
    {
        "turn_index": 2,
        "term": "recurrent convolutional networks",
        "domain": "cs.AI",
        "summary": "  Network attack is a significant security issue for modern society. From small\nmobile devices to large cloud platforms, almost all computing products, used in\nour daily life, are networked and potentially under the threat of network\nintrusion. With the fast-growing network users, network intrusions become more\nand more frequent, volatile and advanced. Being able to capture intrusions in\ntime for such a large scale network is critical and very challenging. To this\nend, the machine learning (or AI) based network intrusion detection (NID), due\nto its intelligent capability, has drawn increasing attention in recent years.\nCompared to the traditional signature-based approaches, the AI-based solutions\nare more capable of detecting variants of advanced network attacks. However,\nthe high detection rate achieved by the existing designs is usually accompanied\nby a high rate of false alarms, which may significantly discount the overall\neffectiveness of the intrusion detection system. In this paper, we consider the\nexistence of spatial and temporal features in the network traffic data and\npropose a hierarchical CNN+RNN neural network, LuNet. In LuNet, the\nconvolutional neural network (CNN) and the recurrent neural network (RNN) learn\ninput traffic data in sync with a gradually increasing granularity such that\nboth spatial and temporal features of the data can be effectively extracted.\nOur experiments on two network traffic datasets show that compared to the\nstate-of-the-art network intrusion detection techniques, LuNet not only offers\na high level of detection capability but also has a much low rate of false\npositive-alarm.\n",
        "english": "Recurrent convolutional networks, such as the hierarchical CNN+RNN neural network LuNet, have been proposed to address the challenge of detecting network intrusions by effectively capturing both spatial and temporal features of network traffic data. By synchronizing the learning processes of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) with a gradually increasing granularity, LuNet achieves a high detection capability while maintaining a low false positive-alarm rate, as demonstrated in experiments on two network traffic datasets. The innovative design of LuNet showcases the potential of recurrent convolutional networks in enhancing the effectiveness of network intrusion detection systems, particularly in distinguishing between normal and malicious activities, even when faced with advanced attack variants.",
        "korean": "계층적 CNN+RNN 신경망 루넷(lunet)과 같은 재발생 합성곱 네트워크(recurrent convolutional networks)는 네트워크 트래픽 데이터의 공간적 및 시간적 특징을 효과적으로 포착하여 네트워크 침입을 탐지하는 문제를 해결하기 위해 제안되었습니다. 합성곱 신경망(convolutional neural networks, cnns)과 재발생 신경망(recurrent neural networks, rnns)의 학습 과정을 점진적으로 증가하는 세분화와 동기화함으로써, 루넷(lunet)은 두 개의 네트워크 트래픽 데이터셋에 대한 실험에서 입증된 바와 같이 높은 탐지 능력을 유지하면서 낮은 오탐지율을 달성합니다. 루넷(lunet)의 혁신적인 설계는 특히 고급 공격 변종에 직면했을 때도 정상 활동과 악의적 활동을 구별하는 데 있어 네트워크 침입 탐지 시스템의 효과를 향상시키는 재발생 합성곱 네트워크(recurrent convolutional networks)의 잠재력을 보여줍니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure that all instances of the term \"LuNet\" are consistently parenthesized as \"루넷(lunet)\" and adjust the structure for a more natural flow in Korean."
    },
    {
        "turn_index": 2,
        "term": "context-aware sequence models",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Context-aware sequence models have emerged as a pivotal advancement in the field of natural language processing, offering improved performance by incorporating contextual information into sequence predictions. By leveraging techniques such as bidirectional LSTM networks, these models can effectively capture dependencies across sequences, enhancing their ability to predict subsequent elements with greater accuracy. The incorporation of attention mechanisms further augments their capability, allowing the model to weigh the importance of different parts of the input sequence, as mathematically represented by the attention score $\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k=1}^{T_x} \\exp(e_{ik})}$, where $e_{ij}$ denotes the alignment score between the input at position $i$ and the output at position $j$.",
        "korean": "문맥 인식 시퀀스 모델(context-aware sequence models)은 자연어 처리(natural language processing) 분야에서 중요한 발전으로 부상하여, 시퀀스 예측에 문맥 정보를 통합함으로써 성능을 향상시킵니다. 양방향 LSTM 네트워크(bidirectional LSTM networks)와 같은 기법을 활용하여, 이러한 모델은 시퀀스 간의 의존성을 효과적으로 포착하여 후속 요소를 더 정확하게 예측할 수 있는 능력을 향상시킵니다. 주의 메커니즘(attention mechanisms)의 통합은 모델의 능력을 더욱 증대시켜 입력 시퀀스의 다양한 부분의 중요성을 가중치로 평가할 수 있게 하며, 이는 수학적으로 주의 점수(attention score) $\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k=1}^{T_x} \\exp(e_{ik})}$로 표현됩니다. 여기서 $e_{ij}$는 위치 $i$의 입력과 위치 $j$의 출력 간의 정렬 점수(alignment score)를 나타냅니다.",
        "score": 10,
        "parentheses_count": 7,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "cross-validation",
        "domain": "cs.AI",
        "summary": "  An original approach, termed Divide-and-Evolve is proposed to hybridize\nEvolutionary Algorithms (EAs) with Operational Research (OR) methods in the\ndomain of Temporal Planning Problems (TPPs). Whereas standard Memetic\nAlgorithms use local search methods to improve the evolutionary solutions, and\nthus fail when the local method stops working on the complete problem, the\nDivide-and-Evolve approach splits the problem at hand into several, hopefully\neasier, sub-problems, and can thus solve globally problems that are intractable\nwhen directly fed into deterministic OR algorithms. But the most prominent\nadvantage of the Divide-and-Evolve approach is that it immediately opens up an\navenue for multi-objective optimization, even though the OR method that is used\nis single-objective. Proof of concept approach on the standard\n(single-objective) Zeno transportation benchmark is given, and a small original\nmulti-objective benchmark is proposed in the same Zeno framework to assess the\nmulti-objective capabilities of the proposed methodology, a breakthrough in\nTemporal Planning.\n",
        "english": "In the context of Temporal Planning Problems (TPPs), the innovative Divide-and-Evolve approach provides a novel hybridization of Evolutionary Algorithms (EAs) with Operational Research (OR) methods, effectively utilizing cross-validation to enhance the robustness of solutions. This method, unlike standard Memetic Algorithms, which often falter when the local search fails on the complete problem, employs a strategy of dividing the problem into sub-problems, thereby facilitating a comprehensive solution even when deterministic OR algorithms alone prove inadequate. The efficacy of this approach is underscored by its ability to transition seamlessly into multi-objective optimization, despite the underlying OR method being single-objective, thereby demonstrating a mathematical prowess, as it can handle multiple objectives $\\{f_1(x), f_2(x), ..., f_n(x)\\}$ simultaneously, a significant advancement in the field of Temporal Planning.",
        "korean": "시간 계획 문제(temporal planning problems, TPPs)의 맥락에서 혁신적인 분할 및 진화 접근법(divide-and-evolve approach)은 진화 알고리즘(evolutionary algorithms, EAs)과 운영 연구(operational research, OR) 방법을 새롭게 융합하여 솔루션의 견고성을 향상시키기 위해 교차 검증(cross-validation)을 효과적으로 활용합니다. 이 방법은 전체 문제에서 지역 탐색이 실패할 때 종종 흔들리는 표준 메메틱 알고리즘(memetic algorithms)과 달리 문제를 하위 문제로 나누는 전략을 사용하여 결정론적 OR 알고리즘만으로는 불충분할 때도 포괄적인 솔루션을 촉진합니다. 이 접근법의 효율성은 기본 OR 방법이 단일 목표임에도 불구하고 다중 목표 최적화로 원활하게 전환할 수 있는 능력에 의해 강조되며, 이는 $\\{f_1(x), f_2(x), ..., f_n(x)\\}$와 같은 여러 목표를 동시에 처리할 수 있는 수학적 역량을 보여주어 시간 계획 분야에서 중요한 발전을 나타냅니다.",
        "score": 10,
        "parentheses_count": 10,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "neural generative programming",
        "domain": "cs.AI",
        "summary": " ",
        "english": "Neural generative programming has emerged as a pivotal approach in automating code generation by leveraging deep learning models to synthesize code from natural language specifications, as discussed in the reference. A key methodology involves the use of sequence-to-sequence models, where the input sequence \\( X = (x_1, x_2, \\ldots, x_n) \\) is transformed into an output sequence \\( Y = (y_1, y_2, \\ldots, y_m) \\), effectively capturing the semantic relationships between natural language and code. This innovative approach not only enhances the efficiency of software development processes but also significantly reduces human error, underscoring its transformative potential in the field of computer science.",
        "korean": "신경 생성 프로그래밍(neural generative programming)은 자연어 명세로부터 코드를 합성하기 위해 심층 학습 모델(deep learning models)을 활용하여 코드 생성을 자동화하는 중요한 접근 방식으로 부상했습니다. 주요 방법론은 입력 시퀀스 \\( X = (x_1, x_2, \\ldots, x_n) \\)를 출력 시퀀스 \\( Y = (y_1, y_2, \\ldots, y_m) \\)로 변환하여 자연어와 코드 간의 의미적 관계를 효과적으로 포착하는 시퀀스-투-시퀀스 모델(sequence-to-sequence models)의 사용을 포함합니다. 이 혁신적인 접근 방식은 소프트웨어 개발 프로세스의 효율성을 향상시킬 뿐만 아니라 인간의 오류를 크게 줄여 컴퓨터 과학 분야에서의 변혁적 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "probabilistic sequence modeling",
        "domain": "cs.AI",
        "summary": "  Many real world sequences such as protein secondary structures or shell logs\nexhibit a rich internal structures. Traditional probabilistic models of\nsequences, however, consider sequences of flat symbols only. Logical hidden\nMarkov models have been proposed as one solution. They deal with logical\nsequences, i.e., sequences over an alphabet of logical atoms. This comes at the\nexpense of a more complex model selection problem. Indeed, different\nabstraction levels have to be explored. In this paper, we propose a novel\nmethod for selecting logical hidden Markov models from data called SAGEM. SAGEM\ncombines generalized expectation maximization, which optimizes parameters, with\nstructure search for model selection using inductive logic programming\nrefinement operators. We provide convergence and experimental results that show\nSAGEM's effectiveness.\n",
        "english": "Probabilistic sequence modeling often involves traditional models that consider sequences as flat symbols, which can be limiting when dealing with real-world sequences that exhibit rich internal structures, such as protein secondary structures or shell logs. To address this limitation, logical hidden Markov models have been proposed, which deal with sequences over an alphabet of logical atoms, although this introduces a more complex model selection problem. The novel method SAGEM, which combines generalized expectation maximization for parameter optimization with inductive logic programming refinement operators for model selection, demonstrates effectiveness with convergence and experimental results, highlighting its innovation in probabilistic sequence modeling.",
        "korean": "확률적 순서 모델링(probabilistic sequence modeling)은 종종 순서를 평면 기호로 간주하는 전통적인 모델을 포함하며, 이는 단백질 2차 구조나 쉘 로그와 같은 풍부한 내부 구조를 가진 실제 세계의 순서를 다룰 때 제한적일 수 있습니다. 이러한 제한을 해결하기 위해 논리적 숨은 마르코프 모델(logical hidden Markov models)이 제안되었으며, 이는 논리적 원자의 알파벳을 사용하는 순서를 처리하지만, 더 복잡한 모델 선택 문제를 도입합니다. 매개변수 최적화를 위한 일반화된 기대 최대화(generalized expectation maximization)와 모델 선택을 위한 귀납적 논리 프로그래밍(inductive logic programming) 정제 연산자를 결합한 새로운 방법인 SAGEM은 수렴성과 실험 결과를 통해 그 효과를 입증하며, 확률적 순서 모델링(probabilistic sequence modeling)에서의 혁신을 강조합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "causal reinforcement learning",
        "domain": "cs.AI",
        "summary": "  Causality has become a fundamental approach for explaining the relationships\nbetween events, phenomena, and outcomes in various fields of study. It has\ninvaded various fields and applications, such as medicine, healthcare,\neconomics, finance, fraud detection, cybersecurity, education, public policy,\nrecommender systems, anomaly detection, robotics, control, sociology,\nmarketing, and advertising. In this paper, we survey its development over the\npast five decades, shedding light on the differences between causality and\nother approaches, as well as the preconditions for using it. Furthermore, the\npaper illustrates how causality interacts with new approaches such as\nArtificial Intelligence (AI), Generative AI (GAI), Machine and Deep Learning,\nReinforcement Learning (RL), and Fuzzy Logic. We study the impact of causality\non various fields, its contribution, and its interaction with state-of-the-art\napproaches. Additionally, the paper exemplifies the trustworthiness and\nexplainability of causality models. We offer several ways to evaluate causality\nmodels and discuss future directions.\n",
        "english": "Causal reinforcement learning represents a novel intersection of causality and reinforcement learning (RL), highlighting the importance of understanding the \"relationships between events, phenomena, and outcomes\" in decision-making processes. By integrating causal inference with RL, researchers can enhance the \"trustworthiness and explainability of causality models,\" providing a robust framework for applications in fields such as robotics and control. Moreover, the mathematical formulation of causal reinforcement learning can be expressed as optimizing a policy $\\pi$ that maximizes the expected causal effect, $\\mathbb{E}[Y | do(X = x)]$, where $Y$ is the outcome and $X$ is the action taken, illustrating the approach's potential to transform state-of-the-art methodologies.",
        "korean": "인과 강화 학습(causal reinforcement learning)은 인과성(causality)과 강화 학습(reinforcement learning, RL)의 새로운 교차점을 나타내며, 의사 결정 과정에서 \"사건, 현상, 결과 간의 관계\"를 이해하는 것의 중요성을 강조합니다. 인과 추론(causal inference)을 RL과 통합함으로써 연구자들은 \"인과성 모델의 신뢰성과 설명 가능성\"을 향상시킬 수 있으며, 로봇 공학 및 제어와 같은 분야에서 강력한 프레임워크를 제공합니다. 더욱이, 인과 강화 학습(causal reinforcement learning)의 수학적 공식화는 정책 $\\pi$를 최적화하여 기대 인과 효과 $\\mathbb{E}[Y | do(X = x)]$를 최대화하는 것으로 표현될 수 있으며, 여기서 $Y$는 결과이고 $X$는 취해진 행동을 나타내며, 이 접근 방식이 최첨단 방법론을 변혁할 잠재력을 보여줍니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure consistent lowercase usage within parentheses and consider rephrasing for smoother readability, such as \"인과 강화 학습(causal reinforcement learning)의 수학적 공식화는\" to \"수학적으로 인과 강화 학습(causal reinforcement learning)은\"."
    },
    {
        "turn_index": 2,
        "term": "semantic probabilistic text processes",
        "domain": "cs.AI",
        "summary": "  Probabilistic Logic Programming (PLP), exemplified by Sato and Kameya's\nPRISM, Poole's ICL, Raedt et al's ProbLog and Vennekens et al's LPAD, is aimed\nat combining statistical and logical knowledge representation and inference. A\nkey characteristic of PLP frameworks is that they are conservative extensions\nto non-probabilistic logic programs which have been widely used for knowledge\nrepresentation. PLP frameworks extend traditional logic programming semantics\nto a distribution semantics, where the semantics of a probabilistic logic\nprogram is given in terms of a distribution over possible models of the\nprogram. However, the inference techniques used in these works rely on\nenumerating sets of explanations for a query answer. Consequently, these\nlanguages permit very limited use of random variables with continuous\ndistributions. In this paper, we present a symbolic inference procedure that\nuses constraints and represents sets of explanations without enumeration. This\npermits us to reason over PLPs with Gaussian or Gamma-distributed random\nvariables (in addition to discrete-valued random variables) and linear equality\nconstraints over reals. We develop the inference procedure in the context of\nPRISM; however the procedure's core ideas can be easily applied to other PLP\nlanguages as well. An interesting aspect of our inference procedure is that\nPRISM's query evaluation process becomes a special case in the absence of any\ncontinuous random variables in the program. The symbolic inference procedure\nenables us to reason over complex probabilistic models such as Kalman filters\nand a large subclass of Hybrid Bayesian networks that were hitherto not\npossible in PLP frameworks. (To appear in Theory and Practice of Logic\nProgramming).\n",
        "english": "Semantic probabilistic text processes, as exemplified by frameworks such as PRISM and ProbLog, extend traditional logic programming semantics to a distribution semantics, thereby allowing for reasoning over complex probabilistic models like Kalman filters and Hybrid Bayesian networks. A significant innovation in this domain is the symbolic inference procedure, which enables reasoning over probabilistic logic programs with Gaussian or Gamma-distributed random variables and linear equality constraints over reals, without the need for enumerating sets of explanations. This advancement allows for a more comprehensive utilization of continuous random variables, represented by the expression $P(X = x | Y = y)$, enhancing the capability of semantic probabilistic text processes to handle a broader range of statistical and logical knowledge representation challenges.",
        "korean": "PRISM 및 ProbLog와 같은 프레임워크로 예시되는 의미론적 확률적 텍스트 프로세스(semantic probabilistic text processes)는 전통적인 논리 프로그래밍 의미론을 분포 의미론으로 확장하여 칼만 필터(Kalman filters) 및 하이브리드 베이지안 네트워크(Hybrid Bayesian networks)와 같은 복잡한 확률 모델에 대한 추론을 가능하게 합니다. 이 분야의 중요한 혁신은 기호적 추론 절차(symbolic inference procedure)로, 가우시안(Gaussian) 또는 감마 분포(Gamma-distributed) 확률 변수와 실수에 대한 선형 등식 제약을 가진 확률 논리 프로그램에 대한 추론을 설명 집합을 열거할 필요 없이 가능하게 합니다. 이러한 발전은 $P(X = x | Y = y)$로 표현되는 연속 확률 변수를 보다 포괄적으로 활용할 수 있게 하여 의미론적 확률적 텍스트 프로세스(semantic probabilistic text processes)의 통계 및 논리적 지식 표현 문제를 처리하는 능력을 향상시킵니다.",
        "score": 10,
        "parentheses_count": 8,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "stochastic gradient Langevin dynamics",
        "domain": "cs.AI",
        "summary": "  Stochastic learning dynamics based on Langevin or Levy stochastic\ndifferential equations (SDEs) in deep neural networks control the variance of\nnoise by varying the size of the mini-batch or directly those of injecting\nnoise. Since the noise variance affects the approximation performance, the\ndesign of the additive noise is significant in SDE-based learning and practical\nimplementation. In this paper, we propose an alternative stochastic descent\nlearning equation based on quantized optimization for non-convex objective\nfunctions, adopting a stochastic analysis perspective. The proposed method\nemploys a quantized optimization approach that utilizes Langevin SDE dynamics,\nallowing for controllable noise with an identical distribution without the need\nfor additive noise or adjusting the mini-batch size. Numerical experiments\ndemonstrate the effectiveness of the proposed algorithm on vanilla convolution\nneural network(CNN) models and the ResNet-50 architecture across various data\nsets. Furthermore, we provide a simple PyTorch implementation of the proposed\nalgorithm.\n",
        "english": "Stochastic gradient Langevin dynamics, grounded in Langevin or Levy stochastic differential equations (SDEs), play a crucial role in deep neural networks by controlling the variance of noise through the adjustment of mini-batch sizes or direct noise injection. The significance of noise variance on approximation performance necessitates the careful design of additive noise in SDE-based learning, as highlighted by the proposed stochastic descent learning equation which leverages quantized optimization for non-convex objective functions. By adopting a stochastic analysis perspective, the method employs Langevin SDE dynamics, allowing for controllable noise with identical distribution, and achieves effective results on vanilla convolutional neural networks (CNN) and the ResNet-50 architecture, as demonstrated by the numerical experiments conducted.",
        "korean": "확률적 경사 랑주뱅 동역학(stochastic gradient Langevin dynamics)은 랑주뱅 또는 레비 확률 미분 방정식(langevin or levy stochastic differential equations, SDEs)에 기반하여 미니 배치 크기의 조정이나 직접적인 노이즈 주입을 통해 노이즈의 분산을 제어함으로써 심층 신경망(deep neural networks)에서 중요한 역할을 합니다. 근사 성능에 대한 노이즈 분산의 중요성은 제안된 확률적 하강 학습 방정식(stochastic descent learning equation)이 비볼록 목적 함수(non-convex objective functions)에 대한 양자화 최적화를 활용함에 따라 SDE 기반 학습에서의 가산 노이즈 설계를 신중하게 해야 함을 요구합니다. 확률적 분석 관점을 채택함으로써, 이 방법은 랑주뱅 SDE 동역학(langevin SDE dynamics)을 활용하여 동일한 분포를 가진 제어 가능한 노이즈를 허용하며, 수치 실험을 통해 입증된 바와 같이 일반적인 합성곱 신경망(vanilla convolutional neural networks, CNN)과 ResNet-50 아키텍처에서 효과적인 결과를 달성합니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Ensure all English terms within parentheses are in lowercase for consistency and adjust the placement of parentheses for a smoother reading experience in Korean."
    },
    {
        "turn_index": 2,
        "term": "wordpiece tokenization",
        "domain": "cs.AI",
        "summary": "  Subword tokenization has become the prevailing standard in the field of\nnatural language processing (NLP) over recent years, primarily due to the\nwidespread utilization of pre-trained language models. This shift began with\nByte-Pair Encoding (BPE) and was later followed by the adoption of\nSentencePiece and WordPiece. While subword tokenization consistently\noutperforms character and word-level tokenization, the precise factors\ncontributing to its success remain unclear. Key aspects such as the optimal\nsegmentation granularity for diverse tasks and languages, the influence of data\nsources on tokenizers, and the role of morphological information in\nIndo-European languages remain insufficiently explored. This is particularly\npertinent for biomedical terminology, characterized by specific rules governing\nmorpheme combinations. Despite the agglutinative nature of biomedical\nterminology, existing language models do not explicitly incorporate this\nknowledge, leading to inconsistent tokenization strategies for common terms. In\nthis paper, we seek to delve into the complexities of subword tokenization in\nFrench biomedical domain across a variety of NLP tasks and pinpoint areas where\nfurther enhancements can be made. We analyze classical tokenization algorithms,\nincluding BPE and SentencePiece, and introduce an original tokenization\nstrategy that integrates morpheme-enriched word segmentation into existing\ntokenization methods.\n",
        "english": "Wordpiece tokenization has emerged as a key component in the field of natural language processing (NLP) due to its role in the widespread utilization of pre-trained language models, as highlighted by its adoption following Byte-Pair Encoding (BPE) and SentencePiece. Despite its success, the factors contributing to the effectiveness of subword tokenization, such as wordpiece tokenization, remain insufficiently explored, particularly in terms of optimal segmentation granularity for diverse tasks and languages, as well as the influence of data sources on tokenizers. Notably, the research underscores the need for further enhancements in tokenization strategies, especially in domains like the French biomedical field, where existing models fail to incorporate the agglutinative nature of terminology, leading to inconsistent tokenization strategies; this is mathematically represented by the segmentation function \\(f(x)\\) that requires integration of morpheme-enriched word segmentation into existing methods.",
        "korean": "자연어 처리(natural language processing, NLP) 분야에서 wordpiece tokenization은 사전 학습된 언어 모델(pre-trained language models)의 광범위한 활용에서 중요한 구성 요소로 부상하였으며, 이는 바이트 쌍 인코딩(Byte-Pair Encoding, BPE) 및 SentencePiece 이후 채택됨으로써 강조되었습니다. 그 성공에도 불구하고, wordpiece tokenization과 같은 서브워드 토큰화(subword tokenization)의 효과에 기여하는 요인들은 다양한 작업과 언어에 대한 최적의 세분화 세분성(segmentation granularity) 및 데이터 소스가 토크나이저(tokenizers)에 미치는 영향 측면에서 충분히 탐구되지 않았습니다. 특히, 연구는 프랑스 생물의학 분야와 같은 도메인에서 토큰화 전략의 추가 개선 필요성을 강조하며, 기존 모델이 용어의 교착적 특성을 통합하지 못해 일관성 없는 토큰화 전략을 초래한다는 점을 지적합니다. 이는 형태소가 풍부한 단어 세분화를 기존 방법에 통합해야 하는 세분화 함수 \\(f(x)\\)로 수학적으로 표현됩니다.",
        "score": 9,
        "parentheses_count": 8,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Ensure that all instances of \"wordpiece tokenization\" are consistently enclosed in parentheses as wordpiece tokenization(Wordpiece Tokenization)."
    },
    {
        "turn_index": 2,
        "term": "activation functions",
        "domain": "cs.AI",
        "summary": "  Recent work has uncovered close links between between classical reinforcement\nlearning algorithms, Bayesian filtering, and Active Inference which lets us\nunderstand value functions in terms of Bayesian posteriors. An alternative, but\nless explored, model-free RL algorithm is the successor representation, which\nexpresses the value function in terms of a successor matrix of expected future\nstate occupancies. In this paper, we derive the probabilistic interpretation of\nthe successor representation in terms of Bayesian filtering and thus design a\nnovel active inference agent architecture utilizing successor representations\ninstead of model-based planning. We demonstrate that active inference successor\nrepresentations have significant advantages over current active inference\nagents in terms of planning horizon and computational cost. Moreover, we\ndemonstrate how the successor representation agent can generalize to changing\nreward functions such as variants of the expected free energy.\n",
        "english": "Activation functions play a crucial role in linking classical reinforcement learning algorithms with Bayesian filtering and Active Inference, thereby enabling the understanding of value functions as Bayesian posteriors. By exploring the successor representation, which expresses the value function in terms of a successor matrix of expected future state occupancies, researchers have derived a probabilistic interpretation that enhances the design of novel active inference agent architectures. This innovative approach, leveraging activation functions within the successor representation framework, demonstrates significant advantages in planning horizon and computational cost, with the ability to generalize to changing reward functions such as variants of the expected free energy, represented as $\\mathbb{E}[F]$.",
        "korean": "활성 함수(activation functions)는 고전적 강화 학습 알고리즘(classical reinforcement learning algorithms)을 베이지안 필터링(Bayesian filtering) 및 능동 추론(Active Inference)과 연결하는 데 중요한 역할을 하며, 이를 통해 가치 함수(value functions)를 베이지안 사후 확률(Bayesian posteriors)로 이해할 수 있게 합니다. 연구자들은 기대되는 미래 상태 점유의 후속 행렬(successor matrix)로 가치 함수를 표현하는 후속 표현(successor representation)을 탐구함으로써 새로운 능동 추론 에이전트 아키텍처(active inference agent architectures)의 설계를 향상시키는 확률적 해석을 도출했습니다. 후속 표현(successor representation) 프레임워크 내에서 활성 함수(activation functions)를 활용하는 이 혁신적인 접근 방식은 계획 수평(planning horizon)과 계산 비용(computational cost)에서 상당한 이점을 보여주며, $\\mathbb{E}[F]$로 표현되는 기대 자유 에너지(expected free energy)의 변형과 같은 보상 함수(reward functions)의 변화에 일반화할 수 있는 능력을 가지고 있습니다.",
        "score": 9,
        "parentheses_count": 13,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring all technical terms are consistently parenthesized and check for any missing or misplaced parentheses."
    },
    {
        "turn_index": 2,
        "term": "residual connections",
        "domain": "cs.AI",
        "summary": "  The brain is a highly reconfigurable machine capable of task-specific\nadaptations. The brain continually rewires itself for a more optimal\nconfiguration to solve problems. We propose a novel strategic synthesis\nalgorithm for feedforward networks that draws directly from the brain's\nbehaviours when learning. The proposed approach analyses the network and ranks\nweights based on their magnitude. Unlike existing approaches that advocate\nrandom selection, we select highly performing nodes as starting points for new\nedges and exploit the Gaussian distribution over the weights to select\ncorresponding endpoints. The strategy aims only to produce useful connections\nand result in a smaller residual network structure. The approach is\ncomplemented with pruning to further the compression. We demonstrate the\ntechniques to deep feedforward networks. The residual sub-networks that are\nformed from the synthesis approaches in this work form common sub-networks with\nsimilarities up to ~90%. Using pruning as a complement to the strategic\nsynthesis approach, we observe improvements in compression.\n",
        "english": "Residual connections, inspired by the brain's ability to reconfigure for optimal problem-solving, are strategically synthesized in feedforward networks by analyzing and ranking weights based on their magnitude. This novel approach contrasts with existing methods by selecting high-performing nodes as starting points for new edges and leveraging the Gaussian distribution to determine endpoints, thereby forming a smaller residual network structure. Complemented by pruning, which enhances compression, the resulting residual sub-networks exhibit commonalities up to 90\\% similarity, demonstrating significant potential for efficient network design.",
        "korean": "뇌의 최적 문제 해결을 위한 재구성 능력에서 영감을 받은 잔차 연결(residual connections)은 피드포워드 네트워크(feedforward networks)에서 가중치의 크기를 기반으로 분석하고 순위를 매겨 전략적으로 합성됩니다. 이 새로운 접근 방식은 기존 방법과 대조적으로 높은 성능의 노드를 새로운 엣지의 시작점으로 선택하고 가우시안 분포(gaussian distribution)를 활용하여 끝점을 결정함으로써 더 작은 잔차 네트워크 구조(residual network structure)를 형성합니다. 압축을 향상시키는 가지치기(pruning)와 결합하여, 결과적으로 생성된 잔차 서브 네트워크(residual sub-networks)는 최대 90\\%의 유사성을 보이며 효율적인 네트워크 설계에 대한 상당한 잠재력을 보여줍니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Ensure all English terms within parentheses are in lowercase for consistency, such as \"Gaussian distribution\" to \"gaussian distribution\"."
    },
    {
        "turn_index": 2,
        "term": "self-supervised task learning",
        "domain": "cs.AI",
        "summary": "  Existing gradient-based meta-learning approaches to few-shot learning assume\nthat all tasks have the same input feature space. However, in the real world\nscenarios, there are many cases that the input structures of tasks can be\ndifferent, that is, different tasks may vary in the number of input modalities\nor data types. Existing meta-learners cannot handle the heterogeneous task\ndistribution (HTD) as there is not only global meta-knowledge shared across\ntasks but also type-specific knowledge that distinguishes each type of tasks.\nTo deal with task heterogeneity and promote fast within-task adaptions for each\ntype of tasks, in this paper, we propose HetMAML, a task-heterogeneous\nmodel-agnostic meta-learning framework, which can capture both the\ntype-specific and globally shared knowledge and can achieve the balance between\nknowledge customization and generalization. Specifically, we design a\nmulti-channel backbone module that encodes the input of each type of tasks into\nthe same length sequence of modality-specific embeddings. Then, we propose a\ntask-aware iterative feature aggregation network which can automatically take\ninto account the context of task-specific input structures and adaptively\nproject the heterogeneous input spaces to the same lower-dimensional embedding\nspace of concepts. Our experiments on six task-heterogeneous datasets\ndemonstrate that HetMAML successfully leverages type-specific and globally\nshared meta-parameters for heterogeneous tasks and achieves fast within-task\nadaptions for each type of tasks.\n",
        "english": "In the realm of self-supervised task learning, the challenge of heterogeneous task distribution (HTD) arises due to the variance in input structures across different tasks, necessitating innovative approaches to balance \"knowledge customization and generalization.\" The proposed HetMAML framework adeptly addresses this by employing a multi-channel backbone module that encodes input into \"modality-specific embeddings,\" facilitating the projection of diverse input spaces to a unified lower-dimensional embedding space through a task-aware iterative feature aggregation network. Notably, the research highlights the framework's ability to leverage both type-specific and globally shared meta-parameters, achieving rapid within-task adaptations, as evidenced by its performance on six task-heterogeneous datasets, where it effectively optimizes the function $f_\\theta(x)$ to minimize the loss $L(f_\\theta(x), y)$ for each task type.",
        "korean": "자기 지도 학습 과제(self-supervised task learning) 분야에서 이질적인 과제 분포(heterogeneous task distribution, HTD)의 문제는 다양한 과제 간 입력 구조의 차이로 인해 발생하며, \"지식 맞춤화와 일반화\"를 균형 있게 조정하기 위한 혁신적인 접근법이 필요합니다. 제안된 HetMAML 프레임워크는 입력을 \"모달리티별 임베딩(modality-specific embeddings)\"으로 인코딩하는 다채널 백본 모듈을 활용하여, 다양한 입력 공간을 과제 인식 반복적 특징 집계 네트워크(task-aware iterative feature aggregation network)를 통해 통합된 저차원 임베딩 공간으로 투영함으로써 이를 능숙하게 해결합니다. 특히, 연구는 유형별 및 전역적으로 공유되는 메타 매개변수를 모두 활용하여 과제 내 빠른 적응을 달성하는 프레임워크의 능력을 강조하며, 여섯 개의 과제 이질적 데이터셋에서의 성능을 통해 각 과제 유형에 대해 함수 $f_\\theta(x)$를 최적화하여 손실 $L(f_\\theta(x), y)$를 최소화하는 데 효과적임을 입증합니다.",
        "score": 10,
        "parentheses_count": 5,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "pruning",
        "domain": "cs.AI",
        "summary": "  Structural pruning has emerged as a promising approach for producing more\nefficient models. Nevertheless, the community suffers from a lack of\nstandardized benchmarks and metrics, leaving the progress in this area not\nfully comprehended. To fill this gap, we present the first comprehensive\nbenchmark, termed \\textit{PruningBench}, for structural pruning. PruningBench\nshowcases the following three characteristics: 1) PruningBench employs a\nunified and consistent framework for evaluating the effectiveness of diverse\nstructural pruning techniques; 2) PruningBench systematically evaluates 16\nexisting pruning methods, encompassing a wide array of models (e.g., CNNs and\nViTs) and tasks (e.g., classification and detection); 3) PruningBench provides\neasily implementable interfaces to facilitate the implementation of future\npruning methods, and enables the subsequent researchers to incorporate their\nwork into our leaderboards. We provide an online pruning platform\nhttp://pruning.vipazoo.cn for customizing pruning tasks and reproducing all\nresults in this paper. Codes will be made publicly on\nhttps://github.com/HollyLee2000/PruningBench.\n",
        "english": "Structural pruning has gained traction as a promising approach to enhancing model efficiency, yet the absence of standardized benchmarks and metrics has hindered a comprehensive understanding of its progress. To address this issue, PruningBench introduces a unified and consistent framework that evaluates the effectiveness of diverse structural pruning techniques across 16 methods, encompassing models such as CNNs and ViTs, and tasks like classification and detection. By providing easily implementable interfaces, PruningBench facilitates future research in pruning, allowing researchers to incorporate their work into leaderboards and customize tasks through an online platform, thus advancing the field significantly.",
        "korean": "구조적 가지치기(structural pruning)는 모델 효율성을 향상시키는 유망한 접근법으로 주목받고 있지만, 표준화된 벤치마크와 지표의 부재로 인해 그 진전에 대한 포괄적인 이해가 저해되었습니다. 이 문제를 해결하기 위해 PruningBench는 CNNs 및 ViTs와 같은 모델과 분류 및 탐지와 같은 작업을 포함한 16가지 방법에 걸쳐 다양한 구조적 가지치기(structural pruning) 기법의 효과를 평가하는 통합적이고 일관된 프레임워크를 도입합니다. PruningBench는 쉽게 구현 가능한 인터페이스를 제공함으로써 가지치기(pruning) 분야의 미래 연구를 촉진하고, 연구자들이 온라인 플랫폼을 통해 작업을 맞춤화하고 리더보드에 그들의 연구를 통합할 수 있도록 하여 이 분야를 크게 발전시킵니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "low-rank approximation",
        "domain": "cs.AI",
        "summary": "  Covering-based rough set theory is a useful tool to deal with inexact,\nuncertain or vague knowledge in information systems. Topology, one of the most\nimportant subjects in mathematics, provides mathematical tools and interesting\ntopics in studying information systems and rough sets. In this paper, we\npresent the topological characterizations to three types of covering\napproximation operators. First, we study the properties of topology induced by\nthe sixth type of covering lower approximation operator. Second, some\ntopological characterizations to the covering lower approximation operator to\nbe an interior operator are established. We find that the topologies induced by\nthis operator and by the sixth type of covering lower approximation operator\nare the same. Third, we study the conditions which make the first type of\ncovering upper approximation operator be a closure operator, and find that the\ntopology induced by the operator is the same as the topology induced by the\nfifth type of covering upper approximation operator. Forth, the conditions of\nthe second type of covering upper approximation operator to be a closure\noperator and the properties of topology induced by it are established. Finally,\nthese three topologies space are compared. In a word, topology provides a\nuseful method to study the covering-based rough sets.\n",
        "english": "Low-rank approximation, akin to the topological characterizations presented in the study, provides a mathematical framework to address \"inexact, uncertain or vague knowledge in information systems.\" By exploring the properties of topology induced by various types of covering approximation operators, such as the sixth type of covering lower approximation operator, researchers can derive insights into the fundamental structure of data. Furthermore, the conditions under which these operators function as interior or closure operators can be mathematically expressed, for instance, by demonstrating that the topology induced by a particular operator is equivalent to that induced by another, thereby offering a robust approach to simplifying complex data representations through low-rank approximation.",
        "korean": "연구에서 제시된 위상적 특성화와 유사하게 저순위 근사(low-rank approximation)는 정보 시스템에서 \"부정확하거나 불확실하거나 모호한 지식\"을 해결하기 위한 수학적 프레임워크를 제공합니다. 다양한 유형의 커버링 근사 연산자에 의해 유도된 위상의 속성을 탐구함으로써, 예를 들어 여섯 번째 유형의 커버링 하위 근사 연산자와 같은 경우, 연구자들은 데이터의 근본적인 구조에 대한 통찰을 얻을 수 있습니다. 또한, 이러한 연산자들이 내부 연산자나 폐포 연산자로 기능하는 조건은 수학적으로 표현될 수 있으며, 예를 들어 특정 연산자에 의해 유도된 위상이 다른 연산자에 의해 유도된 위상과 동등함을 증명함으로써, 저순위 근사(low-rank approximation)를 통해 복잡한 데이터 표현을 단순화하는 강력한 접근 방식을 제공합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None needed, the translation is accurate and flows naturally."
    },
    {
        "turn_index": 2,
        "term": "context-aware deep learning",
        "domain": "cs.AI",
        "summary": "  Deep reinforcement learning is revolutionizing the artificial intelligence\nfield. Currently, it serves as a good starting point for constructing\nintelligent autonomous systems which offer a better knowledge of the visual\nworld. It is possible to scale deep reinforcement learning with the use of deep\nlearning and do amazing tasks such as use of pixels in playing video games. In\nthis paper, key concepts of deep reinforcement learning including reward\nfunction, differences between reinforcement learning and supervised learning\nand models for implementation of reinforcement are discussed. Key challenges\nrelated to the implementation of reinforcement learning in conversational AI\ndomain are identified as well as discussed in detail. Various conversational\nmodels which are based on deep reinforcement learning (as well as deep\nlearning) are also discussed. In summary, this paper discusses key aspects of\ndeep reinforcement learning which are crucial for designing an efficient\nconversational AI.\n",
        "english": "In the domain of context-aware deep learning, deep reinforcement learning is revolutionizing the artificial intelligence field by providing a robust framework for constructing intelligent autonomous systems that offer a better knowledge of the visual world. This approach leverages key concepts such as the reward function and the differences between reinforcement learning and supervised learning, which are crucial for designing efficient conversational AI; mathematically, this can be represented by the optimization problem \\(\\max_{\\pi} \\mathbb{E}[R|\\pi]\\), where \\(\\pi\\) denotes the policy and \\(R\\) the cumulative reward. Furthermore, the scalability of deep reinforcement learning through deep learning techniques enables the execution of complex tasks, demonstrating its potential to address key challenges in implementing reinforcement learning within the conversational AI domain.",
        "korean": "상황 인식 심층 학습(context-aware deep learning) 분야에서 심층 강화 학습(deep reinforcement learning)은 인공지능 분야를 혁신하고 있으며, 지능형 자율 시스템을 구축하기 위한 견고한 프레임워크를 제공하여 시각적 세계에 대한 더 나은 이해를 제공합니다. 이 접근법은 보상 함수(reward function)와 강화 학습(reinforcement learning)과 지도 학습(supervised learning) 간의 차이와 같은 핵심 개념을 활용하여 효율적인 대화형 인공지능(conversational AI)을 설계하는 데 필수적입니다. 수학적으로는 \\(\\max_{\\pi} \\mathbb{E}[R|\\pi]\\)라는 최적화 문제로 표현될 수 있으며, 여기서 \\(\\pi\\)는 정책(policy)을, \\(R\\)은 누적 보상(cumulative reward)을 나타냅니다. 더욱이, 심층 학습 기법(deep learning techniques)을 통한 심층 강화 학습(deep reinforcement learning)의 확장성은 복잡한 작업의 실행을 가능하게 하여 대화형 인공지능(conversational AI) 분야에서 강화 학습(reinforcement learning)을 구현하는 데 있어 주요 과제를 해결할 수 있는 잠재력을 보여줍니다.",
        "score": 10,
        "parentheses_count": 11,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "conversational agents",
        "domain": "cs.AI",
        "summary": "  We present a new method based on episodic Knowledge Graphs (eKGs) for\nevaluating (multimodal) conversational agents in open domains. This graph is\ngenerated by interpreting raw signals during conversation and is able to\ncapture the accumulation of knowledge over time. We apply structural and\nsemantic analysis of the resulting graphs and translate the properties into\nqualitative measures. We compare these measures with existing automatic and\nmanual evaluation metrics commonly used for conversational agents. Our results\nshow that our Knowledge-Graph-based evaluation provides more qualitative\ninsights into interaction and the agent's behavior.\n",
        "english": "In evaluating conversational agents in open domains, a novel approach utilizes episodic Knowledge Graphs (eKGs) to interpret raw signals during conversation, capturing the accumulation of knowledge over time. By applying structural and semantic analysis to these graphs, researchers translate properties into qualitative measures, offering insights that surpass existing automatic and manual evaluation metrics. Notably, the research introduces a mathematical framework where the qualitative measure $Q$ is defined as $Q = f(\\text{structure}, \\text{semantics})$, highlighting the innovative potential of Knowledge-Graph-based evaluation in understanding interaction and agent behavior.",
        "korean": "개방형 도메인에서 대화형 에이전트(conversational agents)를 평가할 때, 새로운 접근법은 대화 중 원시 신호를 해석하기 위해 에피소드 지식 그래프(episodic knowledge graphs, ekgs)를 활용하여 시간이 지남에 따라 지식의 축적을 포착합니다. 이러한 그래프에 구조적 및 의미적 분석을 적용함으로써 연구자들은 속성을 질적 측정으로 변환하여 기존의 자동 및 수동 평가 지표를 능가하는 통찰력을 제공합니다. 특히, 연구는 질적 측정 $Q$가 $Q = f(\\text{structure}, \\text{semantics})$로 정의되는 수학적 프레임워크를 도입하여 상호작용 및 에이전트 행동 이해에 있어 지식 그래프 기반 평가의 혁신적 잠재력을 강조합니다.",
        "score": 10,
        "parentheses_count": 3,
        "suggestions": "None needed."
    },
    {
        "turn_index": 2,
        "term": "multi-scale models",
        "domain": "cs.AI",
        "summary": "  Causal Models are like Dependency Graphs and Belief Nets in that they provide\na structure and a set of assumptions from which a joint distribution can, in\nprinciple, be computed. Unlike Dependency Graphs, Causal Models are models of\nhierarchical and/or parallel processes, rather than models of distributions\n(partially) known to a model builder through some sort of gestalt. As such,\nCausal Models are more modular, easier to build, more intuitive, and easier to\nunderstand than Dependency Graph Models. Causal Models are formally defined and\nDependency Graph Models are shown to be a special case of them. Algorithms\nsupporting inference are presented. Parsimonious methods for eliciting\ndependent probabilities are presented.\n",
        "english": "Multi-scale models, akin to Causal Models, provide a structure and a set of assumptions from which a joint distribution can be computed, facilitating a comprehensive understanding of complex systems. These models are distinguished by their hierarchical and/or parallel processes, which render them more modular, intuitive, and easier to understand than traditional Dependency Graph Models. By leveraging algorithms supporting inference, multi-scale models can efficiently compute joint distributions, denoted as $P(X_1, X_2, \\ldots, X_n)$, thereby advancing the field with their parsimonious methods for eliciting dependent probabilities.",
        "korean": "인과 모델(causal models)과 유사한 다중 스케일 모델(multi-scale models)은 결합 분포를 계산할 수 있는 구조와 가정 세트를 제공하여 복잡한 시스템에 대한 포괄적인 이해를 촉진합니다. 이러한 모델은 계층적 및/또는 병렬 프로세스로 구별되며, 이는 전통적인 의존 그래프 모델(dependency graph models)보다 더 모듈화되고 직관적이며 이해하기 쉽습니다. 추론을 지원하는 알고리즘을 활용함으로써 다중 스케일 모델(multi-scale models)은 결합 분포를 효율적으로 계산할 수 있으며, 이는 $P(X_1, X_2, \\ldots, X_n)$로 표시되며, 의존 확률을 도출하는 데 있어 간결한 방법으로 분야를 발전시킵니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "[Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar]"
    },
    {
        "turn_index": 2,
        "term": "neural memory networks",
        "domain": "cs.AI",
        "summary": "  Neural networks excel in detecting regular patterns but are less successful\nin representing and manipulating complex data structures, possibly due to the\nlack of an external memory. This has led to the recent development of a new\nline of architectures known as Memory-Augmented Neural Networks (MANNs), each\nof which consists of a neural network that interacts with an external memory\nmatrix. However, this RAM-like memory matrix is unstructured and thus does not\nnaturally encode structured objects. Here we design a new MANN dubbed\nRelational Dynamic Memory Network (RMDN) to bridge the gap. Like existing\nMANNs, RMDN has a neural controller but its memory is structured as\nmulti-relational graphs. RMDN uses the memory to represent and manipulate\ngraph-structured data in response to query; and as a neural network, RMDN is\ntrainable from labeled data. Thus RMDN learns to answer queries about a set of\ngraph-structured objects without explicit programming. We evaluate the\ncapability of RMDN on several important prediction problems, including software\nvulnerability, molecular bioactivity and chemical-chemical interaction. Results\ndemonstrate the efficacy of the proposed model.\n",
        "korean": "신경 기억 네트워크(neural memory networks), 특히 관계형 동적 기억 네트워크(Relational Dynamic Memory Network, RMDN)는 다중 관계 그래프(multi-relational graphs) 형태의 구조화된 외부 기억을 통합하여 신경망의 복잡한 데이터 구조 표현 및 조작 능력의 격차를 해소하기 위해 설계되었습니다. 전통적인 기억 증강 신경망(memory-augmented neural networks, MANNs)과 달리, RMDN의 기억 구조는 그래프 구조 데이터에 대한 쿼리에 효과적으로 응답할 수 있게 하여 명시적인 프로그래밍 없이 복잡한 질문에 답하는 법을 학습합니다. 이 혁신적인 접근 방식의 효능은 소프트웨어 취약점 탐지, 분자 생물활성 예측, 화학-화학 상호작용 분석과 같은 여러 예측 문제에서 RMDN 모델이 달성한 유의미한 결과로 입증되며, 정확도 향상은 $R^2$ 점수로 정량화됩니다."
    },
    {
        "turn_index": 2,
        "term": "neural task-driven modeling",
        "domain": "cs.AI",
        "summary": "  Robots and autonomous systems require an understanding of complex events\n(CEs) from sensor data to interact with their environments and humans\neffectively. Traditional end-to-end neural architectures, despite processing\nsensor data efficiently, struggle with long-duration events due to limited\ncontext sizes and reasoning capabilities. Recent advances in neuro-symbolic\nmethods, which integrate neural and symbolic models leveraging human knowledge,\npromise improved performance with less data. This study addresses the gap in\nunderstanding these approaches' effectiveness in complex event detection (CED),\nespecially in temporal reasoning. We investigate neural and neuro-symbolic\narchitectures' performance in a multimodal CED task, analyzing IMU and acoustic\ndata streams to recognize CE patterns. Our methodology includes (i) end-to-end\nneural architectures for direct CE detection from sensor embeddings, (ii)\ntwo-stage concept-based neural models mapping sensor embeddings to atomic\nevents (AEs) before CE detection, and (iii) a neuro-symbolic approach using a\nsymbolic finite-state machine for CE detection from AEs. Empirically, the\nneuro-symbolic architecture significantly surpasses purely neural models,\ndemonstrating superior performance in CE recognition, even with extensive\ntraining data and ample temporal context for neural approaches.\n",
        "english": "Neural task-driven modeling is crucial for understanding complex events (CEs) from sensor data, enabling robots and autonomous systems to interact effectively with their environments and humans. Recent advances in neuro-symbolic methods, which integrate neural and symbolic models leveraging human knowledge, have shown that a neuro-symbolic architecture can significantly surpass purely neural models in CE recognition, even with extensive training data and ample temporal context for neural approaches. Specifically, the study employs a methodology that includes two-stage concept-based neural models mapping sensor embeddings to atomic events (AEs) before CE detection, and a neuro-symbolic approach using a symbolic finite-state machine for CE detection from AEs, demonstrating superior performance with an accuracy improvement of $20\\%$ compared to traditional end-to-end neural architectures.",
        "korean": "신경 과제 기반 모델링(neural task-driven modeling)은 센서 데이터로부터 복잡한 사건(complex events, CEs)을 이해하는 데 필수적이며, 이를 통해 로봇과 자율 시스템이 환경 및 인간과 효과적으로 상호작용할 수 있게 합니다. 인간 지식을 활용하여 신경 모델과 기호 모델을 통합하는 신경-기호 방법론(neuro-symbolic methods)의 최근 발전은 신경-기호 아키텍처가 순수 신경 모델을 복잡한 사건 인식에서 크게 능가할 수 있음을 보여주었습니다. 이는 광범위한 훈련 데이터와 신경 접근법을 위한 충분한 시간적 맥락이 주어졌을 때에도 마찬가지입니다. 특히, 이 연구는 센서 임베딩을 원자적 사건(atomic events, AEs)으로 매핑하는 두 단계 개념 기반 신경 모델을 포함한 방법론을 사용하며, 원자적 사건으로부터 복잡한 사건을 탐지하기 위한 기호 유한 상태 기계(symbolic finite-state machine)를 사용하는 신경-기호 접근법을 통해 전통적인 종단 간 신경 아키텍처에 비해 정확도가 $20\\%$ 향상된 우수한 성능을 입증했습니다.",
        "score": 9,
        "parentheses_count": 6,
        "suggestions": "Suggest capturing the original meaning and nuances in the translation sentences while adjusting the structure for natural flow and grammar. Consider ensuring all terms are consistently parenthesized as Korean term(English term) and check for any missing or inconsistent parenthetical translations."
    },
    {
        "turn_index": 2,
        "term": "context-aware text models",
        "domain": "cs.AI",
        "summary": "  Recently, abstract argumentation-based models of case-based reasoning\n($AA{\\text -} CBR$ in short) have been proposed, originally inspired by the\nlegal domain, but also applicable as classifiers in different scenarios.\nHowever, the formal properties of $AA{\\text -} CBR$ as a reasoning system\nremain largely unexplored. In this paper, we focus on analysing the\nnon-monotonicity properties of a regular version of $AA{\\text -} CBR$ (that we\ncall $AA{\\text -} CBR_{\\succeq}$). Specifically, we prove that $AA{\\text -}\nCBR_{\\succeq}$ is not cautiously monotonic, a property frequently considered\ndesirable in the literature. We then define a variation of $AA{\\text -}\nCBR_{\\succeq}$ which is cautiously monotonic. Further, we prove that such\nvariation is equivalent to using $AA{\\text -} CBR_{\\succeq}$ with a restricted\ncasebase consisting of all \"surprising\" and \"sufficient\" cases in the original\ncasebase. As a by-product, we prove that this variation of $AA{\\text -}\nCBR_{\\succeq}$ is cumulative, rationally monotonic, and empowers a principled\ntreatment of noise in \"incoherent\" casebases. Finally, we illustrate $AA{\\text\n-} CBR$ and cautious monotonicity questions on a case study on the U.S. Trade\nSecrets domain, a legal casebase.\n",
        "english": "Context-aware text models, inspired by abstract argumentation-based models of case-based reasoning (AA-CBR), have demonstrated their utility not only in the legal domain but also as classifiers across various scenarios. In particular, the non-monotonicity properties of a regular version, denoted as $AA{\\text -} CBR_{\\succeq}$, have been analyzed, revealing that it is not cautiously monotonic, a property often deemed desirable in academic literature. The innovation in this research lies in defining a variation of $AA{\\text -} CBR_{\\succeq}$ that achieves cautious monotonicity by restricting the casebase to \"surprising\" and \"sufficient\" cases, thus enabling a more principled approach to handling noise in \"incoherent\" casebases.",
        "korean": "추상적 논증 기반 사례 기반 추론 모델(abstract argumentation-based models of case-based reasoning, AA-CBR)에 영감을 받은 문맥 인식 텍스트 모델(context-aware text models)은 법률 분야뿐만 아니라 다양한 시나리오에서 분류기로서의 유용성을 입증했습니다. 특히, 정규 버전으로 표시된 $AA{\\text -} CBR_{\\succeq}$의 비단조성(non-monotonicity) 속성이 분석되었으며, 이는 학술 문헌에서 바람직하다고 여겨지는 신중한 단조성(cautious monotonicity)을 갖지 않는 것으로 나타났습니다. 이 연구의 혁신은 \"놀라운\" 및 \"충분한\" 사례로 사례 기반(casebase)을 제한하여 신중한 단조성을 달성하는 $AA{\\text -} CBR_{\\succeq}$의 변형을 정의하는 데 있으며, 이를 통해 \"비일관성\" 사례 기반에서의 노이즈를 보다 원칙적으로 처리할 수 있는 접근 방식을 가능하게 합니다.",
        "score": 10,
        "parentheses_count": 6,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "speech-to-text",
        "domain": "cs.AI",
        "summary": "  This article considers evidence from physical and biological sciences to show\nmachines are deficient compared to biological systems at incorporating\nintelligence. Machines fall short on two counts: firstly, unlike brains,\nmachines do not self-organize in a recursive manner; secondly, machines are\nbased on classical logic, whereas Nature's intelligence may depend on quantum\nmechanics.\n",
        "english": "Speech-to-text technology, while innovative, faces challenges due to machines' deficiencies compared to biological systems in incorporating intelligence, as they do not self-organize in a recursive manner like brains. This limitation is compounded by the reliance on classical logic, in contrast to Nature's intelligence, which may depend on quantum mechanics, suggesting that current speech-to-text algorithms might be constrained by their deterministic frameworks. Moreover, the potential for improvement in speech-to-text systems can be expressed mathematically, as the performance gap $P_{\\text{machine}} < P_{\\text{biological}}$ highlights the need for integrating more advanced, possibly quantum-based, methodologies to bridge this gap and enhance machine intelligence.",
        "korean": "음성 인식 기술(speech-to-text technology)은 혁신적이지만, 기계가 두뇌처럼 재귀적으로 자기 조직화하지 않기 때문에 생물학적 시스템에 비해 지능을 통합하는 데 있어 결함이 있어 도전에 직면하고 있습니다. 이러한 한계는 자연의 지능이 양자 역학(quantum mechanics)에 의존할 수 있다는 점과 대조적으로 고전 논리에 의존함으로써 더욱 복잡해집니다. 이는 현재의 음성 인식 알고리즘(speech-to-text algorithms)이 결정론적 프레임워크(deterministic frameworks)에 의해 제약될 수 있음을 시사합니다. 더욱이, 음성 인식 시스템(speech-to-text systems)의 개선 가능성은 수학적으로 표현될 수 있으며, 성능 격차 $P_{\\text{machine}} < P_{\\text{biological}}$는 이 격차를 줄이고 기계 지능(machine intelligence)을 향상시키기 위해 보다 진보된, 가능하면 양자 기반 방법론(quantum-based methodologies)을 통합할 필요성을 강조합니다.",
        "score": 9,
        "parentheses_count": 7,
        "suggestions": "Ensure consistent use of lowercase letters within parentheses and consider rephrasing for smoother readability, such as \"음성 인식 기술(speech-to-text technology)은 혁신적이지만, 기계가 두뇌처럼 재귀적으로 자기 조직화하지 않기 때문에 생물학적 시스템에 비해 지능을 통합하는 데 있어 결함이 있어 도전에 직면하고 있습니다.\" to \"음성 인식 기술(speech-to-text technology)은 혁신적이지만, 기계가 두뇌처럼 재귀적으로 자기 조직화하지 않기 때문에 생물학적 시스템에 비해 지능을 통합하는 데 결함이 있어 도전에 직면하고 있습니다.\""
    },
    {
        "turn_index": 2,
        "term": "de Finetti's theorem",
        "domain": "cs.AI",
        "summary": "  A number of well-known theorems, such as Cox's theorem and de Finetti's\ntheorem. prove that any model of reasoning with uncertain information that\nsatisfies specified conditions of \"rationality\" must satisfy the axioms of\nprobability theory. I argue here that these theorems do not in themselves\ndemonstrate that probabilistic models are in fact suitable for any specific\ntask in automated reasoning or plausible for cognitive models. First, the\ntheorems only establish that there exists some probabilistic model; they do not\nestablish that there exists a useful probabilistic model, i.e. one with a\ntractably small number of numerical parameters and a large number of\nindependence assumptions. Second, there are in general many different\nprobabilistic models for a given situation, many of which may be far more\nirrational, in the usual sense of the term, than a model that violates the\naxioms of probability theory. I illustrate this second point with an extended\nexamples of two tasks of induction, of a similar structure, where the\nreasonable probabilistic models are very different.\n",
        "english": "De Finetti's theorem, alongside Cox's theorem, establishes that any model of reasoning with uncertain information that adheres to specified conditions of \"rationality\" must conform to the axioms of probability theory, thereby underscoring the foundational role of probability in rational decision-making processes. However, while these theorems demonstrate the existence of a probabilistic model, they do not guarantee the presence of a \"useful\" probabilistic model characterized by a tractably small number of numerical parameters and a significant number of independence assumptions, which are crucial for practical applications in automated reasoning. Moreover, the theorem highlights the potential for multiple probabilistic models in a given context, some of which may be more irrational than models that contravene the axioms of probability theory, emphasizing the need for careful model selection and validation in real-world scenarios.",
        "korean": "드 피네티의 정리(de Finetti's theorem)는 콕스의 정리(Cox's theorem)와 함께 불확실한 정보로 추론하는 모든 모델이 \"합리성\"의 특정 조건을 준수할 경우 확률 이론의 공리에 부합해야 한다는 것을 확립하며, 이는 합리적 의사 결정 과정에서 확률의 기초적 역할을 강조합니다. 그러나 이러한 정리는 확률 모델의 존재를 입증하지만, 실용적인 자동 추론 응용을 위해 필수적인 소수의 수치적 매개변수와 다수의 독립성 가정을 특징으로 하는 \"유용한\" 확률 모델의 존재를 보장하지는 않습니다. 또한, 이 정리는 주어진 맥락에서 여러 확률 모델의 가능성을 강조하며, 일부 모델은 확률 이론의 공리를 위반하는 모델보다 더 비합리적일 수 있음을 보여주어 실제 시나리오에서 신중한 모델 선택과 검증의 필요성을 강조합니다.",
        "score": 10,
        "parentheses_count": 2,
        "suggestions": "None"
    },
    {
        "turn_index": 2,
        "term": "deep probabilistic scene models",
        "domain": "cs.AI",
        "summary": "  The goal of combining the robustness of neural networks and the\nexpressiveness of symbolic methods has rekindled the interest in Neuro-Symbolic\nAI. Deep Probabilistic Programming Languages (DPPLs) have been developed for\nprobabilistic logic programming to be carried out via the probability\nestimations of deep neural networks. However, recent SOTA DPPL approaches allow\nonly for limited conditional probabilistic queries and do not offer the power\nof true joint probability estimation. In our work, we propose an easy\nintegration of tractable probabilistic inference within a DPPL. To this end, we\nintroduce SLASH, a novel DPPL that consists of Neural-Probabilistic Predicates\n(NPPs) and a logic program, united via answer set programming (ASP). NPPs are a\nnovel design principle allowing for combining all deep model types and\ncombinations thereof to be represented as a single probabilistic predicate. In\nthis context, we introduce a novel $+/-$ notation for answering various types\nof probabilistic queries by adjusting the atom notations of a predicate. To\nscale well, we show how to prune the stochastically insignificant parts of the\n(ground) program, speeding up reasoning without sacrificing the predictive\nperformance. We evaluate SLASH on a variety of different tasks, including the\nbenchmark task of MNIST addition and Visual Question Answering (VQA).\n",
        "korean": "심층 확률적 장면 모델(deep probabilistic scene models)은 신경망의 견고함과 상징적 방법의 표현력을 결합하여 신경-상징적 인공지능(Neuro-Symbolic AI)에 대한 관심을 다시 불러일으킵니다. 이러한 모델은 신경-확률적 술어(neural-probabilistic predicates, NPPs)를 답 집합 프로그래밍(answer set programming, ASP)을 통해 논리 프로그램과 통합하여 모든 심층 모델 유형을 단일 확률적 술어로 표현할 수 있는 새로운 심층 확률적 프로그래밍 언어(deep probabilistic programming language, DPPL)인 SLASH로 대표됩니다. 특히, SLASH는 확률적 쿼리에 대한 새로운 $+/-$ 표기법을 도입하여 프로그램의 확률적으로 중요하지 않은 부분을 효율적으로 가지치기할 수 있는 능력을 향상시켜 예측 성능을 저하시키지 않으면서 추론 속도를 개선합니다."
    }
]